{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7fafe1-2bea-4046-9b37-6dc78b382acb",
   "metadata": {},
   "source": [
    "# ED LOS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f453c3-8724-4e53-8365-f9e526ee5924",
   "metadata": {},
   "source": [
    "## load dataset + packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0993543-ef50-4aad-9a2f-ac884adc295d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import te2rules\n",
    "import numpy as np\n",
    "from te2rules.explainer import ModelExplainer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19f6f95-9afa-4268-a713-16aa746cd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('df_master_imputed_iter_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e20c0-c7b2-4c28-846c-b12a44502bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886df3f6-fd90-4e4e-9065-3cef07e66f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4406b0-4365-4048-b942-c78bb2197c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of ED LOS in hours is: 6.402329931825367\n",
      "The std of ED LOS in hours is: 4.284560545043614\n"
     ]
    }
   ],
   "source": [
    "# ed_los_iter is the imputed outcome variable\n",
    "\n",
    "# Calculate the mean of ed_los in hours\n",
    "mean_ed_los_hours = df_master['ed_los_hours_iter'].mean()\n",
    "std_ed_los_hours = df_master['ed_los_hours_iter'].std()\n",
    "\n",
    "print(f'The mean of ED LOS in hours is: {mean_ed_los_hours}')\n",
    "print(f'The std of ED LOS in hours is: {std_ed_los_hours}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23cffcf-ce58-4d9d-ac1e-492864fb129e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of ED LOS in hours is: 6.439400452445864\n",
      "The std of ED LOS in hours is: 4.3320501376395075\n"
     ]
    }
   ],
   "source": [
    "#original ed los\n",
    "# Convert the ed_los column to timedelta\n",
    "df_master['ed_los'] = pd.to_timedelta(df_master['ed_los'])\n",
    "\n",
    "# Convert the timedelta to hours\n",
    "df_master['ed_los_hours'] = df_master['ed_los'].dt.total_seconds() / 3600\n",
    "\n",
    "# Calculate the mean of ed_los in hours\n",
    "mean_ed_los_hours = df_master['ed_los_hours'].mean()\n",
    "std_ed_los_hours = df_master['ed_los_hours'].std()\n",
    "\n",
    "print(f'The mean of ED LOS in hours is: {mean_ed_los_hours}')\n",
    "print(f'The std of ED LOS in hours is: {std_ed_los_hours}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234833b3-7136-420d-9476-c377cb51d957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_master['triage_acuity_iter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1772c2ad-cefe-477b-8816-35bf1c161c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  2.  4.  1.  5. -0.]\n"
     ]
    }
   ],
   "source": [
    "# Round off all the decimal values in the 'triage_acuity' column\n",
    "df_master['triage_acuity_iter'] = df_master['triage_acuity_iter'].round()\n",
    "\n",
    "# Check the unique values in the 'triage_acuity' column after rounding off\n",
    "unique_values_rounded = df_master['triage_acuity_iter'].unique()\n",
    "print(unique_values_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a883c3-85c5-42eb-bda7-3947f940eaac",
   "metadata": {},
   "source": [
    "## 4.5 hour Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9adddda4-f853-4b79-8a1d-e22aee6aa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS_category\n",
      "long     252029\n",
      "short    158898\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold for LOS classification\n",
    "threshold = 4.5  # Define your threshold value here (in hours)\n",
    "\n",
    "# Create a new binary variable indicating short or long stays\n",
    "df_master['LOS_category'] = df_master['ed_los_hours_iter'].apply(lambda x: 'short' if x <= threshold else 'long')\n",
    "\n",
    "# Optionally, encode the binary variable as 0s and 1s\n",
    "df_master['LOS_category_encoded'] = df_master['LOS_category'].map({'short': 0, 'long': 1})\n",
    "\n",
    "# Display the counts of each category\n",
    "print(df_master['LOS_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880bd5a3-bfd3-4fd6-9abb-a362db3c4651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train= df_master.sample(frac=0.8,random_state=10) #set seed\n",
    "df_test= df_master.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99a8607-0b6d-4b8d-9363-1d1086235301",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "671e8ea4-c7ab-497e-9800-7ae4be199d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>arrival_transport</th>\n",
       "      <th>disposition</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>dod</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>insurance</th>\n",
       "      <th>in_year</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome_inhospital_mortality</th>\n",
       "      <th>ed_los</th>\n",
       "      <th>intime_icu</th>\n",
       "      <th>time_to_icu_transfer</th>\n",
       "      <th>outcome_icu_transfer_12h</th>\n",
       "      <th>outcome_hospitalization</th>\n",
       "      <th>outcome_critical</th>\n",
       "      <th>n_ed_30d</th>\n",
       "      <th>n_ed_90d</th>\n",
       "      <th>n_ed_365d</th>\n",
       "      <th>next_ed_visit_time</th>\n",
       "      <th>next_ed_visit_time_diff</th>\n",
       "      <th>outcome_ed_revisit_3d</th>\n",
       "      <th>n_hosp_30d</th>\n",
       "      <th>n_hosp_90d</th>\n",
       "      <th>n_hosp_365d</th>\n",
       "      <th>n_icu_30d</th>\n",
       "      <th>n_icu_90d</th>\n",
       "      <th>n_icu_365d</th>\n",
       "      <th>ed_los_hours</th>\n",
       "      <th>time_to_icu_transfer_hours</th>\n",
       "      <th>next_ed_visit_time_diff_days</th>\n",
       "      <th>triage_temperature</th>\n",
       "      <th>triage_heartrate</th>\n",
       "      <th>triage_resprate</th>\n",
       "      <th>triage_o2sat</th>\n",
       "      <th>triage_sbp</th>\n",
       "      <th>triage_dbp</th>\n",
       "      <th>...</th>\n",
       "      <th>race_BLACK/AFRICAN</th>\n",
       "      <th>race_BLACK/AFRICAN AMERICAN</th>\n",
       "      <th>race_BLACK/CAPE VERDEAN</th>\n",
       "      <th>race_BLACK/CARIBBEAN ISLAND</th>\n",
       "      <th>race_HISPANIC OR LATINO</th>\n",
       "      <th>race_HISPANIC/LATINO - CENTRAL AMERICAN</th>\n",
       "      <th>race_HISPANIC/LATINO - COLUMBIAN</th>\n",
       "      <th>race_HISPANIC/LATINO - CUBAN</th>\n",
       "      <th>race_HISPANIC/LATINO - DOMINICAN</th>\n",
       "      <th>race_HISPANIC/LATINO - GUATEMALAN</th>\n",
       "      <th>race_HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>race_HISPANIC/LATINO - MEXICAN</th>\n",
       "      <th>race_HISPANIC/LATINO - PUERTO RICAN</th>\n",
       "      <th>race_HISPANIC/LATINO - SALVADORAN</th>\n",
       "      <th>race_MULTIPLE RACE/ETHNICITY</th>\n",
       "      <th>race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER</th>\n",
       "      <th>race_OTHER</th>\n",
       "      <th>race_PATIENT DECLINED TO ANSWER</th>\n",
       "      <th>race_PORTUGUESE</th>\n",
       "      <th>race_SOUTH AMERICAN</th>\n",
       "      <th>race_UNABLE TO OBTAIN</th>\n",
       "      <th>race_UNKNOWN</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_WHITE - BRAZILIAN</th>\n",
       "      <th>race_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>race_WHITE - OTHER EUROPEAN</th>\n",
       "      <th>race_WHITE - RUSSIAN</th>\n",
       "      <th>arrival_transport_AMBULANCE</th>\n",
       "      <th>arrival_transport_HELICOPTER</th>\n",
       "      <th>arrival_transport_OTHER</th>\n",
       "      <th>arrival_transport_UNKNOWN</th>\n",
       "      <th>arrival_transport_WALK IN</th>\n",
       "      <th>disposition_ADMITTED</th>\n",
       "      <th>disposition_ELOPED</th>\n",
       "      <th>disposition_EXPIRED</th>\n",
       "      <th>disposition_HOME</th>\n",
       "      <th>disposition_LEFT AGAINST MEDICAL ADVICE</th>\n",
       "      <th>disposition_LEFT WITHOUT BEING SEEN</th>\n",
       "      <th>disposition_OTHER</th>\n",
       "      <th>disposition_TRANSFER</th>\n",
       "      <th>insurance_Medicaid</th>\n",
       "      <th>insurance_Medicare</th>\n",
       "      <th>insurance_Other</th>\n",
       "      <th>disposition_encoded</th>\n",
       "      <th>arrival_transport_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "      <th>cci_score</th>\n",
       "      <th>eci_score</th>\n",
       "      <th>LOS_category</th>\n",
       "      <th>LOS_category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853.0</td>\n",
       "      <td>33258284</td>\n",
       "      <td>2180-05-06 19:17:00</td>\n",
       "      <td>2180-05-06 23:30:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-05-06 19:17:00</td>\n",
       "      <td>2180-05-06 23:30:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2180</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 04:13:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>50 days 16:24:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.216667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.68</td>\n",
       "      <td>36.888889</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357.0</td>\n",
       "      <td>38112554</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>2180-06-26 21:31:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>2180-06-26 18:27:00</td>\n",
       "      <td>2180-06-27 18:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>2180-06-26 21:31:00</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2180</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 05:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-07-22 16:24:00</td>\n",
       "      <td>25 days 18:53:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.79</td>\n",
       "      <td>37.166667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034.0</td>\n",
       "      <td>32952584</td>\n",
       "      <td>2180-07-22 16:24:00</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>HOME</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2180</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 13:30:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.555556</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034.0</td>\n",
       "      <td>39399961</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2180</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 08:06:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>13 days 06:58:00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.29</td>\n",
       "      <td>37.055556</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920.0</td>\n",
       "      <td>35968195</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>2180-08-06 01:44:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2180-09-09</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>2180-08-06 01:44:00</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2180</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 04:46:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.444444</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410922</th>\n",
       "      <td>425082</td>\n",
       "      <td>19999784</td>\n",
       "      <td>26194817.0</td>\n",
       "      <td>35692999</td>\n",
       "      <td>2119-06-18 14:21:00</td>\n",
       "      <td>2119-06-18 21:09:29</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>WALK IN</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>57</td>\n",
       "      <td>2119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2119-06-18 21:08:00</td>\n",
       "      <td>2119-07-02 14:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2119-06-18 14:21:00</td>\n",
       "      <td>2119-06-19 17:32:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2119</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 06:48:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2119-07-09 17:38:00</td>\n",
       "      <td>20 days 20:28:31</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.808056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.85</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410923</th>\n",
       "      <td>425080</td>\n",
       "      <td>19999784</td>\n",
       "      <td>24935234.0</td>\n",
       "      <td>37972930</td>\n",
       "      <td>2119-07-09 17:38:00</td>\n",
       "      <td>2119-07-10 00:04:00</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>WALK IN</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>57</td>\n",
       "      <td>2119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2119-07-09 22:31:00</td>\n",
       "      <td>2119-07-12 16:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2119-07-09 17:38:00</td>\n",
       "      <td>2119-07-10 00:04:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2119</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 06:26:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2119-08-11 09:15:00</td>\n",
       "      <td>32 days 09:11:00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.38</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410924</th>\n",
       "      <td>425081</td>\n",
       "      <td>19999784</td>\n",
       "      <td>25715748.0</td>\n",
       "      <td>34149746</td>\n",
       "      <td>2119-08-11 09:15:00</td>\n",
       "      <td>2119-08-11 13:40:00</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>WALK IN</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>57</td>\n",
       "      <td>2119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2119-08-11 11:36:00</td>\n",
       "      <td>2119-08-19 11:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2119-08-11 09:15:00</td>\n",
       "      <td>2119-08-11 13:40:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2119</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 04:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.111111</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410925</th>\n",
       "      <td>425083</td>\n",
       "      <td>19999828</td>\n",
       "      <td>25744818.0</td>\n",
       "      <td>32917002</td>\n",
       "      <td>2149-01-08 09:11:00</td>\n",
       "      <td>2149-01-08 18:12:00</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>46</td>\n",
       "      <td>2147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2149-01-08 16:44:00</td>\n",
       "      <td>2149-01-18 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2149-01-08 09:11:00</td>\n",
       "      <td>2149-01-08 18:12:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2149</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 09:01:00</td>\n",
       "      <td>2149-01-08 18:12:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.888889</td>\n",
       "      <td>112.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410926</th>\n",
       "      <td>425086</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745.0</td>\n",
       "      <td>34731548</td>\n",
       "      <td>2145-11-02 19:28:00</td>\n",
       "      <td>2145-11-02 22:59:00</td>\n",
       "      <td>F</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>AMBULANCE</td>\n",
       "      <td>ADMITTED</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2145-11-02 21:38:00</td>\n",
       "      <td>2145-11-11 12:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2145-11-02 19:28:00</td>\n",
       "      <td>2145-11-02 22:59:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>2145</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 03:31:00</td>\n",
       "      <td>2145-11-02 22:59:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410927 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  subject_id     hadm_id   stay_id               intime  \\\n",
       "0            0    10000032  22595853.0  33258284  2180-05-06 19:17:00   \n",
       "1            1    10000032  22841357.0  38112554  2180-06-26 15:54:00   \n",
       "2            3    10000032  29079034.0  32952584  2180-07-22 16:24:00   \n",
       "3            4    10000032  29079034.0  39399961  2180-07-23 05:54:00   \n",
       "4            2    10000032  25742920.0  35968195  2180-08-05 20:58:00   \n",
       "...        ...         ...         ...       ...                  ...   \n",
       "410922  425082    19999784  26194817.0  35692999  2119-06-18 14:21:00   \n",
       "410923  425080    19999784  24935234.0  37972930  2119-07-09 17:38:00   \n",
       "410924  425081    19999784  25715748.0  34149746  2119-08-11 09:15:00   \n",
       "410925  425083    19999828  25744818.0  32917002  2149-01-08 09:11:00   \n",
       "410926  425086    19999987  23865745.0  34731548  2145-11-02 19:28:00   \n",
       "\n",
       "                    outtime gender                    race arrival_transport  \\\n",
       "0       2180-05-06 23:30:00      F                   WHITE         AMBULANCE   \n",
       "1       2180-06-26 21:31:00      F                   WHITE         AMBULANCE   \n",
       "2       2180-07-23 05:54:00      F                   WHITE         AMBULANCE   \n",
       "3       2180-07-23 14:00:00      F                   WHITE         AMBULANCE   \n",
       "4       2180-08-06 01:44:00      F                   WHITE         AMBULANCE   \n",
       "...                     ...    ...                     ...               ...   \n",
       "410922  2119-06-18 21:09:29      M  BLACK/AFRICAN AMERICAN           WALK IN   \n",
       "410923  2119-07-10 00:04:00      M  BLACK/AFRICAN AMERICAN           WALK IN   \n",
       "410924  2119-08-11 13:40:00      M  BLACK/AFRICAN AMERICAN           WALK IN   \n",
       "410925  2149-01-08 18:12:00      F                   WHITE         AMBULANCE   \n",
       "410926  2145-11-02 22:59:00      F                 UNKNOWN         AMBULANCE   \n",
       "\n",
       "       disposition  anchor_age  anchor_year         dod            admittime  \\\n",
       "0         ADMITTED          52         2180  2180-09-09  2180-05-06 22:23:00   \n",
       "1         ADMITTED          52         2180  2180-09-09  2180-06-26 18:27:00   \n",
       "2             HOME          52         2180  2180-09-09  2180-07-23 12:35:00   \n",
       "3         ADMITTED          52         2180  2180-09-09  2180-07-23 12:35:00   \n",
       "4         ADMITTED          52         2180  2180-09-09  2180-08-05 23:44:00   \n",
       "...            ...         ...          ...         ...                  ...   \n",
       "410922    ADMITTED          57         2119         NaN  2119-06-18 21:08:00   \n",
       "410923    ADMITTED          57         2119         NaN  2119-07-09 22:31:00   \n",
       "410924    ADMITTED          57         2119         NaN  2119-08-11 11:36:00   \n",
       "410925    ADMITTED          46         2147         NaN  2149-01-08 16:44:00   \n",
       "410926    ADMITTED          57         2145         NaN  2145-11-02 21:38:00   \n",
       "\n",
       "                  dischtime deathtime               ethnicity  \\\n",
       "0       2180-05-07 17:15:00       NaN                   WHITE   \n",
       "1       2180-06-27 18:49:00       NaN                   WHITE   \n",
       "2       2180-07-25 17:55:00       NaN                   WHITE   \n",
       "3       2180-07-25 17:55:00       NaN                   WHITE   \n",
       "4       2180-08-07 17:50:00       NaN                   WHITE   \n",
       "...                     ...       ...                     ...   \n",
       "410922  2119-07-02 14:25:00       NaN  BLACK/AFRICAN AMERICAN   \n",
       "410923  2119-07-12 16:07:00       NaN  BLACK/AFRICAN AMERICAN   \n",
       "410924  2119-08-19 11:55:00       NaN  BLACK/AFRICAN AMERICAN   \n",
       "410925  2149-01-18 17:00:00       NaN                   WHITE   \n",
       "410926  2145-11-11 12:57:00       NaN                 UNKNOWN   \n",
       "\n",
       "                  edregtime            edouttime insurance  in_year  age  \\\n",
       "0       2180-05-06 19:17:00  2180-05-06 23:30:00     Other     2180   52   \n",
       "1       2180-06-26 15:54:00  2180-06-26 21:31:00  Medicaid     2180   52   \n",
       "2       2180-07-23 05:54:00  2180-07-23 14:00:00  Medicaid     2180   52   \n",
       "3       2180-07-23 05:54:00  2180-07-23 14:00:00  Medicaid     2180   52   \n",
       "4       2180-08-05 20:58:00  2180-08-06 01:44:00  Medicaid     2180   52   \n",
       "...                     ...                  ...       ...      ...  ...   \n",
       "410922  2119-06-18 14:21:00  2119-06-19 17:32:00     Other     2119   57   \n",
       "410923  2119-07-09 17:38:00  2119-07-10 00:04:00     Other     2119   57   \n",
       "410924  2119-08-11 09:15:00  2119-08-11 13:40:00     Other     2119   57   \n",
       "410925  2149-01-08 09:11:00  2149-01-08 18:12:00     Other     2149   48   \n",
       "410926  2145-11-02 19:28:00  2145-11-02 22:59:00     Other     2145   57   \n",
       "\n",
       "        outcome_inhospital_mortality          ed_los           intime_icu  \\\n",
       "0                              False 0 days 04:13:00                  NaN   \n",
       "1                              False 0 days 05:37:00                  NaN   \n",
       "2                              False 0 days 13:30:00  2180-07-23 14:00:00   \n",
       "3                              False 0 days 08:06:00  2180-07-23 14:00:00   \n",
       "4                              False 0 days 04:46:00                  NaN   \n",
       "...                              ...             ...                  ...   \n",
       "410922                         False 0 days 06:48:29                  NaN   \n",
       "410923                         False 0 days 06:26:00                  NaN   \n",
       "410924                         False 0 days 04:25:00                  NaN   \n",
       "410925                         False 0 days 09:01:00  2149-01-08 18:12:00   \n",
       "410926                         False 0 days 03:31:00  2145-11-02 22:59:00   \n",
       "\n",
       "       time_to_icu_transfer  outcome_icu_transfer_12h  \\\n",
       "0                       NaN                     False   \n",
       "1                       NaN                     False   \n",
       "2           0 days 08:06:00                      True   \n",
       "3           0 days 00:00:00                      True   \n",
       "4                       NaN                     False   \n",
       "...                     ...                       ...   \n",
       "410922                  NaN                     False   \n",
       "410923                  NaN                     False   \n",
       "410924                  NaN                     False   \n",
       "410925      0 days 00:00:00                      True   \n",
       "410926      0 days 00:00:00                      True   \n",
       "\n",
       "        outcome_hospitalization  outcome_critical  n_ed_30d  n_ed_90d  \\\n",
       "0                          True             False         0         0   \n",
       "1                          True             False         0         1   \n",
       "2                          True              True         1         2   \n",
       "3                          True              True         2         3   \n",
       "4                          True             False         2         3   \n",
       "...                         ...               ...       ...       ...   \n",
       "410922                     True             False         0         0   \n",
       "410923                     True             False         1         1   \n",
       "410924                     True             False         0         2   \n",
       "410925                     True              True         0         0   \n",
       "410926                     True              True         0         0   \n",
       "\n",
       "        n_ed_365d   next_ed_visit_time next_ed_visit_time_diff  \\\n",
       "0               0  2180-06-26 15:54:00        50 days 16:24:00   \n",
       "1               1  2180-07-22 16:24:00        25 days 18:53:00   \n",
       "2               2  2180-07-23 05:54:00         0 days 00:00:00   \n",
       "3               3  2180-08-05 20:58:00        13 days 06:58:00   \n",
       "4               4                  NaN                     NaN   \n",
       "...           ...                  ...                     ...   \n",
       "410922          0  2119-07-09 17:38:00        20 days 20:28:31   \n",
       "410923          1  2119-08-11 09:15:00        32 days 09:11:00   \n",
       "410924          2                  NaN                     NaN   \n",
       "410925          0                  NaN                     NaN   \n",
       "410926          0                  NaN                     NaN   \n",
       "\n",
       "        outcome_ed_revisit_3d  n_hosp_30d  n_hosp_90d  n_hosp_365d  n_icu_30d  \\\n",
       "0                       False           0           0            0          0   \n",
       "1                       False           0           1            1          0   \n",
       "2                        True           1           2            2          0   \n",
       "3                       False           1           2            2          0   \n",
       "4                       False           1           2            3          1   \n",
       "...                       ...         ...         ...          ...        ...   \n",
       "410922                  False           0           0            0          0   \n",
       "410923                  False           1           1            1          0   \n",
       "410924                  False           1           3            3          0   \n",
       "410925                  False           0           0            0          0   \n",
       "410926                  False           0           0            0          0   \n",
       "\n",
       "        n_icu_90d  n_icu_365d  ed_los_hours  time_to_icu_transfer_hours  \\\n",
       "0               0           0      4.216667                         NaN   \n",
       "1               0           0      5.616667                         NaN   \n",
       "2               0           0     13.500000                         8.1   \n",
       "3               0           0      8.100000                         0.0   \n",
       "4               1           1      4.766667                         NaN   \n",
       "...           ...         ...           ...                         ...   \n",
       "410922          0           0      6.808056                         NaN   \n",
       "410923          0           0      6.433333                         NaN   \n",
       "410924          0           0      4.416667                         NaN   \n",
       "410925          0           0      9.016667                         0.0   \n",
       "410926          0           0      3.516667                         0.0   \n",
       "\n",
       "        next_ed_visit_time_diff_days  triage_temperature  triage_heartrate  \\\n",
       "0                              50.68           36.888889              70.0   \n",
       "1                              25.79           37.166667              88.0   \n",
       "2                               0.00           36.555556              87.0   \n",
       "3                              13.29           37.055556              77.0   \n",
       "4                                NaN           37.444444             105.0   \n",
       "...                              ...                 ...               ...   \n",
       "410922                         20.85           37.000000              80.0   \n",
       "410923                         32.38           36.666667              91.0   \n",
       "410924                           NaN           37.111111              92.0   \n",
       "410925                           NaN           35.888889             112.0   \n",
       "410926                           NaN                 NaN               NaN   \n",
       "\n",
       "        triage_resprate  triage_o2sat  triage_sbp  triage_dbp  ...  \\\n",
       "0                  16.0          97.0       106.0        63.0  ...   \n",
       "1                  18.0          97.0       116.0        88.0  ...   \n",
       "2                  14.0          97.0        71.0        43.0  ...   \n",
       "3                  16.0          98.0        96.0        50.0  ...   \n",
       "4                  18.0          96.0       106.0        57.0  ...   \n",
       "...                 ...           ...         ...         ...  ...   \n",
       "410922             18.0         100.0       161.0       100.0  ...   \n",
       "410923             16.0          99.0       148.0        90.0  ...   \n",
       "410924             18.0         100.0       122.0        77.0  ...   \n",
       "410925             18.0         100.0       110.0        82.0  ...   \n",
       "410926              NaN           NaN         NaN         NaN  ...   \n",
       "\n",
       "        race_BLACK/AFRICAN  race_BLACK/AFRICAN AMERICAN  \\\n",
       "0                    False                        False   \n",
       "1                    False                        False   \n",
       "2                    False                        False   \n",
       "3                    False                        False   \n",
       "4                    False                        False   \n",
       "...                    ...                          ...   \n",
       "410922               False                         True   \n",
       "410923               False                         True   \n",
       "410924               False                         True   \n",
       "410925               False                        False   \n",
       "410926               False                        False   \n",
       "\n",
       "       race_BLACK/CAPE VERDEAN  race_BLACK/CARIBBEAN ISLAND  \\\n",
       "0                        False                        False   \n",
       "1                        False                        False   \n",
       "2                        False                        False   \n",
       "3                        False                        False   \n",
       "4                        False                        False   \n",
       "...                        ...                          ...   \n",
       "410922                   False                        False   \n",
       "410923                   False                        False   \n",
       "410924                   False                        False   \n",
       "410925                   False                        False   \n",
       "410926                   False                        False   \n",
       "\n",
       "        race_HISPANIC OR LATINO  race_HISPANIC/LATINO - CENTRAL AMERICAN  \\\n",
       "0                         False                                    False   \n",
       "1                         False                                    False   \n",
       "2                         False                                    False   \n",
       "3                         False                                    False   \n",
       "4                         False                                    False   \n",
       "...                         ...                                      ...   \n",
       "410922                    False                                    False   \n",
       "410923                    False                                    False   \n",
       "410924                    False                                    False   \n",
       "410925                    False                                    False   \n",
       "410926                    False                                    False   \n",
       "\n",
       "        race_HISPANIC/LATINO - COLUMBIAN  race_HISPANIC/LATINO - CUBAN  \\\n",
       "0                                  False                         False   \n",
       "1                                  False                         False   \n",
       "2                                  False                         False   \n",
       "3                                  False                         False   \n",
       "4                                  False                         False   \n",
       "...                                  ...                           ...   \n",
       "410922                             False                         False   \n",
       "410923                             False                         False   \n",
       "410924                             False                         False   \n",
       "410925                             False                         False   \n",
       "410926                             False                         False   \n",
       "\n",
       "        race_HISPANIC/LATINO - DOMINICAN  race_HISPANIC/LATINO - GUATEMALAN  \\\n",
       "0                                  False                              False   \n",
       "1                                  False                              False   \n",
       "2                                  False                              False   \n",
       "3                                  False                              False   \n",
       "4                                  False                              False   \n",
       "...                                  ...                                ...   \n",
       "410922                             False                              False   \n",
       "410923                             False                              False   \n",
       "410924                             False                              False   \n",
       "410925                             False                              False   \n",
       "410926                             False                              False   \n",
       "\n",
       "        race_HISPANIC/LATINO - HONDURAN  race_HISPANIC/LATINO - MEXICAN  \\\n",
       "0                                 False                           False   \n",
       "1                                 False                           False   \n",
       "2                                 False                           False   \n",
       "3                                 False                           False   \n",
       "4                                 False                           False   \n",
       "...                                 ...                             ...   \n",
       "410922                            False                           False   \n",
       "410923                            False                           False   \n",
       "410924                            False                           False   \n",
       "410925                            False                           False   \n",
       "410926                            False                           False   \n",
       "\n",
       "        race_HISPANIC/LATINO - PUERTO RICAN  \\\n",
       "0                                     False   \n",
       "1                                     False   \n",
       "2                                     False   \n",
       "3                                     False   \n",
       "4                                     False   \n",
       "...                                     ...   \n",
       "410922                                False   \n",
       "410923                                False   \n",
       "410924                                False   \n",
       "410925                                False   \n",
       "410926                                False   \n",
       "\n",
       "        race_HISPANIC/LATINO - SALVADORAN  race_MULTIPLE RACE/ETHNICITY  \\\n",
       "0                                   False                         False   \n",
       "1                                   False                         False   \n",
       "2                                   False                         False   \n",
       "3                                   False                         False   \n",
       "4                                   False                         False   \n",
       "...                                   ...                           ...   \n",
       "410922                              False                         False   \n",
       "410923                              False                         False   \n",
       "410924                              False                         False   \n",
       "410925                              False                         False   \n",
       "410926                              False                         False   \n",
       "\n",
       "        race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER  race_OTHER  \\\n",
       "0                                                False       False   \n",
       "1                                                False       False   \n",
       "2                                                False       False   \n",
       "3                                                False       False   \n",
       "4                                                False       False   \n",
       "...                                                ...         ...   \n",
       "410922                                           False       False   \n",
       "410923                                           False       False   \n",
       "410924                                           False       False   \n",
       "410925                                           False       False   \n",
       "410926                                           False       False   \n",
       "\n",
       "        race_PATIENT DECLINED TO ANSWER  race_PORTUGUESE  race_SOUTH AMERICAN  \\\n",
       "0                                 False            False                False   \n",
       "1                                 False            False                False   \n",
       "2                                 False            False                False   \n",
       "3                                 False            False                False   \n",
       "4                                 False            False                False   \n",
       "...                                 ...              ...                  ...   \n",
       "410922                            False            False                False   \n",
       "410923                            False            False                False   \n",
       "410924                            False            False                False   \n",
       "410925                            False            False                False   \n",
       "410926                            False            False                False   \n",
       "\n",
       "        race_UNABLE TO OBTAIN  race_UNKNOWN  race_WHITE  \\\n",
       "0                       False         False        True   \n",
       "1                       False         False        True   \n",
       "2                       False         False        True   \n",
       "3                       False         False        True   \n",
       "4                       False         False        True   \n",
       "...                       ...           ...         ...   \n",
       "410922                  False         False       False   \n",
       "410923                  False         False       False   \n",
       "410924                  False         False       False   \n",
       "410925                  False         False        True   \n",
       "410926                  False          True       False   \n",
       "\n",
       "        race_WHITE - BRAZILIAN  race_WHITE - EASTERN EUROPEAN  \\\n",
       "0                        False                          False   \n",
       "1                        False                          False   \n",
       "2                        False                          False   \n",
       "3                        False                          False   \n",
       "4                        False                          False   \n",
       "...                        ...                            ...   \n",
       "410922                   False                          False   \n",
       "410923                   False                          False   \n",
       "410924                   False                          False   \n",
       "410925                   False                          False   \n",
       "410926                   False                          False   \n",
       "\n",
       "        race_WHITE - OTHER EUROPEAN  race_WHITE - RUSSIAN  \\\n",
       "0                             False                 False   \n",
       "1                             False                 False   \n",
       "2                             False                 False   \n",
       "3                             False                 False   \n",
       "4                             False                 False   \n",
       "...                             ...                   ...   \n",
       "410922                        False                 False   \n",
       "410923                        False                 False   \n",
       "410924                        False                 False   \n",
       "410925                        False                 False   \n",
       "410926                        False                 False   \n",
       "\n",
       "        arrival_transport_AMBULANCE  arrival_transport_HELICOPTER  \\\n",
       "0                              True                         False   \n",
       "1                              True                         False   \n",
       "2                              True                         False   \n",
       "3                              True                         False   \n",
       "4                              True                         False   \n",
       "...                             ...                           ...   \n",
       "410922                        False                         False   \n",
       "410923                        False                         False   \n",
       "410924                        False                         False   \n",
       "410925                         True                         False   \n",
       "410926                         True                         False   \n",
       "\n",
       "        arrival_transport_OTHER  arrival_transport_UNKNOWN  \\\n",
       "0                         False                      False   \n",
       "1                         False                      False   \n",
       "2                         False                      False   \n",
       "3                         False                      False   \n",
       "4                         False                      False   \n",
       "...                         ...                        ...   \n",
       "410922                    False                      False   \n",
       "410923                    False                      False   \n",
       "410924                    False                      False   \n",
       "410925                    False                      False   \n",
       "410926                    False                      False   \n",
       "\n",
       "        arrival_transport_WALK IN  disposition_ADMITTED  disposition_ELOPED  \\\n",
       "0                           False                  True               False   \n",
       "1                           False                  True               False   \n",
       "2                           False                 False               False   \n",
       "3                           False                  True               False   \n",
       "4                           False                  True               False   \n",
       "...                           ...                   ...                 ...   \n",
       "410922                       True                  True               False   \n",
       "410923                       True                  True               False   \n",
       "410924                       True                  True               False   \n",
       "410925                      False                  True               False   \n",
       "410926                      False                  True               False   \n",
       "\n",
       "        disposition_EXPIRED  disposition_HOME  \\\n",
       "0                     False             False   \n",
       "1                     False             False   \n",
       "2                     False              True   \n",
       "3                     False             False   \n",
       "4                     False             False   \n",
       "...                     ...               ...   \n",
       "410922                False             False   \n",
       "410923                False             False   \n",
       "410924                False             False   \n",
       "410925                False             False   \n",
       "410926                False             False   \n",
       "\n",
       "        disposition_LEFT AGAINST MEDICAL ADVICE  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "...                                         ...   \n",
       "410922                                    False   \n",
       "410923                                    False   \n",
       "410924                                    False   \n",
       "410925                                    False   \n",
       "410926                                    False   \n",
       "\n",
       "        disposition_LEFT WITHOUT BEING SEEN  disposition_OTHER  \\\n",
       "0                                     False              False   \n",
       "1                                     False              False   \n",
       "2                                     False              False   \n",
       "3                                     False              False   \n",
       "4                                     False              False   \n",
       "...                                     ...                ...   \n",
       "410922                                False              False   \n",
       "410923                                False              False   \n",
       "410924                                False              False   \n",
       "410925                                False              False   \n",
       "410926                                False              False   \n",
       "\n",
       "        disposition_TRANSFER  insurance_Medicaid  insurance_Medicare  \\\n",
       "0                      False               False               False   \n",
       "1                      False                True               False   \n",
       "2                      False                True               False   \n",
       "3                      False                True               False   \n",
       "4                      False                True               False   \n",
       "...                      ...                 ...                 ...   \n",
       "410922                 False               False               False   \n",
       "410923                 False               False               False   \n",
       "410924                 False               False               False   \n",
       "410925                 False               False               False   \n",
       "410926                 False               False               False   \n",
       "\n",
       "        insurance_Other  disposition_encoded  arrival_transport_encoded  \\\n",
       "0                  True                    1                          1   \n",
       "1                 False                    1                          1   \n",
       "2                 False                    0                          1   \n",
       "3                 False                    1                          1   \n",
       "4                 False                    1                          1   \n",
       "...                 ...                  ...                        ...   \n",
       "410922             True                    1                          0   \n",
       "410923             True                    1                          0   \n",
       "410924             True                    1                          0   \n",
       "410925             True                    1                          1   \n",
       "410926             True                    1                          1   \n",
       "\n",
       "        race_encoded  cci_score  eci_score  LOS_category  LOS_category_encoded  \n",
       "0                  0          0          0         short                     0  \n",
       "1                  0          5          5          long                     1  \n",
       "2                  0          5          8          long                     1  \n",
       "3                  0          5          8          long                     1  \n",
       "4                  0          5          9          long                     1  \n",
       "...              ...        ...        ...           ...                   ...  \n",
       "410922             1          0          0          long                     1  \n",
       "410923             1          2          3          long                     1  \n",
       "410924             1          2          3         short                     0  \n",
       "410925             0          2          8          long                     1  \n",
       "410926             9          0          0         short                     0  \n",
       "\n",
       "[410927 rows x 198 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa4e352e-1b43-4cb7-9bb6-b194f81a1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#252033/410927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5faa490-7e13-4fd7-9b62-da9bbfff3088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = [\"age\", \"gender_encoded\",\"cci_score\",\"eci_score\",\n",
    "            \n",
    "            \"n_ed_30d\", \"n_ed_90d\", \"n_ed_365d\", \"n_hosp_30d\", \"n_hosp_90d\", \n",
    "            \"n_hosp_365d\", \"n_icu_30d\", \"n_icu_90d\", \"n_icu_365d\",\n",
    "            \n",
    "            \"triage_temperature_iter\", \"triage_heartrate_iter\", \"triage_resprate_iter\",\n",
    "            \"triage_o2sat_iter\", \"triage_sbp_iter\", \"triage_dbp_iter\", \"triage_pain_iter\", \n",
    "            \"triage_acuity_iter\",\n",
    "            \n",
    "            #\"ed_temperature_last_knn\",\"ed_heartrate_last_knn\",\"ed_resprate_last_knn\",\"ed_o2sat_last_knn\",\n",
    "            #\"ed_sbp_last_knn\",\"ed_dbp_last_knn\",\"ed_pain_last_knn\",\n",
    "            \n",
    "    'race_AMERICAN INDIAN/ALASKA NATIVE','race_ASIAN','race_ASIAN - ASIAN INDIAN','race_ASIAN - CHINESE',\n",
    "    'race_ASIAN - KOREAN','race_ASIAN - SOUTH EAST ASIAN','race_BLACK/AFRICAN','race_BLACK/AFRICAN AMERICAN',\n",
    "    'race_BLACK/CAPE VERDEAN','race_BLACK/CARIBBEAN ISLAND',\n",
    "    'race_HISPANIC OR LATINO','race_HISPANIC/LATINO - CENTRAL AMERICAN','race_HISPANIC/LATINO - COLUMBIAN',\n",
    "    'race_HISPANIC/LATINO - CUBAN','race_HISPANIC/LATINO - DOMINICAN','race_HISPANIC/LATINO - GUATEMALAN',\n",
    "    'race_HISPANIC/LATINO - HONDURAN','race_HISPANIC/LATINO - MEXICAN','race_HISPANIC/LATINO - PUERTO RICAN',\n",
    "    'race_HISPANIC/LATINO - SALVADORAN','race_MULTIPLE RACE/ETHNICITY','race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "    'race_OTHER','race_PATIENT DECLINED TO ANSWER','race_PORTUGUESE',\n",
    "    'race_SOUTH AMERICAN','race_UNABLE TO OBTAIN','race_UNKNOWN','race_WHITE','race_WHITE - BRAZILIAN',\n",
    "    'race_WHITE - EASTERN EUROPEAN','race_WHITE - OTHER EUROPEAN','race_WHITE - RUSSIAN',\n",
    "    'arrival_transport_AMBULANCE','arrival_transport_HELICOPTER','arrival_transport_OTHER','arrival_transport_UNKNOWN',\n",
    "    'arrival_transport_WALK IN',\n",
    "    'disposition_ADMITTED','disposition_ELOPED','disposition_EXPIRED',\n",
    "    'disposition_HOME','disposition_LEFT AGAINST MEDICAL ADVICE','disposition_LEFT WITHOUT BEING SEEN','disposition_OTHER',\n",
    "    'disposition_TRANSFER',\n",
    "\n",
    "\n",
    "            \n",
    "            \"chiefcom_chest_pain\", \"chiefcom_abdominal_pain\", \"chiefcom_headache\",\n",
    "            \"chiefcom_shortness_of_breath\", \"chiefcom_back_pain\", \"chiefcom_cough\", \n",
    "            \"chiefcom_nausea_vomiting\", \"chiefcom_fever_chills\", \"chiefcom_syncope\", \n",
    "            \"chiefcom_dizziness\", \n",
    "            \n",
    "            \"cci_MI\", \"cci_CHF\", \"cci_PVD\", \"cci_Stroke\", \"cci_Dementia\", \n",
    "            \"cci_Pulmonary\", \"cci_Rheumatic\", \"cci_PUD\", \"cci_Liver1\", \"cci_DM1\", \n",
    "            \"cci_DM2\", \"cci_Paralysis\", \"cci_Renal\", \"cci_Cancer1\", \"cci_Liver2\", \n",
    "            \"cci_Cancer2\", \"cci_HIV\", \n",
    "            \n",
    "            \"eci_Arrhythmia\", \"eci_Valvular\", \"eci_PHTN\",  \"eci_HTN1\", \"eci_HTN2\", \n",
    "            \"eci_NeuroOther\", \"eci_Hypothyroid\", \"eci_Lymphoma\", \"eci_Coagulopathy\", \n",
    "            \"eci_Obesity\", \"eci_WeightLoss\", \"eci_FluidsLytes\", \"eci_BloodLoss\",\n",
    "            \"eci_Anemia\", \"eci_Alcohol\", \"eci_Drugs\",\"eci_Psychoses\", \"eci_Depression\",\n",
    "            \"med_event\",'microbiology_event'\n",
    "           ]\n",
    "\n",
    "outcome = \"LOS_category_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5283fa38-d2b8-45de-bea9-79fa2b8bce67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train[variable]\n",
    "y_train = df_train[outcome]\n",
    "\n",
    "X_test = df_test[variable]\n",
    "y_test = df_test[outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b6593-6051-4599-97fe-ff4f13fedd95",
   "metadata": {},
   "source": [
    "### Random Forest (ALL VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3db5a483-bae1-4bab-b94f-4aa8332c35f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7125387844497171\n",
      "AUC Score: 0.7486823784117952\n",
      "Specificity: 0.48184568835098335\n",
      "Sensitivity: 0.8576015220881147\n",
      "F1 Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.56     31728\n",
      "           1       0.72      0.86      0.79     50457\n",
      "\n",
      "    accuracy                           0.71     82185\n",
      "   macro avg       0.70      0.67      0.67     82185\n",
      "weighted avg       0.71      0.71      0.70     82185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all variables\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 4: Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate Classifier\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate AUC Score\n",
    "auc_score = roc_auc_score(y_test, rf_classifier.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC Score:\", auc_score)\n",
    "\n",
    "# Calculate Specificity and Sensitivity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = classification_report(y_test, y_pred)\n",
    "print(\"F1 Score:\\n\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "467fe91a-b585-47c8-9132-64a2253cb02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.083850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>triage_sbp_iter</td>\n",
       "      <td>0.081646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>triage_heartrate_iter</td>\n",
       "      <td>0.080770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>triage_dbp_iter</td>\n",
       "      <td>0.079240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>triage_temperature_iter</td>\n",
       "      <td>0.075929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>race_HISPANIC/LATINO - CUBAN</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>race_MULTIPLE RACE/ETHNICITY</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>race_UNABLE TO OBTAIN</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>disposition_EXPIRED</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Feature  Importance\n",
       "0                                              age    0.083850\n",
       "17                                 triage_sbp_iter    0.081646\n",
       "14                           triage_heartrate_iter    0.080770\n",
       "18                                 triage_dbp_iter    0.079240\n",
       "13                         triage_temperature_iter    0.075929\n",
       "..                                             ...         ...\n",
       "34                    race_HISPANIC/LATINO - CUBAN    0.000413\n",
       "42  race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER    0.000341\n",
       "41                    race_MULTIPLE RACE/ETHNICITY    0.000224\n",
       "47                           race_UNABLE TO OBTAIN    0.000149\n",
       "61                             disposition_EXPIRED    0.000130\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({'Feature': variable, 'Importance': feature_importances})\n",
    "\n",
    "# Sort features by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top n most important features\n",
    "n = 18  # Number of top features to display\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b6730-06e4-4b99-b4d1-7a2a3eff3a1d",
   "metadata": {},
   "source": [
    "### Gradient Boosting (ALL VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74ccae60-4ef3-408a-8668-1753954eaec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7100444119973232\n",
      "Accuracy: 0.7100444119973232\n",
      "AUC Score: 0.7443582158691345\n",
      "Specificity: 0.4281391830559758\n",
      "Sensitivity: 0.8873099867213667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53     31728\n",
      "           1       0.71      0.89      0.79     50457\n",
      "\n",
      "    accuracy                           0.71     82185\n",
      "   macro avg       0.71      0.66      0.66     82185\n",
      "weighted avg       0.71      0.71      0.69     82185\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13584 18144]\n",
      " [ 5686 44771]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Train Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate Classifier\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate AUC Score\n",
    "auc_score = roc_auc_score(y_test, gb_classifier.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC Score:\", auc_score)\n",
    "\n",
    "# Calculate Specificity and Sensitivity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b643cc5b-3609-4ec4-b18b-d4dcdf6602f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>triage_acuity_iter</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>disposition_ADMITTED</td>\n",
       "      <td>0.099718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>arrival_transport_UNKNOWN</td>\n",
       "      <td>0.083275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eci_score</td>\n",
       "      <td>0.079053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>chiefcom_abdominal_pain</td>\n",
       "      <td>0.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>race_HISPANIC/LATINO - PUERTO RICAN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cci_MI</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>cci_CHF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>cci_PVD</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_hosp_30d</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Importance\n",
       "20                   triage_acuity_iter    0.341333\n",
       "59                 disposition_ADMITTED    0.099718\n",
       "57            arrival_transport_UNKNOWN    0.083275\n",
       "3                             eci_score    0.079053\n",
       "68              chiefcom_abdominal_pain    0.067900\n",
       "..                                  ...         ...\n",
       "39  race_HISPANIC/LATINO - PUERTO RICAN    0.000000\n",
       "77                               cci_MI    0.000000\n",
       "78                              cci_CHF    0.000000\n",
       "79                              cci_PVD    0.000000\n",
       "7                            n_hosp_30d    0.000000\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = gb_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({'Feature': variable, 'Importance': feature_importances})\n",
    "\n",
    "# Sort features by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top n most important features\n",
    "#n = 18  # Number of top features to display\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9de4e60b-0b38-4f0c-ba8d-3d4a7fe02145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', 'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE', 'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME']\n"
     ]
    }
   ],
   "source": [
    "# Extract the first 10 variable names\n",
    "top_10_variables = importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "# Display the first 10 variable names\n",
    "print(top_10_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd54354-7a08-40f7-bd52-be9405256e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f79601b-fb69-4d18-9d9b-bbff140f3740",
   "metadata": {},
   "source": [
    "### Gradeint Boosting (With CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ee87a1f-e19d-433d-9619-02f34609a025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics Across 5 Folds:\n",
      "Accuracy: 0.7123 (+/- 0.0017)\n",
      "AUC Score: 0.7471 (+/- 0.0014)\n",
      "Specificity: 0.4386 (+/- 0.0044)\n",
      "Sensitivity: 0.8848 (+/- 0.0018)\n",
      "F1 Score: 0.6940 (+/- 0.0020)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define feature columns and target outcome\n",
    "X = df_master[variable]  \n",
    "y = df_master[outcome]   \n",
    "\n",
    "# Define 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics for each fold\n",
    "accuracy_list = []\n",
    "auc_list = []\n",
    "specificity_list = []\n",
    "sensitivity_list = []\n",
    "f1_list = []\n",
    "feature_importances_list = []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train Gradient Boosting Classifier\n",
    "    gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    gb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = gb_classifier.predict(X_test)\n",
    "    y_pred_prob = gb_classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics for the fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    f1 = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']\n",
    "    feature_importances = gb_classifier.feature_importances_\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy)\n",
    "    auc_list.append(auc_score)\n",
    "    specificity_list.append(specificity)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    f1_list.append(f1)\n",
    "    feature_importances_list.append(feature_importances)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "print(\"Average Metrics Across 5 Folds:\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_list):.4f} (+/- {np.std(accuracy_list):.4f})\")\n",
    "print(f\"AUC Score: {np.mean(auc_list):.4f} (+/- {np.std(auc_list):.4f})\")\n",
    "print(f\"Specificity: {np.mean(specificity_list):.4f} (+/- {np.std(specificity_list):.4f})\")\n",
    "print(f\"Sensitivity: {np.mean(sensitivity_list):.4f} (+/- {np.std(sensitivity_list):.4f})\")\n",
    "print(f\"F1 Score: {np.mean(f1_list):.4f} (+/- {np.std(f1_list):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcd10c04-dd8d-48f5-afbc-744761151109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                             Feature  Importance\n",
      "20                triage_acuity_iter    0.335681\n",
      "59              disposition_ADMITTED    0.097400\n",
      "57         arrival_transport_UNKNOWN    0.083431\n",
      "3                          eci_score    0.076012\n",
      "68           chiefcom_abdominal_pain    0.068335\n",
      "..                               ...         ...\n",
      "77                            cci_MI    0.000000\n",
      "78                           cci_CHF    0.000000\n",
      "80                        cci_Stroke    0.000000\n",
      "35  race_HISPANIC/LATINO - DOMINICAN    0.000000\n",
      "30       race_BLACK/CARIBBEAN ISLAND    0.000000\n",
      "\n",
      "[114 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate average feature importances\n",
    "average_feature_importances = np.mean(feature_importances_list, axis=0)\n",
    "feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': average_feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances_df)\n",
    "\n",
    "# Optional: Save to CSV for further analysis\n",
    "# feature_importances_df.to_csv('feature_importances.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86f7790b-b1a5-4837-b70f-29c9926eb7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', 'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE', 'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME']\n"
     ]
    }
   ],
   "source": [
    "# Extract the first 10 variable names\n",
    "top_10_variables = feature_importances_df.head(10)['Feature'].tolist()\n",
    "\n",
    "# Display the first 10 variable names\n",
    "print(top_10_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0b73a-a860-4692-a4d5-2d1e7c45c796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba15cc-c2c5-40d0-9dd6-f6ece8676889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5f9e3-6852-4f6c-8f6c-bc52e9373756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e901644-8b9c-410b-a6c0-8e0b869a79d0",
   "metadata": {},
   "source": [
    "### Repeat Experiment with top 10 vars and stratified 5 folds CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb5bfea-f1ec-4f35-854c-856f14bdbfdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = ['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', \n",
    "            'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE',\n",
    "            'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME']\n",
    "\n",
    "\n",
    "outcome = \"LOS_category_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83f1dfa5-b354-4c99-933f-b2448fe2fc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "X_train = df_train[variable]\n",
    "y_train = df_train[outcome]\n",
    "\n",
    "X_test = df_test[variable]\n",
    "y_test = df_test[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc0d927f-678b-4031-80d4-a4062f8dd970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8435b85c-7c26-41f4-8b4d-0f8565d9a515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': array([1, 1, 1, ..., 0, 0, 1]),\n",
       " 'GB': array([1, 1, 1, ..., 0, 0, 0]),\n",
       " 'LR': array([1, 1, 1, ..., 0, 0, 1]),\n",
       " 'MLP': array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db9e71-7fcd-4f96-85fc-4ada91a46b3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "220aadc7-6136-4561-a3d5-92aebb3e78d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define feature columns and target outcome\n",
    "X = df_master[variable]  \n",
    "y = df_master[outcome]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bcb1dc9c-6665-4619-b43a-4f69a9eae0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.7329 (+/- 0.0003)\n",
      "Mean Validation Accuracy: 0.6799 (+/- 0.0017)\n",
      "Mean Train AUC: 0.8048 (+/- 0.0004)\n",
      "Mean Validation AUC: 0.7010 (+/- 0.0016)\n",
      "Mean Train Sensitivity: 0.8367 (+/- 0.0019)\n",
      "Mean Validation Sensitivity: 0.7926 (+/- 0.0018)\n",
      "Mean Train Specificity: 0.5682 (+/- 0.0028)\n",
      "Mean Validation Specificity: 0.5011 (+/- 0.0066)\n",
      "Mean Train F1 Score: 0.7935 (+/- 0.0005)\n",
      "Mean Validation F1 Score: 0.7523 (+/- 0.0008)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6825\n",
      "AUC Score: 0.7049\n",
      "Specificity: 0.4977\n",
      "Sensitivity: 0.7991\n",
      "F1 Score: 0.7553\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = rf_classifier.predict(X_train_fold)\n",
    "    y_val_pred = rf_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, rf_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, rf_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "y_test_pred_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "#save model predictions\n",
    "\n",
    "model_predictions['RF'] = y_test_pred\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cb370-1b10-48cc-a8b0-7aa5af0b3bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70dc8b2-5e27-436e-97fb-ea6d9178320e",
   "metadata": {},
   "source": [
    "#### gradeint boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8cdaa142-33cf-49bb-8af6-ffe549429444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.6998 (+/- 0.0006)\n",
      "Mean Validation Accuracy: 0.6993 (+/- 0.0012)\n",
      "Mean Train AUC: 0.7309 (+/- 0.0007)\n",
      "Mean Validation AUC: 0.7302 (+/- 0.0015)\n",
      "Mean Train Sensitivity: 0.8824 (+/- 0.0045)\n",
      "Mean Validation Sensitivity: 0.8820 (+/- 0.0045)\n",
      "Mean Train Specificity: 0.4101 (+/- 0.0086)\n",
      "Mean Validation Specificity: 0.4095 (+/- 0.0076)\n",
      "Mean Train F1 Score: 0.7829 (+/- 0.0006)\n",
      "Mean Validation F1 Score: 0.7825 (+/- 0.0011)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6993\n",
      "AUC Score: 0.7313\n",
      "Specificity: 0.3997\n",
      "Sensitivity: 0.8882\n",
      "F1 Score: 0.7837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    gb_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = gb_classifier.predict(X_train_fold)\n",
    "    y_val_pred = gb_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, gb_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, gb_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = gb_classifier.predict(X_test)\n",
    "y_test_pred_prob = gb_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#save model predictions\n",
    "\n",
    "model_predictions['GB'] = y_test_pred\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824908c-e1ba-4647-9857-93d2e6f7fc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faaeac77-761e-47d0-a28d-6ba9d9102914",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06c2098b-44b0-4004-b9b7-cd2a2d68f6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.6930 (+/- 0.0002)\n",
      "Mean Validation Accuracy: 0.6929 (+/- 0.0008)\n",
      "Mean Train AUC: 0.6994 (+/- 0.0002)\n",
      "Mean Validation AUC: 0.6994 (+/- 0.0013)\n",
      "Mean Train Sensitivity: 0.8581 (+/- 0.0008)\n",
      "Mean Validation Sensitivity: 0.8581 (+/- 0.0009)\n",
      "Mean Train Specificity: 0.4312 (+/- 0.0013)\n",
      "Mean Validation Specificity: 0.4310 (+/- 0.0031)\n",
      "Mean Train F1 Score: 0.7742 (+/- 0.0002)\n",
      "Mean Validation F1 Score: 0.7742 (+/- 0.0004)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6939\n",
      "AUC Score: 0.6990\n",
      "Specificity: 0.4346\n",
      "Sensitivity: 0.8573\n",
      "F1 Score: 0.7745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = lr_classifier.predict(X_train_fold)\n",
    "    y_val_pred = lr_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, lr_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, lr_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = lr_classifier.predict(X_test)\n",
    "y_test_pred_prob = lr_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "#save model predictions\n",
    "\n",
    "model_predictions['LR'] = y_test_pred\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf1745-9e95-4835-98de-079fdcd221c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "664768e5-f043-46c4-a02c-4bbef7d5bdf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d1dad27-034d-4dc9-96d5-b55dc2903df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.6810 (+/- 0.0004)\n",
      "Mean Validation Accuracy: 0.6810 (+/- 0.0012)\n",
      "Mean Train AUC: 0.6852 (+/- 0.0006)\n",
      "Mean Validation AUC: 0.6851 (+/- 0.0019)\n",
      "Mean Train Sensitivity: 0.8948 (+/- 0.0003)\n",
      "Mean Validation Sensitivity: 0.8948 (+/- 0.0018)\n",
      "Mean Train Specificity: 0.3420 (+/- 0.0010)\n",
      "Mean Validation Specificity: 0.3421 (+/- 0.0020)\n",
      "Mean Train F1 Score: 0.7747 (+/- 0.0002)\n",
      "Mean Validation F1 Score: 0.7748 (+/- 0.0010)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6807\n",
      "AUC Score: 0.6834\n",
      "Specificity: 0.3393\n",
      "Sensitivity: 0.8954\n",
      "F1 Score: 0.7749\n"
     ]
    }
   ],
   "source": [
    "#TAKES VERY LONG TIME\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    svm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = svm_classifier.predict(X_train_fold)\n",
    "    y_val_pred = svm_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, svm_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, svm_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "y_test_pred_prob = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55283c-8d7e-445f-b4c2-c70285914aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2e8723b-16a6-45b9-b379-6877cffb04be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "Mean Train AUC: 0.7299 (+/- 0.0011)\n",
      "Mean Validation AUC: 0.7297 (+/- 0.0021)\n",
      "Mean Train Accuracy: 0.6975 (+/- 0.0017)\n",
      "Mean Validation Accuracy: 0.6971 (+/- 0.0025)\n",
      "Mean Train Sensitivity: 0.8359 (+/- 0.0292)\n",
      "Mean Validation Sensitivity: 0.8351 (+/- 0.0288)\n",
      "Mean Train Specificity: 0.4780 (+/- 0.0424)\n",
      "Mean Validation Specificity: 0.4782 (+/- 0.0396)\n",
      "Mean Train F1 Score: 0.7720 (+/- 0.0071)\n",
      "Mean Validation F1 Score: 0.7716 (+/- 0.0075)\n",
      "\n",
      "Test Set Evaluation:\n",
      "AUC Score: 0.7309\n",
      "Accuracy: 0.6998\n",
      "Specificity: 0.4301\n",
      "Sensitivity: 0.8698\n",
      "F1 Score: 0.7804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, f1_score, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Define MLP model architecture\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Initialize the MLP model\n",
    "    mlp_model = create_mlp()\n",
    "\n",
    "    # Train the model\n",
    "    mlp_model.fit(X_train_fold, y_train_fold, batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred_prob = mlp_model.predict(X_train_fold)\n",
    "    y_train_pred = (y_train_pred_prob > 0.5).astype(int)\n",
    "    y_val_pred_prob = mlp_model.predict(X_val_fold)\n",
    "    y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, y_train_pred_prob))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "\n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, y_val_pred_prob))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "mlp_model = create_mlp()\n",
    "mlp_model.fit(X_train, y_train, batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred_prob = mlp_model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#save model predictions\n",
    "\n",
    "model_predictions['MLP'] = y_test_pred\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52061ff-b931-45de-83af-8e3256792beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9dc3b5-fe01-45b7-92e2-722ac6b72288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8d5b491-224c-4feb-a666-b56dfa584c7a",
   "metadata": {},
   "source": [
    "### Mcnemar Test to Compare (Imbalanced dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cbf59-e0a6-42d6-8a1d-91292d3237de",
   "metadata": {},
   "source": [
    "McNemar's test is used for comparing the classification performance of two models to determine if the observed differences are statistically significant, we compare across models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7bfdad59-6bfa-4e3f-a99b-b0a1982f68c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "814086be-c4f5-412e-9dfe-b482c62c5716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flatten the MLP predictions and update the dictionary\n",
    "model_predictions['MLP'] = model_predictions['MLP'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e263fa63-9063-41a7-9c6d-3b408f977e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': array([1, 0, 1, ..., 0, 1, 1]),\n",
       " 'GB': array([1, 0, 1, ..., 0, 1, 1]),\n",
       " 'LR': array([1, 0, 0, ..., 0, 1, 0]),\n",
       " 'MLP': array([1, 0, 1, ..., 0, 1, 1])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6bcc37-eca1-4c13-85a9-a9135d374200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9039c3-01c5-4a01-a167-d6b0f5f08663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3665d5d-7315-48bc-bde5-f88a49b7d015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between RF and GB:\n",
      "Chi-squared statistic: 4101.0\n",
      "p-value: 3.6697148431845475e-45\n",
      "The difference between RF and GB is statistically significant.\n",
      "\n",
      "Comparison between RF and LR:\n",
      "Chi-squared statistic: 5147.0\n",
      "p-value: 1.5938230236417899e-18\n",
      "The difference between RF and LR is statistically significant.\n",
      "\n",
      "Comparison between RF and MLP:\n",
      "Chi-squared statistic: 3850.0\n",
      "p-value: 6.947795419467272e-50\n",
      "The difference between RF and MLP is statistically significant.\n",
      "\n",
      "Comparison between GB and LR:\n",
      "Chi-squared statistic: 1812.0\n",
      "p-value: 2.351898580546245e-12\n",
      "The difference between GB and LR is statistically significant.\n",
      "\n",
      "Comparison between GB and MLP:\n",
      "Chi-squared statistic: 1370.0\n",
      "p-value: 0.49452048057625353\n",
      "The difference between GB and MLP is not statistically significant.\n",
      "\n",
      "Comparison between LR and MLP:\n",
      "Chi-squared statistic: 2559.0\n",
      "p-value: 9.805126715938419e-11\n",
      "The difference between LR and MLP is statistically significant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform pairwise McNemar's test for all model combinations\n",
    "model_pairs = list(itertools.combinations(model_predictions.keys(), 2))\n",
    "\n",
    "for model_a_name, model_b_name in model_pairs:\n",
    "    # Predictions for the selected models\n",
    "    model_a_predictions = model_predictions[model_a_name]\n",
    "    model_b_predictions = model_predictions[model_b_name]\n",
    "\n",
    "    # Construct contingency table\n",
    "    both_correct = np.sum((model_a_predictions == y_test) & (model_b_predictions == y_test))\n",
    "    model_a_correct_b_wrong = np.sum((model_a_predictions == y_test) & (model_b_predictions != y_test))\n",
    "    model_b_correct_a_wrong = np.sum((model_b_predictions == y_test) & (model_a_predictions != y_test))\n",
    "    both_wrong = np.sum((model_a_predictions != y_test) & (model_b_predictions != y_test))\n",
    "\n",
    "    # Construct contingency table for McNemar's test\n",
    "    contingency_table = [[both_correct, model_a_correct_b_wrong],\n",
    "                         [model_b_correct_a_wrong, both_wrong]]\n",
    "\n",
    "    # Apply McNemar's test\n",
    "    result = mcnemar(contingency_table, exact=True)\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Comparison between {model_a_name} and {model_b_name}:\")\n",
    "    print(f\"Chi-squared statistic: {result.statistic}\")\n",
    "    print(f\"p-value: {result.pvalue}\")\n",
    "\n",
    "    if result.pvalue < 0.05:\n",
    "        print(f\"The difference between {model_a_name} and {model_b_name} is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(f\"The difference between {model_a_name} and {model_b_name} is not statistically significant.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768fa7a-5d94-48a2-af34-ad4b95a70e17",
   "metadata": {},
   "source": [
    " this means that GB and MLP performed similarly on the dataset, and there is no statistically significant advantage of one over the other in terms of predictive accuracy when evaluated using McNemar's test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32477967-6b74-4985-bac9-0b2a75cac807",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9066c2e-4807-4b71-b2e8-15a896b57974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e21b80f4-f509-492b-997e-2b6d1351851b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define feature columns and target outcome\n",
    "X = df_master[variable]  \n",
    "y = df_master[outcome]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "553648fb-7dd2-4b27-8112-0f6cc040ff9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB1kAAAdiCAYAAADXKlTMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3gUVd/G8XvTGyWUAKGE0HvvvSNSRZCmIKD4UARBUBCk9y7SRDpKk14UqSoCUpTekRo6CYHQU+b9g5eVJQkkZMOE8P1cV67HPXP2zG82ebh39uycsRiGYQgAAAAAAAAAAAAAECMOZhcAAAAAAAAAAAAAAK8TJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkRYzt37tQ777yjTJkyydXVVWnSpFHp0qX1+eef2/SrVKmSLBaLsmTJIsMwIo3zxx9/yGKxyGKxaPbs2ZG2//XXX2rcuLHSpUsnFxcXpU2bVo0aNdKOHTts+j0Z40U/v/32m86ePfvcPv3797fnS/Vcv/32m82+HR0dlTp1atWtW1d79ux5ZXU8a/bs2bJYLDp79qxp+47qp3v37q+8npgYOnSoVqxYYXYZAF5j5Kp9nTlzRp07d1bu3Lnl6ekpNzc3Zc6cWe+//762bNkS5WsXH6LK00qVKqlSpUrxut8jR46of//+Ueb4hx9+GOm9R4YMGfTee+/p0KFD8VpXTLyo9syZM7/ymgAkPuSufTw5n12yZMkr26f0cnlw6dIl9e/fX/v27Yu0rX///rJYLC9Vx9OvvYuLi7Jmzaru3bvr9u3bsR7vdfUq3tsAwOuO9x728fRn6VEdvyRVqVJFFosl0nuFzJkzq06dOs8d/9lsd3V1Vc6cOdWvXz89ePDATkeBxMzJ7ALweli7dq3q1aunSpUqaeTIkUqXLp0uX76sPXv2aOHChRozZoxN/yRJkujMmTPavHmzqlatarNt5syZSpo0aZQnIN9++60+++wzlShRQiNHjpSfn5/Onz+vSZMmqVy5cvrmm2/UqVMnSYoUFIMGDdKWLVu0efNmm/Y8efIoKChIkvTpp5+qefPmkfabIUOG2L8ocTR06FBVrlxZoaGh2rt3rwYMGKCKFStq3759yp49+yuvJyGYNWuWcuXKZdPm6+trUjXPN3ToUDVq1EgNGjQwuxQAryFy1b5WrVql5s2bK1WqVPrf//6nIkWKyNXVVadOndKSJUtUpUoVbdy4MdJr96pMnjw53vdx5MgRDRgwQJUqVYryQ2h3d3fr7zIsLEynTp3S4MGDVaZMGR09elTp06eP9xqj87zav/76a3Xp0sWcwgAkGuTu6+9l8uDSpUsaMGCAMmfOrEKFCtls++ijj/TWW2+9VC1PZ2pwcLCWLFmiMWPG6MCBA1q/fv1Ljfm6eRXvbQDgdcZ7D/tLkiSJZsyYoQ8//NCm/cyZM/rtt9+UNGnSlx776Wy/efOmFixYoIEDB+rYsWNatGhRXMrGm8AAYqBChQpG1qxZjdDQ0EjbwsPDbR5XrFjRyJs3r1GqVCmjefPmNttu375teHh4GB9//LEhyZg1a5Z1259//mk4ODgYderUibSf0NBQo06dOoaDg4Px559/Rlljq1atDE9Pzyi3nTlzxpBkjBo1KiaHGyMVK1Y0WrVqFevnbdmyxZBk/PTTTzbtc+bMMSQZffv2tVOFsTNr1ixDknHmzBnT9r179+54Gf/u3bt2H9PT0/Olfv8AYBjkalReNldPnTpleHh4GMWLFzdu3boVZZ8tW7YY+/bte+449soKs/L0p59+MiQZW7ZsibQtut/lpk2bDEnGd9999woqjN7zagcAeyB3I7P3+WxCtHv37ki/p7iK7vdUuXJlQ5Jx+vRpu+0rJsLCwowHDx680n0CAF6M9x6RxfW9x0cffWRIMk6cOGGzvU+fPkaGDBmMWrVqGX5+fjbb/Pz8jNq1az93/Oheh/LlyxuSjICAgFjXjDcLywUjRgIDA5UqVSo5OUW++NnBIeo/ozZt2mjZsmUKDg62ti1cuFCS1LRp00j9hw0bJovFoilTpkTaj5OTkyZPniyLxaLhw4fH4UgSrmLFikmSrl69atM+YMAAlSxZUilSpFDSpElVpEgRzZgxI9LyEU+WP1i3bp2KFCkid3d35cqVSzNnzoy0r7/++ktly5aVm5ubfH191atXL4WGhkbqFxERoZEjRypXrlxydXWVj4+PWrZsqYCAAJt+lSpVUr58+bRjxw6VKVNG7u7uypw5s2bNmiXp8be3ihQpIg8PD+XPn1/r1q17qddo1apVKl26tDw8PJQkSRJVr1490rewniz79M8//6hRo0by9vZW1qxZJUmGYWjy5MkqVKiQ3N3d5e3trUaNGun06dM2Y+zdu1d16tSRj4+PXF1d5evrq9q1a1uP22Kx6O7du5ozZ451KQmWSgIQG+Sq/YwdO1b37t3T5MmTo/3maqVKlVSwYEHr4+dlxZ49e9S0aVNlzpzZmmfNmjXTuXPnIo0b0zyNakm9R48eafDgwdaMTZ06tVq3bq3r16/b9ItJvs+ePVuNGzeWJFWuXPmFSyk9kSxZMkmSs7OzTfuhQ4dUv359eXt7y83NTYUKFdKcOXMiPf/8+fN6//33rXmZO3dujRkzRhERETb9pkyZooIFC8rLy0tJkiRRrly59NVXX8Wo9qiWh7RYLOrUqZPmzZun3Llzy8PDQwULFtSaNWsi1bhy5UoVKFBArq6uypIli7755puXXiISwOuL3H31Ypolhw8fVo0aNeTh4aHUqVOrY8eOWrt2rXW5wieiyoOffvpJJUuWVLJkyeTh4aEsWbKoTZs2kh4vLVi8eHFJUuvWrSMtbxhdFsyfP1+lS5eWl5eXvLy8VKhQIc2YMeOFxxvd+fyiRYtUunRpeXp6ysvLSzVr1tTevXsjPf/7779Xjhw55Orqqjx58mj+/PmRjvnJ0o0jR47U4MGD5e/vL1dXV23ZskXS4/cw9erVU4oUKeTm5qbChQtr8eLFNvu5d++eunfvLn9/f7m5uSlFihQqVqyYFixYYO1z+vRpNW3aVL6+vtblLatWrWqz7HJU722CgoLUoUMHpU+fXi4uLsqSJYt69+6thw8f2vSLTY4DwOuK9x72V716dWXMmNHmXDgiIkJz5sxRq1aton1dX1apUqUkKcrPAoCnMcmKGCldurR27typzp07a+fOnVF+gPispk2bytHR0ebN+owZM9SoUaNIH4KGh4dry5YtKlasWLTLDWTMmFFFixbV5s2bFR4e/lLHERERobCwsEg/CcGZM2ckSTly5LBpP3v2rD755BMtXrxYy5YtU8OGDfXpp59q0KBBkcbYv3+/Pv/8c3Xt2tX6oWLbtm31xx9/WPscOXJEVatWVXBwsGbPnq2pU6dq7969Gjx4cKTx2rdvry+//FLVq1fXqlWrNGjQIK1bt05lypTRjRs3bPpeuXJFrVu31kcffaSVK1cqf/78atOmjQYOHKhevXrpiy++0NKlS+Xl5aUGDRro0qVLkfYXHh4e7e9m/vz5ql+/vpImTaoFCxZoxowZunnzpipVqqQ///wz0lgNGzZUtmzZ9NNPP2nq1KmSpE8++USfffaZqlWrphUrVmjy5Mk6fPiwypQpYz0Zvnv3rqpXr66rV69q0qRJ2rBhg8aPH69MmTIpJCRE0uPlNdzd3fX2229rx44d2rFjB8slAYgVctV+NmzYoHTp0lk/3IyNqLLi7Nmzypkzp8aPH69ff/1VI0aM0OXLl1W8eHGb7ItNnj4rIiJC9evX1/Dhw9W8eXOtXbtWw4cP14YNG1SpUiXdv3/fpv+L8r127doaOnSoJGnSpEnWbKpdu7bNOE9+Pw8ePNChQ4fUo0cPeXt72/Q7fvy4ypQpo8OHD2vChAlatmyZ8uTJow8//FAjR4609rt+/brKlCmj9evXa9CgQVq1apWqVaum7t27W5ejkh5/KNChQwdVrFhRy5cv14oVK9S1a1fdvXs3VrU/a+3atZo4caIGDhyopUuXKkWKFHrnnXdsvji1bt06NWzYUClTptSiRYs0cuRILViwIMoP+QEkbuTuqxXTLLl8+bIqVqyo48ePa8qUKZo7d65CQkJsciQ6O3bsUJMmTZQlSxYtXLhQa9euVd++fa2vR5EiRaxf+u3Tp481Xz766KNox+zbt69atGghX19fzZ49W8uXL1erVq1i9OHqmTNn5OTkpCxZsljbhg4dqmbNmilPnjxavHix5s2bp5CQEJUvX15Hjhyx9ps2bZratWunAgUKaNmyZerTp48GDBhgM8n8tAkTJmjz5s0aPXq0fvnlF+XKlUtbtmxR2bJlFRwcrKlTp2rlypUqVKiQmjRpYvOlq27dumnKlCnq3Lmz1q1bp3nz5qlx48YKDAy09nn77bf1999/a+TIkdqwYYOmTJmiwoUL23zo/6wHDx6ocuXKmjt3rrp166a1a9fq/fff18iRI9WwYcNI/WOS4wDwOuO9h/05ODjoww8/1Ny5c63Hs379egUEBKh169Z239+pU6ckSalTp7b72EhkzL6UFq+HGzduGOXKlTMkGZIMZ2dno0yZMsawYcOMkJAQm75PljgwjMeX2xcrVswwDMM4fPiwIcn47bffIi3bc+XKFUOS0bRp0+fW0aRJE0OScfXq1UjbYrLEQXQ/W7dufe5+IyIijNDQUJufChUqGC1btozU/iJPljhYtGiRERoaaty7d8/Ytm2bkTNnTiNPnjzGzZs3o31ueHi4ERoaagwcONBImTKlERERYd3m5+dnuLm5GefOnbO23b9/30iRIoXxySefWNuaNGliuLu7G1euXLG2hYWFGbly5bJZ3vDo0aOGJKNDhw42NezcudOQZHz11VfWtooVKxqSjD179ljbAgMDDUdHR8Pd3d24ePGitX3fvn2GJGPChAnWtidLK0b1ExoaaoSHhxu+vr5G/vz5bZbUCAkJMXx8fIwyZcpY2/r16xflsss7duwwJBljxoyxab9w4YLh7u5ufPHFF4ZhGMaePXsMScaKFSui+hVYsVwwgLggV+2Xq25ubkapUqUitT/JzCc/T+dHdFkRlbCwMOPOnTuGp6en8c0331jbY5qnhvH4d1ixYkXr4wULFhiSjKVLl9rs68nvcfLkyda2mOb7i5YLjur3lC5dukhLRzVt2tRwdXU1zp8/b9Neq1Ytw8PDwwgODjYMwzB69uxpSDJ27txp0699+/aGxWIxjh8/bhiGYXTq1MlInjx5pJqe9qLan13ySZKRJk0a4/bt29a2K1euGA4ODsawYcOsbcWLFzcyZsxoPHz40NoWEhJipEyZ0uA0CHizkLv2P5993nLBMc2SHj16GBaLxTh8+LBNv5o1a0bKhWfzYPTo0YYk61hRed5ywU/eCzxx+vRpw9HR0WjRokW04z2pw9PT0/p63bhxw5gyZYrh4OBgc458/vx5w8nJyfj0009tnh8SEmKkTZvWeO+99wzDePx+JW3atEbJkiVt+p07d85wdna2OeYnfwdZs2Y1Hj16ZNM/V65cRuHChSP9DuvUqWOkS5fO+j4oX758RoMGDaI9vhs3bhiSjPHjxz/3dXj2vc3UqVMNScbixYtt+o0YMcKQZKxfv97aFtMcB4DXGe894ue9x+nTpw2LxWKsWbPGMAzDaNy4sVGpUiXDMAyjdu3acVou+Ek9169fN7755hvDYrEYxYsXf2F9AFeyIkZSpkyprVu3avfu3Ro+fLjq16+vEydOqFevXsqfP3+kqxqfaNOmjfbs2aODBw9qxowZypo1qypUqPDSdRj/v0Tuyy7x1qVLF+3evTvST6FChZ77vN9//13Ozs42P3/88Yfmzp0bqf3s2bMxqqVJkyZydnaWh4eHypYtq9u3b2vt2rVKnjy5Tb/NmzerWrVqSpYsmRwdHeXs7Ky+ffsqMDBQ165ds+lbqFAhZcqUyfrYzc1NOXLksPnm7ZYtW1S1alWlSZPG2ubo6KgmTZrYjPVkyaFnbyZeokQJ5c6dW5s2bbJpT5cunYoWLWp9nCJFCvn4+KhQoULy9fW1tufOnVtS1EstzJ07N9LvxsnJScePH9elS5f0wQcf2Cz94OXlpXfffVd//fWX7t27ZzPWu+++a/N4zZo1slgsev/9922+eZU2bVoVLFjQ+i3hbNmyydvbW19++aWmTp1q8w1jALAXctX+ufqshg0b2ozTuXPnSH2ezQpJunPnjr788ktly5ZNTk5OcnJykpeXl+7evaujR49a+8U0T6OyZs0aJU+eXHXr1rXJpEKFCilt2rSRrlyJSb6/iLu7u/X3s3PnTi1btkw5cuSwrsrwxObNm1W1alVlzJjR5vkffvih7t27Z+27efNm5cmTRyVKlIjUzzAMbd68WdLj9w3BwcFq1qyZVq5cGe3fdmxVrlxZSZIksT5OkyaNfHx8rK/J3bt3tWfPHjVo0EAuLi7Wfl5eXqpbt65dagDw+iB34z93nxbTLPn999+VL18+5cmTx6Zfs2bNXriPJ0sBv/fee1q8eLEuXrwYp5o3bNig8PBwdezY8YV97969a329UqVKpfbt26tJkyYaMmSItc+vv/6qsLAwtWzZ0ibr3dzcVLFiRWvWHz9+XFeuXNF7771ns49MmTKpbNmyUe6/Xr16Nkv9nzp1SseOHVOLFi0kyWZ/b7/9ti5fvqzjx49LepzLv/zyi3r27Knffvst0uoZKVKkUNasWTVq1CiNHTtWe/fujXQbgKhs3rxZnp6eatSokU37k88Tnv384EU5DgCvO957xM97D39/f1WqVEkzZ85UYGCgVq5cab1VQFw8ne2pU6fWZ599plq1amn58uVxHhuJX+RFwYHnKFasmHU5vtDQUH355ZcaN26cRo4cabPszxMVKlRQ9uzZ9d1332nx4sX67LPPovxHPVWqVPLw8LAumRuds2fPysPDQylSpHip+jNkyPBSywkWLVpUu3fvtmn75JNP5Ovrq379+tm0Pz2h+DwjRoxQlSpVdO/ePa1fv17Dhg1TgwYNtHPnTrm6ukqSdu3apRo1aqhSpUr6/vvvlSFDBrm4uGjFihUaMmRIpBOilClTRtqPq6urTb/AwEClTZs2Ur9n254sF5QuXbpIfX19fSOd/ET1O3FxcYnU/uSDzgcPHkTqnzt37ih/Py+qJSIiQjdv3pSHh4e1/dm+V69elWEYNh+GP+3Jsk7JkiXT77//riFDhuirr77SzZs3lS5dOn388cfq06dPpPvWAUBckKv/edlczZQpU5QfyI0ZM0Z9+vSR9N8Hsc+KKleaN2+uTZs26euvv1bx4sWVNGlSWSwWvf322y+Vp1G5evWqgoODbSb/nvbsCXdM8v1FHBwcIv2uatasqYwZM6pbt27WD7wDAwOjzdsn25/877P3xouq3wcffKCwsDB9//33evfddxUREaHixYtr8ODBql69eozrf9aLXpObN29Gm/vRvRcAkPiRu/+J6/ns88QmS/z9/SP1i8m/0xUqVNCKFSs0YcIEtWzZUg8fPlTevHnVu3fvGE3SPuvJPdGjW3Lxae7u7tYl+69cuaIxY8ZowYIFKlCggHr27Cnpv3uzRvce5MmXh5+8FtHlVVR/U1Gd60pS9+7d1b179yj39+S9xYQJE5QhQwYtWrRII0aMkJubm2rWrKlRo0Ype/bsslgs2rRpkwYOHKiRI0fq888/V4oUKdSiRQsNGTLEZmL0aU/eFz37/w8fHx85OTnZLEcs2ee9DQC8Dnjv8R97vfdo27atWrdurbFjx8rd3T3SF3xextPZ7urqKj8/v0hLNAPRYZIVL83Z2Vn9+vXTuHHjdOjQoWj7tW7dWn369JHFYlGrVq2i7OPo6KjKlStr3bp1CggIiPLEJiAgQH///bdq1aolR0dHux1HTCRJkiRSoCRJkkQpU6Z8qaCRHk/qPXluhQoV5O7urj59+ujbb7+1nhgtXLhQzs7OWrNmjdzc3KzPXbFixcsdiB6fzFy5ciVS+7NtT056Ll++HOn3cenSJaVKleqla4itp2t51qVLl+Tg4CBvb2+b9mffgKRKlUoWi0Vbt261TmI/7em2/Pnza+HChTIMQwcOHNDs2bM1cOBAubu7W0+aAcDeyNWXy9Xq1atr0qRJ2rNnj81zs2bN+sLnPpsVt27d0po1a9SvXz+bf+8fPnyooKAgm74xzdOopEqVSilTptS6deui3B7dB5j25uHhoaxZs2r//v3WtpQpU0abt5Ks+R/TftLjv9nWrVvr7t27+uOPP9SvXz/VqVNHJ06ckJ+fn12P6Qlvb29ZLBbrB89Pi8nvCEDiR+7G7Xz2eWKTJXH5d7p+/fqqX7++Hj58qL/++kvDhg1T8+bNlTlzZpUuXTpWNT+531pAQECkK3Cf9ewXl6pXr66iRYtqwIABatGihTJmzGg9xiVLljw3656c68bmdYjqXFeSevXqFeX9TyUpZ86ckiRPT08NGDBAAwYM0NWrV61XtdatW1fHjh2TJPn5+WnGjBmSpBMnTmjx4sXq37+/Hj16ZL2HfVTHsXPnThmGYVPftWvXFBYW9ko/PwCAhIr3HvZ579GwYUN17NhRw4cP18cffyx3d/c4jSdF/aVkIKZYLhgxEtUJkiTrsnnP+8ZJq1atVLduXfXo0UPp06ePtl+vXr1kGIY6dOgQ6Wbc4eHhat++vQzDUK9evV7iCBK+L774QtmyZdPw4cMVEhIi6fHJk5OTk00Q3r9/X/PmzXvp/VSuXFmbNm2yOYkLDw/XokWLbPpVqVJFkvTDDz/YtO/evVtHjx5V1apVX7qG2MqZM6fSp0+v+fPnW5e5kB4v5bB06VKVLl3a5irWqNSpU0eGYejixYvWb5E9/ZM/f/5Iz7FYLCpYsKDGjRun5MmT659//rFu41u2AOKCXLWfrl27ysPDQx07drTm58uyWCwyDCPSl3GmT58e6TWMaZ5GpU6dOgoMDFR4eHiUmfTkg9DYeFJzbLLpzp07OnXqlHx8fKxtVatW1ebNm60fhD8xd+5ceXh4qFSpUtZ+R44cscnGJ/0sFosqV64caX+enp6qVauWevfurUePHunw4cMvXfuLeHp6qlixYlqxYoUePXpkbb9z547WrFljt/0AeD2Qu69WTLOkYsWKOnToUKRbtCxcuDBW+3N1dVXFihU1YsQISdLevXut7VLM8qVGjRpydHTUlClTYrXvJ/uZNGmSHjx4oMGDB0t6vFqEk5OT/v333yiz/skHuTlz5lTatGm1ePFimzHPnz+v7du3x2j/OXPmVPbs2bV///5o9xXVF7jSpEmjDz/8UM2aNdPx48cj3YJHknLkyKE+ffoof/78kTL/aVWrVtWdO3cifSF87ty51u0A8CbhvUf8cXd3V9++fVW3bl21b9/e7HIArmRFzNSsWVMZMmRQ3bp1lStXLkVERGjfvn0aM2aMvLy81KVLl2if6+vrG6MrL8uWLavx48frs88+U7ly5dSpUydlypRJ58+f16RJk7Rz506NHz9eZcqUeenjOH/+vP76669I7alTp47RFS/xydnZWUOHDtV7772nb775Rn369FHt2rU1duxYNW/eXO3atVNgYKBGjx4d5ZWYMdWnTx+tWrVKVapUUd++feXh4aFJkybp7t27Nv1y5sypdu3a6dtvv5WDg4Nq1aqls2fP6uuvv1bGjBnVtWvXuB5yjDk4OGjkyJFq0aKF6tSpo08++UQPHz7UqFGjFBwcrOHDh79wjLJly6pdu3Zq3bq19uzZowoVKsjT01OXL1/Wn3/+qfz586t9+/Zas2aNJk+erAYNGihLliwyDEPLli1TcHCwzbKG+fPn12+//abVq1crXbp0SpIkyUt9KA7gzUSu2k/WrFm1YMECNWvWzPpveZEiReTq6qpr165p/fr1khSjpX6SJk2qChUqaNSoUUqVKpUyZ86s33//XTNmzIh0z/SY5mlUmjZtqh9//FFvv/22unTpohIlSsjZ2VkBAQHasmWL6tevr3feeSdWr0O+fPkkSdOmTVOSJEnk5uYmf39/6xUyERER1t9VRESELl68qAkTJujmzZvq37+/dZx+/fppzZo1qly5svr27asUKVLoxx9/1Nq1azVy5EglS5ZM0uPJ7blz56p27doaOHCg/Pz8tHbtWk2ePFnt27dXjhw5JMn6zeKyZcsqXbp0unLlioYNG6ZkyZJZl1B8Ue0va+DAgapdu7Zq1qypLl26KDw8XKNGjZKXl1ekK5MBJG7krv1FVYf0eOI0plny2WefaebMmapVq5YGDhyoNGnSaP78+dYrKp8sqRuVvn37KiAgQFWrVlWGDBkUHBysb775Rs7OzqpYsaKkx+8R3N3d9eOPPyp37tzy8vKSr69vlB9sZ86cWV999ZUGDRqk+/fvq1mzZkqWLJmOHDmiGzduaMCAAc99PSpWrKi3335bs2bNUs+ePeXv76+BAweqd+/eOn36tN566y15e3vr6tWr2rVrl/WKUgcHBw0YMECffPKJGjVqpDZt2ig4OFgDBgxQunTpnvsaPO27775TrVq1VLNmTX344YdKnz69goKCdPToUf3zzz/66aefJEklS5ZUnTp1VKBAAXl7e+vo0aOaN2+e9YvLBw4cUKdOndS4cWNlz55dLi4u2rx5sw4cOPDcVZ1atmypSZMmqVWrVjp79qzy58+vP//8U0OHDtXbb7+tatWqxeg4ACCx4L1H/OrWrZu6desWo75XrlzRkiVLIrVnzpyZq1dhHwYQA4sWLTKaN29uZM+e3fDy8jKcnZ2NTJkyGR988IFx5MgRm74VK1Y08ubN+9zxdu/ebUgyZs2aFWnbjh07jEaNGhlp0qQxnJycDB8fH6Nhw4bG9u3bnztmq1atDE9Pzyi3nTlzxpAU7U+LFi2e/wJEoWLFikarVq1i/bwtW7YYkoyffvopyu0lS5Y0vL29jeDgYMMwDGPmzJlGzpw5DVdXVyNLlizGsGHDjBkzZhiSjDNnzlif5+fnZ9SuXTvKOitWrGjTtm3bNqNUqVKGq6urkTZtWqNHjx7GtGnTIo0ZHh5ujBgxwsiRI4fh7OxspEqVynj//feNCxcuRNpHVL/z6GqSZHTs2NH6eNasWYYkY/fu3VG+Jk+sWLHCKFmypOHm5mZ4enoaVatWNbZt22bTp1+/foYk4/r161GOMXPmTKNkyZKGp6en4e7ubmTNmtVo2bKlsWfPHsMwDOPYsWNGs2bNjKxZsxru7u5GsmTJjBIlShizZ8+2GWffvn1G2bJlDQ8PD0NSpNcYAJ6HXI3sZXP1iX///df49NNPjZw5cxru7u6Gq6ur4efnZzRu3NhYvny5ERERYe37vKwICAgw3n33XcPb29tIkiSJ8dZbbxmHDh0y/Pz8ItUX0zyNKotDQ0ON0aNHGwULFjTc3NwMLy8vI1euXMYnn3xinDx50tovNvk+fvx4w9/f33B0dLT5e2jVqlWk35GPj49RsWJFY/ny5ZHGPnjwoFG3bl0jWbJkhouLi1GwYMEo/7bOnTtnNG/e3EiZMqXh7Oxs5MyZ0xg1apQRHh5u7TNnzhyjcuXKRpo0aQwXFxfD19fXeO+994wDBw7EuHY/Pz+bvs++j3j6tXr2d7R8+XIjf/78houLi5EpUyZj+PDhRufOnQ1vb+9IzweQeJG7kcX1fDa6ny1bthiGEfMsOXTokFGtWjXDzc3NSJEihdG2bVtjzpw5hiRj//791n7P5sGaNWuMWrVqGenTpzdcXFwMHx8f4+233za2bt1qM/6CBQuMXLlyGc7OzoYko1+/foZh/Pde4Flz5841ihcvbs3mwoUL29T9vN/TwYMHDQcHB6N169bWthUrVhiVK1c2kiZNan1v0qhRI2Pjxo02z502bZqRLVs2w8XFxciRI4cxc+ZMo379+kbhwoWtfZ78HYwaNSrK/e/fv9947733DB8fH8PZ2dlImzatUaVKFWPq1KnWPj179jSKFStmeHt7Wz9j6Nq1q3Hjxg3DMAzj6tWrxocffmjkypXL8PT0NLy8vIwCBQoY48aNM8LCwqzjRPU+JDAw0Pjf//5npEuXznBycjL8/PyMXr16GQ8ePLDpF5scB4DXFe89Iouvz9KfqF27dqRzRz8/v2iP4Uktz3sdgJiwGMZTa28CAAAAQCIVGhqqQoUKKX369NarnAEACUu7du20YMECBQYGysXFxexyTBEcHKwcOXKoQYMGmjZtmtnlAAAAIBosFwwAAAAgUWrbtq2qV69uXap46tSpOnr0qL755huzSwMA6PHS7r6+vsqSJYv1vtnTp09Xnz593pgJ1itXrmjIkCGqXLmyUqZMqXPnzmncuHEKCQl57nKSAAAAMB+TrAAAAAASpZCQEHXv3l3Xr1+Xs7OzihQpop9//pl7wwFAAuHs7KxRo0YpICBAYWFhyp49u8aOHftGTS66urrq7Nmz6tChg4KCguTh4aFSpUpp6tSpyps3r9nlAQAA4DlYLhgAAAAAAAAAAAAAYsHB7AIAAAAAAAAAAAAA4HXCJCsAAAAAAAAAAAAAxAKTrAAAAAAAAAAAAAAQC0yyAgAAAAAAAAAAAEAsOJldQHxwrzXO7BKAePXvgo5mlwDEO9/kLmaXgDgoNniL2SUA8err+rnNLgGIV/XzpzW7BMSRe+FOZpcAxKubuyeaXQIQr9wS5ae2b4507ZaaXQIQr37pU8PsEoB4VShTkhj140pWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgF0yZZg4KCFBAQYNN2+PBhtW7dWu+9957mz59vUmUAACR+5DAAAOYiiwEAMA85DACwB9MmWTt27KixY8daH1+7dk3ly5fX7t279fDhQ3344YeaN2+eWeUBAJCokcMAAJiLLAYAwDzkMADAHkybZP3rr79Ur1496+O5c+cqRYoU2rdvn1auXKmhQ4dq0qRJZpUHAECiRg4DAGAushgAAPOQwwAAezBtkvXKlSvy9/e3Pt68ebPeeecdOTk5SZLq1aunkydPmlUeAACJGjkMAIC5yGIAAMxDDgMA7MG0SdakSZMqODjY+njXrl0qVaqU9bHFYtHDhw9NqAwAgMSPHAYAwFxkMQAA5iGHAQD2YNoka4kSJTRhwgRFRERoyZIlCgkJUZUqVazbT5w4oYwZM5pVHgAAiRo5DACAuchiAADMQw4DAOzByawdDxo0SNWqVdMPP/ygsLAwffXVV/L29rZuX7hwoSpWrGhWeQAAJGrkMAAA5iKLAQAwDzkMALAH0yZZCxUqpKNHj2r79u1KmzatSpYsabO9adOmypMnj0nVAQCQuJHDAACYiywGAMA85DAAwB4shmEYZhdhb+61xpldAhCv/l3Q0ewSgHjnm9zF7BIQB8UGbzG7BCBefV0/t9klAPGqfv60ZpeAOHIv3MnsEoB4dXP3RLNLAOKVm2mXxsAe0rVbanYJQLz6pU8Ns0sA4lWhTEli1M+0e7JKUlhYmEaNGqUiRYrIy8tLSZIkUZEiRTR69GiFhoaaWRoAAIkeOQwAgLnIYgAAzEMOAwDiyrTvRN2/f1/Vq1fXjh07VK1aNVWoUEGGYejYsWP68ssvtWrVKq1fv15ubm5mlQgAQKJFDgMAYC6yGAAA85DDAAB7MG2SddiwYbpw4YL27t2rAgUK2Gzbv3+/6tWrp+HDh6t///7mFAgAQCJGDgMAYC6yGAAA85DDAAB7MG254IULF2rs2LGRQkySChYsqNGjR2v+/PkmVAYAQOJHDgMAYC6yGAAA85DDAAB7MG2S9fz58ypRokS020uVKqXz58+/wooAAHhzkMMAAJiLLAYAwDzkMADAHkybZE2aNKmuXbsW7fYrV64oadKkr7AiAADeHOQwAADmIosBADAPOQwAsAfTJlkrV66soUOHRrt9+PDhqlSp0qsrCACANwg5DACAuchiAADMQw4DAOzByawd9+vXTyVLllSpUqXUrVs35cqVS5J05MgRjRs3TkeOHNFff/1lVnkAACRq5DAAAOYiiwEAMA85DACwB9MmWfPkyaMNGzaobdu2atq0qSwWiyTJMAzlypVLv/76q/LmzWtWeQAAJGrkMAAA5iKLAQAwDzkMALAH0yZZpcc3ED98+LD27dunEydOSJJy5MihQoUK6e7du/rjjz9UoUIFM0sEACDRIocBADAXWQwAgHnIYQBAXJk6yfpEoUKFVKhQIZu2U6dOqXLlygoPDzenKAAA3hDkMAAA5iKLAQAwDzkMAHhZDmYXAAAAAAAAAAAAAACvEyZZAQAAAAAAAAAAACAWmGQFAAAAAAAAAAAAgFgw7Z6sq1ateu72M2fOvKJKAAB485DDAACYiywGAMA85DAAwB5Mm2Rt0KDBC/tYLJb4LwQAgDcQOQwAgLnIYgAAzEMOAwDswbRJ1oiICLN2DQDAG48cBgDAXGQxAADmIYcBAPbAPVkBAAAAAAAAAAAAIBZMu5IVCYNvSk8NblNeNYpllruLk05evKn24zdo76lrkqTeLUqpccWcypA6iR6FhmvvqWvqP2ebdh+/8txxOzUorI9rF1DG1EkVePu+lv95Ul/P+lMPQ8NjvG8grlYuXaRVyxbpyqVLkqTMWbKqZdv/qWSZ8tY+586c1rRJ47T/nz2KMCKU2T+b+g0drTRp00U55pnTpzTru0k6cfyIrl6+pI6ffaFGzT6ItoYfZ0/X9Cnf6N0m76tTty/te4AAXnvtKmRWuwr+Nm037jzUW+O3S5JSeDrr0ypZVSpLCiVxc9I/54M1at1JXbh5P9oxs6Ty0P8q+itXuiTyTe6uMetPasGugEj9GhX11QelMymVl4tOX7+nMetPat+FW/Y9QOApm5f9oHXzv1e52o1Ur/WnkiTDMLRh8Wzt3Lha9++GKFO2PGrw8WdKm9E/2nHCw8K0efkP+vu3X3U76IZS+2bU2+9/opyFS9r0275uuX5ftVAhN4OUJmNm1fuwk/zzFIzXYwTw+vFNnUyDu9RXjbJ55e7qrJPnr6n9gB+19+gFSdK0Ae/rg3qlbJ6z68AZVWw15rnjdmpeSR83Lq+Mab0VGHxXyzfu1dffrtLDR2GR+nZvU0ODPq2niT9uUY/RS+13cHjjLV44X4sXLdClixclSVmzZdcn7TuoXPmKkfoO7N9XS39apB5f9tL7LT+MdsxTp05q8rcTdPTIYV26dDHa/levXtX4saO0betWPXz4QH5+mdV/0BDlyZvPXocHIJFIm9xNfRrmV+V8aeTu4qh/r97R53P+1oHzwXJytOjL+nlVNX9a+aXy1O37odp69JqGLDukq7ceRDumk6NFn76VU++V8VPa5O7690qIhiw7pC2Hr8Z434A9rF+9RBtWL9H1q5clSRn8sujd9z9S4RJlJUlNqheL8nktPu6seu+1jHbcnVs3adHsqbp6OUBp0mVQ09YdVKJc5Sj7Ll8wSwtnTlKtd5rpww6fx/GI8CwmWd9gyb1ctXlME/2+P0ANvl6ua8H3lcU3mYLvPrT2OXXxprpO3qIzV27J3cVJn75TWKuHNFS+trN041bUH/A2rZxLg1qX0//GrdeOI5eVPUNyfd+tpiTpi2m/x3jfQFyl9kmjjzt8pvQZM0mSfl27Sn16dNa0eT/JP0s2XQy4oM7tWqpWvYb68OMO8vTy0rkzZ+Ti4hLtmA8fPJBv+gyqVLWGJo0f+dz9HztySGtWLFGWbDnselwAEpd/r91Rhx/3Wx+HG4b1v0c3zq+wCEOfLz6ouw/D1KJURk1+v5AaT92pB6FRL2/l5uyogOAH2nj0urpVzxZln+p5fPR5jewa/ssJ7b9wSw2L+GpCswJqPHWXrt4mi2F/F04d1c6Nq5XOL6tN+28rFmjrmsV6r2MvpfbNoE1L5un7gZ+rx4Qf5ObuEeVYvy6Yrn+2btC7/+shn/SZdGLfLs0Z1UcdB09S+iyPM3ffts1aPXuiGnzUVZlz5dPODas1Y+iX+nzcHHmnThPvxwvg9ZA8ibs2z+6m33efVINOk3UtKERZMqZScIjtue6v2w7rk34/WB8/eurLw1FpWquYBnWur//1/1E79p9Wdj8ffT/w8RczvxizzKZv0TyZ1LZhGR04EfkLUUBc+aRJqy5duytjpsfnxKtXrlCXTh21aOlyZcuW3dpv86aNOnRgv1L7+LxwzAf37ytDxgyqXvMtjR4xLMo+t2/d0ofvN1OxEiU1aer3SpEyhQIuXFCSJEntc2AAEo1kHs5a9UUlbTt+XS0mbNONkIfKnNpTt+6HSpLcXRyVP1NyjVtzVEcCbimZh4sGNimgOR3L6K2hm6Md98v6efVuyUzqPu8fnboSokp502hG+9KqN2KLDv3/l4tftG/AHlKm8lHztp2UJn1GSdIf69doVL/PNWLKj8qYOau+W7TOpv/eXdv13dhBKlm+SrRjnjhyQOMHf6X3PvyfSpStrF3btmj84J4aMG6Gsue2/TLTqeOHtenn5cqUJXs0oyGumGR9g33euLgCrt/RJ+PWW9vOX7tt02fRb8dtHn/5/R9q/VZ+5fNPpd/2XYhy3JK50mnHkUvW556/dluLfzuuYjnTxmrfQFyVKV/J5vFH7Ttr1bJFOnLogPyzZNOMKRNUskx5/e/TbtY+vv8feNHJlSefcuV5HFbTJo+Ptt/9e/c0pG9Pdf+qn+bNmvbSxwAg8QuLMBR491Gk9kwp3FUgQzK9N3WnTt+4J0ka/ssJre9aTjXzptHKfZejHO/I5RAduRwiSepUJUuUfVqUzKiV+y5bxxi74ZRKZ02hRkXTa9KW0/Y4LMDq4f17WvDNYDX6Xw9tWjLP2m4Yhv5c+5OqNPxA+UtVkCQ1+bSXBrZ9R/u2blSpGvWiHO/vP9arasMPlLvI4yvLStdsoBP7duuP1YvVrEsfSdLW1YtVvMrbKlmtjiSpXutPdWLfLv21fqVqtWgXn4cL4DXyeevqCrhyU5/0/28C9fzloEj9Hj0K09XAkBiPW7KAv3bsO61F6/ZYx1y8bo+K5fWz6efp7qJZQz9Uh0EL1POjt17yKIDoVaps+wHtp126avHCBTqwf591kvXq1asaNmSgpkyboU/bf/LCMfPlL6B8+QtIkiaMi/qK7pkzvleatGk1aMh/k7Dp02d42cMAkIh1rJlTl27eV9c5f1vbAgLvWf875H6Ymo7/0+Y5vRfs17reVZQ+hbsuBkV9EVCjUpn0zc/HtPnQ49UY5/5+WpXzptH/qudQp5m7Y7RvwB6Klq5g87hpm45av2apTh49qIyZsyp5ilQ22/fs+F15CxZTmnTR5+bPyxaoQNGSeqdZa0nSO5la6+iBf/Tzsvnq0nuotd+D+/c0cdjXate1t5b/OMOOR4WncU/WN1jtUln0z8mr+vGr2jq34BPtmNhCrd+KftkWZycHta2VX8F3Hujg6evR9tt+5KIKZ/NRsRyPrxLInDaZahbPrHW7zrz0voG4Cg8P1+b1v+jB/fvKm6+gIiIi9Nf2P5Qhk596dP5E77xVUe3bNNefv2+yy/7GjxqiUmXLq2iJ0nYZD0DilSmFh37pUkYrO5XS0HfyKH1yN0mSs+Pjt2kPw/+7YjXCkMLCI1QoY7KX3p+Tg0W50nnpr9O2HyL/dTpIBTK8/LhAdFZMH69cRUorewHbZZCCrl1WSHCQchT8r93J2UVZ8hTUueOHoh0vPDRUTs+sOuHk4qKzxw5KksJCQ3Xx9AnlKFjcpk/2gsV19jnjAnjz1K6YX/8cOa8fR7bRuU3DtGPBl2r9TplI/coXy65zm4bpwIq+mvR1M6X29nruuNv3nVbhPBmtk6qZ06dUzbJ5te7Pwzb9xvdqonVbD2nLzuNRDQPYVXh4uH75ea3u37+nggULS5IiIiLUu2cPfdi6rc2VrXH1+5bNyps3n7p37axK5UvrvXcbaOlPi+02PoDEo2bBdNp/7qamfVJSB0fX1vo+VdWiXObnPieph7MiIgzduhf9FacuTg56+MzqT/cfhatEtpRx2jcQFxHh4dq25Vc9fHBfOfIUiLQ9+Gag9u78U5Vr1X/uOCeOHFCBora3yylYrJROHDlg0zbj2xEqXLKsChSx7Qv7Mv1K1ixZsmj37t1KmTKlTXtwcLCKFCmi06e5miK++KdNpo9rF9CEZf9o5KJdKpYjrcb8r7IehoZr/qaj1n61Svhrbs+35eHqrCtBd1Wn9zIF3o5+zfuffj+hVMk8tGl0E1kskrOTo75bs1+jf9od630DcXX61Al1/Oh9PXr0SO7uHho4YrwyZ8mqoMAbun/vnhbMnak2/+ukTzp11a4df6rvl101dvIMFSpS/MWDR2Pz+l908vgRTZ210I5HAsQPcthchy7eVr9VR3Uu8J5SermobTk/zfiwiJp8t0tnA+/pUvB9daqcVUN/Pq77j8LVolRGpUriqlReri+9z+QeznJycFDQM1fPBt0NVSqv6JdLB17Gvj836eKZE/p0+HeRtoXcfDzR75U8hU27V3JvBV+/Gqn/EzkKFdfW1Yvln6egUqbx1amDf+vI7m2KiHj8IcrdkFuKiAiXVzLbcZMk81ZIcOQr1ACzkcXm8U+fSh83Lq8JP2zWyBnrVSyfn8Z80UgPQ8M0f80uSdL6bUe0bMNenb8cpMzpU6pvhzr6ZVpnlWk+Uo9CI99fVZJ++vVvpfL20qZZXWWRRc7Ojvpu8R8aPWuDtU/jmkVVKFdGlXv/+bcgAeLq5Inj+qB5Uz169FAeHh4aN2GSsmZ7fEuJWTO+l6OTk5q/H/09315GQMAFLV60QB+0aq227f6nQwcPaMSwwXJxcVHd+g3sui8grshhc2VK7amWFbNo2oaTmvDzMRX2T6FBTQvpUViEfvrrfKT+rk4O6v1OPi3fdUF3HkSdw5L02+Gr+qR6dv118obOXr+j8rl89FahdHKwWF5638DLOn/mlPp0bq3QR4/k5u6u7v1GKYNf5JXHfl+/Rm4entHeW/WJ4JuBSuZt+29WMu+UCr4ZaH28bcuvOnPymIZOmmufg0C0TJ9kPXv2rMLDI9/P5OHDh7p48eILn//w4UM9fGh77zAjIkwWB9MPLcFzsFj0z8mr6jdnmyRp/7/XlccvpdrVLmAz0fn7/gsq2fEHpUrmrtZv5dcPvWqrwmcLdD2ae7KWz59BXzQpoS6TNmv38cvK6ptcoz+ppCtBJTV8wc5Y7RuIq4x+/po+b4nu3AnRH5s3aPjAPho/ZZa8kiSRJJWpUEmNmz0+ocyWI5cOH9yv1ct+eulJ1mtXr2ji2OEaOWGaXFxffhIEeFXimsNP+j6bxRFhj+TgxITdi2z/978Jn3+v39WBgFta0bGU6hRIpx93XtAXSw7p6zq5tKV7eYVFRGjXmZvadirwOSPG3FO3fpUkWfR4+VbAXoJvXNOqWd/qo69Hy9kl+ky0PPVBh6THf5zPtj2lXuvOWjp1lEZ3+UAWWZQira+KVa6lPVt+eWbcZ4aVZFH04wJmia8sNiLCZXFwtEuNiZWDg0X/HDmvfhNXS5L2Hw9Qnqzp1K5xeesk65L1/1j7H/n3sv45cl7Hfx6oWuXzauXm/VGOW75odn3Rtqa6DFuk3QfPKWvGVBrdo5Gu3Lit4d+vU4Y0yTWqx7uq22GSHj6K/gNiwB4yZ/bX4qUrFBJyWxs3rNfXX32pGbN/0MOHD/TjvLlauGRZ5CyOo4gIQ3nz5VPnzx7fmid37jz699QpLV60gElWJDjxlsPhobI4OtulxsTMwWLR/nM3NWzF49UeDl24pRzpkqplxSyRJjqdHC2a2q6kHByknvP3Pnfcvov2a3TLoto6sIYMw9DZ63e1cNs5NS3739L9sdk3EBe+Gfw0cup83b0Top1/btakUf3Vf8y0SBOtv/26SuWqvCWX55w/P/FschuGYT3fvXHtiuZMHqOvhk+M0ViIG9NmIletWmX9719//VXJkv23PF14eLg2bdqkzJkzv3CcYcOGacCAATZtjllryDk79zN5kStBd3X0vO0HtccuBKlBWdslYu49DNPpy7d0+vIt7Tp2RQenf6hWNfNp9OLdikq/lmW0YPNRzf718XJsh88GysPVWZM6V9OIhTtlGDHfNxBXzs7OSp8xkyQpZ+68Onb0kJYu+kGdu38lR0cnZfbPatM/U2Z/Hdz//Ddqz3Pi2GHdvBmkTz5sYm2LCA/Xgb1/a/mSBVq/9W85OvJhF8xnrxyWos7idJVbyrfKh/Yo9Y3yIDRC/167q4wp3CVJx67cUYvpe+Tp6ihnRwcF3wvV7NZFdeTyy9/HPPheqMIiIpTymatWvT2dFXg3+uWWgNgKOH1cd27d1IQv/rsHakREuM4c3a/tvyxXjwmP788acjNQSZ/6Fu6dW8FKksw72nG9kiVXqy+HKPTRQ90Lua2kKVLplx++UwqfdJIkzyTJ5ODgGOmq1Tu3bsorefTjAq9afGexY5rick5Xwi61JlZXbtzW0dNXbNqOnbmiBlULPfc55y8HKVum1NH26dehthas3aXZy3dIkg6fuiQPd1dN6tNMI6b/qsK5MylNyqTa/uMX1uc4OTmqXJGs+l+TCkpW8jNFRPDFJ9iHs4uLMvk9nlTImy+/Dh86qB9/mKssWbIoKChQb1X772qZ8PBwjRk1Qj/Om6tfNmx+6X2mTp1aWbLanmtnyZJFGzf8+tJjAvYW3znsWaSxkhRtEs0z8MS1W/d14pLt+e3JKyGqXSS9TZuTo0XT2pVUxpQeajx263OvYpWkwDuP1HryDrk6Ocjby0VXgh+od8N8On/jv3uuxnTfQFw5OTsrbfqMkqSsOfPo3+NH9PPyBWr3WW9rn6MH9+rShXPq0ntYdMNYJX/mqlVJuh0cpGTej1dzOnPymG4FB6lXhw+s2yMiwnX04F79unKxfvx5uxz4fNpuTJtkbdCggfW/W7VqZbPN2dlZmTNn1pgxY144Tq9evdStWzebNp/GkZcjQ2Q7jlxSjgy2y6hlT++t89ee/8GtxWKRq3P0/yd0d3VSxDNXwkREGLJYLLJYLDIM46X3DcSVYUihoY/k7OysXHny6sK5szbbA86fU5q06V56/CLFSmnm/GU2bSMGfa1Mfv5q1rINE6xIMOyVw1LUWVxp7I441/gmcna0KHMqD+29cMum/e7DcEnhyujtrtzpkmjK7y+/ZFVYhKFjl++opH8K/Xb8hrW9pH8K/X7ixnOeCcROtvxF1W3sLJu2xZOGyyd9JlVq0Fwp0vgqSfIUOnlgj9JnySHp8f1UTx/Zr7ff/+SF4zu7uCpZytQKDwvTwZ1/qEDpSpIen8Cmz5JDJw/sUb6SFaz9Tx7Yo7zFy9nvAIE4iu8s9in/ZZxrTOx27DutHH4+Nm3ZM/no/OXolxZPkcxTGdJ46/KN6M9d3d1cIk2SRkREyGJ5fJX9ll3HVbTREJvt0wa8r+NnrmrM7A1MsCJeGYah0EePVKdefZUsbXsP4vbt2qpO3fpq8E7DOO2jUOEiOnvmjE3bubNn5evLxAUSjvjO4Rxdf45zjW+CXacClS1tEpu2rGm8FBD032TokwlWfx8vNRrzh24+c+ub53kYFqErwQ/k5GhR7SLptXpPQKz2DcQLw1DYI9svuW/5ZaWyZM+tzFlzvPDpOfIU0IG/d6r2uy2sbQf+3mm9z2u+wsU1aprtbeymjB6o9Bn9VK9JKyZY7cy0SdYn90zy9/fXnj17Iq17H1Ourq5yfWZJTpYKjplvV/yjLWOaqEeT4lr6xwkVz5lWbWrlV6cJGyVJHq5O+rJpSa3d+a+uBN1ViiTualengNKn8tKyrSet40z/vKYuBd5R39mPl/79eedpdW5YRPv/vaZdx64oq29y9W1ZRmv/+td6sviifQP28P3kb1SydDn5pEmre/fuavOGddr/z26NGD9FktTk/dYa2Lu7ChQuqsJFS2jXX39q+5+/a/zkmdYxhvb/SqlT++jjjp9JkkJDQ3XuzL+SHn8QfOP6NZ06cUzu7h5KnzGTPDw95Z/V9opsN3d3JU2WPFI7YCZ75bAUdRazVHDMdKmaVVtPBurK7Qfy9nh8T1ZPVyetOXBZklQ1d2oF3wvVlVsPlM3HS5/XyKbfj1/XztM3rWMMqJdb10IeatKWxxOvTg4WZUntKUlydnRQ6iSuypHGS/cehSvg5uOl/n/ceUED6+fW0cu3dSDgthoW8VXaZK5a+k/MlsMCYsLN3UNpM9kuf+Ti6i6PJMms7eVqN9bmZT8qVboMSpUugzYv+0HOrq4qVL6a9TkLJwxRspSpVavF4ytiz584oltBN+Trn023A69rw+LZMiIiVKlBM+tzytd9T4u+HaIMWXIqU8682rlhjYJvXFOpGvVewZEDMRPfWcxSwS/27Q+btWX25+rRpoaWbvhHxfNmVpt3y6rToAWSJE93F/X5X22t2LRPl6/fkp9vSg38tK4Cg+9o1VNLBU8f9IEuXbulvt8+virq5z8OqfP7lbX/eIB2HTyrrBlTq2/7Olr7+0FFRBi6c++hjvx72aaWu/cfKejW3UjtQFxMGD9W5cpXUJq0aXXv7l2t++Vn7dm9S5O/m67kyb2V/JkVHpydnJUqVSpl9v8vv3v3+kI+PmnUpevnkqTQR4/077+Pz4lDQx/p2rWrOnb0qDw8PKxXzL7fspVavd9M06dNVY2atXTo4AEtWbJYffsPfEVHDrxYvOcwSwXHyLSNp7S6ZyV1rpVTq/YEqLB/Cr1f3l895j1ert/RwaLvPyml/JmSq+XE7XJwsCh10sevdfDdRwoNf/xZ84TWxXQl+L6GLn+89G9hf2+lS+6uQxduKV1yN31eN48cLBZN+vVEjPcN2MOCGZNUqEQZpUydRg/u39P2Lb/q8IG/9dXQCdY+9+7e0V9bN+qDdp9FOcbEEX2VIpWPmrftJEmq9U5T9e/WTisXzlaxMpW0Z/tvOvjPTg0YN0OS5O7hqUz+2WzGcHNzk1fS5JHaEXemzkaGhoYqc+bMCgwMjFOQ4eX8feKqmgxarYEfltNXzUvp7JVb6vHdb1q45ZgkKTzCUM6M3nq/Wl2lTOamoNsPtOfEVVXrsdhmqd+MPklsrlwdvuDxksD9WpaVb0ov3bh1T2t3nlb/OdtjvG/AHm4GBWrogK8UdOO6PL2SKEu27BoxfoqKlXz8bd3ylaqq65d9NX/OdH07drgyZsqsAcPGKn+hItYxrl29LAeH/1a5D7x+TR9/0Nj6eNGPs7Xox9kqWKSYxk+xvVoHSOjIYfOlSeqqIe/kUXIPZ928G6pDF2+p9ay/deXW4/v5pPJyUdfq2ZTS00U37jzS2gNXNH3rWZsx0iZztcnh1ElcNf/j/+4r3bJ0JrUsnUl/n7upT+btkyRtOHJNydyd9FH5zErl5ap/r99Vl4UHrPsFXpVKDZop9NFDLf9+nO7fvaOM2XPr469Hy83dw9on+MY1WRwcrI9DQx/p14XTFXT1slzc3JWrcEk16dxb7p7/fQu9UNkquhdySxuXzNXtm4FKm8lfbb4aIe/UaV/p8QEvQhab6+8j59Xk8+818NN6+qpdLZ29GKgeo5Zq4S97JD0+J86bzVfN65RQ8iTuunLjtn7ffUIffDlTd+79l5kZ06awufp0+PR1MgxD/TrUka9PMt24eUdr/zik/v9/71fgVQkMvKHePb/Q9evX5JUkiXLkyKnJ301X6TJlYzzGlcuX5WD5L4evXb+mJo0aWB/PmTVTc2bNVLHiJTRj9uNbAeTLX0Bjv5moCePH6rspk5Q+QwZ98eVXql2HLzshYSGHzbf/3E21mbxDXzXMp651cuvCjbvqu2i/lu26IElK5+2utwr5SpI29a1m89yGo3/Xjv9fjSl9Cg+b82I3Z0d9WT+vMqX21L2HYdp08Io+nblbt+//d/Xgi/YN2MOt4EBNGtFXN4NuyMPTS5n8s+uroRNUoGgpa5/tv62XYRgqWyXqW2AGXrtik8U58xZUl95DtGj2FC2aM1Vp0mVQl97DlD13vng/HkRmMQzD1HVoUqdOre3btyt7dvtd4eVea5zdxgISon8XdDS7BCDe+SbnSshXIT5yWJKKDd5i1/GAhObr+rnNLgGIV/XzMyH9qsRXFrsX7mTX8YCE5ubuiWaXAMQrNxbqeyXiK4fTtVtq1/GAhOaXPjXMLgGIV4UyJXlxJ0kOL+4Sv1q2bKkZM2aYXQYAAG8kchgAAHORxQAAmIccBgDEhenfiXr06JGmT5+uDRs2qFixYvL09LTZPnbsWJMqAwAg8SOHAQAwF1kMAIB5yGEAQFyYPsl66NAhFSny+P6HJ06csNlmsViiegoAALATchgAAHORxQAAmIccBgDEhemTrFu2cM82AADMQg4DAGAushgAAPOQwwCAuDD9nqxPCwgI0MWLF80uAwCANxI5DACAuchiAADMQw4DAGLL9EnWiIgIDRw4UMmSJZOfn58yZcqk5MmTa9CgQYqIiDC7PAAAEjVyGAAAc5HFAACYhxwGAMSF6csF9+7dWzNmzNDw4cNVtmxZGYahbdu2qX///nrw4IGGDBlidokAACRa5DAAAOYiiwEAMA85DACIC9MnWefMmaPp06erXr161raCBQsqffr06tChA0EGAEA8IocBADAXWQwAgHnIYQBAXJi+XHBQUJBy5coVqT1XrlwKCgoyoSIAAN4c5DAAAOYiiwEAMA85DACIC9MnWQsWLKiJEydGap84caIKFixoQkUAALw5yGEAAMxFFgMAYB5yGAAQF6YvFzxy5EjVrl1bGzduVOnSpWWxWLR9+3ZduHBBP//8s9nlAQCQqJHDAACYiywGAMA85DAAIC5Mv5K1YsWKOnHihN555x0FBwcrKChIDRs21PHjx1W+fHmzywMAIFEjhwEAMBdZDACAechhAEBcmH4lqyT5+vpyE3EAAExCDgMAYC6yGAAA85DDAICXlSAmWYODg7Vr1y5du3ZNERERNttatmxpUlUAALwZyGEAAMxFFgMAYB5yGADwskyfZF29erVatGihu3fvKkmSJLJYLNZtFouFIAMAIB6RwwAAmIssBgDAPOQwACAuTL8n6+eff642bdooJCREwcHBunnzpvUnKCjI7PIAAEjUyGEAAMxFFgMAYB5yGAAQF6ZPsl68eFGdO3eWh4eH2aUAAPDGIYcBADAXWQwAgHnIYQBAXJg+yVqzZk3t2bPH7DIAAHgjkcMAAJiLLAYAwDzkMAAgLky5J+uqVaus/127dm316NFDR44cUf78+eXs7GzTt169eq+6PAAAEjVyGAAAc5HFAACYhxwGANiLxTAM41Xv1MEhZhfQWiwWhYeHx3p891rjYv0c4HXy74KOZpcAxDvf5C5ml5BoxXcOS1KxwVte6nnA6+Lr+rnNLgGIV/XzpzW7hETtVWSxe+FOL/U84HVxc/dEs0sA4pWbKZfGvBleRQ6na7f0pZ4HvC5+6VPD7BKAeFUoU5IY9TMlriMiIszYLQAAEDkMAIDZyGIAAMxDDgMA7MX0e7ICAAAAAAAAAAAAwOvEtEnWnTt36pdffrFpmzt3rvz9/eXj46N27drp4cOHJlUHAEDiRg4DAGAushgAAPOQwwAAezBtkrV///46cOCA9fHBgwfVtm1bVatWTT179tTq1as1bNgws8oDACBRI4cBADAXWQwAgHnIYQCAPZg2ybpv3z5VrVrV+njhwoUqWbKkvv/+e3Xr1k0TJkzQ4sWLzSoPAIBEjRwGAMBcZDEAAOYhhwEA9mDaJOvNmzeVJk0a6+Pff/9db731lvVx8eLFdeHCBTNKAwAg0SOHAQAwF1kMAIB5yGEAgD2YNsmaJk0anTlzRpL06NEj/fPPPypdurR1e0hIiJydnc0qDwCARI0cBgDAXGQxAADmIYcBAPZg2iTrW2+9pZ49e2rr1q3q1auXPDw8VL58eev2AwcOKGvWrGaVBwBAokYOAwBgLrIYAADzkMMAAHtwMmvHgwcPVsOGDVWxYkV5eXlpzpw5cnFxsW6fOXOmatSoYVZ5AAAkauQwAADmIosBADAPOQwAsAfTJllTp06trVu36tatW/Ly8pKjo6PN9p9++kleXl4mVQcAQOJGDgMAYC6yGAAA85DDAAB7MG2S9YlkyZJF2Z4iRYpXXAkAAG8echgAAHORxQAAmIccBgDEhWn3ZAUAAAAAAAAAAACA11GMrmRdtWpVjAesV6/eSxcDAACiRhYDAGAechgAAHORxQCAhChGk6wNGjSI0WAWi0Xh4eFxqQcAAESBLAYAwDzkMAAA5iKLAQAJUYwmWSMiIuK7DgAA8BxkMQAA5iGHAQAwF1kMAEiI4nRP1gcPHtirDgAA8BLIYgAAzEMOAwBgLrIYAGCmWE+yhoeHa9CgQUqfPr28vLx0+vRpSdLXX3+tGTNm2L1AAABgiywGAMA85DAAAOYiiwEACUWsJ1mHDBmi2bNna+TIkXJxcbG258+fX9OnT7drcQAAIDKyGAAA85DDAACYiywGACQUsZ5knTt3rqZNm6YWLVrI0dHR2l6gQAEdO3bMrsUBAIDIyGIAAMxDDgMAYC6yGACQUMR6kvXixYvKli1bpPaIiAiFhobapSgAABA9shgAAPOQwwAAmIssBgAkFLGeZM2bN6+2bt0aqf2nn35S4cKF7VIUAACIHlkMAIB5yGEAAMxFFgMAEgqn2D6hX79++uCDD3Tx4kVFRERo2bJlOn78uObOnas1a9bER40AAOApZDEAAOYhhwEAMBdZDABIKGJ9JWvdunW1aNEi/fzzz7JYLOrbt6+OHj2q1atXq3r16vFRIwAAeApZDACAechhAADMRRYDABKKWF/JKkk1a9ZUzZo17V0LAACIIbIYAADzkMMAAJiLLAYAJAQvNckqSXv27NHRo0dlsViUO3duFS1a1J51AQCAFyCLAQAwDzkMAIC5yGIAgNliPckaEBCgZs2aadu2bUqePLkkKTg4WGXKlNGCBQuUMWNGe9cIAACeQhYDAGAechgAAHORxQCAhCLW92Rt06aNQkNDdfToUQUFBSkoKEhHjx6VYRhq27ZtfNQIAACeQhYDAGAechgAAHORxQCAhCLWV7Ju3bpV27dvV86cOa1tOXPm1LfffquyZcvatTgAABAZWQwAgHnIYQAAzEUWAwASilhfyZopUyaFhoZGag8LC1P69OntUhQAAIgeWQwAgHnIYQAAzEUWAwASilhPso4cOVKffvqp9uzZI8MwJD2+yXiXLl00evRouxcIAABskcUAAJiHHAYAwFxkMQAgobAYT5LoOby9vWWxWKyP7969q7CwMDk5PV5t+Ml/e3p6KigoKP6qjSH3WuPMLgGIV/8u6Gh2CUC8803uYnYJCcrrlsXFBm8xuwQgXn1dP7fZJQDxqn7+tGaXkKC8bjksSe6FO5ldAhCvbu6eaHYJQLxyi/VN3hK31y2L07VbanYJQLz6pU8Ns0sA4lWhTEli1C9GcT1+/Pi41AIAAOKILAYAwDzkMAAA5iKLAQAJUYwmWVu1ahXfdQAAgOcgiwEAMA85DACAuchiAEBCFKeFJ+7fvx/pJuNJkyaNU0EAACDmyGIAAMxDDgMAYC6yGABgJofYPuHu3bvq1KmTfHx85OXlJW9vb5sfAAAQv8hiAADMQw4DAGAushgAkFDEepL1iy++0ObNmzV58mS5urpq+vTpGjBggHx9fTV37tz4qBEAADyFLAYAwDzkMAAA5iKLAQAJRayXC169erXmzp2rSpUqqU2bNipfvryyZcsmPz8//fjjj2rRokV81AkAAP4fWQwAgHnIYQAAzEUWAwASilhfyRoUFCR/f39Jj9e3DwoKkiSVK1dOf/zxh32rAwAAkZDFAACYhxwGAMBcZDEAIKGI9SRrlixZdPbsWUlSnjx5tHjxYkmPv0GUPHlye9YGAACiQBYDAGAechgAAHORxQCAhCLWk6ytW7fW/v37JUm9evWyrn3ftWtX9ejRw+4FAgAAW2QxAADmIYcBADAXWQwASCgshmEYcRng/Pnz2rNnj7JmzaqCBQvaq644ca81zuwSgHj174KOZpcAxDvf5C5ml/DaSIhZXGzwFrNLAOLV1/Vzm10CEK/q509rdgmvjYSYw5LkXriT2SUA8erm7olmlwDEKzcnsyt4fSTELE7XbqnZJQDx6pc+NcwuAYhXhTIliVG/WF/J+qxMmTKpYcOGSpEihdq0aRPX4QAAQCyRxQAAmIccBgDAXGQxAMAscZ5kfSIoKEhz5syx13AAACCWyGIAAMxDDgMAYC6yGADwqtltkhUAAAAAAAAAAAAA3gRMsgIAAAAAAAAAAABALDDJCgAAAAAAAAAAAACx4BTTjg0bNnzu9uDg4LjWYjc3V3c1uwQgXnkX72R2CUC8u793otklJDivUxb/2bOy2SUA8YosRmJHDkf2OuWwJJ37Y5zZJQDxyvut4WaXAMSr+xt7ml1CgvM6ZfGZye+aXQIQrzgnRmIX03PiGE+yJkuW7IXbW7ZsGdPhAABALJHFAACYhxwGAMBcZDEAIKGJ8STrrFmz4rMOAADwAmQxAADmIYcBADAXWQwASGi4JysAAAAAAAAAAAAAxAKTrAAAAAAAAAAAAAAQC0yyAgAAAAAAAAAAAEAsMMkKAAAAAAAAAAAAALHAJCsAAAAAAAAAAAAAxMJLTbLOmzdPZcuWla+vr86dOydJGj9+vFauXGnX4gAAQNTIYgAAzEMOAwBgLrIYAJAQxHqSdcqUKerWrZvefvttBQcHKzw8XJKUPHlyjR8/3t71AQCAZ5DFAACYhxwGAMBcZDEAIKGI9STrt99+q++//169e/eWo6Ojtb1YsWI6ePCgXYsDAACRkcUAAJiHHAYAwFxkMQAgoYj1JOuZM2dUuHDhSO2urq66e/euXYoCAADRI4sBADAPOQwAgLnIYgBAQhHrSVZ/f3/t27cvUvsvv/yiPHny2KMmAADwHGQxAADmIYcBADAXWQwASCicYvuEHj16qGPHjnrw4IEMw9CuXbu0YMECDRs2TNOnT4+PGgEAwFPIYgAAzEMOAwBgLrIYAJBQxHqStXXr1goLC9MXX3yhe/fuqXnz5kqfPr2++eYbNW3aND5qBAAATyGLAQAwDzkMAIC5yGIAQEJhMQzDeNkn37hxQxEREfLx8bFnTXH2IMzsCoD45V28k9klAPHu/t6JZpfwWiCLAXOQxUjsyOGYSag5LEnXQkLNLgGIV37vjDG7BCBe3d/Y0+wSXgsJNYs5J0ZixzkxEruYnhPH+krWp6VKlSouTwcAAHFEFgMAYB5yGAAAc5HFAAAzxXqS1d/fXxaLJdrtp0+fjlNBAADg+chiAADMQw4DAGAushgAkFDEepL1s88+s3kcGhqqvXv3at26derRo4e96gIAANEgiwEAMA85DACAuchiAEBCEetJ1i5dukTZPmnSJO3ZsyfOBQEAgOcjiwEAMA85DACAuchiAEBC4WCvgWrVqqWlS5faazgAABBLZDEAAOYhhwEAMBdZDAB41ew2ybpkyRKlSJHCXsMBAIBYIosBADAPOQwAgLnIYgDAqxbr5YILFy5sc2NxwzB05coVXb9+XZMnT7ZrcQAAIDKyGAAA85DDAACYiywGACQUsZ5kbdCggc1jBwcHpU6dWpUqVVKuXLnsVRcAAIgGWQwAgHnIYQAAzEUWAwASilhNsoaFhSlz5syqWbOm0qZNG181AQCAaJDFAACYhxwGAMBcZDEAICGJ1T1ZnZyc1L59ez18+DC+6gEAAM9BFgMAYB5yGAAAc5HFAICEJFaTrJJUsmRJ7d27Nz5qAQAAMUAWAwBgHnIYAABzkcUAgIQi1vdk7dChgz7//HMFBASoaNGi8vT0tNleoEABuxUHAAAiI4sBADAPOQwAgLnIYgBAQmExDMOIScc2bdpo/PjxSp48eeRBLBYZhiGLxaLw8HB71xhrD8LMrgCIX97FO5ldAhDv7u+daHYJCQ5ZDCQcZDESO3I4stcphyXpWkio2SUA8crvnTFmlwDEq/sbe5pdQoLzOmUx58RI7DgnRmIX03PiGE+yOjo66vLly7p///5z+/n5+cVox/GJEENiR4jhTcCHu5GRxUDCQRYjsSOHI3udclhikhWJH5OsSOyYZI3sdcpizomR2HFOjMQupufEMV4u+MlcbEIIKQAA3kRkMQAA5iGHAQAwF1kMAEhoHGLT2WKxxFcdAAAgBshiAADMQw4DAGAushgAkJDE+EpWScqRI8cLgywoKChOBQEAgOiRxQAAmIccBgDAXGQxACAhidUk64ABA5QsWbL4qgUAALwAWQwAgHnIYQAAzEUWAwASklhNsjZt2lQ+Pj7xVQsAAHgBshgAAPOQwwAAmIssBgAkJDG+Jyvr3QMAYC6yGAAA85DDAACYiywGACQ0MZ5kNQwjPusAAAAvQBYDAGAechgAAHORxQCAhCbGywVHRETEZx0AAOAFyGIAAMxDDgMAYC6yGACQ0MT4SlYAAAAAAAAAAAAAQAKcZA0LC9OdO3fMLgMAgDcSOQwAgLnIYgAAzEMOAwBiw7RJ1p9//lnz5s2zaRsyZIi8vLyUPHly1ahRQzdv3jSpOgAAEjdyGAAAc5HFAACYhxwGANiDaZOso0eP1u3bt62Pt2/frr59++rrr7/W4sWLdeHCBQ0aNMis8gAASNTIYQAAzEUWAwBgHnIYAGAPpk2yHjp0SGXKlLE+XrJkiapXr67evXurYcOGGjNmjFavXm1WeQAAJGrkMAAA5iKLAQAwDzkMALAH0yZZQ0JClDJlSuvjP//8U1WqVLE+zps3ry5dumRGaQAAJHrkMAAA5iKLAQAwDzkMALAH0yZZfX19dfToUUnSnTt3tH//fpUtW9a6PTAwUB4eHmaVBwBAokYOAwBgLrIYAADzkMMAAHswbZK1UaNG+uyzzzRv3jx9/PHHSps2rUqVKmXdvmfPHuXMmdOs8gAASNTIYQAAzEUWAwBgHnIYAGAPTmbtuF+/frp06ZI6d+6stGnT6ocffpCjo6N1+4IFC1S3bl2zygMAIFEjhwEAMBdZDACAechhAIA9WAzDMMwuwt4ehJldARC/vIt3MrsEIN7d3zvR7BIQB2QxEjuyGIkdOfz6uxYSanYJQLzye2eM2SUA8er+xp5ml4A44JwYiR3nxEjsYnpObNqVrE87cOCATpw4IYvFouzZs6tAgQJmlwQAwBuDHAYAwFxkMQAA5iGHAQAvy9RJ1l27dqlt27Y6cuSInlxQa7FYlDdvXs2YMUPFixc3szwAABI1chgAAHORxQAAmIccBgDElYNZOz5y5IiqVq0qd3d3/fDDD/rnn3/0999/a968eXJ1dVXVqlV15MgRs8oDACBRI4cBADAXWQwAgHnIYQCAPZh2T9bGjRsrPDxcS5culcVisdlmGIYaNmwoZ2dnLV68ONZjs+Y9EjvWvMebgHvBxa/4zGGJLEbiRxYjsSOH4198ZzH3ZEVixz1ZkdhxT9b4xTkxEDecEyOxS/D3ZP3tt9/0yy+/RAox6fGyDF999ZXefvttEyoDACDxI4cBADAXWQwAgHnIYQCAPZi2XHBISIjSpEkT7fa0adMqJCTkFVYEAMCbgxwGAMBcZDEAAOYhhwEA9mDaJGvmzJm1a9euaLfv3LlTfn5+r7AiAADeHOQwAADmIosBADAPOQwAsAfTJlmbNGmibt266dChQ5G2HTx4UN27d1fTpk1NqAwAgMSPHAYAwFxkMQAA5iGHAQD2YDEMwzBjxw8ePFDVqlW1c+dOVa9eXblz55YkHTlyRBs3blSJEiW0efNmubm5xX5sbiyORI4bi+NNENObi+PlxGcOS2QxEj+yGIkdORz/4juLr4WE2rNcIMHxe2eM2SUA8er+xp5ml5CocU4MxA3nxEjsYnpObNokqyQ9evRI48aN04IFC3TixAlJUo4cOdS0aVN17dpVrq6uLzUuIYbEjhDDm4APd+NffOWwRBYj8SOLkdiRw69GfGYxk6xI7JhkRWLHJGv845wYeHmcEyOxey0mWZ/nwoUL6tevn2bOnBnr5xJiSOwIMbwJ+HDXXHHJYYksRuJHFiOxI4fNF9csZpIViR2TrEjsmGQ1F+fEwPNxTozELqbnxKbdk/VFgoKCNGfOHLPLAADgjUQOAwBgLrIYAADzkMMAgJhIsJOsAAAAAAAAAAAAAJAQMckKAAAAAAAAAAAAALHAJCsAAAAAAAAAAAAAxIKTWTtu2LDhc7cHBwe/mkIAAHgDkcMAAJiLLAYAwDzkMADAHkybZE2WLNkLt7ds2fIVVQMAwJuFHAYAwFxkMQAA5iGHAQD2YNok66xZs8zaNf7f4oXztXjRAl26eFGSlDVbdn3SvoPKla+o0NBQTZwwXn9u/UMBAReUxMtLJUuXUZeun8vHJ020Y4aGhmrG999p9aoVunb1qjJn9tdn3bqrbPkK1j53797RpAnfaPOmjQoKClSu3Hn0Rc+vlC9/gXg/Zrx5fFMn0+Au9VWjbF65uzrr5Plraj/gR+09ekGSdH/vxCif99W45Ro3d1O04zaoWkh9O9RWlgypdDrghvpPXK1VWw5Yt5ctklVdW1ZTkTyZlC51Mr3XdZpW/3Yg2vGAV40cThhmfP+dNm1YrzNnTsvVzU2FChXWZ926K7N/Fmufr7/qqVUrl9s8L3+BgvphweJoxz116qQmfztBR48c1qVLF9Xjy156v+WHz61jwvixavF+S33Rq3ecjwt44tjaAfLzTRmpfeqiP9R1uO3f8Le9m+qjRuXUY9QSTZz/23PH7dS8kj5uXF4Z03orMPiulm/cq6+/XaWHj8KsfV70HgAwG1lsvuVLFmrFkkW6cvmSJMk/SzZ9+NH/VKpseWufs2f+1dQJ47Tvnz2KMCLknyWbBg4fozRp071w/I2//qwBvb9QuYpVNGzMBNt9/7RQC+bNUuCN68qcJZs6f/6lChYuat8DBCT5pvTS4I8rqUaJrHJ3cdLJgCC1H/Oz9p68Kknq3bKcGlfKrQypk+hRWIT2nryi/jN/1+5jl587bjJPV/VvU0H1y+WUdxI3nb0crJ7fbdavu05b+7SrV1hdG5dU2pReOnL2hr6YvFHbDgXE6/ECMUUOJwwxOSe+d/euxo8boy2bN+pWcLB806dX8xYf6L2mzaMdNybnxH/v2a3ZM2fo6JFDun79usZNmKQqVavF16HiDfWic+L6VQqq7bvlVDh3RqXy9lLJJsN04MTFF477onNiLw9X9etQR/WqFFRqby/tPx6g7iOX6O8j5+1+jG860yZZYT6fNGnVpWt3ZcyUSZK0euUKdenUUYuWLleaNGl17OgRtftfe+XMmUu3b9/WyOFD1aVTey1YvCzaMSdOGK+1a1ap34DB8vfPou3btqprl06a8+NC5c6dR5LUv28fnTp5UkOGj1Tq1D5au2aVPvmotZat+llp0kQ/gQvEVvIk7to8u5t+331SDTpN1rWgEGXJmErBIfetfTJX62XznBpl82pqv+ZavmlftOOWLOCvecNba8CUtVq1eb/qVSmoH0a0VdU2Y7X70DlJkqe7qw6euKh5q/7SwjEfx8vxAXj97dm9S02atVDe/PkVHhaubyeM0/8+bqtlq9bKw8PD2q9sufIaOHiY9bGzs/Nzx31w/74yZMyg6jXf0ugRw57b99DBA1ry0yLlyJEzbgcDRKHc+6Pk6GCxPs6TzVc/T/1UyzbstelXt1IBFc+fWZeuBb9wzKa1imlQ5/r6X/8ftWP/aWX389H3Az+QJH0x5vH71Ji8BwAAH5+0+l+nrkqf8fE58bo1K9Xr808188cl8s+aTRcDzqvjRy1Vu15Dtfmko7y8vHT27Gm5uLi8cOwrly9p8jdjopw43bT+F00YM1zdevZR/oKFtWrZT+rR+X+a99OqGE3eAjGV3MtVm7/5QL/vO6cGvRbrWvA9ZfFNruA7D619TgUEqevE9TpzOVjuLs769N3iWj2iifK1/E43bkWdm85ODlo7sqmuBd9Vi4HLdfF6iDL4JFXIvUfWPo0q5dKo9tXUZcKv2nH4oj6qXUgrhr2nIm2n68K12/F+7ABeDzE5Jx41Yph279qpocNHyTd9eu3Ytk1DBw9Qah8fVa4S9aRoTM6J79+/p5w5c6r+Ow31+Wefxtsx4s32onNiD3cX7dj/r5Zt/EdT+raI0ZgxOSee0re58mTzVZs+c3T5+i01e7uE1k79VEXeHaxL12/Z+SjfbEyyvsEqVa5i8/jTLl21eOECHdi/Tw3fbazvptt+o6vnV33UomljXb50Sel8faMcc+3qlfqoXXuVr1BRkvRe0+bavu1PzZ09U8NGjNaDBw+0acN6jf92sooWKy5Jat/xU23ZtFE/LZyvTl26xsOR4k31eevqCrhyU5/0/8Hadv5ykE2fq4EhNo/rVsqv33ef1NmLgdGO26l5JW3aeUyjZ66XJI2euV7li2RTpxaV1arXbEnS+m1HtH7bETsdCYDEasq0GTaPBw4epsrlS+vokcPWnJQkFxcXpUqdOsbj5stfwLpCxIRxY6Ltd+/uXfX6sof6DRis77+bEsvqgRe7cfOOzePurfPp3/PXtfXvk9Y239TJNK5nY9XtMEnLv23/wjFLFvDXjn2ntWjdHkmPs33xuj0qltfP2icm7wEAoGyFSjaP23XsohVLF+nwwf3yz5pN0yZNUKky5dWhy+fWPr4ZMr5w3PDwcA3s86XatOug/fv+0Z0Q23OORT/OVe36DVW3QSNJUufPe2rXjm1avmSh/teJc2LYz+dNSyng+m19Mvpna9v5q7YfrC7abHve+uXUTWr9dkHly+Kj3/aei3LcVm8VkHcSN1XqPE9h4RGPx31m4rTzuyU0e91+zf7l8YpOPaZsUrVi/vq4bmH1nfF7nI8NQOIQk3Pi/fv3qW79BipeoqQkqdF7TbTkp0U6fOhQtJOsMTknLle+osqVr2ivQwGi9KJz4gVrd0uSMqVLEeMxX3RO7ObqrAZVC6lx12na9s+/kqQh3/2supUL6OPG5TVg8po4Hxf+42B2AUgYwsPD9cvPa3X//j0VLFg4yj537tyRxWJRkqRJox3n0aNQubjafqvX1dVN+/755//3E6bw8HC5urra9nFz0969/8TxKABbtSvm1z9HzuvHkW10btMw7VjwpVq/Uyba/j4pkuitcvk0Z8WO545bsoC/Nu04ZtO2ccdRlSqYJZpnAEDMPPkQNukz9wfas3uXKpUvrbpv19SAvn0UGBj9F0FiY+jggapQoaJKlY7+30bAXpydHNX07eKas/K/nLVYLJoxuKXGzdmko6evxGic7ftOq3CejNYTyMzpU6pm2bxa9+dha5/YvgcAgPDwcG389Wc9uH9feQsUUkREhHZs+0MZ/TKrW6d2qlu9gtq1aqY/fov+liJPzJ4+Rcm9vVWnwbuRtoWGhurEsSMqUcr236Tipcro0IH9djseQJJql86uf05c0Y9fN9C5nz7Vjqmt1frtgtH2d3ZyUNvahRR854EO/nvtuePuPHJR4zvX0NmfPtWe79uqR7PScvj/K3WcnRxUOEdabdpz1uZ5m/4+q1J50tvl2AAkTlGdExcuUkS/b9msq1evyjAM7dr5l86dPaMyZcuZVSbwUqI6J34ZLzondnJ0kJOTox48CrV53oOHoSpTOGuc9o3IuJL1DXfyxHF90LypHj16KA8PD42bMElZs2WL1O/hw4f6Ztxo1apdR15eXtGOV6ZsOc2bM1tFixVXxoyZtPOvHfptyyaFh4dLkjw9vVSwUGFNmzpZ/lmyKGXKVPrl5zU6eGC/Mvn5RTsu8DL806fSx43La8IPmzVyxnoVy+enMV800sPQMM1fsytS//frllTIvQdasXnfc8dNkyqprj1zBey1wBClSZnEnuUDeMMYhqHRI4epcJGiyp49h7W9bPkKql7zLaXz9dXFgABN/vYbfdymlRb+tCxGyxVG55ef1+ro0SOav2iJPcoHXqhe5QJKnsRdP6zeaW37vHV1hYVHaNKC32I8zk+//q1U3l7aNKurLLLI2dlR3y3+Q6NnbbD2ie17AABvrn9PnVD71i306NEjubt7aMiob+SfJasCb9zQ/Xv39OPsGfqo/adq/2k37dzxp/r0+EzfTJ2pwkWLRznegX3/aO3K5Zo5P+p8vRV8U+Hh4fJOYXtvLu8UKRV044bdjw9vNv90yfVx3cKasGSXRi7YoWI502lMx2p6GBqu+RsOWfvVKplVc/vUl4ers64E3VGdLxcq8Hb0S+z7p0uuSoX9tHDTYb3z1WJlS59C4zrXkJOjg4b9sE2pknnIydFB127etXne1Zt3lSaFZ7wdL4DXW3TnxD179dGAfl+rRpUKcnJyksViUb+Bg1WkaDETqwViL6pz4pfxonPiO/ce6q/9p9Xr41o6fuaqrgbe1ntvFVPxfH46df66PQ4FT3ntJ1kfPnyohw8f2rQZjq6RrpRE1DJn9tfipSsUEnJbGzes19dffakZs3+wmWgNDQ3Vl927KiLCUO+v+z93vC969dbAfn3UoE4tWSwWZciYUfUbNNTKFf/dx3XIsJHq9/VXql65ghwdHZUrdx7Vql1Hx46wtCrsy8HBon+OnFe/iaslSfuPByhP1nRq17h8lB+wtqxfSot+2WO9QfjzGDJsHlsskmFE0xlI5Mhi+xg2eKBOnjih2fPm27S/Vett639nz55DefPl01vVquiP339Tteo1XmpfVy5f1sjhQzR12kx+T3hlWjUoo1+3HdHl/7//S+HcGdWxWSWVaT4iVuOUL5pdX7StqS7DFmn3wXPKmjGVRvdopCs3bmv49+skxf49APC6iyqLHz5y4N/4GMjk56+Z85fqTsht/bZ5g4b0761vp81WkiSPv0BZrmJlNWnRUpKUPWcuHdq/TyuXLo5ykvXe3bsa3LeXvujdX8mTez93vxaLxbbBMCK3AXHkYLHonxOX1W/mH5Kk/aeuKk/mVGpXt7DNJOvv+8+r5CczlSqZh1q/XVA/9GmgCp/O1fXge1GP62DR9eC76jhunSIiDO09eVXpUnrps/dKatgP26z9DIPzZrwZOCe2j+jOief/OE8HDuzTNxOnyNfXV3/v2aOhgwYodWofVmXCa+XZc+KXFZNz4jZ95uq7/i10ev0QhYWFa9+xC1r0yx4Vyv3iW18gdkyfZF21alWU7RaLRW5ubsqWLZv8/f2jff6wYcM0YMAAm7beX/dTn7797VlmouXs4mK9gjRvvvw6fOigfvxhrvr2Hyjp8QRrj88/08WAAH0/a85zr2KVpBQpUmj8t5P18OFDBQcHy8fHR+PHjpZv+gzWPhkzZdLMOT/o3r17unv3jlKn9lGPzz9T+gwZnjMyEHtXbtyOtPTgsTNX1KBqoUh9yxbOqpz+afVBz1mRtj3r6o3bSpPSdtns1CmS6FpQSDTPABKuuOawRBbbw7Ahg/Tbb5s1c84PSpM27XP7pk7tI19fX50/d/al93fkyGEFBQaq2XsNrW3h4eH6e89uLVzwo3bvPShHR8eXHh94VqZ03qpSMqeadv/e2la2cFb5pPDSiZ8HWtucnBw1vFtDdWpRWblq94tyrH4damvB2l2avfzxEkuHT12Sh7urJvVpphHTf5VhGLF6DwCYLb6yuHvPPurxVV+71ZlYOTs7K0PGTJKkXHny6diRw1qy4Ad99sVXcnR0UmZ/2yXV/Pyz6MC+qG91czHggi5fuqie3TpZ2yIiHt+vslLJgvpx6Wr5pEknR0dHBQXaXrV682aQvFPaXt0KxNWVoDs6es72NhPHzgeqQfmcNm33HoTq9KVgnb4UrF1HL+ng7HZqVauARi/4K+pxA+8oNDxCERH/zZgeOx+odCm95OzkoBu37iksPEJpUth+huST3DPS1a2A2TgnThiiOyd+8OCBJowfp3ETJqpCxUqSpBw5c+n48aOaM2sGk6x4bUR1TvyyYnJOfCbghmp89I083FyU1MtNV27c1rzhrXX2on1uP4X/mD7J2qBBA1kslii+3fa4zWKxqFy5clqxYoW8vSN/E7RXr17q1q2bTZvhyLeEXpZhGAp99EjSfxOs58+d0/RZc1/4Tdynubq6Kk2aNAoNDdWmDetV461akfp4eHjIw8NDt2/d0o5tf+qzbj3sdhyAJO3Yd1o5/Hxs2rJn8tH5y0GR+rZqUFp/HzmvgycuvnDcnQfOqEqpXPr2xy3Wtqqlc+mv/afjXjTwisU1hyWyOC4Mw9CwIYO0edMGzZg9TxkyvPgbhcHBN3XlymWlTu3zwr7RKVmqlJasWG3T1q93L2XOkkWt237MBCvs7oN6pXUtKES/bP3vvqnz1+7W5p3HbfqtntxR89fu0tyVUX+oK0nubi42H+pKjycxLJb/rpCJzXsAwGzxlcW3HjnEW82JmWEYehT6SM7OzsqdN6/Onztjs/3C+bNKm843yudmyuyvOQuX27R9P+Vb3bt3V10+7ymfNOnk7OysHLnyaPfOHapQuZq13+6dO1SuYmX7HxDeaDsOByhHxhQ2bdkzpND5q8+/gsZiscjVOfqPDHccDlCTKnltrkzNniGFLt8IUWjY4y8W7D1xRVWKZtaqbSesz6tSNLPWbD/5kkcDxA/Oic31onPisLAwhYWFWu/5/ISDg6MiuDQer5GozolfVkzOiZ+49+CR7j14pORJ3FWtTG71Hr8yzvuHLdPPujZs2KDixYtrw4YNunXrlm7duqUNGzaoRIkSWrNmjf744w8FBgaqe/fuUT7f1dVVSZMmtflhKYaYmTB+rP75e48uXgzQyRPH9e0347Rn9y69XaeuwsLC1L1rZx05fEjDRoxWRHi4bly/rhvXr1snYSWpd68v9M24MdbHBw7s18YN6xVw4YL++XuPOnzykSKMCH3Y5iNrn21/btW2rX8oIOCCdmzfpo9at5RfZn/Vf6ehAHv69ofNKpHfXz3a1FCWjKnU5K1iavNuWX236A+bfkk83dSwemHNXr49ynGmD/pAAz+tZ308acFvqlYqlz7/sJpyZE6jzz+spiolcmniU5Ounu4uKpAjvQrkSC/p8Q3IC+RIr4xpY/5lBeBViGsOS2RxXAwdNEA/r1ml4SPHyNPD05q1Dx48kPR42cExo0Zo/769ungxQLt37VTnju2V3NtbVar998Hss3kc+uiRjh09qmNHjyo09JGuXbuqY0eP6vy5c5Ie3yM9e/YcNj/uHh5Kniy5zb1vAHuwWCxqWb+UflyzU+HhEdb2oFt3deTfyzY/oWHhunrjtk6eu2bt92wO//zHIX3cuJwa1ywqP9+UqlIyl/q2r6O1vx+0nmjG9D0AkBCQxeb5btJ47d/7ty5fuqh/T53QtEnfaN/fu1XjrdqSpGYftNbmDeu0avkSBVw4r6WL5mv71t/1TuOm1jEG9+2lqRPHSXr8e8iSLbvNj1eSJPLw8FSWbNnl7OwsSWrSoqXWrFiqtSuX6eyZfzVhzAhdu3JZDd5t8upfBCRq3y7drRK5fdWjWWll8U2uJlXyqM3bBfXdysdXY3u4OWtAmwoqkdtXmXySqlC2NJrcrZbSp06iZb8fs44z/cs6Gti2ovXx96v3KkVSN43pWF3Z0nvrrZJZ1aN5aU1d9d9V3hOW7lLrWgXV8q0CypkppUa2r6qMPkk1ffXeV/cCADFADpvrRefEXl5eKla8hMaOHqXdu3YqIOCCVi5fpjWrVqhq1Zc/J5Yen28/6SNJFwMCdOzoUV2+dOkVHT3eFNGdE0uSd1IPFciRXrmzPr6CO0fmNCqQI73SpExi7fMy58TVSudW9TK5rdvXfd9FJ89e09xVO17BEb9ZTL+StUuXLpo2bZrKlPnv0v6qVavKzc1N7dq10+HDhzV+/Hi1adPGxCoTp8DAG+rd8wtdv35NXkmSKEeOnJr83XSVLlNWFy8G6LctmyVJ771b3+Z502fNVfESJSU9vqebg+W/ufpHDx9q0oTxCgi4IA8PD5WrUFFDho9U0qT/La16506IJowfq6tXrihZsuSqWr2GPu3S1XrCCdjL30fOq8nn32vgp/X0VbtaOnsxUD1GLdXCX/bY9Gtcs6gssmjxuj1RjpMxbQqbbwf9tf+MWvaapX4d6qhvhzo6feGGPug5U7sP/fdGrUgeP62f3sX6eGT3dyVJ81b9pXb9frDnYQJxQg6ba/GiBZKkth9+YNM+cPAw1X+noRwcHXXyxAmtXrVCIbdDlDp1ahUvUVIjR4+Tp+d/y689m8fXrl9Tk0YNrI/nzJqpObNmqljxEpoxe178HhTwjColcypTuhSasyL6q1Of59kcHj59nQzDUL8OdeTrk0w3bt7R2j8Oqf/E/67Ojul7ACAhIIvNczMwUIP79lLgjevy9EqirNlzaPSEqSpe6vHvokLlaureq69+mD1d34wepkx+mTVoxDgVKFTEOsbVK5dlcYjd99er1qil27duafb0qQq8cV3+WbNr5DdTor1CFnhZfx+/oib9lmngRxX11QdldfZysHpM2aSFm49IksLDI5QzY0q9XyO/UiZ1V9Dt+9pz4oqqdf1BR8/9t6R1Rp+kNlkccD1Edb9cpJEdqmr392116UaIJi3bozGL/sv6Jb8dU4qk7vrq/bJKm8JTh8/eUIOvftL5a7df3QsAxAA5bK4XnRNL0ohRY/XN+LHq9WV33b51S+l8fdWpc1c1btLM2v9lzokPHz6kj1q3tPYZPXKYJKle/Xc0aOhw+x4o3mjPOyeuXTG/vh/439//vBGP/60ZPPVnDfnuZ0kvd06czMtNAz+tp/Rpkivo1j2t3LRP/SatVliY7SQv4s5iPLsWwivm7u6u3bt3K1++fDbtBw8eVIkSJXT//n2dO3dOuXPn1r1792I05oOw+KgUSDi8i3d6cSfgNXd/70SzS3gjxEcOS2QxEj+yGIkdOfzqxFcWXwsJtXepQILi986YF3cCXmP3N/Y0u4Q3AufEwMvhnBiJXUzPiU1fLrho0aLq0aOHrl+/bm27fv26vvjiCxUvXlySdPLkSWXIkMGsEgEASLTIYQAAzEUWAwBgHnIYABAXpi8XPGPGDNWvX18ZMmRQxowZZbFYdP78eWXJkkUrVz6+Ce+dO3f09ddfm1wpAACJDzkMAIC5yGIAAMxDDgMA4sL05YIlyTAM/frrrzpx4oQMw1CuXLlUvXp1OcTyviZPsBwDEjuWY8CbgGUKXx1757BEFiPxI4uR2JHDr1Z8ZDHLBSOxY7lgJHYsF/zqcE4MxB7nxEjsYnpOnCAmWe2NEENiR4jhTcCHu683shiJHVmMxI4cfv0xyYrEjklWJHZMsr7eOCdGYsc5MRK7mJ4Tm75csCRt2rRJmzZt0rVr1xQREWGzbebMmSZVBQDAm4EcBgDAXGQxAADmIYcBAC/L9EnWAQMGaODAgSpWrJjSpUsni8VidkkAALwxyGEAAMxFFgMAYB5yGAAQF6ZPsk6dOlWzZ8/WBx98YHYpAAC8cchhAADMRRYDAGAechgAEBcvf/duO3n06JHKlCljdhkAALyRyGEAAMxFFgMAYB5yGAAQF6ZPsn700UeaP3++2WUAAPBGIocBADAXWQwAgHnIYQBAXJi+XPCDBw80bdo0bdy4UQUKFJCzs7PN9rFjx5pUGQAAiR85DACAuchiAADMQw4DAOLC9EnWAwcOqFChQpKkQ4cO2WzjRuMAAMQvchgAAHORxQAAmIccBgDEhemTrFu2bDG7BAAA3ljkMAAA5iKLAQAwDzkMAIgL0+/J+rSAgABdvHjR7DIAAHgjkcMAAJiLLAYAwDzkMAAgtkyfZI2IiNDAgQOVLFky+fn5KVOmTEqePLkGDRqkiIgIs8sDACBRI4cBADAXWQwAgHnIYQBAXJi+XHDv3r01Y8YMDR8+XGXLlpVhGNq2bZv69++vBw8eaMiQIWaXCABAokUOAwBgLrIYAADzkMMAgLiwGIZhmFmAr6+vpk6dqnr16tm0r1y5Uh06dHipJRoehNmrOiBh8i7eyewSgHh3f+9Es0t4I8RHDktkMRI/shiJHTn86sRXFl8LCbVHeUCC5ffOGLNLAOLV/Y09zS7hjcA5MfByOCdGYhfTc2LTlwsOCgpSrly5IrXnypVLQUFBJlQEAMCbgxwGAMBcZDEAAOYhhwEAcWH6JGvBggU1cWLkGeGJEyeqYMGCJlQEAMCbgxwGAMBcZDEAAOYhhwEAcWH6PVlHjhyp2rVra+PGjSpdurQsFou2b9+uCxcu6Oeffza7PAAAEjVyGAAAc5HFAACYhxwGAMSF6VeyVqxYUSdOnNA777yj4OBgBQUFqWHDhjp+/LjKly9vdnkAACRq5DAAAOYiiwEAMA85DACIC9OvZJUe32B8yJAhNm0XLlxQmzZtNHPmTJOqAgDgzUAOAwBgLrIYAADzkMMAgJdl+pWs0QkKCtKcOXPMLgMAgDcSOQwAgLnIYgAAzEMOAwBiIsFOsgIAAAAAAAAAAABAQsQkKwAAAAAAAAAAAADEApOsAAAAAAAAAAAAABALTmbtuGHDhs/dHhwc/GoKAQDgDUQOAwBgLrIYAADzkMMAAHswbZI1WbJkL9zesmXLV1QNAABvFnIYAABzkcUAAJiHHAYA2INpk6yzZs0ya9cAALzxyGEAAMxFFgMAYB5yGABgD9yTFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAAIBaYZAUAAAAAAAAAAACAWGCSFQAAAAAAAAAAAABigUlWAAAAAAAAAAAAAIgFJlkBAAAAAAAAAAAA/B979x0eRdm2cfjakE5CSGihhl5CV3rvqICggoKFKqKC0qQLoQoiCEpVeu8dRKXa6EqRIijSu4QAhhaS5/uDj31Zk0CWJExIfudx5HjfnZl95p6w5trZe+cZOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrAAAAAAAAAAAAADjBZowxVheBp9vt27c1dOhQ9erVSx4eHlaXAyQ4XuMAkjL+RiEl4HUOICnjbxSSO17jAJI6/k4hueM1nnTRZEW8Xbt2TX5+frp69arSpEljdTlAguM1DiAp428UUgJe5wCSMv5GIbnjNQ4gqePvFJI7XuNJF9MFAwAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyIt48PDwUEhLCDZeRbPEaB5CU8TcKKQGvcwBJGX+jkNzxGgeQ1PF3Cskdr/Gky2aMMVYXAQAAAAAAAAAAAABPC65kBQAAAAAAAAAAAAAn0GQFAAAAAAAAAAAAACfQZAUAAAAAAAAAAAAAJ9BkBQAAAAAAAAAAAAAn0GRNIWw2m5YvX251GQAApEjkMAAA1iKLAQCwFlkMIDmiyZoMXLx4Ue3atVOOHDnk4eGhwMBA1a1bV1u3bn0i+49rQD5quwMHDujVV19VhgwZ5OHhoXz58qlv3766ceOGw3a7d+9W/fr1lTFjRnl6eipnzpx67bXX9M8//8TzSJDUtWzZUo0aNbK6jGgeVdfNmzcVEhKiAgUKyMPDQ+nTp1fjxo114MABh+3Cw8PVo0cP5c6dW56ensqQIYOqVaum1atXJ/IRAIgPcpgcTinIYQBJFVlMFqcUZDGApIosJotTAnIYMXG1ugDE3yuvvKKIiAjNmDFDuXPn1oULF7RhwwaFhoYm6n7v3Lkjd3f3BBlr27ZtqlWrlmrVqqU1a9YoU6ZM2rFjh7p27aqNGzdq06ZNcnd318WLF1WrVi01aNBA3333ndKmTatjx45p5cqV0cIOSApu376tWrVq6eTJkxo5cqTKli2rCxcuaOjQoSpbtqzWr1+vcuXKSZLeffdd7dixQ2PHjlVwcLAuX76sLVu26PLlyxYfBYCHIYfJYSRd5DCQMpDFZDGSLrIYSBnIYrIYSRM5/AQYPNWuXLliJJnNmzc/dDtJZtKkSaZRo0bGy8vL5M2b16xYscJhm82bN5vSpUsbd3d3ExgYaHr06GEiIiLs66tWrWrat29vOnfubNKlS2eqVKligoKCjCT7T1BQ0ENrWLZsWbTlUVFRJjg42JQqVcpERkY6rNuzZ4+x2Wxm2LBhxhhjli1bZlxdXR3qQsrRokUL07Bhw1jXx+U1/MEHH5hu3boZf39/kylTJhMSEuIwxqFDh0zFihWNh4eHKVSokFm3bl2sr9241DVs2DBjs9nMnj17HJZHRkaaUqVKmeDgYBMVFWWMMcbPz89Mnz79ob8DAEkLOYyUhBwGkBSRxUhJyGIASRFZjJSCHEZMmC74Kefj4yMfHx8tX75ct2/ffui2AwYM0Kuvvqp9+/bphRde0BtvvGH/NtGZM2f0wgsvqHTp0tq7d68mTJigKVOmaPDgwQ5jzJgxQ66urvrll1/01VdfaefOnZKkadOm6dy5c/bHztizZ48OHjyoLl26yMXF8SVZvHhx1apVS/PmzZMkBQYG6u7du1q2bJmMMU7vC8mXM6/h1KlTa/v27Ro+fLgGDhyodevWSZKioqLUqFEjeXt7a/v27fr666/Vp0+feNU1d+5c1a5dW8WLF3dY7uLios6dO+vgwYPau3evpHuv72+++UbXr1+P1z4BPDnkMHAPOQzAKmQxcA9ZDMAqZDFADqdo1vZ4kRAWL15s/P39jaenp6lQoYLp1auX2bt3r8M2kszHH39sf/zvv/8am81m1q5da4wxpnfv3qZAgQL2by0YY8y4ceOMj4+P/ds7VatWNSVKlIi2fz3imxSP2m7+/PlGktm9e3eMz/vwww+Nl5eX/XHv3r2Nq6urCQgIMM8995wZPny4OX/+/CP3j6ffw76VE9fXcKVKlRyeV7p0adOjRw9jjDFr1641rq6u5ty5c/b18f22kKenp+nYsWOM63777TcjySxYsMAYY8wPP/xgsmXLZtzc3EypUqVMp06dzM8//xzrfgEkDeQwOZxSkMMAkiqymCxOKchiAEkVWUwWpwTkMGLClazJwCuvvKKzZ89q5cqVqlu3rjZv3qxnnnlG06dPd9iuWLFi9v+fOnVq+fr66uLFi5KkQ4cOqXz58rLZbPZtKlasqH///VenT5+2LytVqlTiHkwMjDEOdQ0ZMkTnz5/XxIkTFRwcrIkTJ6pgwYL6/fffn3htSDri+hp+8L8DScqcObP9v4PDhw8re/bsCgwMtK8vU6ZMotVs/v/bbvdrrlKliv7++29t2LBBr7zyig4cOKDKlStr0KBBiVYDgPgjh8lhkMMArEUWk8UgiwFYiywmi1M6cjjlosmaTHh6eqp27drq16+ftmzZopYtWyokJMRhGzc3N4fHNptNUVFRkqIHxf1l97e7L3Xq1Alee/78+SVJBw8ejHH9H3/8oXz58jksS5cunZo0aaKRI0fq0KFDypIli0aMGJHgteHpEdfXsLP/HcRX/vz5H/raluTw+nZzc1PlypXVs2dPff/99xo4cKAGDRqkO3fuJGhdABIWOUwOp3TkMACrkcVkcUpHFgOwGllMFqdk5HDKRZM1mQoODlZ4eLhT22/ZssVhHvktW7bI19dXWbNmfehz3dzcFBkZ+di1lihRQgULFtSoUaPsf1Du27t3r9avX69mzZrF+nx3d3flyZPHqeNF8hOf1/B9BQsW1MmTJ3XhwgX7sse5j8ODmjZtqvXr19vntr8vKipKo0aNUnBwcLQ58R8UHBysu3fv6tatW/GqA8CTRQ4jpSGHASQ1ZDFSGrIYQFJDFiMlIYdTLlerC0D8XL58WU2aNFHr1q1VrFgx+fr6ateuXRo+fLgaNmwY53Hef/99jR49Wh988IE6dOigw4cPKyQkJMabff9Xzpw5tWHDBlWsWFEeHh7y9/ePddtjx45pz549Dsvy5s2ryZMnq06dOnrllVfUq1cvBQYGavv27eratavKly+vTp06SZJWr16t+fPnq2nTpsqfP7+MMVq1apW++eYbTZs2Lc7Hi6fX1atXo72GAgIC4vUavq927drKkyePWrRooeHDh+v69ev2m4s/6ltEsdXVuXNnrVixQg0aNNDIkSNVtmxZXbhwQZ988okOHTqk9evX28euVq2amjVrplKlSildunQ6ePCgevfurerVqytNmjRx+wUBeKLIYXI4pSGHASQ1ZDFZnNKQxQCSGrKYLE5JyGFEk3i3e8WTcOvWLdOzZ0/zzDPPGD8/P+Pt7W0KFChgPv74Y3Pjxg37dorh5sh+fn5m2rRp9sebN282pUuXNu7u7iYwMND06NHDRERE2NdXrVo1xpskr1y50uTNm9e4urqaoKCgWGuVFOPPpk2bjDHG7Nu3z7zyyismXbp0xs3NzeTJk8d8/PHHJjw83D7G0aNHTdu2bU3+/PmNl5eXSZs2rSldurTDcSD5atGiRYyvoRYtWhhjHu813LBhQ/vzjTHm0KFDpmLFisbd3d0ULFjQrFq1ykgy33777WPXFR4ebj7++GOTN29e4+bmZgICAswrr7xifv/9d4dxPvnkE1O+fHkTEBBgPD09Te7cuc2HH35o/vnnn3j93gAkHnKYHE5JyGEASRFZTBanJGQxgKSILCaLUwpyGDGxGfPA9csAAAe//PKLKlWqpL/++kt58uSxuhwAAFIUchgAAGuRxQAAWIccTvposgLAA5YtWyYfHx/ly5dPf/31lzp27Ch/f3/9/PPPVpcGAECyRw4DAGAtshgAAOuQw08f7skKAA+4fv26unfvrlOnTil9+vSqVauWRo4caXVZAACkCOQwAADWIosBALAOOfz04UpWAAAAAAAAAAAAAHCCi9UFAAAAAAAAAAAAAMDThCYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOIEmKwAAAAAAAAAAAAA4gSYrkMD69++vEiVK2B+3bNlSjRo1euJ1HD9+XDabTXv27Em0ffz3WB/Hk6gTAJBykMPOIYcBAAmNLHYOWQwASGhksXPIYsQHTVakCC1btpTNZpPNZpObm5ty586tjz76SOHh4Ym+7y+++ELTp0+P07ZP+g96tWrV1KlTpyeyLwBAykUOx4wcBgA8KWRxzMhiAMCTQhbHjCzG087V6gKAJ+W5557TtGnTFBERoZ9++klvv/22wsPDNWHChGjbRkREyM3NLUH26+fnlyDjAADwNCOHAQCwFlkMAIC1yGIg+eFKVqQYHh4eCgwMVPbs2fX666/rjTfe0PLlyyX9b1qBqVOnKnfu3PLw8JAxRlevXtU777yjjBkzKk2aNKpRo4b27t3rMO6wYcOUKVMm+fr6qk2bNrp165bD+v9OxxAVFaVPP/1UefPmlYeHh3LkyKEhQ4ZIknLlyiVJKlmypGw2m6pVq2Z/3rRp01SoUCF5enqqYMGCGj9+vMN+duzYoZIlS8rT01OlSpXS7t274/0769Gjh/Lnzy9vb2/lzp1bffv2VURERLTtvvrqK2XPnl3e3t5q0qSJwsLCHNY/qnYAQPJHDjuPHAYAJCSy2HlkMQAgIZHFziOLkdRxJStSLC8vL4c/yH/99ZcWLlyoJUuWKFWqVJKkevXqKSAgQN988438/Pz01VdfqWbNmjpy5IgCAgK0cOFChYSEaNy4capcubJmzZqlL7/8Urlz5451v7169dKkSZM0atQoVapUSefOndMff/wh6V4QlSlTRuvXr1fhwoXl7u4uSZo0aZJCQkI0duxYlSxZUrt371bbtm2VOnVqtWjRQuHh4apfv75q1Kih2bNn69ixY+rYsWO8f0e+vr6aPn26smTJot9//11t27aVr6+vunfvHu33tmrVKl27dk1t2rRR+/btNWfOnDjVDgBImcjhRyOHAQCJiSx+NLIYAJCYyOJHI4uR5BkgBWjRooVp2LCh/fH27dtNunTpzKuvvmqMMSYkJMS4ubmZixcv2rfZsGGDSZMmjbl165bDWHny5DFfffWVMcaY8uXLm3fffddhfdmyZU3x4sVj3Pe1a9eMh4eHmTRpUox1Hjt2zEgyu3fvdliePXt2M3fuXIdlgwYNMuXLlzfGGPPVV1+ZgIAAEx4ebl8/YcKEGMd6UNWqVU3Hjh1jXf9fw4cPN88++6z9cUhIiEmVKpU5deqUfdnatWuNi4uLOXfuXJxqj+2YAQDJBzkcM3IYAPCkkMUxI4sBAE8KWRwzshhPO65kRYqxevVq+fj46O7du4qIiFDDhg01ZswY+/qgoCBlyJDB/vjXX3/Vv//+q3Tp0jmMc/PmTR09elSSdOjQIb377rsO68uXL69NmzbFWMOhQ4d0+/Zt1axZM851X7p0SadOnVKbNm3Utm1b+/K7d+/a59M/dOiQihcvLm9vb4c64mvx4sUaPXq0/vrrL/3777+6e/eu0qRJ47BNjhw5lC1bNof9RkVF6fDhw0qVKtUjawcApAzksPPIYQBAQiKLnUcWAwASElnsPLIYSR1NVqQY1atX14QJE+Tm5qYsWbJEu3F46tSpHR5HRUUpc+bM2rx5c7Sx0qZN+1g1eHl5Of2cqKgoSfemNShbtqzDuvvTRhhjHqueh9m2bZuaNm2qAQMGqG7duvLz89P8+fM1cuTIhz7PZrPZ/zcutQMAUgZy2DnkMAAgoZHFziGLAQAJjSx2DlmMpwFNVqQYqVOnVt68eeO8/TPPPKPz58/L1dVVOXPmjHGbQoUKadu2bWrevLl92bZt22IdM1++fPLy8tKGDRv09ttvR1t/f477yMhI+7JMmTIpa9as+vvvv/XGG2/EOG5wcLBmzZqlmzdv2oPyYXXExS+//KKgoCD16dPHvuzEiRPRtjt58qTOnj2rLFmySJK2bt0qFxcX5c+fP061AwBSBnLYOeQwACChkcXOIYsBAAmNLHYOWYynAU1WIBa1atVS+fLl1ahRI3366acqUKCAzp49q2+++UaNGjVSqVKl1LFjR7Vo0UKlSpVSpUqVNGfOHB04cCDWG4t7enqqR48e6t69u9zd3VWxYkVdunRJBw4cUJs2bZQxY0Z5eXnp22+/VbZs2eTp6Sk/Pz/1799fH374odKkSaPnn39et2/f1q5du3TlyhV16dJFr7/+uvr06aM2bdro448/1vHjxzVixIg4HeelS5e0Z88eh2WBgYHKmzevTp48qfnz56t06dJas2aNli1bFuMxtWjRQiNGjNC1a9f04Ycf6tVXX1VgYKAkPbJ2AABiQg6TwwAAa5HFZDEAwFpkMVmMp4C1t4QFnoz/3lj8v0JCQhxuBn7ftWvXzAcffGCyZMli3NzcTPbs2c0bb7xhTp48ad9myJAhJn369MbHx8e0aNHCdO/ePdYbixtjTGRkpBk8eLAJCgoybm5uJkeOHOaTTz6xr580aZLJnj27cXFxMVWrVrUvnzNnjilRooRxd3c3/v7+pkqVKmbp0qX29Vu3bjXFixc37u7upkSJEmbJkiVxurG4pGg/ISEhxhhjunXrZtKlS2d8fHzMa6+9ZkaNGmX8/Pyi/d7Gjx9vsmTJYjw9Pc3LL79sQkNDHfbzsNq5sTgAJH/kcMzIYQDAk0IWx4wsBgA8KWRxzMhiPO1sxiTCZNkAAAAAAAAAAAAAkEy5WF0AAAAAAAAAAAAAADxNaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iyAgAAAAAAAAAAAIATaLICAAAAAAAAAAAAgBNosgIAAAAAAAAAAACAE2iy4qG+/PJL2Ww2FSlSJNZtbDab/SdVqlTy9/dX8eLF1a5dO23bti3e41++fFm9evVScHCwUqdOLT8/PxUsWFBvvfWW9u3bJ0mqX7++0qZNq1OnTkV7fmhoqDJnzqyKFSsqKipKmzdvtte7devWaNu3bNlSPj4+D607oU2fPt3h9+jq6qrMmTOradOm+vPPP59oLQ/q37+/bDabpfuO6Wfs2LGW1PQwN27cUP/+/bV582arSwGQhJGrT9a+ffvUpk0b5cmTR15eXvLy8lK+fPnUrl077dq164nVEVOe5syZUy1btkzU/W7ZskX9+/dXWFhYtHXVqlVzeK25ubkpZ86catOmjU6cOJGodcXFo2qvVq3aE68JwNOH3H0y7p/PPslslR4vDw4ePKj+/fvr+PHj0da1bNlSOXPmfKw6HnwdeXp6Kjg4WIMHD9adO3ecHu9p9STe2wBAUsd7jyfjwc/SY/os1hijvHnzymazRXuvYLPZ1KFDh4eO/99s9/LyUvHixTV69GhFRUUl4JEgOaDJioeaOnWqJOnAgQPavn17rNs1btxYW7du1c8//6z58+erefPm2rZtm8qXL6+OHTs+9vj//vuvypUrp+nTp+vtt9/WypUrNWfOHL3zzjs6duyY9uzZI0maPHmyXF1d9fbbb0cbo0OHDrp+/bpmzJghFxfHl3z37t0f+Tt4kqZNm6atW7dq/fr16tChg1auXKlKlSrpypUrVpdmmW+//VZbt251+GnSpInVZUVz48YNDRgwgCYrgIciV5+cr776Ss8++6y2b9+ujh07avXq1VqzZo06deqkAwcOqHTp0jp69Khl9S1btkx9+/ZN1H1s2bJFAwYMiLFRKUm5c+e2Z+uGDRvUvXt3rV69WpUrV9aNGzcStbZHeVjt48eP1/jx4598UQCeOuRu8vY4eXDw4EENGDAgxiZr3759tWzZsseq5cFMXbRokfLly6e+ffs+8kPc5ORJvLcBgKSO9x5Plq+vr6ZMmRJt+Q8//KCjR4/K19f3scd+MNsXLFigrFmzqnPnzurVq1d8SkZyZIBY7Ny500gy9erVM5JM27ZtY9xOkmnfvn205Xfv3jWtW7c2ksz48eMfa/ypU6caSWbjxo0x7jsyMtL+/xcsWGAkmYkTJ9qXLV26NNr+N23aZCSZ5557zkgyK1eudBizRYsWJnXq1DHu71GCgoJMSEiI08+bNm2akWR27tzpsHzAgAFGkpk6depj1RNfISEhxqo/E/f3fenSpUQZPzw8PEHHu3TpkpH0WP/+AFIGctV5j5urP//8s3FxcTENGjQwt2/fjnGbhQsXmjNnzjx0nITKCqvy9LPPPjOSzLFjx6Ktq1q1qilcuHC05VOmTDGSzHffffcEKozdw2oHgLggd52X0OezSdGiRYuMJLNp06YEGzOmTI2IiDD58uUz7u7u5ubNmwm2r7i4c+eOiYiIeKL7BADw3uNxxPe9x9tvv228vLzM1atXHda/+eabpnz58qZw4cKmatWqDuti+/0/KKZsv3PnjsmdO7fx9vY2d+7ccbpmJF9cyYpY3f8WyLBhw1ShQgXNnz/fqasaUqVKpbFjxyp9+vT67LPPHmv8y5cvS5IyZ84c4z4e/DbNq6++qqZNm+qjjz7S8ePHdfnyZb377ruqXbu23nvvvWjPbdmypYKDg9WrVy9FRkbG+biepFKlSkmSLly4YF9269Ytde3aVSVKlJCfn58CAgJUvnx5rVixItrz709/MGvWLBUqVEje3t4qXry4Vq9eHW3bNWvWqESJEvLw8FCuXLk0YsSIGGu6deuWevXqpVy5csnd3V1Zs2ZV+/bto11pkjNnTtWvX1+rV69WyZIl5eXlpUKFCtn3PX36dBUqVEipU6dWmTJlHntqqalTp6p48eLy9PRUQECAXnrpJR06dMhhm/vTVvz++++qU6eOfH19VbNmTUnSnTt3NHjwYBUsWFAeHh7KkCGDWrVqpUuXLjmMsXHjRlWrVk3p0qWTl5eXcuTIoVdeeUU3btzQ8ePHlSFDBknSgAED7FNJMFUSgAeRq0/OJ598olSpUumrr76Su7t7jNs0adJEWbJksT9+WFasW7dODRs2VLZs2eTp6am8efOqXbt2+ueff6KNG9c8jWlKvWvXrumjjz5yyNhOnTopPDzcYbu45Hv//v3VrVs3SVKuXLkeOpXSg/z8/CRJbm5uDst//vln1axZU76+vvL29laFChW0Zs2aaM/fv3+/GjZsKH9/f3l6eqpEiRKaMWOGwzZRUVEaPHiwChQoIC8vL6VNm1bFihXTF198Eafa/zs95PHjx2Wz2TRixAh9/vnnypUrl3x8fFS+fPkYp9uaNGmS8ufPLw8PDwUHB2vu3LmPPUUkgKSL3E164polP//8s8qXLy9PT09lzZpVffv21eTJk2Wz2RyuQI1puuAJEyaoePHi8vHxka+vrwoWLKjevXtLuncOen9WpOrVq9vzZfr06ZJini44KipKY8aMUYkSJeyZVa5cOa1cufKhx+rq6qoSJUrozp07DufKxhiNHz/ePp6/v78aN26sv//+2+H5xhh98sknCgoKkqenp0qVKqV169ZFO+b7UzjOmjVLXbt2VdasWeXh4aG//vpLkrR+/XrVrFlTadKkkbe3typWrKgNGzY47OvSpUt65513lD17dvs5ccWKFbV+/Xr7Nrt371b9+vWVMWNGeXh4KEuWLKpXr55Onz5t3yam9zYnT57Um2++aX9eoUKFNHLkSIepFp3NcQBIqnjv8eQ1a9ZMkjRv3jz7sqtXr2rJkiVq3bp1gu7Lzc1Nzz77rG7cuBHtc2OkbDRZEaObN29q3rx5Kl26tIoUKaLWrVvr+vXrWrRokVPjeHl5qVatWjp27JjDm++4jl++fHlJUvPmzbV8+XJ7UMRm3Lhx8vX1VevWrfX+++/rzp079mkU/itVqlQaOnSoDhw4EO3Dv6Ti2LFjkqT8+fPbl92+fVuhoaH66KOPtHz5cs2bN0+VKlXSyy+/rJkzZ0YbY82aNRo7dqwGDhyoJUuW2BuRD57EbdiwQQ0bNpSvr6/mz5+vzz77TAsXLtS0adMcxjLGqFGjRhoxYoTeeustrVmzRl26dNGMGTNUo0YN3b5922H7vXv3qlevXurRo4eWLl0qPz8/vfzyywoJCdHkyZP1ySefaM6cObp69arq16+vmzdvRqs/MjJSd+/etf88GOJDhw5VmzZtVLhwYS1dulRffPGF9u3bp/Lly0e7l+2dO3f04osvqkaNGlqxYoUGDBigqKgoNWzYUMOGDdPrr7+uNWvWaNiwYfaT1/v1HD9+XPXq1ZO7u7umTp2qb7/9VsOGDVPq1Kl1584dZc6cWd9++60kqU2bNvapJJgqCcB95OqTExkZqU2bNqlUqVKxnljGJqaskKSjR4+qfPnymjBhgr7//nv169dP27dvV6VKlRQREWF/flzzNCY3btxQ1apVNWPGDH344Ydau3atevTooenTp+vFF1+UMcZh+0fl+9tvv60PPvhAkrR06VJ7Nj3zzDMO49zP1xs3bmjHjh0aOHCgcufOrQoVKti3+eGHH1SjRg1dvXpVU6ZM0bx58+Tr66sGDRpowYIF9u0OHz6sChUq6MCBA/ryyy+1dOlSBQcHq2XLlho+fLh9u+HDh6t///5q1qyZ1qxZowULFqhNmzb2D6HjWvt/jRs3TuvWrdPo0aM1Z84chYeH64UXXtDVq1ft23z99dd65513VKxYMS1dulQff/wx0/0DyRC5m/TENUv27dun2rVr68aNG5oxY4YmTpyo3377TUOGDHnkPubPn6/3339fVatW1bJly7R8+XJ17tzZ/mWlevXq6ZNPPpF073d9P1/q1asX65gtW7ZUx44dVbp0aS1YsEDz58/Xiy++GON0w/917NgxpU2b1v6FXElq166dOnXqpFq1amn58uUaP368Dhw4oAoVKjh8ubpPnz7q06ePnnvuOa1YsULvvvuu3n77bR05ciTGffXq1UsnT57UxIkTtWrVKmXMmFGzZ89WnTp1lCZNGs2YMUMLFy5UQECA6tat69Bofeutt7R8+XL169dP33//vSZPnqxatWrZX6/h4eGqXbu2Lly44JC1OXLk0PXr12M9/kuXLqlChQr6/vvvNWjQIK1cuVK1atXSRx99FOM0ynHJcQBIqnjvYY00adKocePGDjXPmzdPLi4ueu211xJ8f0ePHpWrq6v8/f0TfGw8xay9kBZJ1cyZMx2mC7h+/brx8fExlStXjratHnGJfY8ePYwks3379scaf+DAgcbd3d1IMpJMrly5zLvvvmv27t0b4/6++eYb+7azZs2Ktv7+FAeLFi0yxhhTqVIlky1bNvsUPnGd4iAqKspEREQ4/AQFBZm+fftGW/4o96c42LZtm4mIiDDXr1833377rQkMDDRVqlR56Bh37941ERERpk2bNqZkyZIO6ySZTJkymWvXrtmXnT9/3ri4uJihQ4fal5UtW9ZkyZLFYRqja9eumYCAAIfpDb/99lsjyQwfPtxhP/enl/j666/ty4KCgoyXl5c5ffq0fdmePXuMJJM5c2aHKRiXL18ebbqJ+1Mr/vcna9asxhhjrly5Yry8vMwLL7zgUMvJkyeNh4eHef311+3LWrRoEeO0y/PmzTOSzJIlSxyW359+4/7UGIsXLzaSzJ49e0xsmC4YwMOQq08uV8+fP28kmaZNm0Zbdz8z7/9ERUXZ18WWFbHVeeLECSPJrFixwr4urnlqzL2cbNGihf3x0KFDjYuLS7SpFu9n0DfffGNfFtd8f9R0wTHlbP78+c2hQ4ccti1XrpzJmDGjuX79un3Z3bt3TZEiRUy2bNnsv8emTZsaDw8Pc/LkSYfnP//888bb29uEhYUZY4ypX7++KVGiRLSaHvSo2h+c8unYsWNGkilatKi5e/euffmOHTuMJDNv3jxjzL2psQIDA03ZsmUdxjtx4oRxc3MzQUFBD60JwNOD3LXmfPZh0wXHNUuaNGliUqdO7XDbmMjISBMcHBwtF/6bBx06dDBp06Z9aK0Pmy64RYsWDlnw448/GkmmT58+Dx3z/pSC939f586dM/369Ys2BePWrVuNJDNy5EiH5586dcp4eXmZ7t27G2OMCQ0NNR4eHua1115z2O7+8x885vuvhypVqjhsGx4ebgICAkyDBg0clkdGRprixYubMmXK2Jf5+PiYTp06xXp8u3btMpLM8uXLH/p7+O97m549e0b7b8cYY9577z1js9nM4cOHjTFxz3EASMp472Hde4/79e3fv98YY0zp0qVNy5YtjTEm3tMF36/n7Nmz9lxr0qTJI+tDysKVrIjRlClT5OXlpaZNm0qSfHx81KRJE/3000/RrhB8FPOfKy+cHb9v3746efKkpk6dqnbt2snHx0cTJ07Us88+6zAVwH3PP/+8ypUrp3z58unNN998ZH2ffvqpTp8+bZ+iLq5mzJghNzc3h58TJ05o0KBB0ZbHVbly5eTm5iZfX18999xz8vf314oVK+Tq6uqw3aJFi1SxYkX5+PjI1dVVbm5umjJlSrRpcqV70yA9eJPvTJkyKWPGjDpx4oSke99K3blzp15++WV5enrat7v/reIHbdy4UZKiTQHUpEkTpU6dOtq0QyVKlFDWrFntjwsVKiTp3rRO3t7e0Zbfr+lB69ev186dO+0/33zzjSRp69atunnzZrRasmfPrho1akSrRZJeeeUVh8erV69W2rRp1aBBA4erZUuUKKHAwED7VS0lSpSQu7u73nnnHc2YMSPaVE4A8Cjk6qMlRq7+17PPPuswzsiRI6Nt89+skKSLFy/q3XffVfbs2e25GxQUJEn27HUmT2OyevVqFSlSRCVKlHDIpLp168Y4ze+j8j0u8uTJY8/XrVu3au7cufLy8lLNmjXtr5vw8HBt375djRs3lo+Pj/25qVKl0ltvvaXTp0/r8OHDku69T6hZs6ayZ8/usJ+WLVvqxo0b2rp1qySpTJky2rt3r95//3199913unbtWpxrfph69eopVapU9sfFihWT9L/3F4cPH9b58+f16quvOjwvR44cqlixYoLUACBpIHcf7Unk7n3OZMn9K17Tp09v387FxSXa3+6YlClTRmFhYWrWrJlWrFgR47T+zli7dq0kqX379o/c9sCBA/bfV+bMmTVw4ED16tVL7dq1s2+zevVq2Ww2vfnmmw5ZHxgYqOLFi9uzftu2bbp9+3a0Yy5XrlysU9v/9/3Lli1bFBoaqhYtWjjsKyoqSs8995x27txpv8K3TJkymj59ugYPHqxt27Y5zNIhSXnz5pW/v7969OihiRMn6uDBg4/8fUj33hcEBwerTJkyDstbtmwpY4z984X7HpXjAJCU8d7j0RLrvUfVqlWVJ08eTZ06Vb///rt27tyZIFMFP5jtWbJk0ciRI/XGG29o0qRJ8R4byQtNVkTz119/6ccff1S9evVkjFFYWJjCwsLUuHFjSYp1yoDY3H9DfP++Z48zfqZMmdSqVStNnDhR+/bt0w8//CB3d3d17Ngxxn16eHjEeg+2/6pQoYIaNWqkYcOG6cqVK3E+rgYNGjg0/3bu3KnMmTOrbdu20ZbH1cyZM7Vz505t3LhR7dq106FDh+xzy9+3dOlSvfrqq8qaNatmz56trVu32sPj1q1b0cZMly5dtGUeHh72qXCvXLmiqKgoBQYGRtvuv8suX74sV1dXh+mOpHv3hgsMDIw2BUVAQIDD4/v/JrEtj6n+4sWLq1SpUvaf+ydaD7vHQJYsWaLV4u3trTRp0jgsu3DhgsLCwuTu7h4tzM+fP28/Kc+TJ4/Wr1+vjBkzqn379sqTJ4/y5Mnj9JsJACkTuRo3CZWr6dOnl5eXV4wfyM2dO1c7d+6M9T5qMWVFVFSU6tSpo6VLl6p79+7asGGDduzYYb9H2OPkaUwuXLigffv2RcsjX19fGWOifVD8qHyPi/v3eCtVqpTKlSunZs2aae3atTp37pz69etnPy5jTKx5K/0vky9fvhyn7Xr16qURI0Zo27Ztev7555UuXTrVrFnzse/Pft9/fyceHh6S/vdvdH//mTJlivbcmJYBeDqRu3GTGOezsXE2Sx737/Rbb72lqVOn6sSJE3rllVeUMWNGlS1bVuvWrXusui9duqRUqVLFKcfvf3Fpx44dWrRokYoXL66hQ4dq/vz59m0uXLggY4wyZcoULe+3bdtmz/rHyav//m7vTz3cuHHjaPv69NNPZYxRaGioJGnBggVq0aKFJk+erPLlyysgIEDNmzfX+fPnJd27X/sPP/ygEiVKqHfv3ipcuLCyZMmikJCQaA3ZB8X1fcF9j8pxAEiqeO8RN4n13sNms6lVq1aaPXu2Jk6cqPz586ty5cpOjRGT+9m+a9cu7d+/X2FhYZo9e7b8/PziPTaSF9dHb4KUZurUqTLGaPHixVq8eHG09TNmzNDgwYMdvmEYm5s3b2r9+vXKkyePsmXLlmDjV6lSRXXq1NHy5ct18eJFZcyY0YkjjG7o0KEqUqSI/f4scZEuXbpoJwHu7u7KkiWLSpUq9Vh1FCpUyP7c6tWrKzIyUpMnT9bixYvtwTl79mzlypVLCxYskM1msz/3v/dDjSt/f3/ZbDb7CdSD/rssXbp0unv3ri5duuTQaDXG6Pz58ypduvRj1fA47v/uz507F23d2bNnHb75LMnhd3Vf+vTplS5dOvv9VP/rwSuEKleurMqVKysyMlK7du3SmDFj1KlTJ2XKlMn+LTIAiAm5GjcJlaupUqVSjRo19P333+vcuXMOH+4FBwdLUqz3UYspK/bv36+9e/dq+vTpatGihX35X3/95bCdM3kak/vN4dhOwP+ba4klc+bMSp8+vfbu3Svp3nG5uLjEmrcP1pYuXbo4befq6qouXbqoS5cuCgsL0/r169W7d2/VrVtXp06dcpjtIiHdf309eM+7++LybwTg6UDuxk1inM/Gxtksic/f6VatWqlVq1YKDw/Xjz/+qJCQENWvX19Hjhyxz0IRVxkyZFBkZKTOnz//yPu83//ikiSVLl1a1atXV+HChdWpUyfVr19fPj4+Sp8+vWw2m3766Sd7A/FB95c9Kq9iupr1v+9h7v8+x4wZo3LlysVY8/2Gbfr06TV69GiNHj1aJ0+e1MqVK9WzZ09dvHjRfq5ctGhRzZ8/X8YY7du3T9OnT9fAgQPl5eWlnj17xjh+XN8XAMDTjvcecZOY7z1atmypfv36aeLEiXG6j3tcPJjtwMNwJSscREZGasaMGcqTJ482bdoU7adr1646d+6cfdqcR43VoUMHXb58WT169His8S9cuKCoqKgYx/7zzz/l7e2ttGnTxvu4CxYsqNatW2vMmDE6efJkvMdLKMOHD5e/v7/69etn/z3YbDa5u7s7nESdP39eK1aseKx9pE6dWmXKlNHSpUsdriS9fv26Vq1a5bBtzZo1Jd1r9D5oyZIlCg8Pt69/EsqXLy8vL69otZw+fdo+XeGj1K9fX5cvX1ZkZKTD1bL3fwoUKBDtOalSpVLZsmU1btw4SdJvv/0miW/ZAogZuWpNrvbq1UuRkZF69913H3qFRVzcz9v/fhj61VdfOTx2Jk9jUr9+fR09elTp0qWLMZNimx7wYR4nm06fPq1//vnHftKdOnVqlS1bVkuXLnUYJyoqSrNnz1a2bNmUP39+SffeJ2zcuNH+4el9M2fOlLe3d4wf8qZNm1aNGzdW+/btFRoaam+AJ0auFihQQIGBgVq4cKHD8pMnT2rLli0Jth8A1iF3k9b57H3OZEnVqlW1ceNGhxkcoqKitGjRIqf3+fzzz6tPnz66c+eODhw4IMm5fHn++eclSRMmTHBq39K9D5KHDRumCxcuaMyYMZLuZb0xRmfOnIkx64sWLSpJKlu2rDw8PLRgwQKHMbdt2xbnqXMrVqyotGnT6uDBgzHuq1SpUjFesZQjRw516NBBtWvXtp/rPshms6l48eIaNWqU0qZNG+M299WsWVMHDx6Mts3MmTNls9lUvXr1OB0LACRlvPdIGu89smbNqm7duqlBgwYOX44GngSuZIWDtWvX6uzZs/r0009VrVq1aOuLFCmisWPHasqUKapfv759+YULF7Rt2zYZY3T9+nXt379fM2fO1N69e9W5c2e1bdv2scafNWuWvvrqK73++usqXbq0/Pz8dPr0aU2ePFkHDhxQv3794jyVwaP0799fc+bM0aZNm5Q6deoEGTO+/P391atXL3Xv3l1z587Vm2++qfr162vp0qV6//331bhxY506dUqDBg1S5syZnZ7j/75BgwbpueeeU+3atdW1a1dFRkbq008/VerUqe1TCElS7dq1VbduXfXo0UPXrl1TxYoVtW/fPoWEhKhkyZJ66623EurQHylt2rTq27evevfurebNm6tZs2a6fPmyBgwYIE9PT4WEhDxyjKZNm2rOnDl64YUX1LFjR5UpU0Zubm46ffq0Nm3apIYNG+qll17SxIkTtXHjRtWrV085cuTQrVu37Fca1apVS9K9q16DgoK0YsUK1axZUwEBAUqfPv1jfSgOIPkgV63J1YoVK2rcuHH64IMP9Mwzz+idd95R4cKF7VfRLFmyRJKiTQ0ck4IFCypPnjzq2bOnjDEKCAjQqlWrYpx6MK55GpNOnTppyZIlqlKlijp37qxixYopKipKJ0+e1Pfff6+uXbuqbNmyTv0e7n9Y+8UXX6hFixZyc3NTgQIF7DM13Lx50z7tcWRkpI4dO6bhw4fb67lv6NChql27tqpXr66PPvpI7u7uGj9+vPbv36958+bZG9EhISFavXq1qlevrn79+ikgIEBz5szRmjVrNHz4cPu0Sg0aNFCRIkVUqlQpZciQQSdOnNDo0aMVFBSkfPnyxan2x+Hi4qIBAwaoXbt2aty4sVq3bq2wsDANGDBAmTNnlosL3z8FnnbkrrXnsxs3boxxtogXXnghzlnSp08frVq1SjVr1lSfPn3k5eWliRMn2u8f+rC/1W3btpWXl5cqVqyozJkz6/z58xo6dKj8/Pzssy4VKVJEkvT111/L19dXnp6eypUrV4zT8FeuXFlvvfWWBg8erAsXLqh+/fry8PDQ7t275e3trQ8++OChv4/mzZvr888/14gRI9S+fXtVrFhR77zzjlq1aqVdu3apSpUqSp06tc6dO6eff/5ZRYsW1XvvvaeAgAB16dJFQ4cOlb+/v1566SWdPn3aqbzy8fHRmDFj1KJFC4WGhqpx48bKmDGjLl26pL179+rSpUuaMGGCrl69qurVq+v1119XwYIF5evrq507d+rbb7/Vyy+/LOnevWTHjx+vRo0aKXfu3DLGaOnSpQoLC1Pt2rVjraFz586aOXOm6tWrp4EDByooKEhr1qzR+PHj9d5779kb6wDwNOO9R9L5LH3YsGFx3vbo0aMxXhUcHBxsnwELiDMDPKBRo0bG3d3dXLx4MdZtmjZtalxdXc358+eNMcZIsv+4uLiYNGnSmKJFi5p33nnHbN26NV7jHzx40HTt2tWUKlXKZMiQwbi6uhp/f39TtWpVM2vWrFjHqFq1qilcuHCM6zZt2mQkmUWLFkVb17t3byPJpE6dOtaxHyYoKMiEhIQ4/bxp06YZSWbnzp3R1t28edPkyJHD5MuXz9y9e9cYY8ywYcNMzpw5jYeHhylUqJCZNGmSCQkJMf/9T1qSad++fYx1tmjRwmHZypUrTbFixYy7u7vJkSOHGTZsWIxj3rx50/To0cMEBQUZNzc3kzlzZvPee++ZK1euRNtHvXr1ou07ppqOHTtmJJnPPvvMvuz+vi9duhT9F/aAyZMn2+v28/MzDRs2NAcOHHDYpkWLFrH+m0ZERJgRI0aY4sWLG09PT+Pj42MKFixo2rVrZ/78809jjDFbt241L730kgkKCjIeHh4mXbp0pmrVqmblypUOY61fv96ULFnSeHh4GEnRfscAUh5y1ZpcvW/Pnj2mVatWJleuXMbDw8N4enqavHnzmubNm5sNGzY4bPuwrDh48KCpXbu28fX1Nf7+/qZJkybm5MmTRlK0+uKapzFl8b///ms+/vhjU6BAAXuuFS1a1HTu3Nn++jDGuXzv1auXyZIli3FxcTGSzKZNm4wx9/5N//tay5Ili3n++efN5s2bo439008/mRo1apjUqVMbLy8vU65cObNq1apo2/3++++mQYMGxs/Pz7i7u5vixYubadOmOWwzcuRIU6FCBZM+fXr776lNmzbm+PHjca69atWq9u1ieh/x4O/qv/9GX3/9tcmbN69xd3c3+fPnN1OnTjUNGzY0JUuWjPZ8AE8Xctfa89nYfo4dO2aMiXuW/PTTT6Zs2bLGw8PDBAYGmm7duplPP/3USDJhYWH27f6bBzNmzDDVq1c3mTJlMu7u7iZLlizm1VdfNfv27XMYf/To0SZXrlwmVapURpI9p1q0aGGCgoIcto2MjDSjRo0yRYoUsWdz+fLlHep+2L/XmjVrjCQzYMAA+7KpU6easmXL2n8PefLkMc2bNze7du2ybxMVFWUGDx5ssmXLZtzd3U2xYsXM6tWrTfHixc1LL71k3+5hrwdjjPnhhx9MvXr1TEBAgHFzczNZs2Y19erVs29/69Yt8+6775pixYqZNGnSGC8vL1OgQAETEhJiwsPDjTHG/PHHH6ZZs2YmT548xsvLy/j5+ZkyZcqY6dOnO+wrpvchJ06cMK+//rpJly6dcXNzMwUKFDCfffaZiYyMtG/jbI4DQFLCe4+k91n6gwoXLuzwXsEY89D3LPdredjvA/gvmzHGJFC/FgAAAACeKmFhYcqfP78aNWqkr7/+2upyAAAxqFOnjo4fP64jR45YXYpljh07poIFCyokJES9e/e2uhwAAACI6YIBAAAApBDnz5/XkCFDVL16daVLl04nTpzQqFGjdP36dXXs2NHq8gAAkrp06aKSJUsqe/bsCg0N1Zw5c7Ru3TpNmTLF6tKemL1792revHmqUKGC0qRJo8OHD2v48OFKkyaN2rRpY3V5AAAA+H80WQEAAACkCB4eHjp+/Ljef/99hYaGytvbW+XKldPEiRNVuHBhq8sDAOjefcL79eun8+fPy2azKTg4WLNmzdKbb75pdWlPTOrUqbVr1y5NmTJFYWFh8vPzU7Vq1TRkyBBlypTJ6vIAAADw/5guGAAAAAAAAAAAAACc4GJ1AQAAAAAAAAAAAADwNKHJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATnC1uoDE4FWqs9UlAInq8pbPrS4BSHTe7jarS0A8FOz5ndUlAIlqQqtSVpcAJKrqBdJZXQLiyatkB6tLABLVlZ1jrS4BSFSeyfJT25TDq8YQq0sAEtXJlT2sLgFIVBl84hbEXMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6gyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOoMkKAAAAAAAAAAAAAE6wrMkaGhqq06dPOyw7cOCAWrVqpVdffVVz5861qDIAAJI/chgAAGuRxQAAWIccBgAkBMuarO3bt9fnn39uf3zx4kVVrlxZO3fu1O3bt9WyZUvNmjXLqvIAAEjWyGEAAKxFFgMAYB1yGACQECxrsm7btk0vvvii/fHMmTMVEBCgPXv2aMWKFfrkk080btw4q8oDACBZI4cBALAWWQwAgHXIYQBAQrCsyXr+/HnlypXL/njjxo166aWX5OrqKkl68cUX9eeff1pVHgAAyRo5DACAtchiAACsQw4DABKCZU3WNGnSKCwszP54x44dKleunP2xzWbT7du3LagMAIDkjxwGAMBaZDEAANYhhwEACcGyJmuZMmX05ZdfKioqSosXL9b169dVo0YN+/ojR44oe/bsVpUHAECyRg4DAGAtshgAAOuQwwCAhOBq1Y4HDRqkWrVqafbs2bp796569+4tf39/+/r58+eratWqVpUHAECyRg4DAGAtshgAAOuQwwCAhGBZk7VEiRI6dOiQtmzZosDAQJUtW9ZhfdOmTRUcHGxRdQAAJG/kMAAA1iKLAQCwDjkMAEgINmOMsbqIhOZVqrPVJQCJ6vKWz60uAUh03u42q0tAPBTs+Z3VJQCJakKrUlaXACSq6gXSWV0C4smrZAerSwAS1ZWdY60uAUhUnpZdGoOE4FVjiNUlAInq5MoeVpcAJKoMPnELYsvuySpJd+/e1WeffaZnnnlGPj4+8vX11TPPPKMRI0YoIiLCytIAAEj2yGEAAKxFFgMAYB1yGAAQX5Z9J+rmzZuqXbu2tm7dqlq1aqlKlSoyxuiPP/5Qjx49tHLlSn3//ffy9PS0qkQAAJItchgAAGuRxQAAWIccBgAkBMuarEOHDtWpU6e0e/duFStWzGHd3r179eKLL2rYsGHq37+/NQUCAJCMkcMAAFiLLAYAwDrkMAAgIVg2XfD8+fP1+eefRwsxSSpevLhGjBihuXPnWlAZAADJHzkMAIC1yGIAAKxDDgMAEoJlTdaTJ0+qTJkysa4vV66cTp48+QQrAgAg5SCHAQCwFlkMAIB1yGEAQEKwrMmaJk0aXbx4Mdb158+fV5o0aZ5gRQAApBzkMAAA1iKLAQCwDjkMAEgIljVZq1evrk8++STW9cOGDVO1atWeXEEAAKQg5DAAANYiiwEAsA45DABICK5W7TgkJERly5ZVuXLl1KVLFxUsWFCSdPDgQY0aNUoHDx7Utm3brCoPAIBkjRwGAMBaZDEAANYhhwEACcGyJmtwcLDWrVunNm3aqGnTprLZbJIkY4wKFiyo7777ToULF7aqPAAAkjVyGAAAa5HFAABYhxwGACQEy5qs0r0biB84cEB79uzRkSNHJEn58+dXiRIlFB4erh9//FFVqlSxskQAAJItchgAAGuRxQAAWIccBgDEl6VN1vtKlCihEiVKOCz766+/VL16dUVGRlpTFAAAKQQ5DACAtchiAACsQw4DAB6Xi9UFAAAAAAAAAAAAAMDThCYrAAAAAAAAAAAAADiBJisAAAAAAAAAAAAAOMGye7KuXLnyoeuPHTv2hCoBACDlIYcBALAWWQwAgHXIYQBAQrCsydqoUaNHbmOz2RK/EAAAUiByGAAAa5HFAABYhxwGACQEy5qsUVFRVu0aAIAUjxwGAMBaZDEAANYhhwEACYF7sgIAAAAAAAAAAACAEyy7khVJQ5YMfhr8QX3VqVBIXp5u+vPEJb03aL52/3E62rZjejfR2y9XULeRyzR23o9xGr9JnZKa+Ulzrdr8u179aGqM23zUsqYGdaivsXN/ULfPl8fncAAHCxfM0+IF83T27BlJUu48efXOu+1VqXIVSVK/Pj21auVyh+cULVZcM+csiHXMlcuXKqRv72jLt+3aKw8PD/vjixcu6ItRI/TLzz/q9u3byhGUUyEDBiu4cJEEODIAyUnGNB766Pn8qpI/vTzcUun4P+H6eMkBHThzzb5Nh1p59GqZbErj5aZ9p65q4PKD+uti+EPH9fV0Vae6+VS7cCb5ebnq9JWb+nTNYf14+B9JUqlc/mpTJacKZ02jjGk81X7mbm04eDFRjxUpzw/fLNWPa5fp8sVzkqTMOXKpXtPWKvJseUnStSuhWjpjvA7t2aEb/15XvsIl9Fq7LsqUJXusY+7esllrF8/UpXOnFXn3rjJmya5ajZqqXPXn7dvcuhGulXMmac+2H3T96hVlz51fr7btpJz5ghP3gAE8dbJk8NPgjg1Vp2JheXm46c+TF/XegDnafeiUfZsCuTJpcMdGqvxMXrm42HTo6Dm92WOqTp2/Euu4fj5e6t+hgRrWKC7/NN46fuayeo5aqu9+PihJSpXKRR+3e0FNXyilTOnS6Pw/1zRr1TYNm/SdjDGJftxIGRbOn6uFC+bp7Jl758R58uZTu/feV6XKVSVJE8aN0bdr1+j8+fNyc3NTcHBhdejYWcWKFY91zPXrvteUSRN16uRJRdy9q6AcQXqrZSs1eLGRfZspk77ShnXf69ixv+Xh6akSJUqqU5ePlDNX7kQ9XgBPpyzpfTW4bXXVKZPnXhafDtV7n63W7j/P27cpkCOdBr9TQ5WL5biXxcf/0ZsDl+rUxWsxjlkoZ3r1a1lVJfMHKigwrbqN+15jl+x02OaPue0VFJg22nMnLt+lzl9+l6DHiJRr2aL5Wr54gc6du5fFuXLnVcu276l8xcqSpClfjdOG79bq4oXzcnVzU4FCwXrn/Y4qXLTYQ8ddOHemli1eoAvnzyltWn9Vq1lb7Tp0tn8+/aj9IuHQZE3B0vp6aeOUD/XDrj/VqOPXuhh6XbmzpVfY9ZvRtm1QtYhKFw7S2YthcR4/R6C/hnZ8UT//djTWbZ4Nzq42L5XXviNnHucQgIfKlCmTPujUVTly5JAkrVq5XJ0/bK/5i5YqT958kqQKFStrwOBP7M9xc3N75Lg+Pj5atmqtw7IHG6zXrl5Vy+bNVLp0WY2dMEkBAQE6deqUfNOkSYjDApCMpPFy1bz3ymr70VC1nfabQsNvK3uAt67djLBv83bVXGpZKad6Lfpdx/+5oXdr5NbUt0vp+RE/K/xOZIzjuqWyaWqbUrocfkcd5+zRhau3FOjn6bC9l1sq/XHuupbuOqMxb5VM9GNFyuSfPqMatXhPGTNnkyRt3fiNJgzpoT6jpytz9lya8EkPpUrlqvf6DJOnV2ptWDFfX/T9UCHj5srD0yvGMb190+j5Ji0UmC1Irq6u2rfzF8384hP5+vmr8DPlJEmzxg7T2RN/q1XnfvILyKDtm7/V6L4dFTJurvzTZXhixw8gaUvr66WN07voh51/qlGH8ffOibM7nhPnypZeG6Z20YzlWzR4whpd/femCuYK1K3bEbGO6+aaSmsmdtDF0Ot6o9sUnbl4Rdky+ev6jdv2bbq2rK23G1dS236zdPDoOT1bOIe+6v+mrl2/pXHzNifmYSMFyZgpUB07f6Ts98+JVyxXxw7ttWDJMuXNm09BQTnVq08/ZcuWXbdu39LsmdP1XtvWWrV2nQICAmIc08/PT2+/855y5cotNzc3/fjDJoV83FsBAelUsdK9D2537dyh15q9ocJFiyrybqTGfDlK77Zto6Ur18jb2/uJHT+ApC+tj6c2ftlcP+w5oUa9FujilXDlzuKvsPBb9m1yZUmrDV8014y1ezV4+o+6Gn5bBXOk1607d2Md19vDTcfOXdHSHw7p0/drx7hNpfemKZXL/+67G5wrg74Z8YaW/nAo4Q4QKV6GTJn07gedlTX7vSxeu3qFenXpoKlzlyh3nrzKniNInXv0UZas2XT79m0tnDNTXdq31fwVa+XvH3MWf//Nak0cM0o9+w1S0eIlderEcQ3p30eS9GHXnnHaLxIOTdYUrGuLmjp9IUztBs63Lzt5Lvo3cbNk8NOo7q+owQdfadnotnEa28XFpmmD39Sgr79VxRK5ldY3+odkqb3cNW3Qm3p/yEL1bBNz2AHxUbVaDYfHHT7srEUL5mvfvr32Jqu7u7vSp3fyw1ab7aHPmTZ1sgIDM2vA4KH2ZVmyZnNuHwBShLer5tK5sFvqvXi/fdmZK7cctmleMUgTN/2tdQfuXWXac+Hv+uXj6qpfIrMW7Ig+84QkvVwqq/y83dRswnbdjbp3NczZMMdxfzryj3468k9CHg4QTbEylRweN3rrXf24dpmO/XFAqVK56tjhA+o3dray5Lh3ZUuzdz9St+b1tPPHdapU58UYxyxQ9BmHxzVffE3bNq7V0YP7VPiZcrpz+7Z2b9ms9/oMU74i975A0OD1t7V3+0/6ce1SNXyzXSIcKYCnUddWtXX6/BW16z/bvuzkuVCHbQZ0aKDvfj6gPl+ssC87fubyQ8dt0ai8/NN4q1rLkbp7N+r/x3U81y5bLJdW/7BP3/58wL7fV58rpWeCc8TrmIAHVavueE78QcfOWjh/nvbt3aO8efPphfoNHNZ/1L2Xli1ZrD+PHFbZcuVjHLN0mbIOj994q4VWrliu3b/9am+yTvh6isM2AwcPVfXK5XXo4AE9W6p0fA8LQDLStVl5nb54Te2Gr7YvO3nhqsM2A1pX03c7jqrP1xvty46fC3vouL8ePqdfD9+bTWdQ2+oxbvPP1RsOjz96vYKOngnVT3tPOnMIwENVquL4+mvXvqOWL56vg7/vVe48eVXn+foO6z/o0l2rVyzR0T+PqFSZcjGOuf/3PSpavKT9uZmzZFWtui/o0IHf47xfJBzuyZqC1atSWL8dOqU5w1roxPcDtXVOV7Vq5Pgfrs1m05SBb2jUrE069Pf5WEaKrvfbdfXPlX81Y8X2WLcZ3aOxvv3lkDbtOPLYxwDEVWRkpL5du0Y3b95QseIl7Mt37dqhGlUrqGH9uhrYv69CLz/8AxNJunnjhp6vU0N1a1bVh+3b6Y9DBx3W/7B5o4KDi6hbl46qUbWCmjZ5SUsXL0zoQwKQDNQolFH7z1zV6NeL65ePq2nph+XVpPT/vpSRLcBLGdN46Jc//9cMjYg02nnsikoGpX3ouHtOhqlfw0L6uU81rexUQe2q5dIDX9IFnrioyEjt/HGd7ty6pVwFi+huxL2rwNzc3O3buKRKpVSubvrr4L44jWmM0R97d+nCmZPKW7jE/+/nrqKiIuXm7uGwrZu7e5zHBZAy1KtaVL8dPKk5w1vrxIah2jqvh1q9VMG+3maz6blKhfXnyYtaOa69TmwYqh9nfqQG1R4+fVu9qkW1fd8xje75mo6v/0S7FvVWt9Z15PJAEG/dc1TVyxRQ3hwZJUlF82dV+RK59d0vBxLnYJHiRUZGau03986JixePPotJxJ07WrJogXx9fZW/QIE4jWmM0fZtW3X8+LGHNk//vX5dkpTGz+/xigeQbNUrn0+/HTmnOSEv68SSTtr6VRu1qlfCvt5mk54rl1d/ngrVyk+b6sSSTvpxXEs1qJg/Qetwc3VR01pFNGPt3gQdF3hQZGSk1n/3jW7dvKnCMUzNHxFxRyuWLpKPj6/y5os9i4uVeEaHDx3Uwf33zm/PnD6lbb/8pPKVqjzWfhE/ll/Jmjt3bu3cuVPp0qVzWB4WFqZnnnlGf//9t0WVJX+5sqZT21cq6Ms5mzV82nqVKpxDIz96Sbcj7mruml2SpK4tauhuZJTGzY/bPVglqXzxXGrZsKzKvj4i1m2a1CmpEgWzqlLzUfE+DuBh/jxyWC3ebKY7d27Ly9tbI0ePVZ7//7ZOxcpVVLvuc8qcOYvOnDmt8WO/1Dtvt9TcBUvk7u4e43g5c+XWgEFDlTd/foX/+6/mzpmpVs1f1/zFyxUUlFPSvWBbtHCe3mzeUm3attP+3/dp+LAhcnN3d7hPDZAUkMPWyh7gpWZls2v6zyf01ea/VSybn/q8WFB3IqO04rezyuBzr0l0+fodh+ddvn5bWfxjnkr1/rjl/AO0as85tZv+m4LSeatfw0JKlcpF4zfEPo0/kBjOHD+q4d3fUcSdO/Lw8lK73kOVJUcuRd69q4CMgVo2c6LeaN9dHh5eWr9inq5duaxrVx5+lfXN8H/Vs1VDRUTckYtLKjV79yMFlywjSfL0Tq3cBYtozYJpCswWpDRpA7Tzx3U6fuSgMj7kXq+AVchi6+TKml5tm1TWl7M3aviU71WqSJBGdm9875x49Q5lDPCRb2pPfdSqtgaMW62Pv1iuOhWDNX/k26r7zpf6+de/Yhk3naqVzq/5a3fqpQ8mKG+OjBrV81W5urpo6NffSpJGTFunND5e2rvsY0VGGqVKZVPIuNVa+O2vT/JXgBTgzyOH9dbrTXXnzm15e3tr1JfjlCfv/65g+WHzJvX4qItu3bqp9BkyaOKkqbFOT3jf9evXVbt6lf/PYRf17hui8hUqxritMUYjhg9VyWeeVb58CdsUARICOWytXFn81fbFZ/Xlou0aPucXlSqYRSM71NHtO5Gau+53ZUybWr7eHvqoWXkNmPaDPv56k+qUya35AxqrbpfZ+nlfwlx1+mLFAkrr46nZ3/GlTCS8o38e0butXtedO3fk5eWtT0Z8qVy5/5fFv/y4Wf17f6Rbt24pXfoMGjV+ktL6+8c6Xq26LyjsyhW93+YtGSNFRt5Vo8av6a1WjrOQPmq/SBiWN1mPHz+uyMjo9xO7ffu2zpx59H06b9++rdu3bzssM1F3ZXOx/NCSPBcXm347eEoh47+RJO09fEbBuQP1zisVNXfNLpUsmE3tm1ZRhTdHxnlMH28PTR34ht4fskCXr4bHuE22TGn1WdeX1KDDRN1+yNz5QELImSuX5i9epuvXr2nDuu/V7+OemjxtlvLkyau6z71g3y5vvvwKLlxEL9SpqZ9+3KyaterEOF6x4iUcroQtUfIZNXv1Zc2fO1s9en0sSYqKMgouXFgfdOwiSSpYKFhHj/6lRQvm0WRFkhPfHL6/7X+zOOruHbm4xvxlBfyPzWbTgTNXNeq7PyVJh85eV95MPmpWNrtW/HbWvp2R+e8TZf6z6EEuNpsuh99Rv6UHFGWkA2euKWMaD7WukosmK564TFlzqM/oGboZfl2/bdmsGaMHq8sn45QlRy616/mJZo0Zqq6vPycXl1QqWLyUCj8b8/SED/Lw8laf0TN0+9YN/bF3lxZP/VLpA7PYpxJu1bmfZn75iXq2aigXl1TKnie/SleprZN/M4MKkp7EymITFSmbS6oEqTG5undOfFIhY1dJkvYePq3gPJn1TpPKmrt6h1xc7k3+tXrz7xozZ5Mkad+RMypbPLfaNq4Ua5PVxcVFl0Kvq/2geYqKMtp96JQyZ/BTp+Y17U3WJnWfVbMXSqtl7xk6ePScihXIqs8+aqxzl65qzqrYZ4QCnJUzZy4tXLJc169f0/p136tv7x6aMn22vdFaukxZLVyyXGFhV7Rk8UJ169pJs+ctitZwelDq1Km1cMly3bhxQ9u3b9XI4cOULVv2aFMJS9LQwQP155Ejmj5rbqIdIxAfiZfDfD4dFy42m347ck4hUzZLkvb+dUHBOTPonRef0dx1v9tngVi95YjGLN4hSdp39ILKFs6mti8+k2BN1hYvFNd3O47q3OV/E2Q84EE5cubUtHlL9O/169q8YZ2GhPTWmEnT7Q3PZ0qX0bR5SxQWFqZVyxarX8+u+nrGPPkHxJzFv+3aoZlTv1LXnn0VXKSYTp86qS9GDNX09BPUsu17cd4vEoZlf+lXrlxp///fffed/B6YMiQyMlIbNmxQzpw5HznO0KFDNWDAAIdlqTKXlVuWR384k9Kd/+eaDh274LDsj2MX1KjGvamPKpbMrYwBPjqyup99vatrKg3r1FAdmlVVwRcHRRszd7Z0ypk1nZZ8/rZ92f0wvL5thIq9MlRF8mZWpnS+2jKri8O4lUrm1ruvVpJfhW6KinrIJ8eAE9zc3JUjR5AkqXDhojqwf7/mzZ6pj0MGRts2Q4aMypwli06eOBHn8V1cXFS4SFGH56TPkCHa3Pa5cufRhvXfP+ZRAAkvoXJYijmL01V8Q+krvZUgtSZnl67f1l8XHb+UdPRiuOoUyXRv/b/3TtTT+3ro0gNXs6bzcdflfx1P4v87bkSk0YNxevRiuDKm8ZBbKpsiIslZPDmubm7KmOXeNNhB+QrpxF+HtGnVQr3RvoeC8hbUx1/M0M3wf3X3boR8/fw17KO3FZS34EPHdHFxsY+ZPXd+nT99Qt8tnmlvsmbInE1dh47X7Vs3detGuPwC0mvS8L5Knylz4h4s4ITEzuJUmUrLLXOZBKk1uTr/z7Vot8X549h5NapZQpL0z5V/FRERqUN/n3PY5vDf51WhZO6HjHtVEXcjHc5r/zh2Xpkz+MnNNZUi7kbqk06NNGLaOi367t6Vqwf+OqscmQPUrVVtmqxIUG7u7soR9P/nxEWK6sD+3zVn9kz163/vnNjb21s5goKUIyhIxYqXUIPn62j50sVq0zb2e5i7uLjYxyxYqJCO/X1UUyZ9Ha3JOnTIIG3evFFTZ8xWpsDARDpC4PEkeg7nrC63XDUTpNbk7Hzovzp03HEWmz9O/qNGVe6dD/xz9YYi7kbq0AnHbQ6f+EcViibMLDU5MqVRjWdyqWnIkgQZD/gvNzd3Zcv+/7kZXESHDu7Xonmz1b1Pf0mSl5e3smUPUrbsQSpStLiaNnpeq5cv1Vut28Y43uQJY1T3hRfV4KXGkqQ8+fLr1q2bGj64v5q3aWf/ouCj9ouEYVmTtVGjRvb/36JFC4d1bm5uypkzp0aOfPQVlL169VKXLl0clmWs1idBakzutu49pvxBGR2W5QvKqJPnrkiS5n6zSxv/c7/UVWPaae43v2pmLCd9h49f1LOvfeqwrP97L8jH20MfjVym0xfCdOnKv9G2+bpfMx0+cVEjZ2ygwYpEZnTnzp0Y14SFXdGF8+eUPkOGuI9mjA7/cchh2qMSJUrqxPFjDtudPH5cmTNnebySgUSQUDksxZzFpQb+EO8aU4LdJ8KUK31qh2U5M3jrbNhNSdLp0Ju6eO22KuRNp0Nn793Lyi2VTaVz+Wvk2tivyPvtRJjql8gsm032K15zZvDWxWu3aLDCcsYYRfz//Vjv80rtI0m6cPaUTvz1h158I+aTSWfGlCQPTy95eHop/N9rOrh7u15u8f7jFw4ksMTO4oyVe8S7xuRu656/o58T58iok+dCJUkRdyP168ETyh+UyXGbB86bYxv3tedLyWazyfx/EOfLkVHnLt1rvkqSl6e7okyUw/Mio4z9QzEgsRhjFBHLOfH99bGdMz90zIg7Do+HDhmkjRvWacr0WcqWjen6kfQkeg6/yC3S4mLr/lPKn91xivJ82QJ08sJVSVLE3Sj9evic8md3vKIvX/Z09m3i663niuti2A2t3fZngowHPFJcsjgi9vW3bt2S7f8vbLvPxcVFRsb+3vNx9ovHY1mTNSrq3slErly5tGvXrodOQ/IwHh4e8vDwcFjGVAxxM2buD9o0taO6taqlJev2qHThHGr9Ujl1GLJQkhR69YZCr95weE7E3ShduHxNf564ZF82ecDrOnvxqvqNW6Pbd+7q4FHHbwKHXb/3QfH95RF3I6NtE37rjkLDwqMtB+JjzBefq2KlKgoMDFR4eLi++/Yb7dq5Q+MmTNKNG+GaOH6sataqowwZMujs2TMa88UopU3rrxo1a9nH+Lh3D2XMmFEfduoqSfpqwlgVLVZcOXLkVHj4v5o3Z5aOHP5Dvfr874rvN5u3VMu3mmnKpImqXfd5Hfh9n5YsWai+/aJfPQtYJaFyWIo5i5kqOG6m/3xc894rq3bVcmnt7xdULJufXi2TTf2WHrRvM/OXE2pXPbdOXL6hE//cULvquXUrIlKr9/zvqpphrxbRxau39fn/Tzs8b9spvVkhh/o0KKjZW04qKJ232lXLrVlb/jeVkrd7KuVI521/nC3ASwUz++rqjQidu3rrCRw9UoLlMyeq8LPl5J8+k27fvKGdP63Tkf279UHI55KkX3/eKB+/tArIkElnjh/VwsmjVaJsFQWX/N+VMNNGDVTagAx6qcW9aY++XTRTOfIWVIbMWRV5N0L7d23Vtk1r9fp73ezPOfDbNsncm6r44rnTWjp9nDJlzaEKteo/2V8A8BCJncVMFfxoY2Zv1KbpXdWtdR0tWfebShfOqdavVFSHQfPs24yasV6zPm2tn3/7Sz/sOqI6FYL1QpUiqtv2C/s2kwe9de+ceMy9q6ImLfpJ7zWtqpHdG2v8vB+UN0cGdWtTR+Pn/e9LaN/8+Lt6tKmrU+eu6ODRcypRMJs+fLO6Zi7f9uR+AUj2vhz9uSpVrqJMgYG6ER6ub9feOyce/9Vk3bhxQ5O/nqhq1WsofYYMuhoWpgXz5+rChfOqXfc5+xh9enVXxoyZ1LHzvXPiKZO+UnDhIsqePYciIu7opx9/1OqVK9Snb3/7cz4ZNEBrv1mt0WPGK7V3av1z6d5nSD6+vvL09HyivwMgNomfw3w+HRdjFu/QpjEt1O31Clqy+ZBKF8yi1vVKqsPn39i3GbVgm2b1fUk/7zupH3afUJ0yefRC+Xyq23mWfZvJPRvo7D/X1W/yZkmSm6uLCgXdu4jC3TWVsqT3VbE8mfTvzTv6++z/vihls0nNnyuuOd/vUyQX/iARfDV2tMpVrKyMme5l8frv12r3rzs1csxXunnzhmZO+VoVq1ZX+vT3snjZovm6dPGCqteqax9jUL9eypAho979oLMkqWKValowZ4byFyik4CLFdObUSU2eMEaVqlRXqlSpHrlfJCxL/9pHREQoZ86cunz5cryCDI/n14On9NpHUzWwQz31fruOjp8NVbeRyzX/29+cGid7oD9XnyJJunz5sj7u3V3/XLokH19f5ctXQOMmTFK5ChV169Yt/fXnEa1etULXr11X+gwZVLp0GX06YpRS///VNJJ0/txZudj+982g69eua9CAEF3+596YBQsW0uRps1SkaDH7NoWLFNXI0WM0ZvTn+nrieGXNmk3duvfSC/UbPNHjBx6FHLbe/tPX9MGsPeryXD69XzOPTl+5qaGrDjs0UCf/cEyebi7q1zBYfl6u2nfqqtpM+VXhd/5336Asab0c7tF6/uottZmySz3rF9SKjhV04dptzfrlhCb98L+r7ItkS6OZ7/xvGsle9e9Nx7Ts1zPqtWh/Ih41UpJrYaGaNmqgroVellfq1MqaM68+CPlcwSXvvfauXvlHi6d+qWthofLzT6dy1Z/XC6+1chgj9NIF2Wz/u7Lr9u2bmjdxhMIuX5Sbu4cCswWpdZcQlar8vy9J3bwRruUzJyjsn0vy9k2jkuWrqdFb7ZTKlQ+7kLSQxdb69eBJvdZ1kgZ+8KJ6v/O8jp+5rG6fLdH8tbvs26zctE8fDJmvbq3raGT3xjpy4qKadZusLXv+tm+TPTDA4Zz49IUwNXh/nIZ3fVk7F/bS2YthGjd3s0ZOX2ffpsunixTyfn190fs1ZfD30blLVzVl8S/65Ou1T+bgkSJcvvyP+vTsrkuXLsrH11f58xfQ+K8mq3yFirp9+7aOHftbK1csU9iVK0qbNq0KFymqaTPnKG/efPYxzp87J5cHcvjmjRv6ZNAAXbhwXh4ensqVO7eGDPtMzz3/gn2bhQvufVGhTUvH24cMHDxUDV96OZGPGog7cth6vx4+p9f6LdbAt6urd/PKOn4uTN3Gr9P8DQfs26z8+bA+GLVW3V6voJEd6ujIqVA1C1miLftP27fJntHPIYszp/PV9kn/u51d59fKq/Nr5fXjnhOq22W2fXmNZ3MpRyY/zVi7N5GPFClVaOhlDerbU5f/uaTUPr7Kky+/Ro75SqXLVdDt27d14vgxrV29QlfDriiNX1oVKlxE4ybPdLgV3YXz5xw+n27Rpp1sNpsmjf9Sly5dVNq0/qpYpZread8xTvtFwrKZh14/nPgyZMigLVu2KF++fI/eOI68SnVOsLGApOjyls+tLgFIdN7utkdvhHhLjByWpII9v0vQ8YCkZkKrUlaXACSq6gX4oPFJSaws9irZIUHHA5KaKzvHWl0CkKg8+W7YE5FoOVxjSIKOByQ1J1dyawokbxl84hbElt/so3nz5poyZYrVZQAAkCKRwwAAWIssBgDAOuQwACA+LP9O1J07dzR58mStW7dOpUqVUurUqR3Wf/45V+wBAJBYyGEAAKxFFgMAYB1yGAAQH5Y3Wffv369nnnlGknTkyBGHdTYbU0UCAJCYyGEAAKxFFgMAYB1yGAAQH5Y3WTdt2mR1CQAApFjkMAAA1iKLAQCwDjkMAIgPy+/J+qDTp0/rzJkzVpcBAECKRA4DAGAtshgAAOuQwwAAZ1neZI2KitLAgQPl5+enoKAg5ciRQ2nTptWgQYMUFRVldXkAACRr5DAAANYiiwEAsA45DACID8unC+7Tp4+mTJmiYcOGqWLFijLG6JdfflH//v1169YtDRkyxOoSAQBItshhAACsRRYDAGAdchgAEB82Y4yxsoAsWbJo4sSJevHFFx2Wr1ixQu+///5jTdHgVapzQpUHJEmXt3xudQlAovN2t1ldQoqQGDksSQV7fpcQ5QFJ1oRWpawuAUhU1Quks7qEFCOxstirZIeEKA9Isq7sHGt1CUCi8rT80piUIdFyuAbNWSRvJ1f2sLoEIFFl8IlbEFs+XXBoaKgKFiwYbXnBggUVGhpqQUUAAKQc5DAAANYiiwEAsA45DACID8ubrMWLF9fYsdG/fTh27FgVL17cgooAAEg5yGEAAKxFFgMAYB1yGAAQH5ZPPDF8+HDVq1dP69evV/ny5WWz2bRlyxadOnVK33zzjdXlAQCQrJHDAABYiywGAMA65DAAID4sv5K1atWqOnLkiF566SWFhYUpNDRUL7/8sg4fPqzKlStbXR4AAMkaOQwAgLXIYgAArEMOAwDiw/IrWaV7NxgfMoSbgQMAYAVyGAAAa5HFAABYhxwGADyuJNFkDQsL044dO3Tx4kVFRUU5rGvevLlFVQEAkDKQwwAAWIssBgDAOuQwAOBxWd5kXbVqld544w2Fh4fL19dXNpvNvs5msxFkAAAkInIYAABrkcUAAFiHHAYAxIfl92Tt2rWrWrdurevXryssLExXrlyx/4SGhlpdHgAAyRo5DACAtchiAACsQw4DAOLD8ibrmTNn9OGHH8rb29vqUgAASHHIYQAArEUWAwBgHXIYABAfljdZ69atq127dlldBgAAKRI5DACAtchiAACsQw4DAOLDknuyrly50v7/69Wrp27duungwYMqWrSo3NzcHLZ98cUXn3R5AAAka+QwAADWIosBALAOOQwASCg2Y4x50jt1cYnbBbQ2m02RkZFOj+9VqrPTzwGeJpe3fG51CUCi83a3WV1CspXYOSxJBXt+91jPA54WE1qVsroEIFFVL5DO6hKStSeRxV4lOzzW84CnxZWdY60uAUhUnpZcGpMyPJEcrjHksZ4HPC1OruxhdQlAosrgE7cgtiSuo6KirNgtAAAQOQwAgNXIYgAArEMOAwASiuX3ZAUAAAAAAAAAAACAp4llTdbt27dr7dq1DstmzpypXLlyKWPGjHrnnXd0+/Zti6oDACB5I4cBALAWWQwAgHXIYQBAQrCsydq/f3/t27fP/vj3339XmzZtVKtWLfXs2VOrVq3S0KFDrSoPAIBkjRwGAMBaZDEAANYhhwEACcGyJuuePXtUs2ZN++P58+erbNmymjRpkrp06aIvv/xSCxcutKo8AACSNXIYAABrkcUAAFiHHAYAJATLmqxXrlxRpkyZ7I9/+OEHPffcc/bHpUuX1qlTp6woDQCAZI8cBgDAWmQxAADWIYcBAAnBsiZrpkyZdOzYMUnSnTt39Ntvv6l8+fL29devX5ebm5tV5QEAkKyRwwAAWIssBgDAOuQwACAhWNZkfe6559SzZ0/99NNP6tWrl7y9vVW5cmX7+n379ilPnjxWlQcAQLJGDgMAYC2yGAAA65DDAICE4GrVjgcPHqyXX35ZVatWlY+Pj2bMmCF3d3f7+qlTp6pOnTpWlQcAQLJGDgMAYC2yGAAA65DDAICEYFmTNUOGDPrpp5909epV+fj4KFWqVA7rFy1aJB8fH4uqAwAgeSOHAQCwFlkMAIB1yGEAQEKwrMl6n5+fX4zLAwICnnAlAACkPOQwAADWIosBALAOOQwAiA/L7skKAAAAAAAAAAAAAE+jOF3JunLlyjgP+OKLLz52MQAAIGZkMQAA1iGHAQCwFlkMAEiK4tRkbdSoUZwGs9lsioyMjE89AAAgBmQxAADWIYcBALAWWQwASIri1GSNiopK7DoAAMBDkMUAAFiHHAYAwFpkMQAgKYrXPVlv3bqVUHUAAIDHQBYDAGAdchgAAGuRxQAAKzndZI2MjNSgQYOUNWtW+fj46O+//5Yk9e3bV1OmTEnwAgEAgCOyGAAA65DDAABYiywGACQVTjdZhwwZounTp2v48OFyd3e3Ly9atKgmT56coMUBAIDoyGIAAKxDDgMAYC2yGACQVDjdZJ05c6a+/vprvfHGG0qVKpV9ebFixfTHH38kaHEAACA6shgAAOuQwwAAWIssBgAkFU43Wc+cOaO8efNGWx4VFaWIiIgEKQoAAMSOLAYAwDrkMAAA1iKLAQBJhdNN1sKFC+unn36KtnzRokUqWbJkghQFAABiRxYDAGAdchgAAGuRxQCApMLV2SeEhITorbfe0pkzZxQVFaWlS5fq8OHDmjlzplavXp0YNQIAgAeQxQAAWIccBgDAWmQxACCpcPpK1gYNGmjBggX65ptvZLPZ1K9fPx06dEirVq1S7dq1E6NGAADwALIYAADrkMMAAFiLLAYAJBVOX8kqSXXr1lXdunUTuhYAABBHZDEAANYhhwEAsBZZDABICh6rySpJu3bt0qFDh2Sz2VSoUCE9++yzCVkXAAB4BLIYAADrkMMAAFiLLAYAWM3pJuvp06fVrFkz/fLLL0qbNq0kKSwsTBUqVNC8efOUPXv2hK4RAAA8gCwGAMA65DAAANYiiwEASYXT92Rt3bq1IiIidOjQIYWGhio0NFSHDh2SMUZt2rRJjBoBAMADyGIAAKxDDgMAYC2yGACQVDh9JetPP/2kLVu2qECBAvZlBQoU0JgxY1SxYsUELQ4AAERHFgMAYB1yGAAAa5HFAICkwukrWXPkyKGIiIhoy+/evausWbMmSFEAACB2ZDEAANYhhwEAsBZZDABIKpxusg4fPlwffPCBdu3aJWOMpHs3Ge/YsaNGjBiR4AUCAABHZDEAANYhhwEAsBZZDABIKmzmfhI9hL+/v2w2m/1xeHi47t69K1fXe7MN3///qVOnVmhoaOJVG0depTpbXQKQqC5v+dzqEoBE5+1ue/RGKcjTlsUFe35ndQlAoprQqpTVJQCJqnqBdFaXkKQ8bTksSV4lO1hdApCoruwca3UJQKLydPomb8nb05bFXjWGWF0CkKhOruxhdQlAosrgE7cgjtNWo0ePjk8tAAAgnshiAACsQw4DAGAtshgAkBTFqcnaokWLxK4DAAA8BFkMAIB1yGEAAKxFFgMAkqJ4TTxx8+bNaDcZT5MmTbwKAgAAcUcWAwBgHXIYAABrkcUAACu5OPuE8PBwdejQQRkzZpSPj4/8/f0dfgAAQOIiiwEAsA45DACAtchiAEBS4XSTtXv37tq4caPGjx8vDw8PTZ48WQMGDFCWLFk0c+bMxKgRAAA8gCwGAMA65DAAANYiiwEASYXT0wWvWrVKM2fOVLVq1dS6dWtVrlxZefPmVVBQkObMmaM33ngjMeoEAAD/jywGAMA65DAAANYiiwEASYXTV7KGhoYqV65cku7Nbx8aGipJqlSpkn788ceErQ4AAERDFgMAYB1yGAAAa5HFAICkwukma+7cuXX8+HFJUnBwsBYuXCjp3jeI0qZNm5C1AQCAGJDFAABYhxwGAMBaZDEAIKlwusnaqlUr7d27V5LUq1cv+9z3nTt3Vrdu3RK8QAAA4IgsBgDAOuQwAADWIosBAEmFzRhj4jPAyZMntWvXLuXJk0fFixdPqLrixatUZ6tLABLV5S2fW10CkOi83W1Wl/DUSIpZXLDnd1aXACSqCa1KWV0CkKiqF0hndQlPjaSYw5LkVbKD1SUAierKzrFWlwAkKk9Xqyt4eiTFLPaqMcTqEoBEdXJlD6tLABJVBp+4BbHTV7L+V44cOfTyyy8rICBArVu3ju9wAADASWQxAADWIYcBALAWWQwAsEq8m6z3hYaGasaMGQk1HAAAcBJZDACAdchhAACsRRYDAJ60BGuyAgAAAAAAAAAAAEBKQJMVAAAAAAAAAAAAAJyQLG+hfmXbKKtLABKVf+kOVpcAJLqbu8daXQLiYc/gulaXACQqshjJHTn89Nv//WdWlwAkqnRNp1ldApCowhe3sroExMOV7/tYXQKQqDgnRnIX13PiODdZX3755YeuDwsLi+tQAADgMZDFAABYhxwGAMBaZDEAIKmJc5PVz8/vkeubN28e74IAAEDMyGIAAKxDDgMAYC2yGACQ1MS5yTptGtOwAABgJbIYAADrkMMAAFiLLAYAJDUuVhcAAAAAAAAAAAAAAE8TmqwAAAAAAAAAAAAA4ASarAAAAAAAAAAAAADgBJqsAAAAAAAAAAAAAOAEmqwAAAAAAAAAAAAA4ITHarLOmjVLFStWVJYsWXTixAlJ0ujRo7VixYoELQ4AAMSMLAYAwDrkMAAA1iKLAQBJgdNN1gkTJqhLly564YUXFBYWpsjISElS2rRpNXr06ISuDwAA/AdZDACAdchhAACsRRYDAJIKp5usY8aM0aRJk9SnTx+lSpXKvrxUqVL6/fffE7Q4AAAQHVkMAIB1yGEAAKxFFgMAkgqnm6zHjh1TyZIloy338PBQeHh4ghQFAABiRxYDAGAdchgAAGuRxQCApMLpJmuuXLm0Z8+eaMvXrl2r4ODghKgJAAA8BFkMAIB1yGEAAKxFFgMAkgpXZ5/QrVs3tW/fXrdu3ZIxRjt27NC8efM0dOhQTZ48OTFqBAAADyCLAQCwDjkMAIC1yGIAQFLhdJO1VatWunv3rrp3764bN27o9ddfV9asWfXFF1+oadOmiVEjAAB4AFkMAIB1yGEAAKxFFgMAkgqbMcY87pP/+ecfRUVFKWPGjAlZU7zdumt1BUDi8i/dweoSgER3c/dYq0t4KpDFgDXIYiR35HDcJNUclqSjl25aXQKQqIq9N9/qEoBEFb64ldUlPBWSahZzTozkjnNiJHdxPSd2+krWB6VPnz4+TwcAAPFEFgMAYB1yGAAAa5HFAAArOd1kzZUrl2w2W6zr//7773gVBAAAHo4sBgDAOuQwAADWIosBAEmF003WTp06OTyOiIjQ7t279e2336pbt24JVRcAAIgFWQwAgHXIYQAArEUWAwCSCqebrB07doxx+bhx47Rr1654FwQAAB6OLAYAwDrkMAAA1iKLAQBJhUtCDfT8889ryZIlCTUcAABwElkMAIB1yGEAAKxFFgMAnrQEa7IuXrxYAQEBCTUcAABwElkMAIB1yGEAAKxFFgMAnjSnpwsuWbKkw43FjTE6f/68Ll26pPHjxydocQAAIDqyGAAA65DDAABYiywGACQVTjdZGzVq5PDYxcVFGTJkULVq1VSwYMGEqgsAAMSCLAYAwDrkMAAA1iKLAQBJhVNN1rt37ypnzpyqW7euAgMDE6smAAAQC7IYAADrkMMAAFiLLAYAJCVO3ZPV1dVV7733nm7fvp1Y9QAAgIcgiwEAsA45DACAtchiAEBS4lSTVZLKli2r3bt3J0YtAAAgDshiAACsQw4DAGAtshgAkFQ4fU/W999/X127dtXp06f17LPPKnXq1A7rixUrlmDFAQCA6MhiAACsQw4DAGAtshgAkFTYjDEmLhu2bt1ao0ePVtq0aaMPYrPJGCObzabIyMiErtFpt+5aXQGQuPxLd7C6BCDR3dw91uoSkhyyGEg6yGIkd+RwdE9TDkvS0Us3rS4BSFTF3ptvdQlAogpf3MrqEpKcpymLOSdGcsc5MZK7uJ4Tx7nJmipVKp07d043bz78RC0oKChOO05MhBiSO0IMKQEf7kZHFgNJB1mM5I4cju5pymGJJiuSP5qsSO5oskb3NGUx58RI7jgnRnIX13PiOE8XfL8XmxRCCgCAlIgsBgDAOuQwAADWIosBAEmNizMb22y2xKoDAADEAVkMAIB1yGEAAKxFFgMAkpI4X8kqSfnz539kkIWGhsarIAAAEDuyGAAA65DDAABYiywGACQlTjVZBwwYID8/v8SqBQAAPAJZDACAdchhAACsRRYDAJISp5qsTZs2VcaMGROrFgAA8AhkMQAA1iGHAQCwFlkMAEhK4nxPVua7BwDAWmQxAADWIYcBALAWWQwASGri3GQ1xiRmHQAA4BHIYgAArEMOAwBgLbIYAJDUxHm64KioqMSsAwAAPAJZDACAdchhAACsRRYDAJKaOF/JCgAAAAAAAAAAAABIgk3Wu3fv6t9//7W6DAAAUiRyGAAAa5HFAABYhxwGADjDsibrN998o1mzZjksGzJkiHx8fJQ2bVrVqVNHV65csag6AACSN3IYAABrkcUAAFiHHAYAJATLmqwjRozQtWvX7I+3bNmifv36qW/fvlq4cKFOnTqlQYMGWVUeAADJGjkMAIC1yGIAAKxDDgMAEoJlTdb9+/erQoUK9seLFy9W7dq11adPH7388ssaOXKkVq1aZVV5AAAka+QwAADWIosBALAOOQwASAiWNVmvX7+udOnS2R///PPPqlGjhv1x4cKFdfbsWStKAwAg2SOHAQCwFlkMAIB1yGEAQEKwrMmaJUsWHTp0SJL077//au/evapYsaJ9/eXLl+Xt7W1VeQAAJGvkMAAA1iKLAQCwDjkMAEgIljVZGzdurE6dOmnWrFlq27atAgMDVa5cOfv6Xbt2qUCBAlaVBwBAskYOAwBgLbIYAADrkMMAgITgatWOQ0JCdPbsWX344YcKDAzU7NmzlSpVKvv6efPmqUGDBlaVBwBAskYOAwBgLbIYAADrkMMAgIRgM8YYq4tIaLfuWl0BkLj8S3ewugQg0d3cPdbqEhAPZDGSO7IYyR05/PQ7eumm1SUAiarYe/OtLgFIVOGLW1ldAuKBc2Ikd5wTI7mL6zmxZVeyPmjfvn06cuSIbDab8uXLp2LFilldEgAAKQY5DACAtchiAACsQw4DAB6XpU3WHTt2qE2bNjp48KDuX1Brs9lUuHBhTZkyRaVLl7ayPAAAkjVyGAAAa5HFAABYhxwGAMSXi1U7PnjwoGrWrCkvLy/Nnj1bv/32m3799VfNmjVLHh4eqlmzpg4ePGhVeQAAJGvkMAAA1iKLAQCwDjkMAEgIlt2TtUmTJoqMjNSSJUtks9kc1hlj9PLLL8vNzU0LFy50emzmvEdyx5z3SAm4F1ziSswclshiJH9kMZI7cjjxJXYWc09WJHfckxXJHfdkTVycEwPxwzkxkrskf0/WzZs3a+3atdFCTLo3LUPv3r31wgsvWFAZAADJHzkMAIC1yGIAAKxDDgMAEoJl0wVfv35dmTJlinV9YGCgrl+//gQrAgAg5SCHAQCwFlkMAIB1yGEAQEKwrMmaM2dO7dixI9b127dvV1BQ0BOsCACAlIMcBgDAWmQxAADWIYcBAAnBsibra6+9pi5dumj//v3R1v3+++/66KOP1LRpUwsqAwAg+SOHAQCwFlkMAIB1yGEAQEKwGWOMFTu+deuWatasqe3bt6t27doqVKiQJOngwYNav369ypQpo40bN8rT09P5sbmxOJI5biyOlCCuNxfH40nMHJbIYiR/ZDGSO3I48SV2Fh+9dDMhywWSnGLvzbe6BCBRhS9uZXUJyRrnxED8cE6M5C6u58SuiVxHrDw9PbVp0yaNGjVK8+bN0w8//CBJyp8/vwYPHqzOnTvLw8PDqvIAAEjWyGEAAKxFFgMAYB1yGACQECy7kvVRTp06pZCQEE2dOtXp5/JNISR3fFMIKQFX0FgrPjkskcVI/shiJHfksPXim8VcyYrkjitZkdxxJau1OCcGHo5zYiR3cT0ntuyerI8SGhqqGTNmWF0GAAApEjkMAIC1yGIAAKxDDgMA4iLJNlkBAAAAAAAAAAAAICmiyQoAAAAAAAAAAAAATqDJCgAAAAAAAAAAAABOcLVqxy+//PJD14eFhT2ZQgAASIHIYQAArEUWAwBgHXIYAJAQLGuy+vn5PXJ98+bNn1A1AACkLOQwAADWIosBALAOOQwASAiWNVmnTZtm1a7x/xbOn6uFC+bp7JkzkqQ8efOp3Xvvq1LlqpKkvr17auWKZQ7PKVqsuGbPWxjrmH/99afGj/lShw4e0NmzZ9StRy+92bxlrNtPmfSVvhz9ud54s7m69+oT/4MC/iNLBj8N7thQdSoWlpeHm/48eVHvDZij3YdORdt2TJ+mertxJXX7bLHGzt380HE7vF5NbZtUVvZAf10OC9ey9bvVd8xK3b5z97H2DTxp5HDSMGXSV9qw7nsdO/a3PDw9VaJESXXq8pFy5srtsN3fR49q9Oef6dddOxUVFaU8efPps5GjlTlLlhjHXbFsqfp93Cva8h2/7ZOHh4ekR78PABLCH2sGKChLumjLJy74UZ2HLVSfdi+oSd1nlC3QX3ciIrX70En1H7tKO/efiNP4Teo+q5nDWmnVpr16tcukOO8XSArIYuutWbZQa5Yv0oVzZyVJQbnyqFnLd1S6fCVJ0guVSsT4vNbvd1Lj11vGOu7yhbO1ZtkiXbpwXmnSplWlarXUst2Hcv//DH7UfoGElDnAW4PfLKXaJbPKy91Vf529qvcm/KI9f1+WayqbQpo9q7olsylnJh9duxGhTb+fVd/Zu3T+ys1YxyyULa0+blpSJXOnU1BGX3Wftl3j1hx02Obg+MYKyugb7blffXtIXSZvS/DjBJxFDicNjzovXb/uey1euECHDu5XWFiYFixeroKFCj10zLicD/+6a6emT52iQwf369KlSxr15TjVqFkrgY8OuOdRnxGn9nLX4A8bqkH1YgrwS60TZ0M1fv5mTVr0c5zGj+282MfbQyHv19eLNYorg7+P9h4+rY+GL9avB08mynGmVJY1WWG9jJkC1bHzR8qeI4ckadWK5erYob0WLFmmvHnzSZIqVqqsgYOH2p/j5ub20DFv3bypbNmzqXbd5zTi06EP3Xb/7/u0eNEC5c9fIJ5HAsQsra+XNk7voh92/qlGHcbrYuh15c6eXmHXo58sNqhWTKWL5tTZi2GPHLfp86U06MOGerf/HG3d+7fyBWXUpIFvSZK6j1zq9L4BpFy7du7Qa83eUOGiRRV5N1Jjvhyld9u20f+xd9/RUVQNGIffTa+kUUNJQgfpUgSE0EF6UYooReyKXYqidEGqqGCliEqxAoKiVBtdmkDovYeEQEgv8/2Rj5UlCcmSwEDye87J0b1z986dZZJ3Zu/MnR+WLJOHh4ck6cTx4+r36MPq0rWbnnn+BXl7eevw4UPWL2oz4+XlpcVLl9uUuV7znuwcBwA5df8jE+XoYLG+rlw2UD9/PFA/rNgmSTp47LxefvdbHTl5Qe6uzhr4SDP9NON5Vek0UhcuXrlh26WK+Wncy53119aDdq8XACSpYKEi6v/0CypWPC0LV/2yRKOHvqQPZi1QUOmy+mrxSpv6Wzb8pWnjR6phaOZfwq75bZlmf/y+XhoyQpWrVtepE8c0ZexwSdKTL7yerfUCucXX00WrxrTVH7vOqsvYFQq/FK/SRb11KSZRkuTh6qQaIf4a/912/XssUr6erprQv66+HdJCjQb/lGm77q5OOnouWj+uP6p3+9XNsE7jIT/J0cHB+rpySV8tHd5GP64/mqvbCODultV5aVxcrGrUrKlWrdto5PBh2W43q/PhuLhYVahQQZ26dNWrLw3MnY0BMpCd74gnvNZNobXLq/+bc3XsdIRa1K+kaUO760z4JS1d++8N27/RefFHbz+symUD9diwL3Qm/JJ6ta2rZR8PVK1uY3Q6/FKub2t+xSBrPtakaTOb1wNffFnfLJivnTu2W79cdXFxUcFChbLdZpWq1VSlajVJ0vtTJ2daLzYmRkMHv67hI8fos08+uoneA1l7tX9LnTx7UU+N+MpadvxMZLp6gYV8NHXIQ+rw7HT9+MEzWbZbr1qI1m8/rIXLt1jb/Gb5FtW+J8judQPI3z76dKbN61Fjxqlpo/oK27Nb99auI0n64P2pur9xY7382iBrvRIlS2bZtsViuWGGZ+c4AMip6wdKX+tfRYeOh+vPfw5IkjVLrxo8+Qf179JAVcoFau2m/Zm26+Bg0eyx/TT645/VsGYZ+Xq727VeAJCkevfbzt7Q96mBWrboW+3d86+CSpeVf0BBm+Ub/lqrarXqqFjxEpm2GbZrpypXraGmrdpKkooUK67QFm20P2xXttcL5JZXOlfVyYgYPT3jvzthjof/l5GXY5PUYfRvNu95deZG/fluB5Uo6KmTF2IybHfroQvaeuiCJGlU73szrHPhcoJtu52r6tCZy/pz99mb2hYAeVNW56UdOnaWJJ06ddKudrM6H76/USizOOG2yM53xPWqheirpRut56uzfvhbA7o1VK3KpW44yHqj82I3V2d1bl5DD738qf7eekiSNPaTn9WhaTU98VAjjZyxNDc3M19zyLoK8oOUlBT98vMyxcXFqnr1mtbyLZs3qUmj+urQtrVGvj1MERERubK+d8aMUuPGobqvfoNcaQ/ISLvQqtq657i+nvCYjq0ap/XzB6t/F9t9zmKxaOaYPpr6xSqFHc7eyd667YdVs3JJ66BqcPEAtW54j5b/tduudQPA9a5ER0uSCvz/+UCpqan68/e1CgoK1tNPDFCTRvXVu+dDWr1q5Y2akSTFxsaqTYumatmssZ5/9imFhe3JtG5mxwFAbnJ2clTPtnX0xeL1mS4f0LWhoqJj9e/+Uzds640nH9CFi1f0xaKM27JnvQAgpWXh7yuXKz4+TpXuqZZu+cXICG1e95datet8w3buqVZTB/ft0b49aV+InTl1r2FKrQABAABJREFUUls2/KU69Rvd1HqBnGhbu5S2HYrQl6820dGZPbVuYkf1a1H+hu/x8XBWaqphvds1Nzg7OahH4zKau4aLnQBkLjfPS+05HwZupex8R7xu+2G1D62qwEJp3wU1rl1O5YIKa+W6sBu2faPzYidHBzk5OSo+McmmPD4hSQ1qlsnhVuFad/2drAkJCUpIsL06znB0tbn9H5k7sH+fHn24pxITE+Th4aGp709XmbJpV842bNRYLVu3UbHAQJ06eVIzPpimJx7rqwXf/iAXF5ebXucvPy9TWNgezVv4XW5tBpChkOIF9cRDjfT+V6s1YeZvql0lSJMHPaiEpGTNW7pJUtrVRMkpqZo+f2222/32139U0M9Lq2a/LIsscnZ21Cff/KFJs1fYtW4gryCLc4dhGJo0YZxq1rpX5cqlffkVGRGh2NhYzZr5mZ4f+JJeeuU1/f3Xn3rlxef1+ey5ql0n4+nZQkqX1qix41SuXAXFxFzR11/OVb9HeumbHxYrKCjYWu9GxwFAbuvYtJp8vd311U8bbcofaFRFc8f3l4ebs85euKz2T3+oiKiM75yRpPrVS6tf5/qq13N8jtYL5CUZZXFCQipZnA1HDh3Qq0/3UWJiotzd3fXWO1NUKiT9F08rf1kidw8PNQxtfsP2Qlu00aWoi3r92f4yDCklJVntOj+k7o8+dlPrBXIipIiXHm9VQR8s3a1JP+zUvWULaVL/ekpMStG83w+lq+/q7KhRj9TWN38dVnRcUgYt3pwOdUrJ19NFXzHIijyKc+Kcye3z0uyeDwO3Q7a+n373W814+2Ed+m2skpJSlGqk6plR87Ru++FM283qvPhKbII27DisoU88oH1HzulcxGV1b1NbdaoE6eDx8FuyrfnVXX8n67hx4+Tj42PzMzGLZ4HiP8HBIfrm+0X6ct5CPdSjl956Y7AOHUybv7vNA23VOLSJypUrryZNm2n6J5/p2NGj+uP3tTe9vrNnzmjC+LF6Z/xEDjRwyzk4WLR97wkN//An7dh3UjO//1uzf1ynJx9Ku4q8ZqWSeq5XEz05/KssWrLV6N5yGjSgtV4ct1D1H35XPV75VG0bVdGQJ9pke91AXkIW545xY0bpwP79enfiFGtZqpEqSWratLke7dtPFStV0oAnnlTj0Cb6duGCTNuqVr2G2nfopAoVK6rWvbU1ccp7CgoK1vyvbf/e3eg4AMhtfTs30K9/79GZ65798vvm/arXc5ya9pui39bt0VcTHlMhP68M2/DycNWssX307Oj5NxyIzc56gbwkoyz+eNpEs7t1VyhRKlgfzl6oKZ/MVdvO3TV57Ns6fiT94NOKZYvVtFXbLJ+JvnPrZi2c+7meffUNvT9rvoaNnaJN6/7UvDmf3tR6gZxwsFi0/UikRszbqh1HIjVrxT7NXrVfj7eqmK6uk6NFX7wcKgeLRS99lruzP/RtXl6/bTupsxfjsq4M3IU4J86Z3D4vze75MHA7ZOc74ud6NVHdqsHq9uLHatD7XQ2Z8qOmDe2hpvUqZNhmds+LHxs2VxaLdPi3sbq08T091ytUC3/ZopTU1FzfzvzM9DtZlyxZkmG5xWKRm5ubypYtq5CQkEzfP3ToUL3yyis2ZYYjg3fZ5eziolJBaVOe3lOlqnbv+ldffzVXb48Yla5uoUKFFRgYqOPHjt70+vbs2a3IiAj16t7VWpaSkqJ/tmzWgvlfa/O2f+Xo6HjT7QPXOnvhcropgPceOavOzWtIkhrWLKPC/l7a//N/+7uTk6PGv9JVz/duqorthmfY7vBn22n+sk2a82Paiefug6fl4e6q6cN66d3Pf5VhGFmuG7hT5DSHJbI4N4wbO1pr167WrC++UpGiRa3lfr5+cnJyUukytne2hJQuo+1b/8l2+w4ODrqnStV0GW7PcQCQE6WK+alZvQrq+dpn6ZbFxifq8IkLOnzigjb9e1T/Ln5bfbs00KRZv6WrW7pEQQUXL6jv33vKWubgYJEkRW+epmpdRuvIyQvZWi9wp7hVWXzyMl+eZIezs7MCS5SSJJWveI8OhO3W4m/naeCgt6x1du3YqpPHj2rIyHezbO/Lz2eoWet2atMh7Zw3pEw5xcfH6YMJo9Wzz+NycHDI9nqBnDobFae9J6JsyvadjFLnekE2ZU6OFn35SlMFF/ZW2xHLc/Uu1pIFPdW0ajH1mrQm19oEchPnxOa71eelmZ0PA7dDVt8Ru7k6a+TADurxymfWR9HtOnBa1SqU0EuPNteajfvStZnd8+IjJy+o1ePT5OHmogJebjp74bK+HN9fR0/lziMhkcb0QdbOnTvLYrHIMAyb8qtlFotF999/vxYtWiQ/P79073d1TT/1QnzyLe1ynmYYhpISM37uRlTURZ09e0aFChW+6fbr3Xefvlv0k03Z8DeHKrh0afUf8AQDrMhV67cfVvkg2/21XKnC1oeLz1u2WauvC6qfZjynecs2ae7iDZm26+7motRU279Zqampslgki0UyjKzXDdwpcprDElmcE4ZhaNzY0Vq9aoVmzvlSJUqUtFnu7OKie6pU1dGjR2zKjx07qmKBxe1az769YSpb/sbP4LrRcQCQE492rK/zkdH65c/dWda1yCJX54xPU/YdPad7HxxrUzbiufby8nDTaxO/08mzF296vYBZblUWuyZwx9jNMGQoKck2C39b+qPKVqis0uUyvpvgWgnx8bJYbCcNc3BwkGEY6f6Ns1ovkFMb9p5TueIFbMrKBfro+IX/7nq5OsBatlgBPTDiF0VeSbi+mRx5tFk5hV+O1/J/TuRqu0Bu4Zz4zpPb56XZPR8GboWsviN2dnKUi7OTUq/7G5SSkmodOL2evefFsfGJio1PlK+3u1o0qKQ331uc083CNUyfLnjFihWqU6eOVqxYoUuXLunSpUtasWKF6tatq6VLl+qPP/5QRESEXnvtNbO7mue8/94Ubf1ni06dOqkD+/fpg2lTtWXzJrVt30GxMTGaPPFd7di+TadOndTmTRv1wnPPyNfPT81atLC28ebQQZo2dbL1dVJiovaGhWlvWJiSkhJ1/vw57Q0L0/FjxyRJnp5eKleuvM2Pu4eHfH18rc+fA3LLB1+tVt2qIXr9sVYqXbKgerSprce6NdQnC/+QJEVeitGeQ2dsfpKSU3TuwmUdOHbe2s7nox/VqIEdra9//mOXnnjofj3U+l4FBQaoWb2KevuZ9lr2+7/Wwdes1g3cKchhc70zeqR+XrpE4ydMlqeHpy6Eh+tCeLji4+Otdfr2H6Bff/lF33/7jY4fO6b5X3+lP9auUfeevax1rs/jj2d8qL//+lMnT5zQ3rAwDX/rDe3bt1cPdf/vPTc6DgByk8ViUZ9O9+nrpRuVkvLfnXUebi4a+XwH1a0arFLF/FSjYgnNePthFS/iqx9WbLXWuzaHExKT02V3VHScrsTGW3M8q/UCdxqy2DxzPnlfu3Zs1bkzp3Tk0AF98ckH+nfbFjVp1dZaJzbmiv5cs0KtO3TJsI1Jo4dp9sfvW1/XbdhYyxZ9q99XLtfZ06e0dfN6ffn5DNW7P9R6UXF21gvkhg+W7lHdcoX1WtdqKl3UW93vL63+Lcrr0+VhkiRHB4u+fq2ZapUpqMem/S5HBwcV8XVXEV93OTv995XhZwMbaeTD91pfOzs5qFqwv6oF+8vFyVGB/h6qFuyv0kW9bdZvsUiPNi2nr9ceVEpq5hcZAGYih82V1Xnppago7Q0L0+FDaVPqHz16RHvDwnQh/L9nSt7M+XBsTIz1O2xJOnXypPaGhenM6dO3Y7ORj2T1HXF0TLz+2HJA77zUWY3uLaegwAA90qGeerevqyVrdljbuZnz4hb1K6llg0rW76+Xf/aiDhw9r7lLcvexAPmd6Xeyvvjii/r000/VoEEDa1nz5s3l5uamJ598Urt379Z7772nxx57zMRe5k0RERf05pBBCg8/Ly9vb5UvX0EzPvlc9Rs0VHx8vA7s36+flixS9OVoFSpUSHXq1tOESVPl6fnfM7LOnjkjh2uu0j0ffl49Huxsff3F7Fn6YvYs1a5TVzPnfHk7Nw/QP3uOq8ern2nUwI5648kHdPRUhF6f+L0W/LLFrnZKFvW3uXN1/OfLZRiGhj/bXoGFfXTh4hUt+2OXRnz4313aubVu4FYjh831zcL5kqQB/R61KR81Zpw6dUmbZrB5i5YaNnyEZn32qd4dN0bBwSGa/N77qnVvbWv96/M4+vJljR7xti5cCJeXt7cqVqysWV98parVqlnr3Og4AMhNzepVUKli/vpike0sESmpqaoQXESPdKinAF9PRV6K1Zbdx9Tisak20yldn8M5XS9wpyGLzRMVGalJo99UZMQFeXp6KaRMeY2aPF216tS31vl95XLJkJq0aJNhG+HnztjcZdCr7xOyWCya+9l0RYSfl4+vn+o2bKy+Tz5v13qB3LD10AX1nLhKox6uraEPVtfR81c0aM4mLfzzsCSpeICn2tdJm7Z6w+TONu9tM/wX/bk7LY9LFPS0yeJifh5aP6mT9fVLnarqpU5V9cfuM3pg+HJrebNqgSpVyEtzVx+4VZsI5Bg5bK6szkvXrlmtt4cNtdYf/NrLkqSnn31ezzw3UNLNnQ/v3r1Lj/fvY309aULaM3Q7duqi0e+Mv3UbjHwnO98R9xkyS6MGdtKcd/rKr4CHjp+J1IjpS/XZt39Z69zMebGPl5tGDeyo4kV8FXkpVotXbdfw6T8pOZmLkHOTxbjRfDW3gbu7uzZv3qwqVarYlP/777+qW7eu4uLidOzYMVWqVEmxsbHZapPpGJDX+dV5PutKwF0ubtuHZnchX7gVOSyRxcj7yGLkdeTw7XOrsvhQONMFI2+r9swCs7sA3FIx3/U3uwv5AufEwM3hnBh5XXbPiU2fLvjee+/V66+/rvBrbvEPDw/XoEGDVKdOHUnSgQMHVKJECbO6CABAnkUOAwBgLrIYAADzkMMAgJwwfbrgmTNnqlOnTipRooRKliwpi8Wi48ePq3Tp0lq8OO0BvFeuXNFbb71lck8BAMh7yGEAAMxFFgMAYB5yGACQE6ZPFyxJhmHo119/1f79+2UYhipWrKiWLVvKweHmbrRlOgbkdUzHgPyAaQpvn9zOYYksRt5HFiOvI4dvr1uRxUwXjLyO6YKR1zFd8O3DOTFgP86Jkddl95z4jhhkzW2EGPI6Qgz5AV/u3t3IYuR1ZDHyOnL47scgK/I6BlmR1zHIenfjnBh5HefEyOuye05s+nTBkrRq1SqtWrVK58+fV2pqqs2yWbNmmdQrAADyB3IYAABzkcUAAJiHHAYA3CzTB1lHjhypUaNGqXbt2ipWrJgsFovZXQIAIN8ghwEAMBdZDACAechhAEBOmD7I+vHHH2vOnDl69NFHze4KAAD5DjkMAIC5yGIAAMxDDgMAcuLmn96dSxITE9WgQQOzuwEAQL5EDgMAYC6yGAAA85DDAICcMH2Q9fHHH9e8efPM7gYAAPkSOQwAgLnIYgAAzEMOAwBywvTpguPj4/Xpp59q5cqVqlatmpydnW2WT5kyxaSeAQCQ95HDAACYiywGAMA85DAAICdMH2TduXOnatSoIUnatWuXzTIeNA4AwK1FDgMAYC6yGAAA85DDAICcMH2Qdc2aNWZ3AQCAfIscBgDAXGQxAADmIYcBADlh+jNZr3Xy5EmdOnXK7G4AAJAvkcMAAJiLLAYAwDzkMADAXqYPsqampmrUqFHy8fFRUFCQSpUqJV9fX40ePVqpqalmdw8AgDyNHAYAwFxkMQAA5iGHAQA5Yfp0wW+++aZmzpyp8ePHq2HDhjIMQ3///bdGjBih+Ph4jR071uwuAgCQZ5HDAACYiywGAMA85DAAICcshmEYZnYgMDBQH3/8sTp27GhTvnjxYj377LM3NUVDfHJu9Q64M/nVed7sLgC3XNy2D83uQr5wK3JYIouR95HFyOvI4dvnVmXxofC43OgecMeq9swCs7sA3FIx3/U3uwv5AufEwM3hnBh5XXbPiU2fLjgyMlIVK1ZMV16xYkVFRkaa0CMAAPIPchgAAHORxQAAmIccBgDkhOmDrNWrV9eHH6YfEf7www9VvXp1E3oEAED+QQ4DAGAushgAAPOQwwCAnDD9mawTJkxQu3bttHLlStWvX18Wi0Xr1q3TiRMn9PPPP5vdPQAA8jRyGAAAc5HFAACYhxwGAOSE6XeyhoaGav/+/erSpYuioqIUGRmprl27at++fWrUqJHZ3QMAIE8jhwEAMBdZDACAechhAEBOmH4nq5T2gPGxY8falJ04cUKPPfaYZs2aZVKvAADIH8hhAADMRRYDAGAechgAcLNMv5M1M5GRkfriiy/M7gYAAPkSOQwAgLnIYgAAzEMOAwCy444dZAUAAAAAAAAAAACAOxGDrAAAAAAAAAAAAABgBwZZAQAAAAAAAAAAAMAOTmatuGvXrjdcHhUVdXs6AgBAPkQOAwBgLrIYAADzkMMAgNxg2iCrj49Plsv79Olzm3oDAED+Qg4DAGAushgAAPOQwwCA3GDaIOvs2bPNWjUAAPkeOQwAgLnIYgAAzEMOAwByA89kBQAAAAAAAAAAAAA7MMgKAAAAAAAAAAAAAHZgkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYgUFWAAAAAAAAAAAAALADg6wAAAAAAAAAAAAAYAcGWQEAAAAAAAAAAADADgyyAgAAAAAAAAAAAIAdGGQFAAAAAAAAAAAAADswyAoAAAAAAAAAAAAAdmCQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsAODrAAAAAAAAAAAAABgBwZZAQAAAAAAAAAAAMAODLICAAAAAAAAAAAAgB0YZAUAAAAAAAAAAAAAOzDICgAAAAAAAAAAAAB2YJAVAAAAAAAAAAAAAOzAICsAAAAAAAAAAAAA2IFBVgAAAAAAAAAAAACwA4OsAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA4MsgIAAAAAAAAAAACAHRhkBQAAAAAAAAAAAAA7MMgKAAAAAAAAAAAAAHZgkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYgUFWAAAAAAAAAAAAALADg6wAAAAAAAAAAAAAYAcGWQEAAAAAAAAAAADADgyyAgAAAAAAAAAAAIAdGGQFAAAAAAAAAAAAADswyAoAAAAAAAAAAAAAdmCQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsIPFMAzD7E7g7paQkKBx48Zp6NChcnV1Nbs7QK5jHwdwJ+NvFPID9nMAdzL+RiGvYx8HcKfj7xTyOvbxOxeDrMixy5cvy8fHR5cuXVKBAgXM7g6Q69jHAdzJ+BuF/ID9HMCdjL9RyOvYxwHc6fg7hbyOffzOxXTBAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA4MsgIAAAAAAAAAAACAHRhkRY65urpq+PDhPHAZeRb7OIA7GX+jkB+wnwO4k/E3Cnkd+ziAOx1/p5DXsY/fuSyGYRhmdwIAAAAAAAAAAAAA7hbcyQoAAAAAAAAAAAAAdmCQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQdZ8wmKxaNGiRWZ3AwCAfIkcBgDAXGQxAADmIosB5EUMsuYB58+f11NPPaVSpUrJ1dVVRYsWVevWrbV+/frbsv7sBmRW9Xbv3q3u3burUKFCcnV1Vbly5fTWW28pNjbWpt62bdvUvn17FS5cWG5ubgoODlaPHj104cKFHG4J7nT9+vVT586dze5GOln1Ky4uTsOHD1eFChXk6uqqggUL6sEHH9Tu3btt6sXExGjw4MEqXbq03NzcVKhQITVp0kRLly69xVsAICfIYXI4vyCHAdypyGKyOL8giwHcqchisjg/IIeRESezO4Cc69atm5KSkvTFF1+odOnSOnfunFatWqXIyMhbut7ExES5uLjkSlsbNmxQixYt1KJFCy1btkxFihTRpk2b9Oqrr2r16tVas2aNXFxcdP78ebVo0UIdOnTQr7/+Kl9fXx05ckRLlixJF3bAnSAhIUEtWrTQ8ePHNXnyZNWrV0/nzp3TuHHjVK9ePa1cuVL33XefJOnpp5/Wpk2b9OGHH6py5cqKiIjQunXrFBERYfJWALgRcpgcxp2LHAbyB7KYLMadiywG8geymCzGnYkcvg0M3NUuXrxoSDLWrl17w3qSjM8++8zo3Lmz4e7ubpQtW9ZYvHixTZ21a9caderUMVxcXIyiRYsagwcPNpKSkqzLQ0NDjeeee854+eWXjYCAAKNx48ZGUFCQIcn6ExQUdMM+/Pjjj+nKU1NTjcqVKxu1a9c2UlJSbJZt377dsFgsxvjx4w3DMIwff/zRcHJysukX8o++ffsanTp1ynR5dvbhgQMHGq+//rrh5+dnFClSxBg+fLhNG2FhYUbDhg0NV1dXo1KlSsaKFSsy3Xez06/x48cbFovF2L59u015SkqKUbt2baNy5cpGamqqYRiG4ePjY8yZM+eGnwGAOws5jPyEHAZwJyKLkZ+QxQDuRGQx8gtyGBlhuuC7nJeXl7y8vLRo0SIlJCTcsO7IkSPVvXt37dy5U23btlXv3r2tVxOdOnVKbdu2VZ06dbRjxw599NFHmjlzpsaMGWPTxhdffCEnJyf9/fff+uSTT7R582ZJ0uzZs3XmzBnra3ts375de/bs0SuvvCIHB9tdsnr16mrRooXmz58vSSpatKiSk5P1448/yjAMu9eFvMuefdjT01MbN27UhAkTNGrUKK1YsUKSlJqaqs6dO8vDw0MbN27Up59+qjfffDNH/Zo3b55atmyp6tWr25Q7ODjo5Zdf1p49e7Rjxw5Jafv3zz//rOjo6BytE8DtQw4DachhAGYhi4E0ZDEAs5DFADmcr5k7xovc8N133xl+fn6Gm5ub0aBBA2Po0KHGjh07bOpIMoYNG2Z9feXKFcNisRi//PKLYRiG8cYbbxgVKlSwXrVgGIYxffp0w8vLy3r1TmhoqFGjRo1061cWV1JkVW/BggWGJGPbtm0Zvu+FF14w3N3dra/feOMNw8nJyfD39zfatGljTJgwwTh79myW68fd70ZX5WR3H77//vtt3lenTh1j8ODBhmEYxi+//GI4OTkZZ86csS7P6dVCbm5uxosvvpjhsq1btxqSjIULFxqGYRi///67UaJECcPZ2dmoXbu28dJLLxl//fVXpusFcGcgh8nh/IIcBnCnIovJ4vyCLAZwpyKLyeL8gBxGRriTNQ/o1q2bTp8+rSVLlqh169Zau3atatWqpTlz5tjUq1atmvX/PT095e3trfPnz0uSwsLCVL9+fVksFmudhg0b6sqVKzp58qS1rHbt2rd2YzJgGIZNv8aOHauzZ8/q448/VuXKlfXxxx+rYsWK+vfff29733DnyO4+fO3vgSQVK1bM+nuwb98+lSxZUkWLFrUur1u37i3rs/H/q92u9rlx48Y6fPiwVq1apW7dumn37t1q1KiRRo8efcv6ACDnyGFyGOQwAHORxWQxyGIA5iKLyeL8jhzOvxhkzSPc3NzUsmVLvf3221q3bp369eun4cOH29Rxdna2eW2xWJSamiopfVBcLbta7ypPT89c73v58uUlSXv27Mlw+d69e1WuXDmbsoCAAD300EOaPHmywsLCFBgYqEmTJuV633D3yO4+bO/vQU6VL1/+hvu2JJv929nZWY0aNdKQIUP022+/adSoURo9erQSExNztV8Achc5TA7nd+QwALORxWRxfkcWAzAbWUwW52fkcP7FIGseVblyZcXExNhVf926dTbzyK9bt07e3t4qXrz4Dd/r7OyslJSUm+5rjRo1VLFiRU2dOtX6B+WqHTt2aOXKlerVq1em73dxcVGZMmXs2l7kPTnZh6+qWLGijh8/rnPnzlnLbuY5Dtfq2bOnVq5caZ3b/qrU1FRNnTpVlStXTjcn/rUqV66s5ORkxcfH56gfAG4vchj5DTkM4E5DFiO/IYsB3GnIYuQn5HD+5WR2B5AzEREReuihh/TYY4+pWrVq8vb21pYtWzRhwgR16tQp2+08++yzeu+99zRw4EA9//zz2rdvn4YPH57hw76vFxwcrFWrVqlhw4ZydXWVn59fpnWPHDmi7du325SVLVtWn3/+uVq1aqVu3bpp6NChKlq0qDZu3KhXX31V9evX10svvSRJWrp0qRYsWKCePXuqfPnyMgxDP/30k37++WfNnj0729uLu9elS5fS7UP+/v452oevatmypcqUKaO+fftqwoQJio6Otj5cPKuriDLr18svv6zFixerQ4cOmjx5surVq6dz587pnXfeUVhYmFauXGltu0mTJurVq5dq166tgIAA7dmzR2+88YaaNm2qAgUKZO8DAnBbkcPkcH5DDgO405DFZHF+QxYDuNOQxWRxfkIOI51b97hX3A7x8fHGkCFDjFq1ahk+Pj6Gh4eHUaFCBWPYsGFGbGystZ4yeDiyj4+PMXv2bOvrtWvXGnXq1DFcXFyMokWLGoMHDzaSkpKsy0NDQzN8SPKSJUuMsmXLGk5OTkZQUFCmfZWU4c+aNWsMwzCMnTt3Gt26dTMCAgIMZ2dno0yZMsawYcOMmJgYaxuHDh0ynnjiCaN8+fKGu7u74evra9SpU8dmO5B39e3bN8N9qG/fvoZh3Nw+3KlTJ+v7DcMwwsLCjIYNGxouLi5GxYoVjZ9++smQZCxfvvym+xUTE2MMGzbMKFu2rOHs7Gz4+/sb3bp1M/7991+bdt555x2jfv36hr+/v+Hm5maULl3aeOGFF4wLFy7k6HMDcOuQw+RwfkIOA7gTkcVkcX5CFgO4E5HFZHF+QQ4jIxbDuOb+ZQCAjb///lv333+/Dh48qDJlypjdHQAA8hVyGAAAc5HFAACYhxy+8zHICgDX+PHHH+Xl5aVy5crp4MGDevHFF+Xn56e//vrL7K4BAJDnkcMAAJiLLAYAwDzk8N2HZ7ICwDWio6M1aNAgnThxQgULFlSLFi00efJks7sFAEC+QA4DAGAushgAAPOQw3cf7mQFAAAAAAAAAAAAADs4mN0BAAAAAAAAAAAAALibMMgKAAAAAAAAAAAAAHZgkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYgUFWAAAAAAAAAAAAALADg6xALhsxYoRq1Khhfd2vXz917tz5tvfj6NGjslgs2r59+y1bx/XbejNuRz8BAPkHOWwfchgAkNvIYvuQxQCA3EYW24csRk4wyIp8oV+/frJYLLJYLHJ2dlbp0qX12muvKSYm5pave9q0aZozZ0626t7uP+hNmjTRSy+9dFvWBQDIv8jhjJHDAIDbhSzOGFkMALhdyOKMkcW42zmZ3QHgdmnTpo1mz56tpKQk/fnnn3r88ccVExOjjz76KF3dpKQkOTs758p6fXx8cqUdAADuZuQwAADmIosBADAXWQzkPdzJinzD1dVVRYsWVcmSJfXwww+rd+/eWrRokaT/phWYNWuWSpcuLVdXVxmGoUuXLunJJ59U4cKFVaBAATVr1kw7duywaXf8+PEqUqSIvL29NWDAAMXHx9ssv346htTUVL377rsqW7asXF1dVapUKY0dO1aSFBISIkmqWbOmLBaLmjRpYn3f7NmzValSJbm5ualixYqaMWOGzXo2bdqkmjVrys3NTbVr19a2bdty/JkNHjxY5cuXl4eHh0qXLq233npLSUlJ6ep98sknKlmypDw8PPTQQw8pKirKZnlWfQcA5H3ksP3IYQBAbiKL7UcWAwByE1lsP7IYdzruZEW+5e7ubvMH+eDBg/rmm2/0/fffy9HRUZLUrl07+fv76+eff5aPj48++eQTNW/eXPv375e/v7+++eYbDR8+XNOnT1ejRo305Zdf6v3331fp0qUzXe/QoUP12WefaerUqbr//vt15swZ7d27V1JaENWtW1crV67UPffcIxcXF0nSZ599puHDh+vDDz9UzZo1tW3bNj3xxBPy9PRU3759FRMTo/bt26tZs2b66quvdOTIEb344os5/oy8vb01Z84cBQYG6t9//9UTTzwhb29vDRo0KN3n9tNPP+ny5csaMGCAnnvuOX399dfZ6jsAIH8ih7NGDgMAbiWyOGtkMQDgViKLs0YW445nAPlA3759jU6dOllfb9y40QgICDC6d+9uGIZhDB8+3HB2djbOnz9vrbNq1SqjQIECRnx8vE1bZcqUMT755BPDMAyjfv36xtNPP22zvF69ekb16tUzXPfly5cNV1dX47PPPsuwn0eOHDEkGdu2bbMpL1mypDFv3jybstGjRxv169c3DMMwPvnkE8Pf39+IiYmxLv/oo48ybOtaoaGhxosvvpjp8utNmDDBuPfee62vhw8fbjg6OhonTpywlv3yyy+Gg4ODcebMmWz1PbNtBgDkHeRwxshhAMDtQhZnjCwGANwuZHHGyGLc7biTFfnG0qVL5eXlpeTkZCUlJalTp0764IMPrMuDgoJUqFAh6+t//vlHV65cUUBAgE07cXFxOnTokCQpLCxMTz/9tM3y+vXra82aNRn2ISwsTAkJCWrevHm2+x0eHq4TJ05owIABeuKJJ6zlycnJ1vn0w8LCVL16dXl4eNj0I6e+++47vffeezp48KCuXLmi5ORkFShQwKZOqVKlVKJECZv1pqamat++fXJ0dMyy7wCA/IEcth85DADITWSx/chiAEBuIovtRxbjTscgK/KNpk2b6qOPPpKzs7MCAwPTPTjc09PT5nVqaqqKFSumtWvXpmvL19f3pvrg7u5u93tSU1MlpU1rUK9ePZtlV6eNMAzjpvpzIxs2bFDPnj01cuRItW7dWj4+PlqwYIEmT558w/dZLBbrf7PTdwBA/kAO24ccBgDkNrLYPmQxACC3kcX2IYtxN2CQFfmGp6enypYtm+36tWrV0tmzZ+Xk5KTg4OAM61SqVEkbNmxQnz59rGUbNmzItM1y5crJ3d1dq1at0uOPP55u+dU57lNSUqxlRYoUUfHixXX48GH17t07w3YrV66sL7/8UnFxcdagvFE/suPvv/9WUFCQ3nzzTWvZsWPH0tU7fvy4Tp8+rcDAQEnS+vXr5eDgoPLly2er7wCA/IEctg85DADIbWSxfchiAEBuI4vtQxbjbsAgK5CJFi1aqH79+urcubPeffddVahQQadPn9bPP/+szp07q3bt2nrxxRfVt29f1a5dW/fff7++/vpr7d69O9MHi7u5uWnw4MEaNGiQXFxc1LBhQ4WHh2v37t0aMGCAChcuLHd3dy1fvlwlSpSQm5ubfHx8NGLECL3wwgsqUKCAHnjgASUkJGjLli26ePGiXnnlFT388MN68803NWDAAA0bNkxHjx7VpEmTsrWd4eHh2r59u01Z0aJFVbZsWR0/flwLFixQnTp1tGzZMv34448ZblPfvn01adIkXb58WS+88IK6d++uokWLSlKWfQcAICPkMDkMADAXWUwWAwDMRRaTxbgLmPtIWOD2uP7B4tcbPny4zcPAr7p8+bIxcOBAIzAw0HB2djZKlixp9O7d2zh+/Li1ztixY42CBQsaXl5eRt++fY1BgwZl+mBxwzCMlJQUY8yYMUZQUJDh7OxslCpVynjnnXesyz/77DOjZMmShoODgxEaGmot//rrr40aNWoYLi4uhp+fn9G4cWPjhx9+sC5fv369Ub16dcPFxcWoUaOG8f3332frweKS0v0MHz7cMAzDeP31142AgADDy8vL6NGjhzF16lTDx8cn3ec2Y8YMIzAw0HBzczO6du1qREZG2qznRn3nweIAkPeRwxkjhwEAtwtZnDGyGABwu5DFGSOLcbezGMYtmCwbAAAAAAAAAAAAAPIoB7M7AAAAAAAAAAAAAAB3EwZZAQAAAAAAAAAAAMAODLICAAAAAAAAAAAAgB0YZAUAAAAAAAAAAAAAOzDICgAAAAAAAAAAAAB2YJAVAAAAAAAAAAAAAOzAICsAAAAAAAAAAAAA2IFBVgAAAAAAAAAAAACwA4OsAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA4MsgIAAAAAAAAAAACAHRhkBQAAAAAAAAAAAAA7MMgKAAAAAAAAAAAAAHZgkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYgUFWAAAAAAAAAAAAALADg6wAAAAAAAAAAAAAYAcGWQEAAAAAAAAAAADADgyyAgAAAAAAAAAAAIAdGGQFAAAAAAAAAAAAADswyAoAAAAAAAAAAAAAdmCQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsAODrAAAAAAAAAAAAABgBwZZAQAAAAAAAAAAAMAODLICAAAAAAAAAAAAgB0YZAUAAAAAAAAAAAAAOzDICgAAAAAAAAAAAAB2YJAVAAAAAAAAAAAAAOzAICsAAAAAAAAAAAAA2IFBVgAAAAAAAAAAAACwA4OsAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA4MsgIAAAAAAAAAAACAHRhkBQAAAAAAAAAAAAA7MMiaR1kslmz9rF271uyuWo0YMUIWi0UXLly4Yb1+/frJy8vrhnXmzJkji8Wio0eP2t2PtWvXymKx6LvvvrP7vbfb1b5e/XF0dFShQoXUoUMHbdmyxbR+5eTzz611Z/Tz2muv3fb+ZMc777yjRYsWmd0NADdAruaPXL3qyJEjeuGFF1SpUiV5enrKzc1NwcHBeuSRR7RmzRoZhnFb+pHR596kSRM1adLklq53z549GjFiRIb/3v369Ut37FGiRAl1795du3btuqX9yo6s+h4cHHzb+wTAfuRu/shds/p6M3lw+vRpjRgxQtu3b0+37Oq//c3049r92cXFRWXKlNFrr72my5cv293e3ep2HNsAQFY49shfxx4Wi0Vz5szJsE6zZs1ksVjSHSsEBwerffv2N2z/+mx3dXVVhQoVNHz4cMXHx+fSVuBO42R2B3BrrF+/3ub16NGjtWbNGq1evdqmvHLlyrezW7dNu3bttH79ehUrVszsrtwW77zzjpo2baqkpCRt27ZNI0eOVGhoqLZv365y5cqZ3T1TzJ49WxUrVrQpCwwMNKk3N/bOO+/owQcfVOfOnc3uCoBMkKv5J1eXLFmihx9+WAULFtTTTz+tWrVqydXVVQcPHtR3332nZs2aaeXKlWrevLkp/ZsxY8YtX8eePXs0cuRINWnSJMMvod3d3a37fnJysg4ePKgxY8aoQYMGCgsLU/HixW95HzNzo76/9dZbevHFF83pGAC7kLv5J3fNcDN5cPr0aY0cOVLBwcGqUaOGzbLHH39cbdq0uam+XJupUVFR+u677zR58mTt3LlTv/322021ebe5Hcc2AJAVjj3y17GHt7e3Zs6cqX79+tmUHzlyRGvXrlWBAgVuuu1rs/3ixYuaP3++Ro0apb1792rhwoU56TbuUAyy5lH33XefzetChQrJwcEhXXleVahQIRUqVMjsbmTb1S8CM7uCJivlypWz/ts2atRIvr6+6tu3r7766iuNHDkyF3t696hSpYpq166d6+3GxsbKw8Mj19sFcGcjV/NHrh46dEi9evXSPffco5UrV9qcWIWGhmrAgAFau3at/Pz8btjOrcyKO+Gk/vp9//7771epUqXUvHlzLVu2TE8++aSJvctcmTJlzO4CgGwid/NH7polt/OgRIkSKlGixE299/r9uk2bNjp8+LBWrFihI0eOKCQkJLe6maWUlBQlJyfL1dX1tq1TujOObQCAY4/8dezRo0cPff755zpw4IDNDUqzZs1S8eLFVbVqVe3Zs+em2r5+v3nggQd09OhRffPNN5oyZYqpFyXj1mC64HwsMjJSzz77rIoXLy4XFxeVLl1ab775phISEmzqWSwWPf/885o9e7YqVKggd3d31a5dWxs2bJBhGJo4caJCQkLk5eWlZs2a6eDBg+nWdfWOjwIFCsjDw0MNGzbUqlWrsuzj3r17Vbp0adWrV0/nz5/P9rZlNr1elSpVtHnzZjVq1EgeHh4qXbq0xo8fr9TU1Bu2d/nyZbVu3VpFihTRpk2bJEnh4eF68sknVbJkSbm6uqpQoUJq2LChVq5cme1+3ipXBxfPnTtnUz5y5EjVq1dP/v7+KlCggGrVqqWZM2emm/bw6vQHy5cvV61ateTu7q6KFStq1qxZ6da1YcMGNWzYUG5ubgoMDNTQoUOVlJSUrl5qaqomTJigihUrytXVVYULF1afPn108uRJm3pX/53Wr1+vBg0ayN3dXcHBwZo9e7YkadmyZapVq5Y8PDxUtWpVLV++/KY+oyVLlqh+/fry8PCQt7e3WrZsme6qtavTbmzdulUPPvig/Pz8rCfkhmFoxowZqlGjhtzd3eXn56cHH3xQhw8ftmlj27Ztat++vQoXLixXV1cFBgaqXbt21u22WCyKiYnRF198YZ1KgqmSgLsTuXr35+qUKVMUGxurGTNmZHrlapMmTVS9enXr6xtlxZYtW9SzZ08FBwdb86xXr146duxYunazm6cZTamXmJioMWPGWDO2UKFC6t+/v8LDw23qZSff58yZo4ceekiS1LRp0yynUrrKx8dHkuTs7GxTvmvXLnXq1El+fn5yc3NTjRo19MUXX6R7//Hjx/XII49Y87JSpUqaPHlyun3po48+UvXq1eXl5SVvb29VrFhRb7zxRrb6ntH0kFd/H7/88ktVqlRJHh4eql69upYuXZquj4sXL1a1atXk6uqq0qVLa9q0aTc9RSSAnCN37/7cza7sZsnu3bvVqlUreXh4qFChQnruuee0bNmydNM7ZpQH3377rerVqycfHx/rZ/vYY49JSptasE6dOpKk/v37W/NlxIgRkjKfLnjevHmqX7++vLy85OXlpRo1amjmzJlZbm9m5/MLFy5U/fr15enpKS8vL7Vu3Vrbtm1L9/7PPvtM5cuXl6urqypXrqx58+al2+ajR4/KYrFowoQJGjNmjEJCQuTq6qo1a9ZISjuG6dixo/z9/eXm5qaaNWvqm2++sVlPbGysXnvtNYWEhMjNzU3+/v6qXbu25s+fb61z+PBh9ezZU4GBgXJ1dVWRIkXUvHlzm2mXMzq2sff3Ozs5DgA5xbFH3jn2aNmypUqWLGlzLpyamqovvvhCffv2lYND7g6bXR10zei7ANz9uJM1n4qPj1fTpk116NAhjRw5UtWqVdOff/6pcePGafv27Vq2bJlN/aVLl2rbtm0aP368LBaLBg8erHbt2qlv3746fPiwPvzwQ126dEmvvPKKunXrpu3bt1tPMr766iv16dNHnTp10hdffCFnZ2d98sknat26tX799ddMp9v7/fff1aVLFzVu3Fjz5s3LlTtCzp49q969e+vVV1/V8OHD9eOPP2ro0KEKDAxUnz59MnzPyZMn1bZtWyUmJmr9+vUqXbq0JOnRRx/V1q1bNXbsWJUvX15RUVHaunWrIiIictzPnDpy5IgkqXz58jblR48e1VNPPaVSpUpJSvtCd+DAgTp16pTefvttm7o7duzQq6++qiFDhqhIkSL6/PPPNWDAAJUtW1aNGzeWlDYlX/Pmza1XDnl4eGjGjBmaN29euj4988wz+vTTT/X888+rffv2Onr0qN566y2tXbtWW7duVcGCBa11z549q/79+2vQoEEqUaKEPvjgAz322GM6ceKEvvvuO73xxhvy8fHRqFGj1LlzZx0+fDjdVMBXr8K9lpNT2p+8efPmqXfv3mrVqpXmz5+vhIQETZgwQU2aNNGqVat0//3327yva9eu6tmzp55++mnFxMRIkp566inNmTNHL7zwgt59911FRkZq1KhRatCggXbs2KEiRYooJiZGLVu2VEhIiKZPn64iRYro7NmzWrNmjaKjoyWlTUfSrFkzNW3aVG+99ZYk5WhKCgDmIFfzRq6uWLFCxYoVu6mZEDLKiqNHj6pChQrq2bOn/P39debMGX300UeqU6eO9uzZY80+e/L0eqmpqerUqZP+/PNPDRo0SA0aNNCxY8c0fPhwNWnSRFu2bJG7u7u1flb53q5dO73zzjt64403NH36dNWqVUtS+rt+rmbs1emCX3/9dfn5+aldu3bWOvv27VODBg1UuHBhvf/++woICNBXX32lfv366dy5cxo0aJCktJPtBg0aKDExUaNHj1ZwcLCWLl2q1157TYcOHbJOI7hgwQI9++yzGjhwoCZNmiQHBwcdPHjQeoVxdvt+vWXLlmnz5s0aNWqUvLy8NGHCBHXp0kX79u2z7p/Lly9X165d1bhxYy1cuFDJycmaNGlSui/AAdwe5G7eyN3syG6WnDlzRqGhofL09NRHH32kwoULa/78+Xr++eezXMf69evVo0cP9ejRQyNGjJCbm5uOHTtmneqvVq1amj17tvr3769hw4ZZs+5Gd6++/fbbGj16tLp27apXX31VPj4+2rVrV7a+XD1y5IicnJys/1ZS2iNmhg0bZu1DYmKiJk6cqEaNGmnTpk3Wu0E//fRTPfXUU+rWrZumTp2qS5cuaeTIkekGAK56//33Vb58eU2aNEkFChRQuXLltGbNGrVp00b16tXTxx9/LB8fHy1YsEA9evRQbGysdWrFV155RV9++aXGjBmjmjVrKiYmRrt27bLZh9q2bauUlBRNmDBBpUqV0oULF7Ru3TpFRUVluv32/n5nJ8cBIKc49shbxx4ODg7q16+fZs6cqTFjxsjR0VG//fabTp48qf79++f6Y2auDqTfTXcLww4G8oW+ffsanp6e1tcff/yxIcn45ptvbOq9++67hiTjt99+s5ZJMooWLWpcuXLFWrZo0SJDklGjRg0jNTXVWv7ee+8ZkoydO3cahmEYMTExhr+/v9GhQweb9aSkpBjVq1c36tatay0bPny4IckIDw83vvzyS8PFxcV44YUXjJSUlBtuS0Zmz55tSDKOHDliLQsNDTUkGRs3brSpW7lyZaN169bW12vWrDEkGd9++62xbds2IzAw0GjUqJERERFh8z4vLy/jpZdeumE/MpKammokJSXZ/DRu3Njo06dPuvKsXO3rwoULjaSkJCM2Ntb4+++/jQoVKhiVK1c2Ll68mOl7U1JSjKSkJGPUqFFGQECAzb9jUFCQ4ebmZhw7dsxaFhcXZ/j7+xtPPfWUtaxHjx6Gu7u7cfbsWWtZcnKyUbFiRZvPPywszJBkPPvsszZ92LhxoyHJeOONN6xlV/+dtmzZYi2LiIgwHB0dDXd3d+PUqVPW8u3btxuSjPfff99advXfPqOfpKQkIyUlxQgMDDSqVq1qs29FR0cbhQsXNho0aGAtu7pPvv322zb9Xr9+vSHJmDx5sk35iRMnDHd3d2PQoEGGYRjGli1bDEnGokWLMvonsPL09DT69u17wzoA7izkat7MVTc3N+O+++5LV341M6/+XPsZZpYVGUlOTjauXLlieHp6GtOmTbOWZzdPDSPtcw8NDbW+nj9/viHJ+P77723WtXnzZkOSMWPGDGtZdvP922+/NSQZa9asSbcNffv2zTBjixUrZvz11182dXv27Gm4uroax48ftyl/4IEHDA8PDyMqKsowDMMYMmRIhvvSM888Y1gsFmPfvn2GYRjG888/b/j6+qbr07Wy6ntQUJBNmSSjSJEixuXLl61lZ8+eNRwcHIxx48ZZy+rUqWOULFnSSEhIsJZFR0cbAQEBBqdUwK1H7ubN3L22r5nJbpa8/vrrhsViMXbv3m1Tr3Xr1uly4fo8mDRpkiHJ2lZGrubq7Nmz0y27+m9/1eHDhw1HR0ejd+/embZ3tR+enp7Wz+vChQvGRx99ZDg4ONicIx8/ftxwcnIyBg4caPP+6Ohoo2jRokb37t0Nw0jbL4sWLWrUq1fPpt6xY8cMZ2dnm20+cuSIIckoU6aMkZiYaFO/YsWKRs2aNdP9G7Zv394oVqyYdZ+uUqWK0blz50y378KFC4Yk47333rvh53D9sY29v9/ZyXEAsBfHHnn/2OPw4cOGxWIxli5dahiGYTz00ENGkyZNDMMwjHbt2qU7dwwKCjLatWt3w/avz/bw8HBj2rRphsViMerUqWP3tuPuwHTB+dTq1avl6empBx980Kb86hWJ108/0LRpU3l6elpfV6pUSVLanOLXTotztfzq1Znr1q1TZGSk+vbtq+TkZOtPamqq2rRpo82bN1vv9rhq7Nix6tevn8aPH69p06bl6u35RYsWVd26dW3KqlWrluHVpL/++qsaNWqkxo0ba8WKFfL397dZXrduXc2ZM0djxozRhg0bMpzSLyO///67nJ2dbX7++OMPzZ07N135tVM03EiPHj3k7OxsnT7i8uXLWrZsmXx9fW3qrV69Wi1atJCPj48cHR3l7Oyst99+WxEREemmkKhRo4b1jldJcnNzU/ny5W0+qzVr1qh58+YqUqSItczR0VE9evSwaevqlEPXP0y8bt26qlSpUrr9rVixYrr33nutr/39/VW4cGHVqFHD5o7V6/e3a82dO1ebN2+2+XFyctK+fft0+vRpPfroozb7lpeXl7p166YNGzYoNjbWpq1u3brZvF66dKksFoseeeQRm/26aNGiql69unUqqrJly8rPz0+DBw/Wxx9/fNNz+QO485Gr/8kLuXq9rl272rTzwgsvpKtzfVZI0pUrVzR48GCVLVtWTk5OcnJykpeXl2JiYhQWFmatl908zcjSpUvl6+urDh062OwTNWrUUNGiRW2mR5Syl+9ZcXd3t2brxo0b9cMPP6h8+fJq27atzdT7q1evVvPmzVWyZEmb9/fr10+xsbHWuqtXr1blypXT7Uv9+vWTYRjWO4nq1q2rqKgo9erVS4sXL9aFCxey3ecbadq0qby9va2vixQposKFC1s/k5iYGG3ZskWdO3eWi4uLtZ6Xl5c6dOiQK30AYB9y9z95MXevld0s+f3331WlSpV0z/fs1atXluu4OhVw9+7d9c033+jUqVM56vOKFSuUkpKi5557Lsu6MTEx1s+rYMGCeuaZZ9SjRw+NHTvWWufXX39VcnKy+vTpY7Mfurm5KTQ01Jr1+/bt09mzZ9W9e3ebdZQqVUoNGzbMcP0dO3a0mer/4MGD2rt3r3r37i1JNutr27atzpw5o3379klK24d++eUXDRkyRGvXrlVcXJxN2/7+/ipTpowmTpyoKVOmaNu2bVlOLynd3O/3jXIcAHIDxx7/ySvHHiEhIWrSpIlmzZqliIgILV682PqogJy4NtsLFSqkl156SQ888IB+/PHHHLeNOxPTBedTERERKlq0aLrnhhQuXFhOTk7pbtO//o/i1S+YMiuPj4+X9N8zRK4PoGtFRkbahM5XX32l4sWLq2fPnvZsUrYEBASkK3N1dU13MiBJixYtUlxcnJ555hm5urqmW75w4UKNGTNGn3/+ud566y15eXmpS5cumjBhgooWLZppH+69915t3rzZpuypp55SYGCghg8fblN+/RS4mXn33XfVrFkzxcbG6rffftO4cePUuXNnbdy40dr3TZs2qVWrVmrSpIk+++wzlShRQi4uLlq0aJHGjh2b7jPIzmd1dT+63vVlV/enYsWKpasbGBiYLpiv36+ktH0rq/3tWpUqVcpwuses+pKamqqLFy/aTKlxfd1z587JMAybL8OvdXUaDB8fH/3+++8aO3as3njjDV28eFHFihXTE088oWHDhqV7bh2Auxe5+p+7OVdLlSqV4cni5MmTNWzYMEn/fRF7vYxy5eGHH9aqVav01ltvqU6dOipQoIAsFovatm17U3makXPnzikqKspm8O9a1w9E2vNvlhkHB4d0Gdu6dWuVLFlSr7zyivUL74iIiEzz9uryq/+9/tl4GdV79NFHlZycrM8++0zdunVTamqq6tSpozFjxqhly5bZ7v/1svpMLl68mGnuZ3YsAODWInf/czfnbnbYkyUhISHp6mXn73Tjxo21aNEivf/+++rTp48SEhJ0zz336M0338zWIO31rj4T/UbTCV/l7u6uP/74Q1LalIyTJ0/W/PnzVa1aNQ0ZMkTSf/thZscgV79Mv/pZZJZXVx8rdK2MznUl6bXXXtNrr72W4fquHlu8//77KlGihBYuXKh3331Xbm5uat26tSZOnKhy5crJYrFo1apVGjVqlCZMmKBXX31V/v7+6t27t8aOHWszMHote3+/c+PYBgCywrHHf/LSsceAAQPUv39/TZkyRe7u7jf83LPr2mx3dXVVUFAQj4bL4xhkzacCAgK0ceNGGYZhEw7nz59XcnKyzfMxc+JqOx988IH1Ac/Xu/4EYPny5erRo4caNWqkVatWKSgoKFf6Yq+pU6dq4cKF1itNWrVqZbO8YMGCeu+99/Tee+/p+PHjWrJkiYYMGaLz589r+fLlmbbr7e2d7otJb29vBQQE3NQz4KS0Qb2r723cuLHc3d01bNgwffDBB9YTowULFsjZ2VlLly6Vm5ub9b2LFi26qXVKafvR2bNn05VfX3Y1kM+cOZPuRPP06dO5tr9lx7V9ud7p06fl4OAgPz8/m/LrD6AKFiwoi8WiP//8M8ODhmvLqlatqgULFsgwDO3cuVNz5szRqFGj5O7ubj1pBnD3I1ezdjfkasuWLTV9+nRt2bLF5r1ZPdNTSp8Vly5d0tKlSzV8+HCbv/cJCQmKjIy0qZvdPM1IwYIFFRAQkOlnlNkXmLnNw8NDZcqU0Y4dO6xlAQEBmeat9N/+nN16ktS/f3/1799fMTEx+uOPPzR8+HC1b99e+/fvv2X7tp+fnywWS4bPX83OvxGA3EfuZu1uyN3ssCdLcvJ3ulOnTurUqZMSEhK0YcMGjRs3Tg8//LCCg4NVv359u/p89XlrJ0+eTHcH7vWuv3CpZcuWuvfeezVy5Ej17t1bJUuWtG7jd999d8P96eq5rj2fQ0bnupI0dOhQde3aNcP3VKhQQZLk6empkSNHauTIkTp37pz1rtYOHTpo7969kqSgoCDNnDlTkrR//3598803GjFihBITE/Xxxx9nuh234/cbAOzBsUfW7sZjj65du+q5557T+PHj9cQTT8jd3T1H7UkZX5SMvI3pgvOp5s2b68qVK+kG2ObOnWtdnhsaNmwoX19f7dmzR7Vr187w5/o7L4KCgqyDV40aNdKBAwdypS/2cnNz0w8//KD27durY8eOWrx4caZ1S5Uqpeeff14tW7bU1q1bb2MvMzZo0CCVLVtW48ePV3R0tKS0kycnJyc5Ojpa68XFxenLL7+86fU0bdpUq1atsjmJS0lJ0cKFC23qNWvWTFLalVXX2rx5s8LCwnJtf8uOChUqqHjx4po3b54Mw7CWx8TE6Pvvv1f9+vWzfDB8+/btZRiGTp06leE+XbVq1XTvsVgsql69uqZOnSpfX1+b/YSrbIG7H7matbshV19++WV5eHjoueees+bnzbJYLDIMI93FOJ9//rlSUlJsyrKbpxlp3769IiIilJKSkuH+cPWLUHtc7bM92XTlyhUdPHhQhQsXtpY1b95cq1evtn4RftXcuXPl4eFh/dKgefPm2rNnT7p/67lz58pisahp06bp1ufp6akHHnhAb775phITE7V79+6b7ntWPD09Vbt2bS1atEiJiYnW8itXrmjp0qW5th4A2UfuZu1uyN3syG6WhIaGateuXeke0bJgwQK71ufq6qrQ0FC9++67kqRt27ZZy6Xs5UurVq3k6Oiojz76yK51X13P9OnTFR8frzFjxkhKmy3CyclJhw4dynQ/lNLOdYsWLapvvvnGps3jx49r3bp12Vp/hQoVVK5cOe3YsSPTdWV0AVeRIkXUr18/9erVS/v27Uv3CB5JKl++vIYNG6aqVavecD+7Xb/fAGAPjj2ydjcee7i7u+vtt99Whw4d9Mwzz5jWD9zduJM1n+rTp4+mT5+uvn376ujRo6patar++usvvfPOO2rbtq1atGiRK+vx8vLSBx98oL59+yoyMlIPPvigChcurPDwcO3YsUPh4eEZnngUK1ZMv//+u1q3bm2dx71KlSrW5SkpKfruu+/Sve/qF265xdnZWfPnz9fjjz+uBx98UHPnzlWvXr106dIlNW3aVA8//LAqVqwob29vbd68WcuXL8/0as/bydnZWe+88466d++uadOmadiwYWrXrp2mTJmihx9+WE8++aQiIiI0adKkDO/EzK5hw4ZpyZIlatasmd5++215eHho+vTp6Z4NUKFCBT355JP64IMP5ODgoAceeEBHjx7VW2+9pZIlS+rll1/O6SZnm4ODgyZMmKDevXurffv2euqpp5SQkKCJEycqKipK48ePz7KNhg0b6sknn1T//v21ZcsWNW7cWJ6enjpz5oz++usvVa1aVc8884yWLl2qGTNmqHPnzipdurQMw9APP/ygqKgom2kNq1atqrVr1+qnn35SsWLF5O3tfVNfigMwD7maPXd6rpYpU0bz589Xr169rH/La9WqJVdXV50/f16//fabJGVrqp8CBQqocePGmjhxogoWLKjg4GD9/vvvmjlzZrpnpmc3TzPSs2dPff3112rbtq1efPFF1a1bV87Ozjp58qTWrFmjTp06qUuXLnZ9Dlf3jU8//VTe3t5yc3NTSEiI9Q6Z1NRUbdiwwfr/p06d0vvvv6+LFy9qxIgR1naGDx+upUuXqmnTpnr77bfl7++vr7/+WsuWLdOECRPk4+MjKW1we+7cuWrXrp1GjRqloKAgLVu2TDNmzNAzzzyj8uXLS5L1yuKGDRuqWLFiOnv2rMaNGycfHx/rFIpZ9f1mjRo1Su3atVPr1q314osvKiUlRRMnTpSXl1e6O5MB3Hrkbvbc6bl71dVMuV5oaGi2s+Sll17SrFmz9MADD2jUqFEqUqSI5s2bZ72j8kbPp3v77bd18uRJNW/eXCVKlFBUVJSmTZsmZ2dnhYaGSko7RnB3d9fXX3+tSpUqycvLS4GBgRlOSxgcHKw33nhDo0ePVlxcnHr16iUfHx/t2bNHFy5c0MiRI2/4eYSGhqpt27aaPXu2hgwZopCQEI0aNUpvvvmmDh8+rDZt2sjPz0/nzp3Tpk2brHeUOjg4aOTIkXrqqaf04IMP6rHHHlNUVJRGjhypYsWKZfsZfZ988okeeOABtW7dWv369VPx4sUVGRmpsLAwbd26Vd9++60kqV69emrfvr2qVasmPz8/hYWF6csvv7ReuLxz5049//zzeuihh1SuXDm5uLho9erV2rlz5w1ndbpdv98AYA+OPbLnbjn2uNYrr7yiV155JVt1z549m+HnGBwczN2r+RiDrPmUm5ub1qxZozfffFMTJ05UeHi4ihcvrtdeey3dXOY59cgjj6hUqVKaMGGCnnrqKUVHR6tw4cKqUaOG9eHgGSlYsKBWr16tdu3aKTQ0VL/++qv1j1V8fLweeuihdO8JCgqy6wHX2eHg4KCZM2fK29tbjzzyiGJiYvToo4+qXr16+vLLL3X06FElJSWpVKlSGjx4sAYNGpSr679ZDz30kOrVq6cpU6Zo4MCBatasmWbNmqV3331XHTp0UPHixfXEE0+ocOHCGjBgwE2to0qVKlq5cqVeffVV9e3bV35+fnr00UfVrVs3PfnkkzZ1P/roI5UpU0YzZ87U9OnT5ePjozZt2mjcuHE5/uLTXg8//LA8PT01btw49ejRQ46Ojrrvvvu0Zs0aNWjQIFttfPLJJ7rvvvv0ySefaMaMGUpNTVVgYKAaNmxofSB8uXLl5OvrqwkTJuj06dNycXFRhQoVNGfOHPXt29fa1rRp0/Tcc8+pZ8+eio2NVWhoqNauXXsrNh3ALUKuZt+dnqsdO3bUv//+q/fee0+zZ8/WyJEjlZqaqqJFi6pu3br68ccf1alTp2y1NW/ePL344osaNGiQkpOT1bBhQ61YsULt2rWzqWdPnl7P0dFRS5Ys0bRp0/Tll19q3LhxcnJyUokSJRQaGprh7ApZCQkJ0Xvvvadp06apSZMmSklJ0ezZs637V1xcnM3UiYULF1alSpX0448/qnPnztbyChUqaN26dXrjjTf03HPPKS4uTpUqVbJpS0qbVnHdunUaOnSohg4dqsuXL6t06dKaMGGCzcluo0aNNGfOHH3zzTe6ePGiChYsqPvvv19z5861Ts2YVd9vVps2bfT999/r7bffVo8ePVS0aFE9++yzOn36dI5mBQFwc8jd7LvTc1dKe/Z5RtasWaMmTZpkK0sCAwP1+++/66WXXtLTTz8tDw8PdenSRaNGjVLfvn3TXeB0rXr16mnLli0aPHiwwsPD5evrq9q1a2v16tW65557JKVNiz9r1iyNHDlSrVq1UlJSkoYPH25zcdG1Ro0apXLlyumDDz5Q79695eTkpHLlyumFF17I1mfy7rvvavny5Ro9erRmzZqloUOHqnLlypo2bZrmz5+vhIQEFS1aVHXq1NHTTz9tfd+TTz4pi8WiCRMmqEuXLgoODtaQIUO0ePFiHT9+PFvrbtq0qTZt2qSxY8fqpZde0sWLFxUQEKDKlSure/fu1nrNmjXTkiVLNHXqVMXGxqp48eLq06eP3nzzTUlpz5YvU6aMZsyYoRMnTshisah06dKaPHmyBg4cmOn6b+fvNwBkF8ce2Xc3HHvcrH/++SfDz7Fv376aM2fO7e8Q7ggW49r5MgEAAAAAWUpKSlKNGjVUvHhx613OAIA7y5NPPqn58+crIiIi3fSK+UVUVJTKly+vzp0769NPPzW7OwAAAHkKd7ICAAAAQBYGDBigli1bWqcq/vjjjxUWFqZp06aZ3TUAgNLuHg0MDFTp0qWtz83+/PPPNWzYsHwzwHr27FmNHTtWTZs2VUBAgI4dO6apU6cqOjpaL774otndAwAAyHMYZAUAAACALERHR+u1115TeHi4nJ2dVatWLf388888Gw4A7hDOzs6aOHGiTp48qeTkZJUrV05TpkzJV4OLrq6uOnr0qJ599llFRkbKw8ND9913nz7++GPr1McAAADIPUwXDAAAAAAAAAAAAAB2cDC7AwAAAAAAAAAAAABwN2GQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsIOT2R24FQb+GGZ2F4BbKtXsDgC3wfQulczuAnJgzubjZncBuKXmrj9ldheAW2r1C/XN7gJyaMofh83uAnBL/bE/0uwuALfUosdrm90F5MCnG46Z3QXglvp+61mzuwDcUr8+Wy9b9biTFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsAODrAAAAAAAAAAAAABgBwZZAQAAAAAAAAAAAMAODLICAAAAAAAAAAAAgB0YZAUAAAAAAAAAAAAAOzDICgAAAAAAAAAAAAB2YJAVAAAAAAAAAAAAAOzAICsAAAAAAAAAAAAA2IFBVgAAAAAAAAAAAACwA4OsAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA4MsgIAAAAAAAAAAACAHRhkBQAAAAAAAAAAAAA7MMgKAAAAAAAAAAAAAHZgkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYgUFWAAAAAAAAAAAAALADg6wAAAAAAAAAAAAAYAcGWQEAAAAAAAAAAADADgyyAgAAAAAAAAAAAIAdGGQFAAAAAAAAAAAAADswyAoAAAAAAAAAAAAAdmCQFQAAAAAAAAAAAADswCArAAAAAAAAAAAAANiBQVYAAAAAAAAAAAAAsAODrAAAAAAAAAAAAABgBwZZAQAAAAAAAAAAAMAODLICAAAAAAAAAAAAgB0YZAUAAAAAAAAAAAAAOzDICgAAAAAAAAAAAAB2YJAVAAAAAAAAAAAAAOzAICsAAAAAAAAAAAAA2IFBVgAAAAAAAAAAAACwA4OsAAAAAAAAAAAAAGAHBlkBAAAAAAAAAAAAwA6mDbJGRkbq5MmTNmW7d+9W//791b17d82bN8+kngEAkPeRwwAAmIssBgDAPOQwACA3mDbI+txzz2nKlCnW1+fPn1ejRo20efNmJSQkqF+/fvryyy/N6h4AAHkaOQwAgLnIYgAAzEMOAwByg2mDrBs2bFDHjh2tr+fOnSt/f39t375dixcv1jvvvKPp06eb1T0AAPI0chgAAHORxQAAmIccBgDkBtMGWc+ePauQkBDr69WrV6tLly5ycnKSJHXs2FEHDhwwq3sAAORp5DAAAOYiiwEAMA85DADIDaYNshYoUEBRUVHW15s2bdJ9991nfW2xWJSQkGBCzwAAyPvIYQAAzEUWAwBgHnIYAJAbTBtkrVu3rt5//32lpqbqu+++U3R0tJo1a2Zdvn//fpUsWdKs7gEAkKeRwwAAmIssBgDAPOQwACA3OJm14tGjR6tFixb66quvlJycrDfeeEN+fn7W5QsWLFBoaKhZ3QMAIE8jhwEAMBdZDACAechhAEBuMG2QtUaNGgoLC9O6detUtGhR1atXz2Z5z549VblyZZN6BwBA3kYOAwBgLrIYAADzkMMAgNxg2iCrJBUqVEidOnXKcFm7du1uc28AAMhfyGEAAMxFFgMAYB5yGACQU6Y9k1WSkpOTNXHiRNWqVUteXl7y9vZWrVq1NGnSJCUlJZnZNQAA8jxyGAAAc5HFAACYhxwGAOSUaXeyxsXFqWXLllq/fr1atGihxo0byzAM7d27V4MHD9aSJUv022+/yc3NzawuAgCQZ5HDAACYiywGAMA85DAAIDeYNsg6btw4nThxQtu2bVO1atVslu3YsUMdO3bU+PHjNWLECHM6CABAHkYOAwBgLrIYAADzkMMAgNxg2nTBCxYs0JQpU9KFmCRVr15dkyZN0rx580zoGQAAeR85DACAuchiAADMQw4DAHKDaYOsx48fV926dTNdft999+n48eO3sUcAAOQf5DAAAOYiiwEAMA85DADIDaYNshYoUEDnz5/PdPnZs2dVoECB29gjAADyD3IYAABzkcUAAJiHHAYA5AbTBlmbNm2qd955J9Pl48ePV5MmTW5fhwAAyEfIYQAAzEUWAwBgHnIYAJAbnMxa8fDhw1WvXj3dd999euWVV1SxYkVJ0p49ezR16lTt2bNHGzZsMKt7AADkaeQwAADmIosBADAPOQwAyA2mDbJWrlxZK1as0IABA9SzZ09ZLBZJkmEYqlixon799Vfdc889ZnUPAIA8jRwGAMBcZDEAAOYhhwEAucG0QVYp7QHiu3fv1vbt27V//35JUvny5VWjRg3FxMTojz/+UOPGjc3sIgAAeRY5DACAuchiAADMQw4DAHLK1EHWq2rUqKEaNWrYlB08eFBNmzZVSkqKOZ0CACCfIIcBADAXWQwAgHnIYQDAzXIwuwMAAAAAAAAAAAAAcDdhkBUAAAAAAAAAAAAA7MAgKwAAAAAAAAAAAADYwbRnsi5ZsuSGy48cOXKbegIAQP5DDgMAYC6yGAAA85DDAIDcYNoga+fOnbOsY7FYbn1HAADIh8hhAADMRRYDAGAechgAkBtMG2RNTU01a9UAAOR75DAAAOYiiwEAMA85DADIDTyTFQAAAAAAAAAAAADsYNqdrLjztCwfoI73FNaag5H64d9zkiRvV0d1uqewKhb2lLuzow5GxOq7HWcVHpOUaTsOFqlV+YKqW8pHvu5OOn8lUYt3nVfY+RhrnTIB7mpeLkClfN3k4+6szzac0M4zV275NiJ/aVuxoNpVKmRTdjk+WUN/OWBTp2GwrzxcHHU0Mk7f7DirM9GJN2y3RqC32lcqpIKezroQk6Sf9oRrx5lo63JXJwe1r1RINQK95eXqqJNR8fp25zkdj4rP3Q0EkKesWzJfv38zS7Vbd1HLR5+VJBmGob9++FLb1yxTfMwVBZapqFb9BqpQieAbtrV305/647s5ijp/Rr6Fiyn0of6qUOd+6/LUlBT9+cNc7V63WjFRkfLy9VfVxq3UsFNvWRy4Bg+5p2+9Eupbr6RNWWRMoh6c+Y8kyc/dWU80LKXapXzl5eqonaej9cHaIzp1KfPMdHSw6OHaxdW6UiEV9HTRiYtx+nTdcW0+FmWt06t2oBqVCVApP3clJKdq95loffb3MZ0giwHcwLafF2rTj3NUpXknNez5dLrlf3z5vsL++EX1ezypai26ZNpO2B+/aP/6VYo8fUySVCiorOp26afCIRWsdU7v/1c7fv1OF44dVOylSLV69i2F1GyQ+xuFfK1nrUD1rBVoU3YxNkn95+2QJL3QOFjNyhe0Wb7v/BUNXrI30zbHtKugKsW805VvOR6lMb8dlCS5OTuo973FVS/IVz7uzjoSEavP1x/XwQuxOd0kAHncxp/m66/vZqtWqy5q2vsZSdKBLX9px5plOnf0gOKvXNajoz5S4aAyWbYVH3NFf30/Wwe3/K342Gj5FCyq0F5PqXT1upLSzovX/ThXYetXK/bSRXn6+uue+1vpvo4Pc16MXPNIneJ6tE4Jm7LI2ET1mrNNkuTm5KAB9Uuqfoi/Crg56Vx0ghbvPKulu89n2mbD0n7qWStQgT5ucnKw6NSleH2//axW7b9grdOjVqAalvZTSV93JSanas/ZaM3ccEInOSfOdQyyQpJUytdNDYN9032h9cR9JZSSKn264aTik1PVtKy/nr8/SGNXHlJiipFhW+0rF1Kdkj6av+2MzkUnqlIRTz1+XwlN/f2oTl5KkJQ2CHXqUoI2Hr+kx+uVyLAdIDecvhyvD/46bn2des1u27JcgJqV9deXW8/ofHSi2lQM0PMNS2nUysNKSM542pgQf3c9Vqe4loaFa8fpaFUP9NaAusU15Y+jOnox7fend81iCizgqi+2nNKl+GTVKemjF+4vpdErD+tSfPIt3V4Ad6fTh/Zp+5qfVbhUaZvyDUsXatMv36v9U6/Jv2gJ/b14nhaMH6wnJ86Wq7tHhm2dPLBHiz4co8YP9lOF2g21b8vfWvThGD3y1lQVL1tJkrR+6QJtW7VU7Z8apIIlgnT2yH4t+3SSXN09VadN11u+vchfjkTE6rUf91hfpxr/hfGo9hWUkmroraV7FZuYogdrBmpSl8rq/9V2xWeSxY/dV1ItKxbS5FWHdPxinOoE+WpUuwoa+O2/Ohie9uVt9eI+WrzzrPaduyIHB4sG1C+lCZ1v3C6A/O38kX0K++MX+ZcIyXD5kW3rdP7wPnn4BmTZ1ul9O1W2bhMVKVNJjs4u2vHrt1o29U11H/mxPP3SBrSSE+IVUKK0KjRspRUfjcnVbQGudSwyTsN/2Wd9nXrdVzn/nLikD/44Yn2dfH2F64xfeVBODv89p9Lb1Unvdb1H645ctJY93yhYpfzc9d7vRxQZm6QmZQM0sm15DfxutyJjM79oH0D+dvbwPu1c+7MKlbQ9L05KiFfxcveofJ3GWjF7arbaSklO0ncTh8ijgK86PP+WvP0L6nJkuFzc3K11Ni1bqB1rlumBJ15XQPEgnTu6X8s/nyxXD0/VapX5xVSAvY5GxGrINRcwXXtO/PT9QapevIAmrDyoc9EJqlXSRwMbhygiJknrj17MqDlFxydr/j+ndSIqTskphuoF++rVZqUVFZekf05ckiRVC/TWT/+e0/7zMXJ0sKhfvRJ6p0NFPTF/Z6bfe+PmcEkG5OJoUd86gZq/7YxiE1Os5YW8XBTi76GF28/oeFS8zl9J1Dfbz8rVyaJ7S/hk2l7dkj76bV+E9pyLUURskv46EqW952LUrOx/J6N7zsVo2f8HqYBbKTVVupyQYv25cs0+3rSsv37dF6Edp6N1JjpBX/5zRi6ODqpTokCm7TUt46+952P02/4InbuSqN/2R2hfeIyalvGXJDk7WFQj0Fs/7jqvgxFxCo9J0s97LygiJkmNQvxu+fYCuPskxsdpyUfj9MCAl+Xm4WUtNwxDm5f/qAadeqlCnUYqVDJE7Z96XUmJCdqzbnWm7W1Z/oNCqtyrBh17KSCwlBp07KWgyjW1efkP1jqnDoSp3L0NVLZmPfkWKqqKdRsrpOq9OnNk/y3dVuRPKamGLsYmWX8uxaVdcFTC1033FPPWe2sOa9/5GJ2Iite0tYfl5uygZhUKZtpey4qF9PWWk9p4LEpnLidoyb/ntPlYlB6q+d+dOkMWh+nXsHAdjYzT4QuxmrDyoIoUcFX5wp63fHsB3H2S4uO0+vOJatznRblek8VXxVy8oL/nzVCzxwfJwdExy/aaPzFY9zRtr4KlysivWEk17vOiDCNVp8K2W+uUqlpHdbv0VelaDXNzU4B0Ug1DUXHJ1p/L1134m5ySarP8SkJKJi2luZKQYlO/RvECSkhO1d//H2R1cbSofrCfvth0UnvOXtHZywlasPV02oXN1800BQBXJcbH6eePx6vVYy/L1dM2iys3bKH6nR9R0D01s93erj9+VfyVaHV6YYSKl79HBQoWUYnyVVS41H93wJ45GKayteqrdI168ilUVOXrNFZwlXt1lvNi5LIUw9DFuCTrz7U34VQq4qUVe8O183S0zkUn6pc94Tp8IVblbnDuuvN0tNYduagTF+N15nKCFu08p8MRsbrnmpkm3ly6Tyv2XdCxi3E6HBGryasPq4i3q8oV4pw4tzHICnWvUVS7z17RvnDbaVuuXpl47VWMhqTk1LTpfjPj5GhR0nUPj09KSVXpG7wHuFUKeblobJuyGtmqjPrXCVSAh7MkKcDDWT5uTgo7/9801cmphg5GxCrkBvtqiL+7zdTXUtpFA6UD0u4oc3CwyNHBouTrfgcSU1Nv+HsDIP/6dc4HKlujnkKq1LIpjwo/q5hLkQqpWtta5uTsolIVq+nkgT3XN2N16uAehVS916asdLXaOnXNe0qWr6Jju7cp4sxJSdK5Y4d0Yt8ulfn/tElAbiru66ZvHrtXX/etqWFtyqlYAVdJkrNj2qlIYsp/mZlqpOVxRtMQXuXsaFFisu1dNonJqaoamPl7PF3SJvC5/otlAJCkv+ZNV6lqdVSicvovb43UVK2eOUnVWz8o/+JBN9V+cmKCUlNS5OqZ+d8p4FYpVsBVs3pV0yc9qurVpqVVxNvFZnmVYt6a07u6pj9URc/eHyQfN/smvWtRoaD+OhxpvSvm6jlxUortOXFCcqoqF+V3AEDGVs39QCHV6yronlpZV86GQ9vWK7BsJa2a+4E+Gthdc954Qht/mq/U1P8uJAksf4+O79muyLNp58Xnjx/Sqf27FFKN82LkruI+bprXt6a+eKS6hrYsq6L/PyeWpN1no3VfiJ8CPNO+s64eWEDFfd30z/GobLdfo3gBlfR1067TlzOt4+mSdqFgdALnxLnN9OmCS5curc2bNysgwHbKnaioKNWqVUuHDx++4fsTEhKUkJBgU5aSlChHZ5dM3oFr1SpeQCV93DRx7dF0y85FJygiJlEdKhfWgu1nlJicqmblAuTj5qQCNzjoDvv/XauHLsTqQkySyhfyVNVi3rJYMn0LcEscvRinuf+c1vkrifJ2dVSbCgX1Wmiwxqw6bN2Ho6+7SvdyfLL8/z8Qm5ECbk7pwig6IVnermlBlZCcqsMRsWpToaDORp/W5fhk1S5ZQMF+7gq/cuNnvQJmyGkOSxlncVJigpxdXDN5B67as36Nzh09oH6jpqdbFhMVKUny9PG1Kff08dOlC+cybfNK1EV5+tjeOe/p46eYS/9NM3Nfhx5KiIvRp4Mek4ODg1JTUxX6UH/d06BZDrYGSC/s7BWN/+2gTkbFy8/DWY/UKa4PHqqix77eoeMX43T2crweb1BKU1YfVnxSqh6qWUwBni4K8Mz8WH7L8Ut6qGYx7Tx1WacvxatWSR81KO0nB4fMDzafbRSknacu62hk3K3YTCBHblUWJycmyIksztLBTWt14fghdXlzWobLty//Vg6ODqrSvNNNr2Pj97Pl6Rug4hkM4gK30v7zVzTt91idvpQgH3cnda8ZqPEdKumF73cpOiFF/5y8pL+PXFT4lQQV8XbVw/cW16i2FfTqoj1ZThssSeUKeSrI30Mf/nnMWhaflKq9566oe81AnYg6rEtxSWpUxl/lC3vqzKWEG7QGmINzYvPt3bBG548dVO/hH+Zam1HhZ3Q5bLsq1W+mrq+M0cVzp7Rq7odKTUlR/c6PSJLqtuuhxNgYzR4ywHpefH+3fqpUv2mu9QPYe+6KJq46ZD0n7nVvcU3tWllPzv9X0QnJmvHnMb3UJETz+tZSckqqUiW9t+aIdp+9csN2PVwcNa9vTTk7WJRqSB/8cVRbT2Y+yPpkwyDtOn1ZxzgnznWm38l69OhRpaSkn4okISFBp06dyvL948aNk4+Pj83Plu8/vRVdzXN83Z3UrVoRzd1yOsOD51RDmrnplAp7uWhC+wqa3LGiyhb00O6zV9I9w+Na3+88p/AriRrWsoymdqqoh6oX0YbjUTKyPj4HctWeczHafjpapy8naF94rD5af0KSVK/Uf9NdX79fZudigOt35evf8sU/p2WxSO88UE7TOlVUk9L+2nLi8g1/bwCz5DSHpYyzeNmcGbnd1TzncsR5rfhyhjo8M0ROLpkPKFmu+ytjGIbS/+W5McMwbN4StmGtdv29Sp2eHar+Yz5S+6de18afv9XOP36zq10gK5uORenPQ5E6EhGrrScu6Y3/P4emVaVCSkk1NHzZfpXwddeSp+rql2frqXoJH208etHmGTXX+/CPIzoZFa85j9bQb8/fpxeahGh5WLhSMwnaF5qEqHRBD4359cAt2UYgp25VFq/6+uPc7mqecyUyXOsWfKJmA16XUwYXaocfO6B/Vy1Wk/6vynKTVw1vX/6tDm1aq1bPvpXhOoBbaevJy1p/NErHLsZp5+lojf5/FjYtlzYt/9+HL+qfE5d0/GK8Nh+/pFHLDyjQx1W1S2X+iKhrtShfUMciY3Ug3Ha2p/fWpj3jdfbD1fVt/3vVrnIR/XEo8ob5DpjlVuXw8rmcE2fH5YjzWvP1R3rgqcE3PC+2W6ohD29ftez/koqElFfF+5qqXsde2rF6qbXKvo1rtWf9KrV7eogeGTlDDzzxurb88p12/8V5MXLPluOX9NfhizoaGadtJy/rrWVpz0lvWTEtiztXK6KKRbz09rJ9ev67Xfrs7+N6vnGwat7gcXaSFJeYomcX/quB3+3WnI0n9FTDUqqWyexOzzUKVkiAh8atOJS7GwdJJt7JumTJEuv///rrr/Lx+e8ALiUlRatWrVJwcHCW7QwdOlSvvPKKTdmQ5UdyrZ95WSlfNxVwc9LrTUOsZY4OFpUp6KHGpf308uK9OhEVr3fXHJGbk4OcHCy6kpiiV0ODdTwq8yseriSm6LONJ+XkYJGni6MuxSer4z2FFBGbdDs2C8hUYoqhU5fjVdjTxfo84AJujrp8zZ2p3q5ONq+vdzk+WQVcbf90erk62dwReyEmSe/9eVwujha5OaW1/1id4vwO4I6SWzksZZzFC//N/E5LpDl75IBiL0dp9lvPWsuM1FQd3/ev/lmxWE9NnC1JunLporz8/ruqOvZyVLo7Va/l5Wt716r1PQX+e8/q+Z+pfoceqvz/K3QLlwzR5Qvntf6nBarWuFWubB+Qkfj/z/hQwsdNknQgPEZPzt8pTxdHOTladCkuWdO7V9G+66bmv9aluGS9vWyfnB0t8nFz1oWYRD3RoJTOXk5/d8zA0GA1CPHTS9/v1gVmlMAd5lZn8cebsvfFcH4WfuyA4qKj9P2YgdYyIzVVZw7s0u41P6let8cUFx2lrwf3sVm+4ZvP9e/KReo9/osbtr/j1++07eeFav/KOwooEXLDusDtkJCcqmMX41TMJ+O76y7GJSn8SqKKFXDLsi0XRwfdX8ZP8/85nW7Z2egEDVu2T65ODvJwdtTFuCS91qy0zkVzJyvuHLc6h7/cfjZX+pnXnTuadl781fDnrGVGaqpO7vtX21Yu1kszl8nBIevnoV/P09dfDo5ONu8NKFZKMZcilZKcJEcnZ/2+8DPVbddTFe9LOy8uVDJEly+c08alC3TP/ZwX49ZISE7V0Yg4Ffdxk4ujRf3qldSo5Qe06ViUJOlIRJxKF/TQgzWKadsN7kw1JJ3+/znw4YhYlfRzV49agdp5ep9NvWfvD1L9EF+9+mOYLsRwTnwrmDbI2rlzZ+v/9+3b12aZs7OzgoODNXny5CzbcXV1laur7cEhUwVnz77wWL2z0nbKi973FtO56ESt3B9hc7de/P+frVHI01ml/Ny0LCw8y/aTUw1dik+Wg0WqEVhA205l/kcBuB2cHCwq6u2qQxfiFBGb9pDxioU9dfL/UxY5WqSyAR5avPt8pm0ciYxTpcKeWnMo0lpWqbCnDkfEpqubmGIoMSVZ7s4OqlTYU4tu0C5wu+VWDksZZ7GzS1ROu5jnBd1TU4+Ps519Y+mnkxQQWFL12/eQb+Fi8vTx19Fd/6hocFlJUkpyko7v3ammPR7PtN3iZSvryK5/VPeBbtayI//+o+LlKltfJyXGy2KxndDE4uAgw7B9dhaQ25wdLQryd9e//7/Y6aqYxLSLlYr7uKl8YS/N3nAiy7aSUgxdiEmUo4NFjcsGaO2BCzbLXwgN0f1l/PXy97szHIAFzHars9jJ5UImtXFV8Uo19NCIj2zK1s6eIt9iJVWjzUPy8PFXyXtsn3O+7L1hKn9fM1VoeOMvX7f/+p22LZuvti+OUaHg8rned+BmODlYVMLXTXvORme43NvVUQU9XXQxGxcI31/aT84ODvr9YESmdRKSU5WQnCpPF0fVLF5AX2w6edN9B3LbrT8nvphJbVwrqHJN9R37iU3Z8s8ny79YSdVt1/2mBlglKbDcPdq7YY2M1FRZHNLOfS+eOyVPX385OqU9Jiw5ISHdTBUWBwcxFR1uJWcHi0r6uWvXmWg5OTjI2dEh3UwPqYZh9ywqFovk7Gj7Pc9zjYLUIMRfry/ew4VOt5Bpg6ypqWlf4oWEhGjLli3p5r3HrZeQnKoz1/1yJSanKiYxxVpeI9BbVxJTdDE2SYE+rupWtYh2no7W3mvuLnj03mKKikvWT3vSBl6D/Nzk6+6sk1Hx8nV30gMVC8likVYe+O/A28XRokJe/w2GB3i4qLiPq2ITU3QxjocvI3d0qVJY/565ootxSdZnsro5OWjj/x8cvuZgpFqXL6jwK0k6fyVRrSsEKDElVZuvuUqoz//37yX/37/XHIrUy42C1LJcgHaeiVa1Yt6qWNhTU/44an1PpcKeskg6dyVRhTxd1KVKYZ2/kqj1/78iCbgTkMPmc3X3UKGStne1uLi6yd2rgLW8TpsuWrdkvvyKFJd/0eJat2S+nF1cVfmaZ6f+9PG78vYrqCY9BkiSarfuoq/GvKL1Py1Q+XsbaP8/63R091Y98tZU63vK1bxP6xbPU4GAwipYIkjnjh7Upl++V/XQ1rdhy5GfPH1/kNYduajz0QnydXfWo3WLy8PFUb+FpV14FFrWX1FxyTofnaCQgh56vnGw/j4cqS3HL1nbGNKyrC7EJOrzdcclSRWLeKmQl4sOhseooJeL+tYrKYtFWnDNnTQvNglR8woFNWzpPsUmpcjv/89bj0lIUWIKFxPgzkAWm8/FzUP+xYNtypxc3eTq6W0td/OynarNwdFR7j5+8i1awlq2euYkefoFqF7X/pLSpgjevHiumj8+WN4Fiyj2UtoFms6u7nJ2c5ckJcXH6dL5//5uRV84pwvHD8nV01veAYVze1ORT/WrW0Kbj0cp/EqifNyd1b1mMXk4O2rNgQi5OTmoZ61ArT96URdjk1TY21WP1C6uywnJ2nDsv8GhF0ODFRGTpK+22N4d36JCQW08FmUzq9NVNYoXkMUinYqKVzEfN/WrW0KnLsVr1f7MB2SB240cvjO4uHuo4HWzPTj//7z4annclcuKjgjXlai0vyGRZ9MuyPT08ZOnr78k6ZdPJsjLL0CNuqedF1dv1l7bVi7W6q8/Us2WnRR19pQ2/jRfNVt2tq6nTM37tPGn+SoQUFgBxYN0/thB/fPrD6rSiPNi5J4nGpTShqMXdT46Ub7uTnq4dto58Yq94YpNStGOU5f1RP1SSkw+qnPRiaoW6K0WFQrp07//e975681L60JMkvVi5B61AnXg/BWdvpwgZweL6gT5qkX5gvrgmu+nn28crKblAjTil/2KS0yVn/v/z4kTk5WYwoUEucm0QVZJSkpKUnBwsCIiIgiyO5SPm5O6Vi0ibzcnXY5P1qbjl7R8r+1drH7uzjbPtXR2cFC7SoVU0NNZCcmp2nPuiub+c1pxSf99oVXKz10vNgqyvu5arYgkaeOxKH219cyt3SjkG77uTupfJ1Berk66kpCsI5FxmvT7UUX+fyB/xYEIOTta1KNGUXk4O+joxTh9+PcJJST/t69ev38fiYzT7M2n1L5yIbWvXEgXYhI1c/MpHb0Yb63j7uygjpULy9fdSbFJqdp+6rKW7AnnQjjcccjhO9997XsoOTFRv875QPGx0QosU1E9B4+Xq7uHtc7lC+dtrnAsUf4edX7+Tf3+7Rz98d0X8itSTJ2ff1PFy1ay1mnZ53n98d0c/TrnfcVejpKXX4BqNmun+7s8clu3D3lfQS8XDWtdTj7uTroUl6w9Z6P1/De7dC46bZoif08XPdMoWH4ezoqMSdJve8P15XV3uRT2drG5stfFyUH965dUYAE3xSWlaOPRKI377YD1blhJ6lStqCTpvW732LT17oqD+jUbM7IAtwtZnDdcibTN4t1rlyo1OVkrPh5rU+/eDr1Vu2Na1oYfO6CfJg22Llv/TdrsFuXrt1DTx169Db1GfhDg6aJXm5a2fqez/3yMBi0JU/iVRLn8f3aJJuUC5OniqIuxSdp1JlqTVh9S/DXf3xTyctX1j1INLOCqykW9NfyX/Rmu19PFUY/WKa4ATxdFJyRr/ZEofb3llFJ4JivuMOTw3eHQtg369fNJ1tfLZrwjSarf+RE16JI2pf/lyPOyOPyXxQUCCuvB18dp7byPNXfYU/LyLaharbqoTrvu1jrNHnlOf//whVbO/UBxl6Pk6Rugak3aqn5nzouRewp6umhoy7Iq4JZ2Trz33BW99P1unf//42zG/XZQj91XUoNblJW3m5PORydozsYTWnrNjIiFvFxtvld2c3LQ841DVNDLRYnJqToRFacJqw7p94P/zbzYoUraeMukzv/NaiZJk1Yd0op9zHiTmyyGYe4RTqFChbRu3TqVK1cu19oc+GNYrrUF3Im4/wL5wfQulbKuhBy7FTksSXM2H8/V9oA7zdz1POsQedvqF+qb3YV841Zl8ZQ/DmddCbiL/bE/MutKwF1s0eO1ze5CvnCrcvjTDceyrgTcxb7fynOHkbf9+my9bNVzyLrKrdWnTx/NnDnT7G4AAJAvkcMAAJiLLAYAwDzkMAAgJ0ydLliSEhMT9fnnn2vFihWqXbu2PD09bZZPmTLFpJ4BAJD3kcMAAJiLLAYAwDzkMAAgJ0wfZN21a5dq1aolSdq/3/ZZDtc+0wQAAOQ+chgAAHORxQAAmIccBgDkhOmDrGvWrDG7CwAA5FvkMAAA5iKLAQAwDzkMAMgJ05/Jeq2TJ0/q1KlTZncDAIB8iRwGAMBcZDEAAOYhhwEA9jJ9kDU1NVWjRo2Sj4+PgoKCVKpUKfn6+mr06NFKTU01u3sAAORp5DAAAOYiiwEAMA85DADICdOnC37zzTc1c+ZMjR8/Xg0bNpRhGPr77781YsQIxcfHa+zYsWZ3EQCAPIscBgDAXGQxAADmIYcBADlh+iDrF198oc8//1wdO3a0llWvXl3FixfXs88+S5ABAHALkcMAAJiLLAYAwDzkMAAgJ0yfLjgyMlIVK1ZMV16xYkVFRkaa0CMAAPIPchgAAHORxQAAmIccBgDkhOmDrNWrV9eHH36YrvzDDz9U9erVTegRAAD5BzkMAIC5yGIAAMxDDgMAcsL06YInTJigdu3aaeXKlapfv74sFovWrVunEydO6Oeffza7ewAA5GnkMAAA5iKLAQAwDzkMAMgJ0+9kDQ0N1f79+9WlSxdFRUUpMjJSXbt21b59+9SoUSOzuwcAQJ5GDgMAYC6yGAAA85DDAICcMP1OVkkKDAzkIeIAAJiEHAYAwFxkMQAA5iGHAQA3644YZI2KitKmTZt0/vx5paam2izr06ePSb0CACB/IIcBADAXWQwAgHnIYQDAzTJ9kPWnn35S7969FRMTI29vb1ksFusyi8VCkAEAcAuRwwAAmIssBgDAPOQwACAnTH8m66uvvqrHHntM0dHRioqK0sWLF60/kZGRZncPAIA8jRwGAMBcZDEAAOYhhwEAOWH6IOupU6f0wgsvyMPDw+yuAACQ75DDAACYiywGAMA85DAAICdMH2Rt3bq1tmzZYnY3AADIl8hhAADMRRYDAGAechgAkBOmPJN1yZIl1v9v166dXn/9de3Zs0dVq1aVs7OzTd2OHTve7u4BAJCnkcMAAJiLLAYAwDzkMAAgt1gMwzBu90odHLJ3A63FYlFKSord7Q/8Mczu9wB3k1SzOwDcBtO7VDK7C3nWrc5hSZqz+fhNvQ+4W8xdf8rsLgC31OoX6pvdhTztdmTxlD8O39T7gLvFH/t5ViLytkWP1za7C3nW7cjhTzccu6n3AXeL77eeNbsLwC3167P1slXPlDtZU1MZIgIAwCzkMAAA5iKLAQAwDzkMAMgtpj+TFQAAAAAAAAAAAADuJqYNsm7cuFG//PKLTdncuXMVEhKiwoUL68knn1RCQoJJvQMAIG8jhwEAMBdZDACAechhAEBuMG2QdcSIEdq5c6f19b///qsBAwaoRYsWGjJkiH766SeNGzfOrO4BAJCnkcMAAJiLLAYAwDzkMAAgN5g2yLp9+3Y1b97c+nrBggWqV6+ePvvsM73yyit6//339c0335jVPQAA8jRyGAAAc5HFAACYhxwGAOQG0wZZL168qCJFilhf//7772rTpo31dZ06dXTixAkzugYAQJ5HDgMAYC6yGAAA85DDAIDcYNoga5EiRXTkyBFJUmJiorZu3ar69etbl0dHR8vZ2dms7gEAkKeRwwAAmIssBgDAPOQwACA3mDbI2qZNGw0ZMkR//vmnhg4dKg8PDzVq1Mi6fOfOnSpTpoxZ3QMAIE8jhwEAMBdZDACAechhAEBucDJrxWPGjFHXrl0VGhoqLy8vffHFF3JxcbEunzVrllq1amVW9wAAyNPIYQAAzEUWAwBgHnIYAJAbTBtkLVSokP78809dunRJXl5ecnR0tFn+7bffysvLy6TeAQCQt5HDAACYiywGAMA85DAAIDeYNsh6lY+PT4bl/v7+t7knAADkP+QwAADmIosBADAPOQwAyAnTnskKAAAAAAAAAAAAAHejbN3JumTJkmw32LFjx5vuDAAAyBhZDACAechhAMD/2Lvv8Ciqt43j90J6AgFCCTX03nvviDTpClioKiIdFRE0FBFEmoUiSBcRFEGp0uSnSBGUIkWw0DtEOgkp5/2DNytLCrskYULy/VwXl+7M7JlnkknuzT47Z2AtshgAkBw51WRt1aqVU4PZbDZFRkYmpB4AABALshgAAOuQwwAAWIssBgAkR041WaOiopK6DgAAEA+yGAAA65DDAABYiywGACRHCbona2hoaGLVAQAAHgJZDACAdchhAACsRRYDAKzkcpM1MjJSo0aNUs6cOeXn56d//vlHkvT2229r1qxZiV4gAABwRBYDAGAdchgAAGuRxQCA5MLlJuvo0aM1d+5cjRs3Th4eHvblpUqV0meffZaoxQEAgJjIYgAArEMOAwBgLbIYAJBcuNxknT9/vmbMmKFnn31WadOmtS8vXbq0/vjjj0QtDgAAxEQWAwBgHXIYAABrkcUAgOTC5Sbr6dOnVbBgwRjLo6KiFB4enihFAQCAuJHFAABYhxwGAMBaZDEAILlwuclaokQJ/fTTTzGWf/XVVypXrlyiFAUAAOJGFgMAYB1yGAAAa5HFAIDkws3VJwQHB+v555/X6dOnFRUVpW+++UaHDx/W/PnztXLlyqSoEQAA3IMsBgDAOuQwAADWIosBAMmFy1eytmjRQosXL9bq1atls9n0zjvv6NChQ1qxYoUaNWqUFDUCAIB7kMUAAFiHHAYAwFpkMQAguXD5SlZJaty4sRo3bpzYtQAAACeRxQAAWIccBgDAWmQxACA5eKgmqyTt2rVLhw4dks1mU7FixVShQoXErAsAADwAWQwAgHXIYQAArEUWAwCs5nKT9dSpU+rYsaN+/vlnZciQQZJ05coVVa9eXYsWLVLu3LkTu0YAAHAPshgAAOuQwwAAWIssBgAkFy7fk7Vbt24KDw/XoUOHFBISopCQEB06dEjGGHXv3j0pagQAAPcgiwEAsA45DACAtchiAEBy4fKVrD/99JO2bt2qIkWK2JcVKVJEH3/8sWrUqJGoxQEAgJjIYgAArEMOAwBgLbIYAJBcuHwla548eRQeHh5jeUREhHLmzJkoRQEAgLiRxQAAWIccBgDAWmQxACC5cLnJOm7cOPXp00e7du2SMUbS3ZuM9+vXT+PHj0/0AgEAgCOyGAAA65DDAABYiywGACQXNhOdRPHImDGjbDab/fHNmzcVEREhN7e7sw1H/7+vr69CQkKSrlon9Vl2yOoSgCQVZXUBwCMwpXUxq0tIVh63LJ6784TVJQBJav6201aXACSpTX2rWV1CsvK45bAkTfzxH6tLAJLUj0eSx88akFSW96hodQnJyuOWxTO2H7e6BCBJLf3tnNUlAEnq+15VnNrOqXuyTp48OSG1AACABCKLAQCwDjkMAIC1yGIAQHLkVJO1c+fOSV0HAACIB1kMAIB1yGEAAKxFFgMAkiOnmqxxuX37doybjKdPnz5BBQEAAOeRxQAAWIccBgDAWmQxAMBKaVx9ws2bN9W7d29lzZpVfn5+ypgxo8M/AACQtMhiAACsQw4DAGAtshgAkFy43GR94403tGnTJk2dOlWenp767LPPNGLECOXIkUPz589PihoBAMA9yGIAAKxDDgMAYC2yGACQXLg8XfCKFSs0f/581a1bV926dVOtWrVUsGBBBQUFaeHChXr22WeTok4AAPD/yGIAAKxDDgMAYC2yGACQXLh8JWtISIjy5csn6e789iEhIZKkmjVr6scff0zc6gAAQAxkMQAA1iGHAQCwFlkMAEguXG6y5s+fX8eOHZMkFS9eXEuWLJF09xNEGTJkSMzaAABALMhiAACsQw4DAGAtshgAkFy43GTt2rWr9u7dK0kaMmSIfe77AQMG6PXXX0/0AgEAgCOyGAAA65DDAABYiywGACQXNmOMScgAJ06c0K5du1SgQAGVKVMmsepKkD7LDlldApCkoqwuAHgEprQuZnUJj43kmMVzd56wugQgSc3fdtrqEoAktalvNatLeGwkxxyWpIk//mN1CUCS+vFIiNUlAElqeY+KVpfw2EiOWTxj+3GrSwCS1NLfzlldApCkvu9VxantXL6S9X558uRRmzZtlClTJnXr1i2hwwEAABeRxQAAWIccBgDAWmQxAMAqCW6yRgsJCdG8efMSazgAAOAishgAAOuQwwAAWIssBgA8aonWZAUAAAAAAAAAAACA1IAmKwAAAAAAAAAAAAC4wGaMMYkx0N69e1W+fHlFRkYmxnAJEhphdQVA0spYqbfVJQBJ7vbuT6wu4bFDFgOPDlmMlI4cdl1yymGJLEbKRxYjpSOLXZecspgcRkpHDiOlczaH3ZwdsE2bNvGuv3LlirNDAQCAh0AWAwBgHXIYAABrkcUAgOTG6Sarv7//A9e/8MILCS4IAADEjiwGAMA65DAAANYiiwEAyY3TTdY5c+YkZR0AAOAByGIAAKxDDgMAYC2yGACQ3KSxugAAAAAAAAAAAAAAeJzQZAUAAAAAAAAAAAAAF9BkBQAAAAAAAAAAAAAX0GQFAAAAAAAAAAAAABfQZAUAAAAAAAAAAAAAFzxUk3XBggWqUaOGcuTIoePHj0uSJk+erG+//TZRiwMAALEjiwEAsA45DACAtchiAEBy4HKTddq0aRo4cKCaNm2qK1euKDIyUpKUIUMGTZ48ObHrAwAA9yGLAQCwDjkMAIC1yGIAQHLhcpP1448/1syZMzV06FClTZvWvrxixYr6/fffE7U4AAAQE1kMAIB1yGEAAKxFFgMAkguXm6xHjx5VuXLlYiz39PTUzZs3E6UoAAAQN7IYAADrkMMAAFiLLAYAJBcuN1nz5cunPXv2xFi+Zs0aFS9ePDFqAgAA8SCLAQCwDjkMAIC1yGIAQHLh5uoTXn/9db366qsKDQ2VMUa//PKLFi1apDFjxuizzz5LihoBAMA9yGIAAKxDDgMAYC2yGACQXLjcZO3atasiIiL0xhtv6NatW+rUqZNy5sypDz/8UB06dEiKGgEAwD3IYgAArEMOAwBgLbIYAJBc2Iwx5mGffOnSJUVFRSlr1qyJWVOChUZYXQGQtDJW6m11CUCSu737E6tLeCyQxYA1yGKkdOSwc5JrDktkMVI+shgpHVnsnOSaxeQwUjpyGCmdszns8pWs98qcOXNCng4AABKILAYAwDrkMAAA1iKLAQBWcrnJmi9fPtlstjjX//PPPwkqCAAAxI8sBgDAOuQwAADWIosBAMmFy03W/v37OzwODw/X7t27tXbtWr3++uuJVRcAAIgDWQwAgHXIYQAArEUWAwCSC5ebrP369Yt1+ZQpU7Rr164EFwQAAOJHFgMAYB1yGAAAa5HFAIDkIk1iDdSkSRMtXbo0sYYDAAAuIosBALAOOQwAgLXIYgDAo5ZoTdavv/5amTJlSqzhAACAi8hiAACsQw4DAGAtshgA8Ki5PF1wuXLlHG4sbozRuXPndPHiRU2dOjVRiwMAADGRxQAAWIccBgDAWmQxACC5cLnJ2qpVK4fHadKkUZYsWVS3bl0VLVo0seoCAABxIIsBALAOOQwAgLXIYgBAcuFSkzUiIkJ58+ZV48aNFRgYmFQ1AQCAOJDFAABYhxwGAMBaZDEAIDlx6Z6sbm5ueuWVVxQWFpZU9QAAgHiQxQAAWIccBgDAWmQxACA5canJKklVqlTR7t27k6IWAADgBLIYAADrkMMAAFiLLAYAJBcu35O1V69eGjRokE6dOqUKFSrI19fXYX3p0qUTrTgAABATWQwAgHXIYQAArEUWAwCSC5sxxjizYbdu3TR58mRlyJAh5iA2m4wxstlsioyMTOwaXRYaYXUFQNLKWKm31SUASe727k+sLiHZIYuB5IMsRkpHDsf0OOWwRBYj5SOLkdKRxTE9TllMDiOlI4eR0jmbw043WdOmTauzZ8/q9u3b8W4XFBTk1I6TEiGGlI4QQ2rAH5QxkcVA8kEWI6Ujh2N6nHJYIouR8pHFSOnI4pgepywmh5HSkcNI6ZzNYaenC47uxSaHkAIAIDUiiwEAsA45DACAtchiAEByk8aVjW02W1LVAQAAnEAWAwBgHXIYAABrkcUAgOTE6StZJalw4cIPDLKQkJAEFQQAAOJGFgMAYB1yGAAAa5HFAIDkxKUm64gRI+Tv759UtQAAgAcgiwEAsA45DACAtchiAEBy4lKTtUOHDsqaNWtS1QIAAB6ALAYAwDrkMAAA1iKLAQDJidP3ZGW+ewAArEUWAwBgHXIYAABrkcUAgOTG6SarMSYp6wAAAA9AFgMAYB1yGAAAa5HFAIDkxunpgqOiopKyDgAA8ABkMQAA1iGHAQCwFlkMAEhunL6SFQAAAAAAAAAAAACQDJusERERunHjhtVlAACQKpHDAABYiywGAMA65DAAwBWWNVlXr16tBQsWOCwbPXq0/Pz8lCFDBj3xxBP6999/LaoOAICUjRwGAMBaZDEAANYhhwEAicGyJuv48eN17do1++OtW7fqnXfe0dtvv60lS5bo5MmTGjVqlFXlAQCQopHDAABYiywGAMA65DAAIDFY1mTdv3+/qlevbn/89ddfq1GjRho6dKjatGmjCRMmaMWKFVaVBwBAikYOAwBgLbIYAADrkMMAgMRgWZP1+vXrCggIsD/esmWL6tevb39cokQJnTlzxorSAABI8chhAACsRRYDAGAdchgAkBgsa7LmyJFDhw4dkiTduHFDe/fuVY0aNezrL1++LB8fH6vKAwAgRSOHAQCwFlkMAIB1yGEAQGKwrMnarl079e/fXwsWLNCLL76owMBAVa1a1b5+165dKlKkiFXlAQCQopHDAABYiywGAMA65DAAIDG4WbXj4OBgnTlzRn379lVgYKA+//xzpU2b1r5+0aJFatGihVXlAQCQopHDAABYiywGAMA65DAAIDHYjDHG6iISW2iE1RUASStjpd5WlwAkudu7P7G6BCQAWYyUjixGSkcOP/7IYqR0ZDFSOrL48UYOI6Ujh5HSOZvDll3Jeq99+/bpyJEjstlsKlSokEqXLm11SQAApBrkMAAA1iKLAQCwDjkMAHhYljZZf/nlF3Xv3l0HDx5U9AW1NptNJUqU0KxZs1SpUiUrywMAIEUjhwEAsBZZDACAdchhAEBCpbFqxwcPHlSDBg3k7e2tzz//XL/99pt+/fVXLViwQJ6enmrQoIEOHjxoVXkAAKRo5DAAANYiiwEAsA45DABIDJbdk7V9+/aKjIzU0qVLZbPZHNYZY9SmTRu5u7tryZIlLo/NnPdI6ZjzHqkB959JWkmZwxJZjJSPLEZKRw4nPbIYSBiyGCkdWZy0yGEgYchhpHTJ/p6smzdv1po1a2KEmHR3Woa33npLTZs2taAyAABSPnIYAABrkcUAAFiHHAYAJAbLpgu+fv26smXLFuf6wMBAXb9+/RFWBABA6kEOAwBgLbIYAADrkMMAgMRgWZM1b968+uWXX+Jcv2PHDgUFBT3CigAASD3IYQAArEUWAwBgHXIYAJAYLGuyPvPMMxo4cKD2798fY93vv/+u1157TR06dLCgMgAAUj5yGAAAa5HFAABYhxwGACQGmzHGWLHj0NBQNWjQQDt27FCjRo1UrFgxSdLBgwe1YcMGVa5cWZs2bZKXl5frY3NjcaRw3FgcqYGzNxfHw0nKHJbIYqR8ZDFSOnI46ZHFQMKQxUjpyOKkRQ4DCUMOI6VzNocta7JK0p07dzRp0iQtWrRIR44ckSQVLlxYHTp00IABA+Tp6flQ4xJiSOkIMaQG/EGZ9JIqhyWyGCkfWYyUjhx+NMhi4OGRxUjpyOKkRw4DD48cRkr3WDRZ43Py5EkFBwdr9uzZLj+XEENKR4ghNeAPSmslJIclshgpH1mMlI4cth5ZDMSPLEZKRxZbixwG4kcOI6VzNoctuyfrg4SEhGjevHlWlwEAQKpEDgMAYC2yGAAA65DDAABnJNsmKwAAAAAAAAAAAAAkRzRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAVuVu24TZs28a6/cuXKoykEAIBUiBwGAMBaZDEAANYhhwEAicGyJqu/v/8D17/wwguPqBoAAFIXchgAAGuRxQAAWIccBgAkBsuarHPmzLFq1/h/s2Z+qo3r1+no0X/k6eWlsmXLqf/A15Q3X377NsYYTZ/6iZZ+tVjXrl1TqdJlNGTYOypYsFCc4y79aolWfLdcf/31pySpePES6tNvoEqVLm3fZsmXX2jJ4kU6c/q0JKlAwUJ6+ZVeqlmrThIdLVKjP1aNUFCOgBjLpy/+UQPGLlHWTOn0br+WalitmPz9vLXlt780cNxX+vvExTjH/H5mP9WuGPP8X/PTfrXpO92p/QLJATmcPPy6a6fmzp6lQwf36+LFi5r00RTVb9DQvn7D+nX6esliHTq4X1euXNHir5eraLFi8Y7pTA478xoASAxp06bRsJebqkPTisoWkF7nLl3TghXbNXbm9zLGSJJ8vT30bt+WalGvtDL5++r4mRBN/XKzZn61Jc5xncljZ/YNWIksTh4elMX3Gjn8HS39arFeHzxEz73QJc4xu3d5Xrt2/hJjea3adfTJtBmSyGI8Gs5k4YwRz+n5p6o6PO+XfUdVp/OEOMft2rq6nm1eWcUL5pAk7T50QsEfr9CuA8dd2jdgJXI4eYgvh8PDw/XJR5O15acfderUSaXz81OVatXVb8AgZc2aLd5xN6z7XlM+/lAnT55Q7tx51LvfADVo2Mi+nvem8ag4k4e3d38S63PfmrRMk+ZvjHWdm1savd7tCT3XvIpyZM2gI8fPa9iH32r91kP2bXiP+tGwrMkK6+3a+Yue6fisSpQqpciISH380ST1fLG7vvlulXx8fCRJc2bN1IJ5czRy9FgF5c2rmZ9OU88eXfXtqrXy9fWLY9wdatK0mcqULS9PTw/Nmf2ZXnmpm5Z+u0rZst0NwKzZAtVvwGvKnSePJGnFt8vVr/erWrx0WbwNXMAVNZ/7QGnT2OyPixfModXT++ib9bslSUsmvaTwiEi17/+prt0MVd/n6mv19D4q1+Zd3Qq9E+uYHQbNlId7WvvjTP6++mXxEPuYzuwXAKLdvn1LRYoUUcvWbTSof59Y15ctV05PNH5SI4KHOTWmMznszGsAIDEM6tJIPdrV1IvvLNDBv8+qQok8+nT4c7p2PVRTFm2WJI17ra3qVCysrkPn6/iZy2pYrZg+HPK0zl68qpWbf491XGfy2Jl9A8CDsjjapo0btH/fXmXJmvWBY06c/LHCw8Ptj69cvaKn27RUoyeetC8ji/EoOJuF3/98QC8Hf25/fCc8Mt5xa1cspCVrf9X2vV8p9E6EBnZuqBXTXlWFtqN15uJVl/YNIHWLL4dDQ0P1x6GDeqnnKypSpKiuXbumcWPfU7/er2jRkm/iHHPvnt1647UBerVPP9Vv0FCbNm7QG4P6a86CL1S6dBlJvDeNR8eZPMzbcIjDc56oUULTgztp2cY9cY47vFcLdWxWSb1GfaHDR8+rUfViWjzhRdXrMlF7D5+SxHvUjwpN1lRs2oxZDo9HvjtG9WpV06GDB1ShYiUZY7RwwXz1eKmnGjZ6QpL07nvvq37t6lq9aqXaP90h1nHHjHP8tGPwiHe1Yd33+mX7NrVo2UqSVLdefYdt+vQboCVfLtK+vXsIMiSaS//ecHj8WteS+vvERf30658qmCerqpTOp/Jt39Whf85JkvqNWawTG8fq6SYVNHfZtljH/PfaLYfH7RtX0K3QOw7hFN9+AeBeNWvVifeTsi2eaiVJOn36lNNjOpPDD3oNACSWKqXzaeX/9mntlgOSpBNnQ/T0kxVVvngeh20+X7nDnpOzv/lZ3dvWUPnieeJssjqTx87sGwAelMWSdP78eY0ZPVLTZsxSn1defuCY/hkyODxeu2aVvLy81Kjxf01WshiPgrNZeOdOhM5fvu70uF2HznN43GvUF2rdsKzqVimiL1b+4tK+AaRu8eVwunTp9Olnjlccv/nWMD3bob3Onjmj7DlyxPq8zxfMU9Vq1dX9xbuZ3T1/Ae3a+YsWzp+n0uMnSuK9aTw6zuTh/Rncom4p/W/nnzp2+nKc43ZqXlnvf/a9vt9yUJI086stalStmPo9X1/dhs2XxHvUj0oaqwtA8nHj+t0f5vT/f0+C06dO6dKli6pWo6Z9Gw8PD1WoWEl7dzv/aYfQ0NuKiIiwj3u/yMhIrVm9Srdv31KZMuUScARA3Nzd0qpD00qa9+3d5qmnx93PmITeibBvExVldCc8QtXLFnB63M6tquur73+L88rX+/cLAI/ag3JYivkaAEgs2/b8rXqVi6hgnrtXfpUqnFPVyubX9z8fsG+zdc8/al6nlHJkuXv+1a5YSIWCsmrDPdMcPUhseezMvgHgQaKiojT0zdfVpWv3h37Tddk3S/Vkk2bxXqFKFiMpOJuFtSoW0vGNY7Rv+Tua8nZHZckY+8xlcfHx8pC7W1r9e/W/D0GRwwCSwo0bN2Sz2ZQuffo4t9m3Z4+qVa/psKx6jVrauyf297N5bxpJydU8zJopnZ6sWVLzlsf/XrKHu5tC74Q7LLsdFq7q5WJ/X5v3qJPOY38la1hYmMLCwhyWmbSe8vT0tKiix5MxRuPHjVG58hVUqFBhSdKlS3fvSxkQ4Dhvd0BAZp05c8bpsT+cOEFZs2ZT1WrVHZb/eeSwnu/UQXfuhMnHx0eTPpqiAgULJvBIgNg9Va+0MqTz1ucrdkiSDh87p+NnLmtUn6fU+91Funn7jvo9X1/Zs/grMLNzb2xULBGkkoVy6JURC53eL5ASkcXJW1w5HC221wBAYhk/Z73S+3lr77Jhiow0SpvWpuApK7Vk7a/2bQa9/5WmvtNJf68brfDwSEWZKL0y8gtt3fOPU/uIK4+d2TeQUpDFSWfOrJlK6+amTs+98FDP/33fPv315xENHzk6zm3IYiQVZ7Jw3c8H9c363TpxNkR5cwbonV7NtWZGX1XvNE53wiPiGf0/o/q21JkLV7Vpxx8u7RtIKcjhRyMsLEwfThqvJs2ay88v7g+DXLp0KZb3swPs73VH471pPAqu5uFzLaro+q1QLd+0J95xN2w7pL7P1deW3/7SPycvqV7lImpep7TSprXFuj3vUSedx/5K1jFjxsjf39/h3wfvj7G6rMfOmHdH6s8jR/T+BxNjrLPZHH8wjTGyxf6zGsOcWTO1ZvUqTfzw4xgvLPLmzaclS5drwReL1f6Zjnr7rcH6+6+/HvoYgPh0blVd3/98UGf///4wERFR6vjaZyoYlFVnf/xAIdsmqlaFQlq75YAio6KcHLOa9v95RrsOHHd6v0BKRBYnX/HlcLT4XgMACdW+cQV1bFpJXd6ap2qd3lePdxao//MN9GyLKvZtXu1YV5VL5VXbftNV/dn39ebEZfpwyDOqV6WIU/uIK4+d2TeQUpDFSePggf1auGC+Ro0eE+PvYmct++ZrFSxUWKVKl45zG7IYScWZLPx63W9au+WADv59Vqt/3K9WvaeqUFBWNalVwql9DOzcUE8/WUEdXpupsHtmiiKHkZqQw0kvPDxcg18boKgoo6FvD3/g9jHez5aJsYz3pvEouJqHL7SsqsVrdjlkamxe++Br/X3igvZ+87au/TJZk95sr/nfbVdkpIl1e96jTjqWX8n63XffxbrcZrPJy8tLBQsWVL58+eJ8/pAhQzRw4ECHZSYtnxJyxZjRo7R58ybNnve5sgUG2pdnzpxF0t1P/2TJktW+PCTksgICMj9w3HlzZmnWzE/16WdzVLhI0Rjr3T08lCcoSJJUomQpHdj/uxZ+Pl/vDB+Z0EMCHOTJnlH1qxRRh9dmOizffeikqnYYq/R+XvJwd9Olf2/ox/mv6deDJx44preXu9o3rqBR01a5vF8gOUloDktkcXL1oByW4n4NACSW9/q30vg56/XV93c/pXvgrzPKkz2TXu/aSAtX7JCXp7tG9GmhZwbOtN+jZv+fZ1S6SC71f76BfthxON7x48vjB+0bSC7I4uTrt193KSTksp5sWM++LDIyUhM+eF8LF8zXmvWb4n3+7du39f2aVerVu2+c25DFSEoPk4XnLl3TibMhKpgnywPH7/98A73e/Qk16/mJ9v/pOOMZOYzHBTmc/IWHh+v1Qf11+tQpzZwzL96rWCUpc+bMunTpksOykMshMd7P5r1pPAqu5GGNcgVUJF+gnn9zTmxDObj07w09PXCmPD3cFODvqzMXr+rdvi117EzM+7jyHnXSsrzJ2qpVK9lsNhnj2GGPXmaz2VSzZk0tX75cGTNmjPF8T8+YUy+EOjebSapnjNGY0aO0aeN6zZq7QLly5XZYnzNXLmXOnEXbt/6sYsWKS5LC79zRr7t2qt/A1+Ide+7szzTz02maNmOWSpQs5XQ94Xdiv68lkBDPP1VNF0Kua81Psc91f+1GqCSpQJ4sKl88j0ZMXfnAMds2Ki9PDzctWr3zofcLJAcJzWGJLE6OHpTDD3oNACQWby8PRRnHGSIio4zSpLk7oY67W1p5uLsp6r7fQZGRUUqT5sFXjcWXxw/aN5BckMXJV/OnWqrKfdPtv/JSdzVv0VKtWrd54PPXrV2jO3fuqFmLp2KsI4vxKDxMFmby91WubBl19tK1eMce8EIDDe7xpJ56dYp+i+WDyuQwHhfkcPIW3WA9cfy4PpszXxkyxP49uFfpsmW1fdvPer5zF/uybVu3qEzZ+O+3ynvTSAqu5GHnVtX068ET+v3IaafHD7sToTMXr8rNLY1aNSirpet/i7EN71EnLctf2axfv16VKlXS+vXrdfXqVV29elXr169X5cqVtXLlSv3444+6fPmyXnst/qYeXPfeqBFavfI7jR03Qb4+vrp08aIuXbyo0NC7DSebzaZnn39Bs2Z+qo0b1uvPP4/o7aFD5OXlpabNmtvHGTrkDX04aYL98ZxZM/XJR5M1YtR7ypEjp33cWzdv2rf5aPJE/fbrLp0+fUp/Hjmsjz+cpF07f1HT5i0e3RcAqYLNZtMLLatq4codiox0DLQ2DcupVoVCypszQM3rltKqab21YvM+bdz+331kPhv1vEb2ifmmSJdW1bRi8z6FXL0ZY92D9gskJ+SwtW7dvKk/Dh3SH4cOSZJOnzqlPw4d0tn/v/f51StX9MehQ/rn778lSceOHdUfhw7p0sX/7iXzMDn8oNcAQGJZ/ePvGty9sZ6sWUJ5smfSU/VKq+9z9fTdpr2SpOs3Q/Xjrj/1Xv9WqlWhkIJyBOi5FlX0bPPK+u6HvfZxHiaPH7RvILkgi60VXxZnyJBRhQoVdvjn7uauzJkzK2++/PYx7s/iaMu++Vr1GjSM9Q1hshiPwoOy0NfbQ2MGtFaV0vmUJ3sm1apQSEs/fFmXr9xwyMv7c3hg54YKfrW5eo5YqONnLitbQDplC0gnX28Pp/cNJBfksLXiy+GIiAi9NqCvDh7YrzHvj1dUZKQ9L+9tht6fw88+94K2bf1Zsz+boaP//K3Zn83Qju3b9OwLne3b8N40HhVn8zCdr5faNCqnucu2xjrO/VlcqWSQWtYvo7w5A1SjXAF998mrSpPGpolzNzg8j/eok57lV7L269dPM2bMUPXq/306tEGDBvLy8tJLL72kAwcOaPLkyerWrZuFVaZMSxYvkiR17/K8w/KR745Ry///VG7X7i8qLCxM740aoWvXrqpU6TKaNnO2fH3/m5bh3NmzSmP7r1+/5MtFCg8P16ABjlMi9ezVW6+82keSdPnyJQ198w1dvHhBfunSqXDhIpr66WeqVr1GkhwrUq/6VYooT/ZMmrd8e4x1gVnS6/1BbZQ1IJ3OXbqmhSt3aMyMtQ7b5A7MpKgox08zFsyTVTXKF1Sznp881H6B5IQcttaBA/vVo+sL9sfjx929b89TLVtr1HtjtfmHTXpn2BD7+sGvDZDkmKkPk8POvAYAEsPA979ScK/m+vCtZ5Qlo5/OXryqWV//rPdmrLFv88KbszWyT0vNfa+zMqb30YmzIRo+ZaVmfrXFvs3D5LEz+waSA7LYWg/KYmfcn8XS3Q9G7f7tV02fOTvW55DFeBQelIWRUUYlCuZQp+aVlSGdt85duqb/7Tyi5wfP1o1bYfZx7s/hl56uJU8Pdy0a38Nhf+9OX63Rn652at9AckEOWyu+HO75am9t/uHu1PxPt23p8LzP5sxXpcp372l5fw6XLVde738wUZ98PFlTPv5IufPk1vvjJ6l06TL2bXhvGo+Ks3nYvnEF2WTTkrW7Yh3n/iz29HRX8KvNlS9nZt24Fabvfz6g7m/P19Ubtx2ex3vUSc9m7p8L4RHz9vbWzp07VbJkSYflv//+uypXrqzbt2/r+PHjKlasmG7duuXUmEzHgJQuY6XeVpcAJLnbu+NuYiPxJEUOS2QxUj6yGCkdOfzokMXAwyGLkdKRxY8GOQw8HHIYKZ2zOWz5dMEVKlTQ66+/rov3THt38eJFvfHGG6pUqZIk6c8//1SuXLmsKhEAgBSLHAYAwFpkMQAA1iGHAQAJYfl0wbNmzVLLli2VK1cu5c6dWzabTSdOnFD+/Pn17bffSpJu3Liht99+2+JKAQBIechhAACsRRYDAGAdchgAkBCWTxcsScYYff/99zpy5IiMMSpatKgaNWqkNGke7kJbpmNASsd0DEgNmBrp0UnsHJbIYqR8ZDFSOnL40SKLAdeRxUjpyOJHhxwGXEcOI6VzNoeTRZM1sRFiSOkIMaQG/EH5eCOLkdKRxUjpyOHHH1mMlI4sRkpHFj/eyGGkdOQwUjpnc9jy6YIlaePGjdq4caMuXLigqKgoh3WzZ8+2qCoAAFIHchgAAGuRxQAAWIccBgA8LMubrCNGjNDIkSNVsWJFZc+eXTabzeqSAABINchhAACsRRYDAGAdchgAkBCWN1mnT5+uuXPn6vnnn7e6FAAAUh1yGAAAa5HFAABYhxwGACTEw9+9O5HcuXNH1atXt7oMAABSJXIYAABrkcUAAFiHHAYAJITlTdYePXroiy++sLoMAABSJXIYAABrkcUAAFiHHAYAJITl0wWHhoZqxowZ2rBhg0qXLi13d3eH9RMnTrSoMgAAUj5yGAAAa5HFAABYhxwGACSE5U3Wffv2qWzZspKk/fv3O6zjRuMAACQtchgAAGuRxQAAWIccBgAkhOVN1h9++MHqEgAASLXIYQAArEUWAwBgHXIYAJAQlt+T9V6nTp3S6dOnrS4DAIBUiRwGAMBaZDEAANYhhwEArrK8yRoVFaWRI0fK399fQUFBypMnjzJkyKBRo0YpKirK6vIAAEjRyGEAAKxFFgMAYB1yGACQEJZPFzx06FDNmjVLY8eOVY0aNWSM0c8//6zhw4crNDRUo0ePtrpEAABSLHIYAABrkcUAAFiHHAYAJITNGGOsLCBHjhyaPn26nnrqKYfl3377rXr16vVQUzSERiRWdUDylLFSb6tLAJLc7d2fWF1CqpAUOSyRxUj5yGKkdOTwo0MWAw+HLEZKRxY/GuQw8HDIYaR0zuaw5dMFh4SEqGjRojGWFy1aVCEhIRZUBABA6kEOAwBgLbIYAADrkMMAgISwvMlapkwZffJJzI7wJ598ojJlylhQEQAAqQc5DACAtchiAACsQw4DABLC8nuyjhs3Ts2aNdOGDRtUrVo12Ww2bd26VSdPntTq1autLg8AgBSNHAYAwFpkMQAA1iGHAQAJYfmVrHXq1NGRI0fUunVrXblyRSEhIWrTpo0OHz6sWrVqWV0eAAApGjkMAIC1yGIAAKxDDgMAEsJmjDFWFxGbkydPKjg4WLNnz3b5udxYHCkdNxZHauDszcWRNBKSwxJZjJSPLEZKRw5bjywG4kcWI6Uji61FDgPxI4eR0jmbw5ZfyRqXkJAQzZs3z+oyAABIlchhAACsRRYDAGAdchgA4Ixk22QFAAAAAAAAAAAAgOSIJisAAAAAAAAAAAAAuIAmKwAAAAAAAAAAAAC4wM2qHbdp0ybe9VeuXHk0hQAAkAqRwwAAWIssBgDAOuQwACAxWNZk9ff3f+D6F1544RFVAwBA6kIOAwBgLbIYAADrkMMAgMRgWZN1zpw5Vu0aAIBUjxwGAMBaZDEAANYhhwEAiYF7sgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2iyAgAAAAAAAAAAAIALaLICAAAAAAAAAAAAgAtosgIAAAAAAAAAAACAC2zGGGN1EXi8hYWFacyYMRoyZIg8PT2tLgdIdJzjAJIzfkchNeA8B5Cc8TsKKR3nOIDkjt9TSOk4x5MvmqxIsGvXrsnf319Xr15V+vTprS4HSHSc4wCSM35HITXgPAeQnPE7Cikd5ziA5I7fU0jpOMeTL6YLBgAAAAAAAAAAAAAX0GQFAAAAAAAAAAAAABfQZAUAAAAAAAAAAAAAF9BkRYJ5enoqODiYGy4jxeIcB5Cc8TsKqQHnOYDkjN9RSOk4xwEkd/yeQkrHOZ582YwxxuoiAAAAAAAAAAAAAOBxwZWsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsqYTNZtPy5cutLgMAgFSJHAYAwFpkMQAA1iKLAaRENFlTgAsXLujll19Wnjx55OnpqcDAQDVu3Fjbtm17JPt3NiAftN2BAwf09NNPK0uWLPL09FShQoX09ttv69atWw7b7d69W82bN1fWrFnl5eWlvHnz6plnntGlS5cSeCRI7rp06aJWrVpZXUYMD6rr9u3bCg4OVpEiReTp6anMmTOrXbt2OnDggMN2N2/e1ODBg5U/f355eXkpS5Ysqlu3rlauXJnERwAgIchhcji1IIcBJFdkMVmcWpDFAJIrspgsTg3IYcTGzeoCkHBt27ZVeHi45s2bp/z58+v8+fPauHGjQkJCknS/d+7ckYeHR6KMtX37djVs2FANGzbUqlWrlC1bNv3yyy8aNGiQNm3apB9++EEeHh66cOGCGjZsqBYtWuj7779XhgwZdPToUX333Xcxwg5IDsLCwtSwYUOdOHFCEyZMUJUqVXT+/HmNGTNGVapU0YYNG1S1alVJUs+ePfXLL7/ok08+UfHixXX58mVt3bpVly9ftvgoAMSHHCaHkXyRw0DqQBaTxUi+yGIgdSCLyWIkT+TwI2DwWPv333+NJLN58+Z4t5NkZs6caVq1amW8vb1NwYIFzbfffuuwzebNm02lSpWMh4eHCQwMNIMHDzbh4eH29XXq1DGvvvqqGTBggAkICDC1a9c2QUFBRpL9X1BQULw1LFu2LMbyqKgoU7x4cVOxYkUTGRnpsG7Pnj3GZrOZsWPHGmOMWbZsmXFzc3OoC6lH586dTcuWLeNc78w53KdPH/P666+bjBkzmmzZspng4GCHMQ4dOmRq1KhhPD09TbFixcz69evjPHedqWvs2LHGZrOZPXv2OCyPjIw0FStWNMWLFzdRUVHGGGP8/f3N3Llz4/0aAEheyGGkJuQwgOSILEZqQhYDSI7IYqQW5DBiw3TBjzk/Pz/5+flp+fLlCgsLi3fbESNG6Omnn9a+ffvUtGlTPfvss/ZPE50+fVpNmzZVpUqVtHfvXk2bNk2zZs3Su+++6zDGvHnz5Obmpp9//lmffvqpdu7cKUmaM2eOzp49a3/sij179ujgwYMaOHCg0qRxPCXLlCmjhg0batGiRZKkwMBARUREaNmyZTLGuLwvpFyunMO+vr7asWOHxo0bp5EjR2r9+vWSpKioKLVq1Uo+Pj7asWOHZsyYoaFDhyaori+++EKNGjVSmTJlHJanSZNGAwYM0MGDB7V3715Jd8/v1atX6/r16wnaJ4BHhxwG7iKHAViFLAbuIosBWIUsBsjhVM3aHi8Sw9dff20yZsxovLy8TPXq1c2QIUPM3r17HbaRZIYNG2Z/fOPGDWOz2cyaNWuMMca89dZbpkiRIvZPLRhjzJQpU4yfn5/90zt16tQxZcuWjbF/PeCTFA/a7ssvvzSSzO7du2N9Xt++fY23t7f98VtvvWXc3NxMpkyZzJNPPmnGjRtnzp0798D94/EX36dynD2Ha9as6fC8SpUqmcGDBxtjjFmzZo1xc3MzZ8+eta9P6KeFvLy8TL9+/WJd99tvvxlJZvHixcYYY/73v/+ZXLlyGXd3d1OxYkXTv39/s2XLljj3CyB5IIfJ4dSCHAaQXJHFZHFqQRYDSK7IYrI4NSCHERuuZE0B2rZtqzNnzui7775T48aNtXnzZpUvX15z58512K506dL2//f19VW6dOl04cIFSdKhQ4dUrVo12Ww2+zY1atTQjRs3dOrUKfuyihUrJu3BxMIY41DX6NGjde7cOU2fPl3FixfX9OnTVbRoUf3++++PvDYkH86ew/f+HEhS9uzZ7T8Hhw8fVu7cuRUYGGhfX7ly5SSr2fz/p92ia65du7b++ecfbdy4UW3bttWBAwdUq1YtjRo1KslqAJBw5DA5DHIYgLXIYrIYZDEAa5HFZHFqRw6nXjRZUwgvLy81atRI77zzjrZu3aouXbooODjYYRt3d3eHxzabTVFRUZJiBkX0sujtovn6+iZ67YULF5YkHTx4MNb1f/zxhwoVKuSwLCAgQO3bt9eECRN06NAh5ciRQ+PHj0/02vD4cPYcdvXnIKEKFy4c77ktyeH8dnd3V61atfTmm29q3bp1GjlypEaNGqU7d+4kal0AEhc5TA6nduQwAKuRxWRxakcWA7AaWUwWp2bkcOpFkzWFKl68uG7evOnS9lu3bnWYR37r1q1Kly6dcubMGe9z3d3dFRkZ+dC1li1bVkWLFtWkSZPsv1Ci7d27Vxs2bFDHjh3jfL6Hh4cKFCjg0vEi5UnIORytaNGiOnHihM6fP29f9jD3cbhXhw4dtGHDBvvc9tGioqI0adIkFS9ePMac+PcqXry4IiIiFBoamqA6ADxa5DBSG3IYQHJDFiO1IYsBJDdkMVITcjj1crO6ACTM5cuX1b59e3Xr1k2lS5dWunTptGvXLo0bN04tW7Z0epxevXpp8uTJ6tOnj3r37q3Dhw8rODg41pt93y9v3rzauHGjatSoIU9PT2XMmDHObY8ePao9e/Y4LCtYsKA+++wzPfHEE2rbtq2GDBmiwMBA7dixQ4MGDVK1atXUv39/SdLKlSv15ZdfqkOHDipcuLCMMVqxYoVWr16tOXPmOH28eHxdvXo1xjmUKVOmBJ3D0Ro1aqQCBQqoc+fOGjdunK5fv26/ufiDPkUUV10DBgzQt99+qxYtWmjChAmqUqWKzp8/r/fee0+HDh3Shg0b7GPXrVtXHTt2VMWKFRUQEKCDBw/qrbfeUr169ZQ+fXrnvkAAHilymBxObchhAMkNWUwWpzZkMYDkhiwmi1MTchgxJN3tXvEohIaGmjfffNOUL1/e+Pv7Gx8fH1OkSBEzbNgwc+vWLft2iuXmyP7+/mbOnDn2x5s3bzaVKlUyHh4eJjAw0AwePNiEh4fb19epUyfWmyR/9913pmDBgsbNzc0EBQXFWaukWP/98MMPxhhj9u3bZ9q2bWsCAgKMu7u7KVCggBk2bJi5efOmfYy///7bvPjii6Zw4cLG29vbZMiQwVSqVMnhOJByde7cOdZzqHPnzsaYhzuHW7ZsaX++McYcOnTI1KhRw3h4eJiiRYuaFStWGElm7dq1D13XzZs3zbBhw0zBggWNu7u7yZQpk2nbtq35/fffHcZ57733TLVq1UymTJmMl5eXyZ8/v+nbt6+5dOlSgr5uAJIOOUwOpybkMIDkiCwmi1MTshhAckQWk8WpBTmM2NiMuef6ZQCAg59//lk1a9bUX3/9pQIFClhdDgAAqQo5DACAtchiAACsQw4nfzRZAeAey5Ytk5+fnwoVKqS//vpL/fr1U8aMGbVlyxarSwMAIMUjhwEAsBZZDACAdcjhxw/3ZAWAe1y/fl1vvPGGTp48qcyZM6thw4aaMGGC1WUBAJAqkMMAAFiLLAYAwDrk8OOHK1kBAAAAAAAAAAAAwAVprC4AAAAAAAAAAAAAAB4nNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WYFENnz4cJUtW9b+uEuXLmrVqtUjr+PYsWOy2Wzas2dPku3j/mN9GI+iTgBA6kEOu4YcBgAkNrLYNWQxACCxkcWuIYuREDRZkSp06dJFNptNNptN7u7uyp8/v1577TXdvHkzyff94Ycfau7cuU5t+6h/odetW1f9+/d/JPsCAKRe5HDsyGEAwKNCFseOLAYAPCpkcezIYjzu3KwuAHhUnnzySc2ZM0fh4eH66aef1KNHD928eVPTpk2LsW14eLjc3d0TZb/+/v6JMg4AAI8zchgAAGuRxQAAWIssBlIermRFquHp6anAwEDlzp1bnTp10rPPPqvly5dL+m9agdmzZyt//vzy9PSUMUZXr17VSy+9pKxZsyp9+vSqX7++9u7d6zDu2LFjlS1bNqVLl07du3dXaGiow/r7p2OIiorS+++/r4IFC8rT01N58uTR6NGjJUn58uWTJJUrV042m01169a1P2/OnDkqVqyYvLy8VLRoUU2dOtVhP7/88ovKlSsnLy8vVaxYUbt3707w12zw4MEqXLiwfHx8lD9/fr399tsKDw+Psd2nn36q3Llzy8fHR+3bt9eVK1cc1j+odgBAykcOu44cBgAkJrLYdWQxACAxkcWuI4uR3HElK1Itb29vh1/If/31l5YsWaKlS5cqbdq0kqRmzZopU6ZMWr16tfz9/fXpp5+qQYMGOnLkiDJlyqQlS5YoODhYU6ZMUa1atbRgwQJ99NFHyp8/f5z7HTJkiGbOnKlJkyapZs2aOnv2rP744w9Jd4OocuXK2rBhg0qUKCEPDw9J0syZMxUcHKxPPvlE5cqV0+7du/Xiiy/K19dXnTt31s2bN9W8eXPVr19fn3/+uY4ePap+/fol+GuULl06zZ07Vzly5NDvv/+uF198UenSpdMbb7wR4+u2YsUKXbt2Td27d9err76qhQsXOlU7ACB1IocfjBwGACQlsvjByGIAQFIiix+MLEayZ4BUoHPnzqZly5b2xzt27DABAQHm6aefNsYYExwcbNzd3c2FCxfs22zcuNGkT5/ehIaGOoxVoEAB8+mnnxpjjKlWrZrp2bOnw/oqVaqYMmXKxLrva9euGU9PTzNz5sxY6zx69KiRZHbv3u2wPHfu3OaLL75wWDZq1ChTrVo1Y4wxn376qcmUKZO5efOmff20adNiHetederUMf369Ytz/f3GjRtnKlSoYH8cHBxs0qZNa06ePGlftmbNGpMmTRpz9uxZp2qP65gBACkHORw7chgA8KiQxbEjiwEAjwpZHDuyGI87rmRFqrFy5Ur5+fkpIiJC4eHhatmypT7++GP7+qCgIGXJksX++Ndff9WNGzcUEBDgMM7t27f1999/S5IOHTqknj17OqyvVq2afvjhh1hrOHTokMLCwtSgQQOn67548aJOnjyp7t2768UXX7Qvj4iIsM+nf+jQIZUpU0Y+Pj4OdSTU119/rcmTJ+uvv/7SjRs3FBERofTp0ztskydPHuXKlcthv1FRUTp8+LDSpk37wNoBAKkDOew6chgAkJjIYteRxQCAxEQWu44sRnJHkxWpRr169TRt2jS5u7srR44cMW4c7uvr6/A4KipK2bNn1+bNm2OMlSFDhoeqwdvb2+XnREVFSbo7rUGVKlUc1kVPG2GMeah64rN9+3Z16NBBI0aMUOPGjeXv768vv/xSEyZMiPd5NpvN/l9nagcApA7ksGvIYQBAYiOLXUMWAwASG1nsGrIYjwOarEg1fH19VbBgQae3L1++vM6dOyc3NzflzZs31m2KFSum7du364UXXrAv2759e5xjFipUSN7e3tq4caN69OgRY330HPeRkZH2ZdmyZVPOnDn1zz//6Nlnn4113OLFi2vBggW6ffu2PSjjq8MZP//8s4KCgjR06FD7suPHj8fY7sSJEzpz5oxy5MghSdq2bZvSpEmjwoULO1U7ACB1IIddQw4DABIbWewashgAkNjIYteQxXgc0GQF4tCwYUNVq1ZNrVq10vvvv68iRYrozJkzWr16tVq1aqWKFSuqX79+6ty5sypWrKiaNWtq4cKFOnDgQJw3Fvfy8tLgwYP1xhtvyMPDQzVq1NDFixd14MABde/eXVmzZpW3t7fWrl2rXLlyycvLS/7+/ho+fLj69u2r9OnTq0mTJgoLC9OuXbv077//auDAgerUqZOGDh2q7t27a9iwYTp27JjGjx/v1HFevHhRe/bscVgWGBioggUL6sSJE/ryyy9VqVIlrVq1SsuWLYv1mDp37qzx48fr2rVr6tu3r55++mkFBgZK0gNrBwAgNuQwOQwAsBZZTBYDAKxFFpPFeAxYe0tY4NG4/8bi9wsODna4GXi0a9eumT59+pgcOXIYd3d3kzt3bvPss8+aEydO2LcZPXq0yZw5s/Hz8zOdO3c2b7zxRpw3FjfGmMjISPPuu++aoKAg4+7ubvLkyWPee+89+/qZM2ea3LlzmzRp0pg6derYly9cuNCULVvWeHh4mIwZM5ratWubb775xr5+27ZtpkyZMsbDw8OULVvWLF261Kkbi0uK8S84ONgYY8zrr79uAgICjJ+fn3nmmWfMpEmTjL+/f4yv29SpU02OHDmMl5eXadOmjQkJCXHYT3y1c2NxAEj5yOHYkcMAgEeFLI4dWQwAeFTI4tiRxXjc2YxJgsmyAQAAAAAAAAAAACCFSmN1AQAAAAAAAAAAAADwOKHJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMkKAAAAAAAAAAAAAC6gyQoAAAAAAAAAAAAALqDJCgAAAAAAAAAAAAAuoMn6mNuxY4dat26tPHnyyNPTU9myZVO1atU0aNAgh+3q1q0rm82m/PnzyxgTY5wff/xRNptNNptNc+fOjbF++/btat++vbJnzy4PDw8FBgaqXbt22rZtm8N20WM86N/mzZt17NixeLcZPny4Nm/e7PSYyUndunVVsmRJq8vQ8OHDHb5G7u7uypMnj1588UWdO3fOsrq6dOmivHnzWrbvuM6hlStXWlJTfM6cOaPhw4drz549VpcCpArkKrnqjC1btqhjx47288TX11clSpTQoEGD9McffzyyOmLL0+jvdVJavXp1nPvImzevw3nk5eWlggULauDAgbp06VKS1uWMB9XepUuXR1oPkNqRu+RufKL/nn3U+fEwebB161YNHz5cV65cibGubt26qlu37kPVce854uvrq/Lly+uTTz6J9ecgpXoUr20ApB689uC1R3yiX3ukSZNG//zzT4z1N2/eVPr06WWz2RxeK0R/b8aPHx/v+Pdnu5+fn6pUqaL58+cn9qHgEXKzugA8vFWrVumpp55S3bp1NW7cOGXPnl1nz57Vrl279OWXX2rChAkO26dLl05Hjx7Vpk2b1KBBA4d1s2fPVvr06XXt2rUY+/n444/Vv39/Va5cWePGjVNQUJBOnDihKVOmqGbNmvrwww/Vu3dvSYoRFKNGjdIPP/ygTZs2OSwvXry4QkJCJEl9+vRRp06dYuw3V65cSp8+fYwxW7durQIFCjzwlxb+s3btWvn7++vGjRtat26dJkyYoK1bt2rPnj1yd3e3urxHztvbO8Y5KUlFixa1oJr4nTlzRiNGjFDevHlVtmxZq8sBUjRylVx1xrBhwzR69GhVq1ZNw4YNU6FChRQREaF9+/Zp3rx5mjhxoiIiIpQ2bVpL6tu2bZty5cqVpPtYvXq1pkyZEucbnjVq1LCfT7dv39auXbs0fPhw/fjjj9q1a1eS1vYg8dW+bNkypU+f/tEXBaRS5C65m1w9TB5s3bpVI0aMUJcuXZQhQwaHdVOnTn3oWu7N1DNnzmjixInq06ePrl27prfeeuuhx32cPIrXNgBSB1578NrDWX5+fpozZ45GjRrlsPyrr75SeHh4gt5PvzfbT506pfHjx6tz5866efOmXnnllQTVDYsYPLZq165tChQoYMLDw2Osi4yMdHhcp04dU6JECVO1alXTqVMnh3XXrl0zPj4+5sUXXzSSzJw5c+zrtmzZYtKkSWOaN28eYz/h4eGmefPmJk2aNGbLli2x1ti5c2fj6+sb67qjR48aSeaDDz5w5nDtgoKCTLNmzVx6zqMW/fVOLPd/X5wVHBxsJJmLFy86LO/atauRZDZt2pRIFbqmc+fOJigoyLJ9x3VOJoabN28m6ng7d+586O8/ANeQq8lXcsnVL774wkgyPXv2NFFRUTHWR0VFmU8++cRERETEO05iZYVVefrqq6+auP6MiOt8evvtt40kc/jw4aQuL17x1Q7g0SJ3k6/kkrtx/T2bHH3wwQdGkjl69GiijRnbuXL16lXj7+9v8uTJk2j7cdatW7diff0DAI8LXnskX8nttUePHj1M7ty5Y5wXNWvWNB07djS+vr6mc+fO9uXOfm9i+178+++/Jn369KZgwYIu14vkgemCH2OXL19W5syZ5eYW84LkNGli/9Z269ZN33zzjcMUNl9++aUkqUOHDjG2HzNmjGw2m6ZNmxZjP25ubpo6dapsNpvGjh2bgCNJuP3796tly5bKmDGjvLy8VLZsWc2bN89hm+jpEr744gsNHjxY2bNnl5+fn1q0aKHz58/r+vXreumll5Q5c2ZlzpxZXbt21Y0bNxzGMMZo6tSpKlu2rLy9vZUxY0a1a9cu1ukD7rds2TL5+PioR48eioiISNTjd1XFihUlSefPn7cvu3jxonr16qXixYvLz89PWbNmVf369fXTTz85PPfe6Q8mTpyofPnyyc/PT9WqVdP27dtj7Gvu3LkqUqSIPD09VaxYsTinPwgJCVGvXr2UM2dOeXh4KH/+/Bo6dKjCwsIctrPZbOrdu7fmzJmjIkWKyNvbWxUrVtT27dtljNEHH3xgr6l+/fr666+/XP76REVFady4cSpatKg8PT2VNWtWvfDCCzp16pTDdtFTWfz444+qXr26fHx81K1bN0nStWvX9Nprrylfvnzy8PBQzpw51b9/f928edNhjK+++kpVqlSRv7+/fHx8lD9/fvsYmzdvVqVKlSRJXbt2dZj+A0DiI1f/Q67G7t1331XmzJk1adKkWKdXstlsevXVVx2uYo0vKxYvXqwnnnhC2bNnl7e3t4oVK6Y333wzRlZIzudpbDlx7tw5vfzyy8qVK5c8PDyUL18+jRgxwuHr5my+d+nSRVOmTLHvK/rfsWPH4v3a+fv7S1KMT/x+9913qlatmnx8fJQuXTo1atQoxievpbtTNDdo0EDp0qWTj4+PqlevrlWrVjlsc+vWLXv2enl5KVOmTKpYsaIWLVrkVO33Tw8ZfY4vWrRIQ4cOVY4cOZQ+fXo1bNhQhw8fdti3MUbvvfeegoKC5OXlpYoVK2r9+vUPPUUkkBqQu/8hdxPG2Sz59ttvVbp0aXl6eip//vz68MMP7dMC3uv+PIiKitK7775r//szQ4YMKl26tD788ENJd6cWfP311yVJ+fLlc5jaUYp9uuCwsDCNHDlSxYoVk5eXlwICAlSvXj1t3bo13mNNnz69Chcu7PC3vCTduXNH7777rv1v2CxZsqhr1666ePFijP0OGjRIgYGB8vHxUe3atfXrr7/GOOa5c+fKZrNp3bp16tatm7JkySIfHx/73+eLFy9WtWrV5OvrKz8/PzVu3Fi7d+922Nc///yjDh06KEeOHPYpORs0aOBwK5xNmzapbt26CggIkLe3t/LkyaO2bdvq1q1b9m1ie23jys+MMzkOIHXgtcd/eO0Rv27duunkyZNav369fdmRI0e0ZcsW+9/ziSVDhgwqUqSIjh8/nqjj4tGhyfoYq1atmnbs2KG+fftqx44dCg8Pf+BzOnTooLRp09rfbJKkWbNmqV27djGmw4mMjNQPP/ygihUrxjk1S+7cuVWhQgVt2rRJkZGRD3UcUVFRioiIiPHPWYcPH1b16tV14MABffTRR/rmm29UvHhxdenSRePGjYux/VtvvaULFy5o7ty5mjBhgjZv3qyOHTuqbdu28vf316JFi/TGG29owYIFMabfefnll9W/f381bNhQy5cv19SpU3XgwAFVr149xh8595o0aZLat2+vt956S5999lmsYf4oHT16VJJUuHBh+7LoKSeCg4O1atUqzZkzR/nz51fdunXtfxzea8qUKVq/fr0mT56shQsX6ubNm2ratKmuXr1q32bu3Lnq2rWrihUrpqVLl2rYsGEaNWpUjCkvQkNDVa9ePc2fP18DBw7UqlWr9Nxzz2ncuHFq06ZNjH2vXLlSn332mcaOHatFixbp+vXratasmQYNGqSff/5Zn3zyiWbMmKGDBw+qbdu2sd474f7z7d7z95VXXtHgwYPVqFEjfffddxo1apTWrl2r6tWrx7gf0NmzZ/Xcc8+pU6dOWr16tXr16qVbt26pTp06mjdvnvr27as1a9Zo8ODBmjt3rp566il7Pdu2bdMzzzyj/Pnz68svv9SqVav0zjvv2M//8uXLa86cOZLuTk+5bds2bdu2TT169Ij7mwvgoZGrd5GrsTtz5owOHjyoRo0aycvLy6XnxpYVkvTnn3+qadOmmjVrltauXav+/ftryZIlatGihcPznc3T2Jw7d06VK1fW999/r3feeUdr1qxR9+7dNWbMGL344osxtn9Qvr/99ttq166dJNlzadu2bcqePbt9DGOM/by7ceOGfvjhB02ePFk1atRQvnz57Nt98cUXatmypdKnT69FixZp1qxZ+vfff1W3bl1t2bLFvt3//vc/1a9fX1evXtWsWbO0aNEipUuXTi1atNDixYvt2w0cOFDTpk1T3759tXbtWi1YsEDt27fX5cuXna49Nm+99ZaOHz+uzz77TDNmzNCff/6pFi1aOPyMDh06VEOHDtWTTz6pb7/9Vj179lSPHj105MiRB36PgNSK3L2L3E0YZ7Nk7dq1atOmjQICArR48WKNGzdOixYtivGGcmzGjRun4cOHq2PHjlq1apUWL16s7t27299w79Gjh/r06SNJ+uabb+z5Ur58+VjHi4iIUJMmTTRq1Cg1b95cy5Yt09y5c1W9enWdOHEi3loiIiJ08uRJh7/lo6Ki1LJlS40dO1adOnXSqlWrNHbsWPuHfW7fvm3ftmvXrpo8ebK6du2qb7/9Vm3btlXr1q1jvZesdPdNZnd3dy1YsEBff/213N3d9d5776ljx44qXry4lixZogULFuj69euqVauWDh48aH9u06ZN9euvv2rcuHFav369pk2bpnLlytn3dezYMTVr1kweHh6aPXu21q5dq7Fjx8rX11d37tyJ82vwMD8zD8pxAKkDrz3u4rXHgxUqVEi1atXS7Nmz7ctmz56tvHnzxpg6OqHCw8N1/PhxZcmSJVHHxSNk2TW0SLBLly6ZmjVrGklGknF3dzfVq1c3Y8aMMdevX3fY9t5L7jt37mwqVqxojDHmwIEDRpLZvHlzjGlJz507ZySZDh06xFvHM888YySZ8+fPx1jnzBQHcf376aefYn3e/ZfVd+jQwXh6epoTJ044bNekSRPj4+Njrly5Yowx5ocffjCSTIsWLRy269+/v5Fk+vbt67C8VatWJlOmTPbH27ZtM5LMhAkTHLY7efKk8fb2Nm+88YZ9WfTXOzIy0vTu3dt4eHiYzz//PNbjuV9kZKQJDw93+CfJzJo1y2HZg6YiNOa/KQ7OnTtnwsPDzb///muWLFlifH19TceOHeN9bkREhAkPDzcNGjQwrVu3ti+P/r6VKlXKoYZffvnFSDKLFi2yH0eOHDlM+fLlHaYUOnbsmHF3d3eY3nD69OlGklmyZIlDDe+//76RZNatW2dfJskEBgaaGzdu2JctX77cSDJly5Z12NfkyZONJLNv3z77ss6dO8d6vtWoUcMYY8yhQ4eMJNOrVy+HWnbs2GEkmbfeesu+rE6dOkaS2bhxo8O2Y8aMMWnSpDE7d+50WP71118bSWb16tXGGGPGjx9vJNnP0dgwXTDw6JCrd5Grsdu+fbuRZN58880Y66IzM/rfvVkUV1bcLyoqyoSHh5v//e9/RpLZu3evvX5n89SYuzkZHBxsf/zyyy8bPz8/c/z4cYftojPowIEDxhjn892YB08XHNv5V7lyZXP27Fn7dtHHVapUKYcpmK5fv26yZs1qqlevbl9WtWpVkzVrVoefw4iICFOyZEmTK1cu+9elZMmSplWrVrF/gZ2s/d4pn6LP8aZNmzpst2TJEiPJbNu2zRhjTEhIiPH09DTPPPOMw3bR53idOnXirQlIrcjdu8jduD1oumBXsqRSpUomd+7cJiwszGG7gICAGLlwfx40b97clC1bNt5a45suuE6dOg5ZMH/+fCPJzJw5M94xg4KCTNOmTe1fs+PHj5sXX3zRuLu7m5UrV9q3W7RokZFkli5d6vD86J+JqVOnGmP++3kZPHiww3bRz7/3mOfMmWMkmRdeeMFh2xMnThg3NzfTp08fh+XXr183gYGB5umnnzbG3P35lmQmT54c5/FF/328Z8+eeL8O97+2cfVn5kE5DiD14LXHXbz2iNu9rz3mzJljPD09zeXLl01ERITJnj27GT58uDHGJGi64Huz/ejRo/b3ql9//XWnjhfJD1eyPsYCAgL0008/aefOnRo7dqxatmypI0eOaMiQISpVqlSMK+6idevWTbt27dLvv/+uWbNmqUCBAqpdu/ZD12H+/6q82KbNc0a/fv20c+fOGP/Kli3r1POjbz6eO3duh+VdunTRrVu3YkwT1Lx5c4fHxYoVkyQ1a9YsxvKQkBD7NAcrV66UzWbTc8895/ApocDAQJUpUybG1Z6hoaFq1aqVFi5cqHXr1unZZ5916nhGjhwpd3d3h3+S1L17d4dlBQoUcGo8SQoMDJS7u7syZsyop59+WhUqVIj1E7vTp09X+fLl5eXlJTc3N7m7u2vjxo06dOhQjG2bNWvmMB1i6dKlJck+tcHhw4d15swZderUyeHcCAoKUvXq1R3G2rRpk3x9fe1Xl0SLnq5o48aNDsvr1asnX19f++Po72GTJk0c9hW9/P7pFry9vWOcb7NmzZIk/fDDDw77jla5cmUVK1YsRi0ZM2ZU/fr1HZatXLlSJUuWVNmyZR3OlcaNGztMGxU9FfDTTz+tJUuW6PTp0wJgHXL1LnLVdQEBAQ5jLV261GF9bFkh3Z1Gr1OnTgoMDFTatGnl7u6uOnXqSJI9e13J09isXLlS9erVU44cORy+zk2aNJF09yrRez0o351Rs2ZN+3n3888/a9asWbp48aLq169v/zmKPq7nn3/eYWouPz8/tW3bVtu3b9etW7d08+ZN7dixQ+3atZOfn599u7Rp0+r555/XqVOn7FP+Va5cWWvWrNGbb76pzZs3O1y5kxBPPfWUw+P7vybbt29XWFiYnn76aYftqlatqrx58yZKDUBKRO7eRe4+PFeyZNeuXWrVqpU8PDwctrt/9ojYVK5cWXv37lWvXr30/fff69q1awmqe82aNfLy8nJqusHVq1fbv2ZBQUGaOXOmPv74Y4fv98qVK5UhQwa1aNHC4XtbtmxZBQYG2r+30Zl/f161a9cuziuE2rZt6/D4+++/V0REhF544QWHfXl5ealOnTr2fWXKlEkFChTQBx98oIkTJ2r37t2KiopyGKts2bLy8PDQSy+9pHnz5jk1daTk+s/Mg3IcQOrBa4+7eO3hnPbt28vDw0MLFy7U6tWrde7cuRjvFz+Me7M9X758WrJkifr06aN33303wWPDGslnjhc8tIoVK9rvsRkeHq7Bgwdr0qRJGjduXKyX+NeuXVuFChXSp59+qiVLlqh///6x/lLPnDmzfHx87FPLxuXYsWPy8fFRpkyZHqr+XLly2et/GJcvX451mrccOXLY19/r/jqj/8iKa3loaKj8/Px0/vx5GWOULVu2WOvInz+/w+MLFy7o5MmTatiwoVNvgkZ76aWXYoRXpUqVFBwc7LDc09PT6TE3bNggf39/hYSEaMaMGVq6dKn69Omj6dOn27eZOHGiBg0apJ49e2rUqFHKnDmz0qZNq7fffjvWJmtAQIDD4+h6ot/QjP66BwYGxnhuYGCgw73bLl++rMDAwBjnYdasWeXm5pYo38N7pUmTJs5zLnpfcZ1T9/8hFtt258+f119//RXjvnPRol+01a5dW8uXL9dHH32kF154QWFhYSpRooSGDh2qjh07xvpcAEmPXCVXYxP9B2hsb8ht3rxZERER+vXXX9WzZ88Y62P7et64cUO1atWSl5eX3n33XRUuXFg+Pj46efKk2rRp81B5Gpvz589rxYoVD8ykaA/Kd2f4+/s7nIPVq1dX8eLFVa1aNU2YMEFjxox5YN5GRUXp33//lTFGxhinzsmPPvpIuXLl0uLFi/X+++/Ly8tLjRs31gcffKBChQo5Xf/9nH3NE9u5HNf5DeA/5C65+7BczZKH/T09ZMgQ+fr66vPPP9f06dOVNm1a1a5dW++///5Dfe8vXryoHDlyxHn/v3vVrFlTkyZNUmRkpP7880+9/fbb6t27t0qUKKGaNWtKupv1V65ccWgg3ys66+PKKzc3txhZF+3+r2301I7RHxi+X/Qx2Ww2bdy4USNHjtS4ceM0aNAgZcqUSc8++6xGjx6tdOnSqUCBAtqwYYPGjRunV199VTdv3lT+/PnVt29f9evXL86vias/M4nx2gZAysJrD157OMPX11fPPPOMZs+eraCgIDVs2FBBQUEujRGb6Gy32Wzy8fFRgQIF4sxwPB5osqYw7u7uCg4O1qRJk7R///44t+vatauGDRsmm82mzp07x7pN2rRpVa9ePa1du1anTp2KdS75U6dO6ddff1WTJk0crnp4lAICAnT27NkYy8+cOSPpbsAlhsyZM8tms+mnn36K9Zfy/cvy5MmjiRMnqnXr1mrTpo2++uorp+7hliNHDnuo3Stv3rwPHaBlypSxfx0aNWqkxo0ba8aMGerevbv9j6PPP/9cdevW1bRp0xyee/369YfaZ/QfMufOnYux7v5lAQEB2rFjh4wxDi9SLly4oIiIiET7Hjojuu6zZ8/GOOfPnDkTo5a4XlR5e3s7zNt///poLVu2VMuWLRUWFqbt27drzJgx6tSpk/Lmzatq1aol9HAAJBC5+p/Unqs5cuRQiRIltH79eoWGhjrsO/oTw9Gf2L1fbFmxadMmnTlzRps3b7ZfvSopxj3RXMnT2GTOnFmlS5fW6NGjY10f29cmKURfNbJ3715Jjnl7vzNnzihNmjTKmDGjjDFKkyaNU+ekr6+vRowYoREjRuj8+fP2q1pbtGihP/74I0mO695jie2eQufOneNqVsAF5O5/UnvuOsOVLLHZbHH+nn4QNzc3DRw4UAMHDtSVK1e0YcMGvfXWW2rcuLFOnjwpHx8fl+rOkiWLtmzZoqioqAc2Wu/94FKVKlVUpUoVlSlTRr169dKePXuUJk0aZc6cWQEBAVq7dm2sY6RLl06SY17lzJnTvj4iIiLGG+rR7n8NE30+fv311w98ozkoKMg+Y9SRI0e0ZMkSDR8+XHfu3LF/4LtWrVqqVauWIiMjtWvXLn388cfq37+/smXLpg4dOsQ67qP6mQGQOvDa4z+89oipW7du+uyzz7Rv3z4tXLgwQWNFu/9DyXj8MV3wYyy2X4bSf9PLxfemWefOndWiRQu9/vrrDi+u7zdkyBAZY9SrV68YN+OOjIzUK6+8ImOMhgwZ8hBHkDgaNGhgf6PyXvPnz5ePj4+qVq2aKPtp3ry5jDE6ffq0/RNP9/4rVapUjOc88cQT+v777/Xjjz+qefPmunnzZqLUkhA2m01TpkxR2rRpNWzYMIfl94fbvn37YkwR4awiRYooe/bsWrRokX0aDOnuFUBbt2512LZBgwa6ceOGli9f7rB8/vz59vWPSvR0jp9//rnD8p07d+rQoUNO1dK8eXP9/fffCggIiPVcie3NVk9PT9WpU0fvv/++JGn37t325RKfsgUeBXL1LnI1bkOHDtWlS5c0cOBAh2x7GNFvWt6fvZ9++qnDY1fyNDbNmzfX/v37VaBAgVi/zg/TZH2YbNqzZ4+ku7NUSHePK2fOnPriiy8cjuvmzZtaunSpqlWrJh8fH/n6+qpKlSr65ptvHPYXFRWlzz//XLly5VLhwoVj7C9btmzq0qWLOnbsqMOHD+vWrVsPXfuDVKlSRZ6enlq8eLHD8u3btzMVIRAPcvcucvfhuZIlFStW1PLly3Xnzh37djdu3NDKlStd2meGDBnUrl07vfrqqwoJCbHPKOFKvjRp0kShoaGaO3euS/uWpEKFCumNN97Q77//bs+d5s2b6/Lly4qMjIz1e1ukSBFJsk9teX9eff3114qIiHBq/40bN5abm5v+/vvvWPcV15vGhQsX1rBhw1SqVCn99ttvMdanTZtWVapU0ZQpUyQp1m2iPaqfGQApD6897uK1h/OqVaumbt26qXXr1mrdurWltSD54krWx1jjxo2VK1cutWjRQkWLFlVUVJT27NmjCRMmyM/PL97pVXLkyBGjoRWbGjVqaPLkyerfv79q1qyp3r17K0+ePDpx4oSmTJmiHTt2aPLkyS5dwn+/EydOaPv27TGWZ8mSxam50oODg+33G3vnnXeUKVMmLVy4UKtWrdK4cePk7+//0LXdq0aNGnrppZfUtWtX7dq1S7Vr15avr6/Onj2rLVu2qFSpUnrllVdiPK9mzZrauHGjnnzyST3xxBNavXp1otX0sAoVKqSXXnpJU6dO1ZYtW1SzZk01b95co0aNUnBwsOrUqaPDhw9r5MiRypcvn9N/cN0rTZo0GjVqlHr06KHWrVvrxRdf1JUrVzR8+PAYUx6+8MILmjJlijp37qxjx46pVKlS2rJli9577z01bdpUDRs2TKxDf6AiRYropZde0scff6w0adKoSZMmOnbsmN5++23lzp1bAwYMeOAY/fv319KlS1W7dm0NGDBApUuXVlRUlE6cOKF169Zp0KBBqlKlit555x2dOnVKDRo0UK5cuXTlyhV9+OGHDvfkK1CggLy9vbVw4UIVK1ZMfn5+cX5CC0DCkKt3katx69ixow4cOKDRo0dr79696tKliwoVKqSoqCidPHlSCxYskPTfFSPxqV69ujJmzKiePXsqODhY7u7uWrhwof1Kz2iu5GlsRo4cqfXr16t69erq27evihQpotDQUB07dkyrV6/W9OnTY/2EdXyi/xh+//337Z/ALl26tH2KoytXrtjPwfDwcB06dEjvvfeePD099eqrr9qPa9y4cXr22WfVvHlzvfzyywoLC9MHH3ygK1euaOzYsfb9jRkzRo0aNVK9evX02muvycPDQ1OnTtX+/fu1aNEie8O6SpUqat68uUqXLq2MGTPq0KFDWrBggf1NdmdqfxiZMmXSwIEDNWbMGGXMmFGtW7fWqVOnNGLECGXPnt2p6SCB1IjcvYvcfbAVK1bEmq3t2rVzOktGjhypZs2aqXHjxurXr58iIyP1wQcfyM/PTyEhIfHuv0WLFipZsqQqVqyoLFmy6Pjx45o8ebKCgoLs09FH58uHH36ozp07y93dXUWKFIm17o4dO2rOnDnq2bOnDh8+rHr16ikqKko7duxQsWLF4ryCM9prr72m6dOna8SIEXr66afVoUMHLVy4UE2bNlW/fv1UuXJlubu769SpU/rhhx/UsmVLtW7dWiVKlFDHjh01YcIEpU2bVvXr19eBAwc0YcIE+fv7O5VXefPm1ciRIzV06FD9888/evLJJ5UxY0adP39ev/zyi31WiX379ql3795q3769ChUqJA8PD23atEn79u3Tm2++KUmaPn26Nm3apGbNmilPnjwKDQ21zwYV33sAj+pnBkDKw2uPu3jt4ZroWRmc8fvvv+vrr7+OsbxSpUqJMtUwkimDx9bixYtNp06dTKFChYyfn59xd3c3efLkMc8//7w5ePCgw7Z16tQxJUqUiHe8nTt3Gklmzpw5MdZt27bNtGvXzmTLls24ubmZrFmzmjZt2pitW7fGO2bnzp2Nr69vrOuOHj1qJMX579lnn431eUFBQaZZs2YOy37//XfTokUL4+/vbzw8PEyZMmViHMcPP/xgJJmvvvrKYfmcOXOMJLNz506H5cHBwUaSuXjxosPy2bNnmypVqhhfX1/j7e1tChQoYF544QWza9cu+zaxfb33799vAgMDTfny5WOM+SBxfV8eJK5jMMaY8+fPGz8/P1OvXj1jjDFhYWHmtddeMzlz5jReXl6mfPnyZvny5aZz584mKCjI/rzo79sHH3wQa53BwcEOyz777DNTqFAh4+HhYQoXLmxmz54dY0xjjLl8+bLp2bOnyZ49u3FzczNBQUFmyJAhJjQ0NMY+Xn31VYdlcdUU2/c8vnMyWmRkpHn//fdN4cKFjbu7u8mcObN57rnnzMmTJx22i+/n6saNG2bYsGGmSJEixsPDw/j7+5tSpUqZAQMGmHPnzhljjFm5cqVp0qSJyZkzp/Hw8DBZs2Y1TZs2NT/99JPDWIsWLTJFixY17u7usX6NASQOcvU/5Gr8fvzxR/PMM8+YXLlyGXd3d+Pj42OKFy9uXnnlFYe646o92tatW021atWMj4+PyZIli+nRo4f57bffYq3P2TyNLScuXrxo+vbta/Lly2fc3d1NpkyZTIUKFczQoUPNjRs3jDGu5XtYWJjp0aOHyZIli7HZbEaSOXr0qDHm7vl073mXNm1akydPHtOuXTuze/fuGGMvX77cVKlSxXh5eRlfX1/ToEED8/PPP8fY7qeffjL169e3nydVq1Y1K1ascNjmzTffNBUrVjQZM2Y0np6eJn/+/GbAgAHm0qVLTtfeuXNn+7ZxnePRX6t7v0dRUVHm3XffNbly5TIeHh6mdOnSZuXKlaZMmTKmdevWMY4HALl7L3I3dtHHENe/aM5mybJly0ypUqWMh4eHyZMnjxk7dqzp27evyZgxo8N29+fBhAkTTPXq1U3mzJntz+3evbs5duyYw/OGDBlicuTIYdKkSWMkmR9++MEYc/frWadOHYdtb9++bd555x17tgcEBJj69es7nJOxnSvRpkyZYiSZefPmGWOMCQ8PN+PHjzdlypQxXl5exs/PzxQtWtS8/PLL5s8//7Q/LzQ01AwcONBkzZrVeHl5mapVq5pt27YZf39/M2DAAPt2cZ1X937N69WrZ9KnT288PT1NUFCQadeundmwYYMx5u77DV26dDFFixY1vr6+xs/Pz5QuXdpMmjTJREREGGPu/ly2bt3aBAUFGU9PTxMQEGDq1KljvvvuO4d9xfbaJiE/M7HlOIDUgdce/+G1R+ziey/9Xr6+vg6vFR70vYmuJb5sx+PLZkwC5zoDAAAAADg4evSoihYtquDgYL311ltWlwMAuE94eLjKli2rnDlzat26dVaXY5mtW7eqRo0aWrhwoTp16mR1OQAAAI8VmqwAAAAAkAB79+7VokWLVL16daVPn16HDx/WuHHjdO3aNe3fv1/ZsmWzukQASPW6d++uRo0aKXv27Dp37pymT5+u//3vf1q3bt0jvUWNldavX69t27apQoUK8vb21t69ezV27Fj5+/tr37598vLysrpEAACAxwr3ZAUAAACABPD19dWuXbs0a9YsXblyRf7+/qpbt65Gjx5NgxUAkonr16/rtdde08WLF+Xu7q7y5ctr9erVqabBKknp06fXunXrNHnyZF2/fl2ZM2dWkyZNNGbMGBqsAAAAD4ErWQEAAAAAAAAAAADABWmsLgAAAAAAAAAAAAAAHic0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAVuVheQFLybfmh1CUCS+uuLV6wuAUhyOTN4WF0CEqD8yE1WlwAkqZFtSlhdApCkmpfMZnUJSCDvcr2tLgFIUv/u/MTqEoAk5ZUi37VNPdJ3mG91CUCS2vVhO6tLAJJU4Ww+Tm3HlawAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgAsuarCEhITp16pTDsgMHDqhr1656+umn9cUXX1hUGQAAKR85DACAtchiAACsQw4DABKDZU3WV199VRMnTrQ/vnDhgmrVqqWdO3cqLCxMXbp00YIFC6wqDwCAFI0cBgDAWmQxAADWIYcBAInBsibr9u3b9dRTT9kfz58/X5kyZdKePXv07bff6r333tOUKVOsKg8AgBSNHAYAwFpkMQAA1iGHAQCJwbIm67lz55QvXz77402bNql169Zyc3OTJD311FP6888/rSoPAIAUjRwGAMBaZDEAANYhhwEAicGyJmv69Ol15coV++NffvlFVatWtT+22WwKCwuzoDIAAFI+chgAAGuRxQAAWIccBgAkBsuarJUrV9ZHH32kqKgoff3117p+/brq169vX3/kyBHlzp3bqvIAAEjRyGEAAKxFFgMAYB1yGACQGNys2vGoUaPUsGFDff7554qIiNBbb72ljBkz2td/+eWXqlOnjlXlAQCQopHDAABYiywGAMA65DAAIDFY1mQtW7asDh06pK1btyowMFBVqlRxWN+hQwcVL17couoAAEjZyGEAAKxFFgMAYB1yGACQGGzGGGN1EYnNu+mHVpcAJKm/vnjF6hKAJJczg4fVJSAByo/cZHUJQJIa2aaE1SUASap5yWxWl4AE8i7X2+oSgCT1785PrC4BSFJell0ag8SQvsN8q0sAktSuD9tZXQKQpApn83FqO8vuySpJERER+uCDD1S+fHn5+fkpXbp0Kl++vMaPH6/w8HArSwMAIMUjhwEAsBZZDACAdchhAEBCWfaZqNu3b6tRo0batm2bGjZsqNq1a8sYoz/++EODBw/Wd999p3Xr1snLy8uqEgEASLHIYQAArEUWAwBgHXIYAJAYLGuyjhkzRidPntTu3btVunRph3V79+7VU089pbFjx2r48OHWFAgAQApGDgMAYC2yGAAA65DDAIDEYNl0wV9++aUmTpwYI8QkqUyZMho/fry++OILCyoDACDlI4cBALAWWQwAgHXIYQBAYrCsyXrixAlVrlw5zvVVq1bViRMnHmFFAACkHuQwAADWIosBALAOOQwASAyWNVnTp0+vCxcuxLn+3LlzSp8+/SOsCACA1IMcBgDAWmQxAADWIYcBAInBsiZrvXr19N5778W5fuzYsapbt+6jKwgAgFSEHAYAwFpkMQAA1iGHAQCJwc2qHQcHB6tKlSqqWrWqBg4cqKJFi0qSDh48qEmTJungwYPavn27VeUBAJCikcMAAFiLLAYAwDrkMAAgMVjWZC1evLjWr1+v7t27q0OHDrLZbJIkY4yKFi2q77//XiVKlLCqPAAAUjRyGAAAa5HFAABYhxwGACQGy5qs0t0biB84cEB79uzRkSNHJEmFCxdW2bJldfPmTf3444+qXbu2lSUCAJBikcMAAFiLLAYAwDrkMAAgoSxtskYrW7asypYt67Dsr7/+Ur169RQZGWlNUQAApBLkMAAA1iKLAQCwDjkMAHhYaawuAAAAAAAAAAAAAAAeJzRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAWW3ZP1u+++i3f90aNHH1ElAACkPuQwAADWIosBALAOOQwASAyWNVlbtWr1wG1sNlvSFwIAQCpEDgMAYC2yGAAA65DDAIDEYFmTNSoqyqpdAwCQ6pHDAABYiywGAMA65DAAIDFwT1YAAAAAAAAAAAAAcIFlV7IiecgR4Kt3u9bUExWD5O3hpj9PX9ErH27Q7r8uSJKGPltF7WsXVq4s6XQnPFK7/7qg4fO3aufh8/GO27tlWb3YrLRyZ0mny9dua9mWv/T23J8VFh4pSfLzdlfw89X0VPUCyuLvo71/X9Brn/6oX/+Mf1zAFd8uXawV3yzWuTNnJEl58xfQ8917qkr1WvZtjh/9RzOmTNK+33YpykQpb76Ceue98coWmD3WMY/+85fmfjpFRw4f1PmzZ9Sr/xtq1/F5h2327t6lxZ/P1Z9/HNTlSxc1ctxk1azTIOkOFMBj6+U6+fRynXwOyy7dCNMTE3+WJGXydVffBgVVrUAm+Xm5affxK3p/7RGdDLkd55ity+VQ8zKBKpDFV5J06Ox1fbLpbx04c93p/QJJYeM3n2v1whmq1aydWnXrK0kyxmjdkjnavn6Fbt28rqBCxdWmxwAF5skX5zhT3+mrvw/sibG8WPmq6jF0nCTp+8WztW7JXIf16TJk0vBZyxPrcACkEDmy+Ovdfi31RI0S8vZ0158nLuiVEQu1+9BJSdKMEc/p+aeqOjznl31HVafzhDjHbFm/jF7v3lgFcmeWu1ta/XXioj5csFGLVu20b+Pn46ngXs31VP0yypLRT3sPn9Jr477WrwdPJM2BIlVa8uUXWrJ4kc6cPi1JKlCwkF5+pZdq1qoTY9uRw9/R0q8W6/XBQ/TcC13iHffatWv65MNJ2rhhva5du6qcuXJp0Otvqlbtu+P+umun5s6epUMH9+vixYua9NEU1W/QMNGPD0DKkD2jt0Z2qqBGZXPKyyOt/jp7Tb0/3ao9R0NibDu5R1V1a1hYb87bqalrDsU5ZotKeTSoVUnlD0wv97Q2/X3uuj5ZdVBf/vSPfZu0aWx6q10Zta+ZT9kyeOvcv7f1xf/+1rhl+2RMkhwqUqHVy5dozfKvdf7c3fen8+TLrw6dX1LFqjUlSZPee0eb1q5weE6R4qU0fvr8eMe9cf26Fsz8RNt+3KQbN64pW2BOdX91gCpWu/u+91efz9LWHzfp9PFj8vD0VNGSZdSlZz/lypM38Q8ylaPJmopl8PPUpvFP63/7TqnVO9/qwpVbyp89g67cCLNv89fpKxowbbOOnrsqbw839WldTiveba2S3efp0rXY3+DtULeIRnWtoZ6TN2jbwTMqlDOjZg5sJEl6Y+aPkqRp/RqqeFCAuo3/Xmcv31TH+kW16r3WKt9zgc5cvpn0B49UIUvWbOrRq79y5s4jSVq36ju9/XpffbrgK+XLX1CnT51Uv5deUJOn2qjLi73k6+enE0ePysPDI84xw0JDlT1nLtVp8ISmTh4X6zaht2+rQKHCerJ5Kw1/c0CSHBuAlOOvCzf0yoI99seR9/w1N/GZ0oqINBqweJ9uhkXquaq5Nf25cmo7bbtCw2Of3qpC3gxau/+89p68qjsRUepcPY+mPldW7abt0MXrd5zaL5DYTvx1SNvXf6fsQQUclv+w/Av9b8USdeg9RFly5NaGr+fr05EDNfjjhfLy9ol1rC6vv6uIiHD741vXr2nCoG4qXa2ew3aBufPp5eCJ9sdp0qRNxCMCkBJkSOetTXMH6n87/1Sr3lN1IeS68ufOrCvXHf/W/f7nA3o5+HP74zv//+HhuIRcvaVxn63V4WPndSc8Uk1rldSM4c/pYsgNbdh29w3hae90UvGCOdRt2DydvXhVHZtW1qrpfVS+7bs6c/Fq4h8sUqWs2QLVb8Bryp3n7t/EK75drn69X9XipctUsGAh+3abNm7Q/n17lSVr1geOGX7njnr26KpMAQEaP+lDZQsM1LmzZ+Xr62ff5vbtWypSpIhatm6jQf37JP6BAUgxMvh6aN3IJvrpwDm1HbtBF6+FKl+2dLp6606MbZtVzK2KBTPrTMitB477780wjV/+u46cvqbwyEg9WT6XpvasrotXQ7Vx391m14CnSqpbw8LqOe1nHTp1ReXyB2hqzxq6dvuOpq35I9GPFalT5izZ1PnlPsqe624Wb1y7QqPfGqDJs75UUL67fx+Xr1Jd/d8cYX+Om7t7vGOGh4fr7UE9lSFDJr056gNlzpJVFy+cl4/Pf39D79/zm5q1fkaFipZQVGSE5s+concGvaKp87+Rl7d3Ehxp6kWTNRUb1K6iTl28rpcnrbcvO3HhusM2izcfdng8eMZP6tq4pErmy6zNe0/GOm6VYtm17eBZ+3NPXLiuJf87ooqFs0mSvDzSqlWNgmo/coV+3n831EYv3KEWVQvoxWalNWL+tkQ7RqRu1WvVdXjc/ZW++u6bxTq0f5/y5S+o2dM+UuXqtfRyn4H2bXLkzB3vmEWLl1TR4iUlSTOnTo51myrVazlcLQsA8YmMMrp8M+YfkHkyeat0Ln+1m7ZD/1y8+wGkMasPa8OgWnqyZDYt33021vGGLTvo8HjUyj/UoHhWVc6XSav2nXvgfoHEFnb7lhZOHqX2Pd/QhqX/fRrXGKMfV36lhm2fV+mqd6986djnLQV3a6XdP61XtSdaxjqeT7r0Do/3/LxR7p6eKlO9rsPyNGnTKn3GgMQ9GAApyqCujXTq3L96efh/DdQTZ2NeNXPnToTOX74eY3lcfvr1T4fHUxZt1rMtqqh6ufzasO2QvDzd1apBWbUfMEM///a3JGn0p6vVol5pvdi+lkZMXfmQRwQ4qluvvsPjPv0GaMmXi7Rv7x57k/X8+fMaM3qkps2YpT6vvPzAMZctW6qr165q3sIv5f7/bwLnyJHTYZuaterEerUsANyv/1MldfryTfWavtW+7MTFmBfgZM/orfFdK6v1mA36avCDZ4vbctBxtsRpa/5Qx9oFVK1oVnuTtXLhLFr160l9v/u0fb/tqudTufz8DYHEU7mGYx6+8GJvrVn+lQ4f2Gdvsrq7eyhjQGanx9ywerluXLumD6bOlZvb3SzOGpjDYZsR46c4PO4/ZLiee6qB/jp8UCXLVniYQ0EcuCdrKtasaj799ucFLRzSVMe/eFHbPu6oro1LxLm9u1sadW9SUlduhOn3oxfj3G7rgTMqVzCrvamaNzC9GlfMq7U7j0mS3NKmkVvaNAq94/jp39A7EapePMf9wwGJIjIyUpvWrVHo7dsqXrKMoqKitH3rj8qdJ0hv9H1ZbZ6so17dOmnL/zZaXSqAVCZPJh99P6CGVvSppjFtSihnBi9Jkofb3ZdpdyL+u2I1ykjhkVEqmzuD0+N7uaeVWxqbrt0Od1ge136BxPbNZ5NUvEI1FS5T0WF5yPmzun4lRIXLVLIvc3P3UIESZXTs8H6nx9+xcZXK1WggTy/HT+NeOntKI3q01uhXntaCicN1+f+nZwKAaM3qlNJvB09o4bhuOr5xjLYtGqyuravH2K5WxUI6vnGM9i1/R1Pe7qgsGf1iGS1udSsXVuG8WbXl17sNVbe0aeTmllahdxyzOTQsXNXLFYhtCCDBIiMjtWb1Kt2+fUtlypSTJEVFRWnom6+rS9fuDle2xud/P2xS6TJlNebdkapXu7ratGyuz2ZMV2Rk/Fd4A0BsmlbIpd3/XNa8/rX196ft9dOY5upc3/H3kc0mzXi1pj5aeUB/nHq42R7qlAxUoezp9fOh/5qv2/64oDols6tg9nSSpJJ5Mqpakaxa9/9NVyCxRUZG6seNaxUaeltFS5a2L9+/Z5eee6q+Xu7UUh+PG6kr/8b80N+9dmz5n4qWKK3pk8bq+ZYN9GrndlqyYFa8WXzzxg1JUrr0/olzMLCz/ErW/Pnza+fOnQoIcPyEyJUrV1S+fHn9888/cTzzrrCwMIWFhTksM5ERsqW1/NCSvXyB/nqxWSl9tGy3xi3eqYpFsmlCz7oKC4/UF5v+mxKhSeV8mj/4Sfl4uutcyE01H7pMl6+FxjnuVz8eUWZ/b238oL1sNsndLa0+XblP47/aJUm6cTtc2w+e0ZCOlXX4ZIjOX7mlp+sUVqUigfrrzJWkPmykMv/8dUS9ezynO3fuyNvbRyPen6y8+Qso5PIl3b51S4vmz1bXnr31Uu8B+mXbFgUPHqCJU2epTPlKDx4cSAESmsNS7FkcFXFHadzinnobd/1++qreXn5QJ0JuKZOvh3rUyqs53Sqo/bQdOnbpls5cua3e9fNr9KrDun0nUs9Vy6Ms6TyVJZ3zX9u+DQro4vUw7fjnX6f2e/V2RFIcKlKp3Vs26tQ/R9T//Rkx1l27clnS3Xul3iudfyaFXDwXY/vYnPjzoM6dOKpneg12WJ6nUHF17POWsuTIretX/tWGpfP18dBeen3yPPmm449KJC9JlcUmKlI2psmOV76cmfVi+1r66PNNGjdrnSqWDNKEN9opLDxCX6z8RZK07ueD+mb9bp04G6K8OQP0Tq/mWjOjr6p3Gqc74XFnZno/L/39/Wh5urspMipK/cYs1qYdd//OvnErTNv3/qMhLzbR4aPndf7yNT39ZEVVKhmkv07E/YFm4GH8eeSwnu/UQXfuhMnHx0eTPpqiAgULSpLmzJqptG5u6vTcC06Pd+rUSZ3ZsV1Nm7fQlGkzdPz4cY15d6QiIiLUs1fvpDoMIMkkWQ5HhsuWNv4pPyHlzZpO3RsW0SerD2rC8v2qUCBA47pU0p3wSC36//unDniqpCKjjMtT+Kb3dtcf09rJ0y2tIqOMBs7eoR9+/29GqEnf7Vd6H3ftmtBKkVFGadPYNHLxbn299VhiHiKgY3//qdd7df7/96e9NfTdCcqT9+4H6ypWqaGa9Ropa7bsOn/2tD6fNVVD+7+kyTO/kHsct7Q7d/a09u3eqboNmyh43Mc6c+qEpk8aq8jICHXsEnNWCmOMZn0yQcVLl1NQ/oJJeqypkeWdyGPHjsXaYQ8LC9Pp0w/+1MiYMWM0YsQIh2VpCzaWe6EmiVZjSpXGZtNvf55X8Ly70zHs/eeiiucJ0EvNSjs0Wf+396Sq9P5CmdN7q+uTJfX5kCaqPWCxLl6N/Z6stUrl1BvPVNL/sXff4VFUfRvH74U0QkJCQklCCb1KkyYdBEQ6goWigKCogFQRASFUgQgC0qWjAvKIUkQsFH2UjlKkCPJQQm8hlNBCct4/eFlZkkCWJExIvp/ryqU7c+bMb7JL7p09O2e6T1mnrftPK3+gr8a8VUOnL0Zq1MI7J6odxvyk6T3r6NAXb+h2dIx2HDyrr37Zr9IFsib/gSNNyRWcVzM+/1pXr17Rf9f+rNFDP9S4qXPk5X3nW2qVq9fUS63unFAWKFREe/7aqeXf/IdBVqQZic1hKe4sDqjZVoG12iVJjanZhoP3fjsxUruOX9LydyupUalAfbnpmPr8Z7cGNS6iX9+vrtsxMdpy6KJ+/+d8gvtvVzm36j2VXZ3m/alb0f9eEfuw/QJJ4eL5M1o6+1O9NWisXN3c421nszk+NjKy3b8wHpvXrFRA7rzKXbCYw/KiTz9j///AYCm4cHGN7NJK29b9oBpNXkn4QQCPQXJlcfrs5eUaWCFJakyt0qWz6c+9YQqZtEKStHP/cRXLH6hOL1WzD7J+/dOf9vZ7/3dKf+4N0/7vh6p+teJatnZnvH1fibypii1HyiuDu2pVLKzRvZvr8PEL9qmEO3w4X9MHt9Ghn0bo9u1o7fj7mL5atU2liz749iWAs/LkyavFS5bqypXLWv3zTxrYv69mzf1CN2/e0Jefz9eir79JcO5KUkyMkZ+fvwYNHqb06dOrWPGndO7sWc2bM4tBVjyRkiuH3Yo3k/tTLyRJjalZunTS9kMXNHTRdknSriPhKprTVx3rFtbC3w6pdF4/vVO/qKr1c34q/Ss3olS173fK6OGiGk8F6qPXyunI2Sv2qYRbVMqjV6rlU8eJv2nf8QiVzOOnUW3L6/TFa1rw34cPrgMJlSN3Hk2YtUiRV69ow69rNO6jQRo5caZy58mvarXr2dsF5yugAoWLqePLDbR142+qXCPuqbFNTIx8fP3Upc9ApU+fXgUKF1P4+XP6ZuH8OAdZp40bpSOH/tHoSXOS7RjTMssGWZcvX27//x9//FE+Pv9+ozw6Olpr1qxRnjx5HtpPv3791KtXL4dl2V6akWR1pmanL0Zq3zHHS8//PhauZlUcv81w7eZtHTp1SYdOXdKW/af114x2alevuMYs3hZnvyGvVdLCtX9r7o97JEl7jlyQp4eLJr9bW6MXbZEx0uHTl/Rc3yXydHdRJk83nb54TZ9/UF9HTl9OnoNFmuXq6qocue7cWLxw0eLav2+3vvnqC737Xn+lT+9in/v+ruA8efXXzu1WlAo8VkmVw1LcWVx9zIZ4WuNBbkTF6ODZSOX2uzPt6b5TV9Tqs63yck8vl/TpFHEtSvM6ltW+kw+/L9xrlXKpQ9Vgvf35Dv1zNvY9bR60XyApHP/fAV29dFHj+rxpXxYTE61De3dq/apv1XfinXsgXr4YrkyZ/73/zNVLF+Xtm/mh/d+6eUM71q9VvVc6PLStu0cGBeTOp3Onjj/CkQDJI7mzOFu1vvG0xl2nz1/WvkOOV87/ffi0mtUu/cBtwk6Fq0DuB39B2BijQ8fufDFq14ETKpw3QH06PGcfZD18/Lyee2OCPD3clMnLQ6fPX9bno17XkRMXEndQwH1c3dyUOzhYklT8qRLas/svffnFfOXLl0/h4Rf0fJ1a9rbR0dEa+/Foffn5fK36eW2c/WXNmlUuLi5Kn/7fK+Xz5c+n8+fPKerWrXivugFSmuTO4Rwd/5MkdaZ2py9ejzUF8P6Tl9Sk4p2/W5WLZFfWTB7aO6mFfb1L+nQa8VpZvdOgqEq8+028fRsjHTpz59z5r6MXVTiHj3o3LWEfZB32almNW7ZbSzYekSTtPRahXFkyqlfTEgyyIkm5uroqKOedz6cLFimuf/7eo+X/WaiufT6M1dYvS1ZlzR6ok8fD4u0vs3+WWFmcMzivLoafV1RUlP2e6ZI0ffwobVn/q0ZOnKUs2bIn4VHhLssGWZs1a2b//3btHK90cXV1VZ48eTR27NiH9uPu7i53d8dvxjNVcMJs3HtKhXI4foBVMEdmhZ198ECnzSa5u8Y/7VQGdxfFGOOwLCbmzhUJNptN5p51127e1rWbt+Xr5a46TwdrwOzfH+FIgIQzRoqKuiVXV1cVLlZcx44ecVh/LOyosgcEWlMc8BglVQ5LcWcxUwU/Gtf0NuXN4qntYREOy6/ejJYUrVx+GVQsMJOmrjv8wH7aVsqtjtXyqOuXO7Tv1MMHZOPbL5AYBUuW1Xvj5jos+2rSKGXLkVu1Xmgt/+xB8vb104Fd25QzXyFJ0u2oKP1vz041ei32t2/vt2P9Ot2OilLZGs89tO3tqFs6e/yo8hUt+dC2wOOS3FnMVMEPt3HHIRUKzuawrGDubAo7Ff99sPx8Mipn9sw6dd65LwjbbJK7W+zPKq7duKVrN27J1zuD6lQuqgHjlznVL+AsY4yibt1SoyZNVbGS4z2I3+nUUY0aN1WzF5rHu33pMk9r1crvFBMTo3Tp0kmSjh45oqxZszLAiidKsucwUwUnyOYD51QwKJPDsgKBmXTs/J37Ry767ZDDFL+S9G3/Olr02yF98ctBp/Zls0lurunsjz3dYn+GHR1jlC5dwq/uBx7F3c+n43L5UoTOnzsjP/8sca6XpGIlSuvX1ascsvjksTD5+WexD7AaYzR9/Ght/G2tRk6YoYCgHEl/IJBk4SBrTMydKevy5s2rbdu2xZr3Hslv4rfbtW7sS+rzcnkt+e2AyhcOUIf6T6nrp2skSZ7uLurbsoJWbjqk0xcj5eftoU6NSipHFi9989s/9n5m9n5OJy9c1aC5d65a+n7LYXV7oYx2/u+ctuw/rfxBvhr0WiWt3HxIMTF3gqvO07lls9l04PhF5Q/y1UcdquqfExc1/+e9j/8XgVRr5pQJqlCpqrJlD9C1a5Fa9/MP2vnnVo0aP1WS9Mqrr2vYgPdUskxZlSlbQVs2/a6Nv/+qcVNm2/sYObi/smTNpje79JAkRUVF6ejh/0m680Hw+XNndfDA38qQwdN+xez1a9d04p5vG506eUIHD/wt70w+DOAixSCHU4YedQvovwfO6/SlG/Z7o2Z0d9F3O+9cVVOnaFZdvBal05duqEA2L/V5vqB+2X9Omw79++Hv0KZFdfbKTU1ae+ebtu0q59Y7NfOp/zd7dDLihvwz3vmw69qtaF2Pik7QfoGk4JHBU4G58zksc/PwkKd3Jvvy6o1e0polXyhrYE5lCcypNUu+kJu7u8pUq2vfZsGnI+Tjl0UNX3UceN2ydqWeqlA1znusLp83WcXLVZFvlmy6eilCq7+erxvXI1Wu5vPJcKTAoyGLrTfxi7VaN7e3+nR4Tkt+/lPli+dRhxZV1HXYQklSxgxu+vDthlq6ZodOnbuk4CB/DX23sS5EXNXye6YKnjnsNZ08e0mDJt65Kuq9Ds/pzz1hOnT8nNxcXfR81eJq07Ciuo1cZN+mTqWistmkA0fOKn+urPqoZzP9c+Ss5i/f+CxIjcIAAOCZSURBVHh/CUjVPh3/iapWq67sAQG6FhmpH1Z9r21bt2jK9Jny9c0s3/tmjnB1cVWWLFmUJ++/+T2g3/vKli27uvfsLUl6+ZVWWvjl5xo9coRatXlVYUePauaM6Wrd5jX7NtciIxUW9u858Ynjx/X3vn3y8fFRYFBQMh81kDDkcMoweeVe/Ty0vno3e0rfbjyqsgWyqP2zBdV9xiZJUvjVmwq/6ni/26joGJ2NuK6Dp/79wtP0zlV0Mvyahvz/tMO9mj6l7Ycu6PCZK3J1SafnSudQq2r51XPWJvs2q/48pvealdDx85H26YK7Niymz50cvAUeZP5nE1W2YhVlyRag69ci9d+1P2r3jm0a/PFkXb92TQvmTFOVGrWV2T+rzp4+qfmfTVQmH189U/1Zex+fjPhQ/lmyqd1b3SRJ9Zu+pO+WLNKMT0PVqEUrnTwepv98MUuNWrSybzN13Ej9d/UqDfhonDJ4ZtTFC3dmWPH08pK7u8fj/SWkcpZe8hkVFaU8efLowoULBJkF/vjnjF4ZvlJD21dW/9YVdOT0ZfWZ/qsW/bJf0p1v7hTOmVmvDmgofx8PhV++oW0HzqhOn6+1L+zfD3dzZfW2D55K0qiFd6YEDmlbSUH+Xjp/6bpWbjmkwfP+nTrSJ6O7hravrBxZvBR+5aaWrT+okHkbdPue+8UBiXUx/IJGDumv8PPnlNHLW/kKFNSo8VNVruKdb+tWq1lbPfsO0oJ5MzXpk1HKlTuPhoz8RCVKP23v4+yZUw7fYLtw7qw6vfaS/fHiL+dq8ZdzVerpcho39c689vv37VGvzv9OXTh1/MeSpHoNm6jvoBHJesyAM8hh62X3dtfI5sXl6+mqi5FR+uvEJbWbtU2nLt2QJGXxdlev5wrK38tN56/c0ne7TmnGf4849BHg46F7YlgvlcshN5d0GvNyCYd20389rOm/Hk7QfoHHpVaz1oq6dVNLPvtE1yOvKnfBouo0aKw8Mnja20ScPxPrXnHnTh7T4X271GlQ3FcXXLpwTl+MG6LIK5eUMZOvggsWU7eR0+SXLSBZjwdwFllsrT/2humV3jM09N0m6t+pvo6cuKA+Hy/RolV3bo0THWNUvECQWjeqIF/vDDp9/rJ+3XpAr/WdravX/v3AN1eAn8M5cUYPN03o/7JyZPPV9ZtROnDkjDp8OM/h/q4+Xh4a+m4T5cjuq/BL17RszQ6FTF6h27c5J0bSuXDhvAZ88L7OnTsrL29vFSpUWFOmz1SlylUS3MfpU6eUzvbvlV8BgYGaNmO2Ph49Ui+90ETZsmdXm1fb6vWO/94eYM+e3Xrj9bb2x2NCR0qSmjR9QcM+GpUERwYkDXLYen8euqA2n6xTSMun1bd5KR09d0UfzN+mxesfPHvT/XJmyehwVWpGdxd90qGigvw9deNWtA6cvKQ3J/+ub/5/amBJ6jNniz58ubTGdqiorD4eOn3xuuasPqBRS3Yl1eEBigi/oE9GfKjwC+eVMaOX8uQvqMEfT1aZ8s/o5s0bOnrooNb9+J0ir15RZv8sKlGmvN4fPFqenhntfZw7c1q2e7I4a/YADR07RTMnjdW7r78s/yzZ1PjF1mrRur29zaqld6Ys79/t33yWpO79hqhO/SbJe9BpjM2Y+66Jf8yyZs2qDRs2qGDBgknWZ4YGE5KsLyAlOrjgHatLAJJdDl+mmnockiOHJenpoXHfwwlILYY2L251CUCyavQU9+t5XJIrizOU6Zqk/QEpzcWtk6wuAUhWHtwN7bFIrhzO1HJ+kvYHpDTbJrxodQlAsiqU3fPhjSSle3iT5NW2bVvNmjXL6jIAAEiTyGEAAKxFFgMAYB1yGACQGJZ/J+rWrVuaOXOmfv75Z5UrV04ZM2Z0WP/JJ59YVBkAAKkfOQwAgLXIYgAArEMOAwASw/JB1t27d+vpp+/c//DAgQMO6+6/9xIAAEha5DAAANYiiwEAsA45DABIDMsHWdetW2d1CQAApFnkMAAA1iKLAQCwDjkMAEgMy+/Jeq/jx4/rxIkTVpcBAECaRA4DAGAtshgAAOuQwwAAZ1k+yBoTE6OhQ4fKx8dHwcHByp07t3x9fTVs2DDFxMRYXR4AAKkaOQwAgLXIYgAArEMOAwASw/LpggcMGKBZs2Zp1KhRqlKliowxWr9+vQYPHqwbN25oxIgRVpcIAECqRQ4DAGAtshgAAOuQwwCAxLB8kHXevHmaOXOmmjRpYl9WqlQp5ciRQ507dybIAABIRuQwAADWIosBALAOOQwASAzLpwsODw9XkSJFYi0vUqSIwsPDLagIAIC0gxwGAMBaZDEAANYhhwEAiWH5IGupUqU0adKkWMsnTZqkUqVKWVARAABpBzkMAIC1yGIAAKxDDgMAEsPy6YJDQ0PVsGFDrV69WpUqVZLNZtOGDRt07Ngxff/991aXBwBAqkYOAwBgLbIYAADrkMMAgMSw/ErWGjVq6MCBA3rhhRcUERGh8PBwNW/eXPv371e1atWsLg8AgFSNHAYAwFpkMQAA1iGHAQCJYfmVrJIUFBTETcQBALAIOQwAgLXIYgAArEMOAwAeVYoYZI2IiNCWLVt09uxZxcTEOKxr27atRVUBAJA2kMMAAFiLLAYAwDrkMADgUVk+yLpixQq1adNGkZGR8vb2ls1ms6+z2WwEGQAAyYgcBgDAWmQxAADWIYcBAIlh+T1Ze/furQ4dOujKlSuKiIjQxYsX7T/h4eFWlwcAQKpGDgMAYC2yGAAA65DDAIDEsHyQ9cSJE+rWrZs8PT2tLgUAgDSHHAYAwFpkMQAA1iGHAQCJYfkga7169bRt2zarywAAIE0ihwEAsBZZDACAdchhAEBiWHJP1uXLl9v/v2HDhurTp4/27t2rEiVKyNXV1aFtkyZNHnd5AACkauQwAADWIosBALAOOQwASCo2Y4x53DtNly5hF9DabDZFR0c73X+GBhOc3gZ4khxc8I7VJQDJLoevm9UlpFrJncOS9PTQtY+0HfCkGNq8uNUlAMmq0VPZrS4hVXscWZyhTNdH2g54UlzcOsnqEoBk5WHJpTFpw+PI4Uwt5z/SdsCTYtuEF60uAUhWhbInbBp5S+I6JibGit0CAACRwwAAWI0sBgDAOuQwACCpWH5PVgAAAAAAAAAAAAB4klg2yLp582atWrXKYdn8+fOVN29eZcuWTZ06ddLNmzctqg4AgNSNHAYAwFpkMQAA1iGHAQBJwbJB1sGDB2vXrl32x3/99Zc6duyoOnXq6IMPPtCKFSs0cuRIq8oDACBVI4cBALAWWQwAgHXIYQBAUrBskHXHjh2qXbu2/fGiRYtUsWJFzZgxQ7169dKnn36qxYsXW1UeAACpGjkMAIC1yGIAAKxDDgMAkoJlg6wXL15U9uzZ7Y9//fVXPf/88/bH5cuX17Fjx6woDQCAVI8cBgDAWmQxAADWIYcBAEnBskHW7Nmz6/Dhw5KkW7du6c8//1SlSpXs669cuSJXV1erygMAIFUjhwEAsBZZDACAdchhAEBSsGyQ9fnnn9cHH3yg3377Tf369ZOnp6eqVatmX79r1y7lz5/fqvIAAEjVyGEAAKxFFgMAYB1yGACQFFys2vHw4cPVvHlz1ahRQ15eXpo3b57c3Nzs62fPnq3nnnvOqvIAAEjVyGEAAKxFFgMAYB1yGACQFCwbZM2aNat+++03Xbp0SV5eXkqfPr3D+v/85z/y8vKyqDoAAFI3chgAAGuRxQAAWIccBgAkBcsGWe/y8fGJc7mfn99jrgQAgLSHHAYAwFpkMQAA1iGHAQCJkaBB1uXLlye4wyZNmjxyMQAAIG5kMQAA1iGHAQCwFlkMAEiJEjTI2qxZswR1ZrPZFB0dnZh6AABAHMhiAACsQw4DAGAtshgAkBIlaJA1JiYmuesAAAAPQBYDAGAdchgAAGuRxQCAlChdYja+ceNGUtUBAAAeAVkMAIB1yGEAAKxFFgMArOT0IGt0dLSGDRumHDlyyMvLS4cOHZIkDRw4ULNmzUryAgEAgCOyGAAA65DDAABYiywGAKQUTg+yjhgxQnPnzlVoaKjc3Nzsy0uUKKGZM2cmaXEAACA2shgAAOuQwwAAWIssBgCkFE4Pss6fP1+fffaZ2rRpo/Tp09uXlyxZUn///XeSFgcAAGIjiwEAsA45DACAtchiAEBK4fQg64kTJ1SgQIFYy2NiYhQVFZUkRQEAgPiRxQAAWIccBgDAWmQxACClcHqQtXjx4vrtt99iLf/Pf/6jMmXKJElRAAAgfmQxAADWIYcBALAWWQwASClcnN0gJCREr732mk6cOKGYmBh988032r9/v+bPn6/vvvsuOWoEAAD3IIsBALAOOQwAgLXIYgBASuH0layNGzfWV199pe+//142m02DBg3Svn37tGLFCtWtWzc5agQAAPcgiwEAsA45DACAtchiAEBK4fSVrJJUr1491atXL6lrAQAACUQWAwBgHXIYAABrkcUAgJTgkQZZJWnbtm3at2+fbDabihYtqrJlyyZlXQAA4CHIYgAArEMOAwBgLbIYAGA1pwdZjx8/rlatWmn9+vXy9fWVJEVERKhy5cpauHChcuXKldQ1AgCAe5DFAABYhxwGAMBaZDEAIKVw+p6sHTp0UFRUlPbt26fw8HCFh4dr3759MsaoY8eOyVEjAAC4B1kMAIB1yGEAAKxFFgMAUgqnr2T97bfftGHDBhUuXNi+rHDhwpo4caKqVKmSpMUBAIDYyGIAAKxDDgMAYC2yGACQUjh9JWvu3LkVFRUVa/nt27eVI0eOJCkKAADEjywGAMA65DAAANYiiwEAKYXTg6yhoaF69913tW3bNhljJN25yXj37t01ZsyYJC8QAAA4IosBALAOOQwAgLXIYgBASmEzd5PoATJnziybzWZ/HBkZqdu3b8vF5c5sw3f/P2PGjAoPD0++ahMoQ4MJVpcAJKuDC96xugQg2eXwdbO6hBTlScvip4eutboEIFkNbV7c6hKAZNXoqexWl5CiPGk5LEkZynS1ugQgWV3cOsnqEoBk5eH0Td5StyctizO1nG91CUCy2jbhRatLAJJVoeyeCWqXoLgeP358YmoBAACJRBYDAGAdchgAAGuRxQCAlChBg6zt2rVL7joAAMADkMUAAFiHHAYAwFpkMQAgJUrUxBPXr1+PdZPxTJkyJaogAACQcGQxAADWIYcBALAWWQwAsFI6ZzeIjIxU165dlS1bNnl5eSlz5swOPwAAIHmRxQAAWIccBgDAWmQxACClcHqQ9f3339fatWs1ZcoUubu7a+bMmRoyZIiCgoI0fz439AYAILmRxQAAWIccBgDAWmQxACClcHq64BUrVmj+/PmqWbOmOnTooGrVqqlAgQIKDg7Wl19+qTZt2iRHnQAA4P+RxQAAWIccBgDAWmQxACClcPpK1vDwcOXNm1fSnfntw8PDJUlVq1bVf//736StDgAAxEIWAwBgHXIYAABrkcUAgJTC6UHWfPny6ciRI5KkYsWKafHixZLufIPI19c3KWsDAABxIIsBALAOOQwAgLXIYgBASuH0IOvrr7+unTt3SpL69etnn/u+Z8+e6tOnT5IXCAAAHJHFAABYhxwGAMBaZDEAIKWwGWNMYjoICwvTtm3blD9/fpUqVSqp6kqUDA0mWF0CkKwOLnjH6hKAZJfD183qEp4YKTGLnx661uoSgGQ1tHlxq0sAklWjp7JbXcITIyXmsCRlKNPV6hKAZHVx6ySrSwCSlYeL1RU8OVJiFmdqOd/qEoBktW3Ci1aXACSrQtk9E9TO6StZ75c7d241b95cfn5+6tChQ2K7AwAATiKLAQCwDjkMAIC1yGIAgFUSPch6V3h4uObNm5dU3QEAACeRxQAAWIccBgDAWmQxAOBxS7JBVgAAAAAAAAAAAABICxhkBQAAAAAAAAAAAAAnMMgKAAAAAAAAAAAAAE5wSWjD5s2bP3B9REREYmtJMheXd7e6BCBZZS7f1eoSgGR3ffskq0tIcZ6kLN7Q/1mrSwCSFVmM1I4cju1JymFJOrVhgtUlAMkqc40BVpcAJKvr60dYXUKK8yRl8dkv2lpdApCsOCdGapfQc+IED7L6+Pg8dH3btoQHAADJhSwGAMA65DAAANYiiwEAKU2CB1nnzJmTnHUAAICHIIsBALAOOQwAgLXIYgBASsM9WQEAAAAAAAAAAADACQyyAgAAAAAAAAAAAIATGGQFAAAAAAAAAAAAACcwyAoAAAAAAAAAAAAATmCQFQAAAAAAAAAAAACc8EiDrJ9//rmqVKmioKAgHT16VJI0fvx4LVu2LEmLAwAAcSOLAQCwDjkMAIC1yGIAQErg9CDr1KlT1atXLzVo0EARERGKjo6WJPn6+mr8+PFJXR8AALgPWQwAgHXIYQAArEUWAwBSCqcHWSdOnKgZM2ZowIABSp8+vX15uXLl9NdffyVpcQAAIDayGAAA65DDAABYiywGAKQUTg+yHj58WGXKlIm13N3dXZGRkUlSFAAAiB9ZDACAdchhAACsRRYDAFIKpwdZ8+bNqx07dsRavmrVKhUrViwpagIAAA9AFgMAYB1yGAAAa5HFAICUwsXZDfr06aMuXbroxo0bMsZoy5YtWrhwoUaOHKmZM2cmR40AAOAeZDEAANYhhwEAsBZZDABIKZweZH399dd1+/Ztvf/++7p27Zpat26tHDlyaMKECWrZsmVy1AgAAO5BFgMAYB1yGAAAa5HFAICUwmaMMY+68fnz5xUTE6Ns2bIlZU2JduO21RUAyStz+a5WlwAku+vbJ1ldwhOBLAasQRYjtSOHEyal5rAkRVyPtroEIFkF1hlkdQlAsrq+foTVJTwRUmoWc06M1I5zYqR2CT0ndvpK1ntlyZIlMZsDAIBEIosBALAOOQwAgLXIYgCAlZweZM2bN69sNlu86w8dOpSoggAAwIORxQAAWIccBgDAWmQxACClcHqQtUePHg6Po6KitH37dv3www/q06dPUtUFAADiQRYDAGAdchgAAGuRxQCAlMLpQdbu3bvHuXzy5Mnatm1bogsCAAAPRhYDAGAdchgAAGuRxQCAlCJdUnVUv359LVmyJKm6AwAATiKLAQCwDjkMAIC1yGIAwOOWZIOsX3/9tfz8/JKqOwAA4CSyGAAA65DDAABYiywGADxuTk8XXKZMGYcbixtjdPr0aZ07d05TpkxJ0uIAAEBsZDEAANYhhwEAsBZZDABIKZweZG3WrJnD43Tp0ilr1qyqWbOmihQpklR1AQCAeJDFAABYhxwGAMBaZDEAIKVwapD19u3bypMnj+rVq6eAgIDkqgkAAMSDLAYAwDrkMAAA1iKLAQApiVP3ZHVxcdE777yjmzdvJlc9AADgAchiAACsQw4DAGAtshgAkJI4NcgqSRUrVtT27duToxYAAJAAZDEAANYhhwEAsBZZDABIKZy+J2vnzp3Vu3dvHT9+XGXLllXGjBkd1pcsWTLJigMAALGRxQAAWIccBgDAWmQxACClsBljTEIadujQQePHj5evr2/sTmw2GWNks9kUHR2d1DU67cZtqysAklfm8l2tLgFIdte3T7K6hBSHLAZSDrIYqR05HNuTlMOSFHE9ZdQBJJfAOoOsLgFIVtfXj7C6hBTnScpizomR2nFOjNQuoefECR5kTZ8+vU6dOqXr168/sF1wcHCCdpycCDGkdoQY0gI+3I2NLAZSDrIYqR05HNuTlMMSg6xI/RhkRWrHIGtsT1IWc06M1I5zYqR2CT0nTvB0wXfHYlNCSAEAkBaRxQAAWIccBgDAWmQxACClSedMY5vNllx1AACABCCLAQCwDjkMAIC1yGIAQEqS4CtZJalQoUIPDbLw8PBEFQQAAOJHFgMAYB1yGAAAa5HFAICUxKlB1iFDhsjHxye5agEAAA9BFgMAYB1yGAAAa5HFAICUxKlB1pYtWypbtmzJVQsAAHgIshgAAOuQwwAAWIssBgCkJAm+Jyvz3QMAYC2yGAAA65DDAABYiywGAKQ0CR5kNcYkZx0AAOAhyGIAAKxDDgMAYC2yGACQ0iR4uuCYmJjkrAMAADwEWQwAgHXIYQAArEUWAwBSmgRfyQoAAAAAAAAAAAAAYJAVAAAAAAAAAAAAAJyS4gZZb9++ratXr1pdBgAAaRI5DACAtchiAACsQw4DAJxh2SDr999/r88//9xh2YgRI+Tl5SVfX18999xzunjxokXVAQCQupHDAABYiywGAMA65DAAIClYNsg6ZswYXb582f54w4YNGjRokAYOHKjFixfr2LFjGjZsmFXlAQCQqpHDAABYiywGAMA65DAAIClYNsi6e/duVa5c2f7466+/Vt26dTVgwAA1b95cY8eO1YoVK6wqDwCAVI0cBgDAWmQxAADWIYcBAEnBskHWK1euyN/f3/74999/17PPPmt/XLx4cZ08edKK0gAASPXIYQAArEUWAwBgHXIYAJAULBtkDQoK0r59+yRJV69e1c6dO1WlShX7+gsXLsjT09Oq8gAASNXIYQAArEUWAwBgHXIYAJAULBtkffHFF9WjRw99/vnnevPNNxUQEKBnnnnGvn7btm0qXLiwVeUBAJCqkcMAAFiLLAYAwDrkMAAgKbhYteOQkBCdPHlS3bp1U0BAgL744gulT5/evn7hwoVq3LixVeUBAJCqkcMAAFiLLAYAwDrkMAAgKdiMMcbqIpLajdtWVwAkr8zlu1pdApDsrm+fZHUJSASyGKkdWYzUjhx+8kVcj7a6BCBZBdYZZHUJQLK6vn6E1SUgETgnRmrHOTFSu4SeE1t2Jeu9du3apQMHDshms6lgwYIqWbKk1SUBAJBmkMMAAFiLLAYAwDrkMADgUVk6yLplyxZ17NhRe/fu1d0Lam02m4oXL65Zs2apfPnyVpYHAECqRg4DAGAtshgAAOuQwwCAxEpn1Y737t2r2rVrK0OGDPriiy/0559/6o8//tDnn38ud3d31a5dW3v37rWqPAAAUjVyGAAAa5HFAABYhxwGACQFy+7J+tJLLyk6OlpLliyRzWZzWGeMUfPmzeXq6qrFixc73Tdz3iO1Y857pAXcCy55JWcOS2QxUj+yGKkdOZz8kjuLuScrUjvuyYrUjnuyJi/OiYHE4ZwYqV2KvyfrL7/8olWrVsUKMenOtAz9+/dXgwYNLKgMAIDUjxwGAMBaZDEAANYhhwEAScGy6YKvXLmi7Nmzx7s+ICBAV65ceYwVAQCQdpDDAABYiywGAMA65DAAIClYNsiaJ08ebdmyJd71mzdvVnBw8GOsCACAtIMcBgDAWmQxAADWIYcBAEnBskHWV155Rb169dLu3btjrfvrr7/03nvvqWXLlhZUBgBA6kcOAwBgLbIYAADrkMMAgKRgM8YYK3Z848YN1a5dW5s3b1bdunVVtGhRSdLevXu1evVqVahQQWvXrpWHh4fzfXNjcaRy3FgcaUFCby6OR5OcOSyRxUj9yGKkduRw8kvuLI64Hp2U5QIpTmCdQVaXACSr6+tHWF1CqsY5MZA4nBMjtUvoObFlg6ySdOvWLY0bN04LFy7UgQMHJEmFChVSy5Yt1bNnT7m7uz9Sv4QYUjtCDGkBH+4mv+TKYYksRupHFiO1I4cfj+TMYgZZkdoxyIrUjkHW5Mc5MfDoOCdGavdEDLI+yLFjxxQSEqLZs2c7vS0hhtSOEENawIe71kpMDktkMVI/shipHTlsvcRmMYOsSO0YZEVqxyCrtTgnBh6Mc2Kkdgk9J7bsnqwPEx4ernnz5lldBgAAaRI5DACAtchiAACsQw4DABIixQ6yAgAAAAAAAAAAAEBKxCArAAAAAAAAAAAAADiBQVYAAAAAAAAAAAAAcIKLVTtu3rz5A9dHREQ8nkIAAEiDyGEAAKxFFgMAYB1yGACQFCwbZPXx8Xno+rZt2z6matKmxYsWaPFXC3XyxAlJUv4CBfXWO51VtVoNRUVFadKn4/X7b//V8ePH5O3lpYqVKqt7z97Kli37A/v9Yv5cLf5qoU6fOiXfzJlVt249devZW+7u7pKk+nWf1cmTJ2Jt90rL1uo/MCTpDxRpWlBWHw3v3lTPVSmuDO6u+ifsrN4Z8qW27zsmSbq+fVKc2/Uf963GzV8T57qi+QI0qHMjlSmaS8FB/urz8deatOAXhzZvvlRVb75YTcFBfpKkfYdO66PPVumn9XuT7uCARCCHU4ZZM6Zrzc8/6fDhQ3L38FDp0mXUo9d7ypM3n73NwP4faPmybx22K1GylL5YuDhB+1j1/Up90KeXaj1bW+MnTnFYd+bMGY3/5GOt/+033bx5Q8HBeTR42AgVK/5U4g8OkPT3yiEKDvKPtXzaV/9Vz1GOr+GJA1rqjRerxpmr93q1cUXNGPparOW+FXvo5q3bsZa/1+E5DXu3iSZ9uU59xixx/iCAZEIWW2/J4kX65j+L7Oen+fIXUMdO76hy1eqSpKED+2vliqUO2xQvUVKzP1/0wH4XfjFf3/xnkc6cPiUf38x6ts5z6tytp/2ceMbUSZo53TGT/fz9tWrNb0l0ZMC/grJk0vDO9fTcM4WUwd1F/xy7oHdGfqPt+0/GajuxT1O90ayC+kxYqUmLN8TbZ9G82TTojdoqUziHggMzx9l+QIdn9WHH2g7LTl+4orxNRiXNgQGJRA6nDAk5J75w/rzGfzJGGzf8ritXrujpsuX0wYCBCg7Ok6B9xHdOzGfUeBwSck484K0G6tiiiny9M2jr7qPqMfIr7Tt0Ot4+E3JOzGfTj49lg6xz5syxatf4f9myB6h7z/eUK3duSdKKZUvVvWsXfbXkW2XPHqC/9+1Vp7ffUeHCRXT58mWFjvpI3bu+o4WLv4m3z5XfLdeEcWM1ZNhHKlWmjI4eOaJBAz6QJPX5oL8k6cuvvlZMdLR9m4MH/9Fbb7yuuvWeT8ajRVrk651Ba+f20q9b/1GzrlN0NvyK8uXKoogr1+1t8tTp57DNc1WKa1pIa327Zke8/Xp6uOnw8fP65uftGt077m8+njgToYETl+l/Yecl3Qm//4zrpGdajnpgSAKPCzmcMmzbukWvtGqj4iVKKPp2tCZ+Ok5vv9lR3yxfKU9PT3u7KlWraejwkfbHrq6uCer/5MkT+mTMaD1dtlysdZcvXVL7V1upXIWKmjxthvz8/XT82DF5e2dK/IEB/6/qqx8rfTqb/XGxAkH6ftq7+ubn7Q7tGtcsqfIl8ujk2YgE9XvpynWVemGow7K4BljLFsutjs0ra9eB484XDyQzsth62bJnV+duPZUrd7AkaeXyperTo6s+X7RE+QoUlCRVqlJVA4eMsG/j8pAM/mHlCk359BN9OHi4SpQqo7CjRzQs5M65cM8+H9jb5ctfQJOmz7I/TpcufZIdF3CXr7eH1k7rpF//PKRmvefp7MWrypfDTxFXb8Rq27haUZUvnksnz11+aL+e7q46fPKivlm7W6O7NYy33Z5DZ9Sw+2z74+iYmEc7ECAZkMMpw8POiY0x6tGti1xcXDR+4hR5eXlp/ry5eqvj67HOm+PyoHNiPqPG4/Cwc+Le7euo26u11CnkC/1z9Kw+ePN5rZz2rko2G6qr127G2+/Dzon5bPrxsWyQFdarWetZh8fvdu+pxYsWatfOHWre4iVNn+n4ZuOD/h+qTcuXdOrkSQUGBcXZ584dO1S6zNNq0KixJClHjpx6vkEj7f5rl72Nn5+fwzazZ36mXLlyq1z5CklxWIBd79fr6vjpi3pr8Bf2ZWGnwh3anLlwxeFx45ol9OvWf3TkxIV4+/1jb5j+2BsmSRrWrUmcbb7/726Hx4Mnr9CbL1VVhZJ5CTIAdlM/m+XweOjwkapVrZL27d2jsuXK25e7ubkpS9asTvUdHR2tfu+/p3e6vKvtf/yhK1ccPzCbPWuGsgcEaNiIfwdvc+TI+QhHAcTv/MWrDo/fe/0p/S/snH774x/7sqCsPhr3wUtq3Hmyvp34ToL6NTKxMvx+GTO4ac5H7dV52EJ98AYflACIrVqNWg6P33m3h775zyLt/muXfZDV1dVN/lkSnsF/7dqpkqXLqF6DRpKkoBw59NzzDbRn918O7dKnT+9Uv8Cj6N2muo6fvaS3Pvr3y/JhpyNitQvKkknjejVW415z9e3HD79y74+/T+iPv+9c/TXsnXrxtrsdHaMz4VfjXQ8ADzsnPnr0iHbt3KEly75Tgf/P5gEDQ1SrWmX98P1KNX/xpXj7ftg5MZ9R43F42Dlxl9a1FDrrRy1bu1OS9MbAz3V0zUd6pX45zVqyPt5+H3ZOzGfTj086qwtAyhAdHa1V36/U9evXVKpUmTjbXL16VTabTd6Z4r/CpczTZbVv7x79tevOoOrxY8f0+2+/qlr1mnG2j7p1Syu/W65mzVvIZrPF2QZ4VA1rlNCfe8P0ZWgHHV0zUhsX9tXrL1SOt302P289X/UpzVu6MUnrSJfOppfqlVXGDG7avOtwkvYNIHW5euXOG+RM901dtW3rFtWsVkmNG9TTkEEf6sKF+L8Ictf0qZOV2c9PzVvEfdL567q1Kl78Kb3Xs5tqVqukl1s005L/JGwKYuBRuLqkV8sG5TVv2b85a7PZNGt4W42bt8apEz2vDO7a//1QHfxhmJZMeFulCsf+gsD4fq/oh992a93m/UlSP4DULTo6Wj/98L2uX7+up0qWsi//c9tWPV+rql5sUl8fDRmk8PAHZ3CpMk/r7717tef/v2h84vgxbfj9N1WpVsOh3bGwMDWsW0PNGtTVgL69deL4saQ/KKR5DasW1Z9/n9CXw1rq6Hf9tHFOF73e2PFqLpvNplmDXtS4Bb9p3+GzSbr/Ajn9dWhZX+37T2/NH/KK8gRlTtL+AaQ+958TR926JUlyd3O3t0mfPr1cXV21/c8/HtjXw86J78Vn1Hgc7j8nzpPDX4FZfbR649/2Nreibuu3Pw7qmVL54utGUsLOie/is+nkxZWsadw/B/brtdYtdevWTXl6emrcp5OVv0CBWO1u3rypCePGqH7DRvLy8oq3v/oNGurixXC1f621JKPbt2/r5VdaqeObneJsv3btal25ckVNmr2QVIcE2OXNkUVvvlRNn36xVqGzflK5p4I19v0XdTPqthZ8tyVW+1cbV9SVaze0dO2OJNl/8QJB+mVeb3m4uejq9Zt6pfcM/c03hQDEwxijMaEjVebpsipYsJB9eZVq1VW33vMKDArSiePHNWXiBL3ZoZ0W/ecbubm5xdnX9j//0LfffK3FS5bGu7/jx49p8VcL9Vq719Wx09va/dcujR45XG5ubmrctFkSHx0gNalVUr7eGfTFis32Zb1fr6vb0TGavPCXBPdz4MgZvRnyhfYcPKlMGT3UpXVNrZ3TSxVajtT/ws5Jkl6qV1ali+RS1VdDk/owAKQyB/85oDfattKtW7eUIYOnRn/yqfLlv3NOXKlqNT1bt54Cg4J08sRxTZ/8qbq8+brmLfw63gx+7vkGirgYrk6vvyojKfr2bbV4qaXadXjT3qZ4iZIKGT5SuYPzKPzCec2ZMV1vtGutRUtWyMfX9zEcNdKKvEGZ9WazCvr0q/UKnf+ryhXLqbE9G905J/5hhySp96vV7mTxf5L2y8Zb9x7XG8O/1j9h55XNz0sftKupddPeUtlXJyj88vWHdwAgzYnrnDhP3nwKCsqhT8eP1cCQocqQIYPmz5ur8+fP6dy5c/H2lZBz4nvxGTUeh/vPiQOy3LmY7Wy44xWpZy9cUe5Av1jb35WQc2KJz6Yflyd+kPXmzZu6edNxbmqT3l3u7u7xbIF75cmTV4uXLNWVK5e1+uefNLB/X82a+4XDQGtUVJT6vtdTMTFGAwYOfmB/W7ds1szp0zRgYIhKlCypsLAwhY4coSxTJ+utd7rEav/tkiWqUrW6smXLntSHBihdOpv+3BumkEkrJEk79x9XsfyB6vRStTgHWds2fUZfrdoW5z3dHsWBI2dUseVI+Xp7qlnt0pox9DU998YEwgypDlmcNEYOH6p/DhzQ3M8XOCx/vn4D+/8XLFhIxZ96Ss/XeVb//fUX1an7XKx+IiOvqv8HfRQyZJgyZ47/TXlMjFHxp55Stx69JElFixbT/w4e1OKvFjLIimTRrlll/bh+r06duyRJKlM0l7q0qqnKrUc71c+Wv45oy19H7I837DikjQv7qnPLGuod+rVyZvfVx31aqHHnyUmW6UBKF1cW34xxIYsTIDhPHn3+1Te6euWK1q75SUMH9dfUmfOUL38B1a1X394uf4GCKlrsKTWtX1vrf/tVtWrXjbO/P7Zu0ZyZ0/V+/0EqXqKkjh8L0yehH8n/s6zq2OnOlOiVq1b/d4OChVSiVGk1b1RPK1csVevX2ifn4SKNSZfOpj//PqGQ6T9Lknb+c0rF8mZTpxcqasEPO1SmcJC6vFRZlTtMTvJ9/7TpgP3/9xw6o827w7RncW+9Wv9pffpV/NMfAk8izomTRlznxK6urho7/lMNHjhA1SpXUPr06VXxmUqqWq16vP0k9Jz4XnxGjcfh/nPiu4wxDo9tttjL7vWwc+K7+Gz68XjipwseOXKkfHx8HH4+Hj3y4RtCkuTq5qbcwcEq/lQJde/ZW4UKF9GXX8y3r4+KilKf3j104vhxTZ85+4FXsUrS5IkT1KhJEzV/8SUVLFRYtevU1bs9emr2zM8UExPj0PbkyRPavGmDmr/4YrIcG3D6/OVYUw/+ffi0cgXEnqKoSpn8Kpw3QHO+3ZBk+4+6Ha1Dx87rz71hGjRxuf46cEJdWtVMsv6BlIIsTryRI4bpl1/WasacecoeEPDAtlmzZlNQUJDCjh6Jc/2xsGM6eeKEunV5R0+XLKanSxbTiuVL9cu6tXq6ZDEdCwv7/36yKl/+/A7b5suXT6dOnUySYwLulTsws56tWFhzl/6bs1XK5Fc2Py8d+H6ormydoCtbJyg4yF+jejXX3yuHJLhvY4z+2HNU+XPfubdhmaK5ld0/kzZ8+b693+rlCqpzqxq6snWC0qVj+i+kPnFl8biPR1ld1hPB1dVNuXIHq2jxp9SlWy8VLFRYXy34PM62WbJmVUBgkI6FHY23v+lTPlX9hk3UtPmLKlCwkGo+W0fvvNtD82bPiHVOfFeGDJ4qUKDQA/sFHsXpC1e074jjlV5/HzmnXNl9JUlVSuVRtswZdWBJH135daiu/DpUwYGZNaprff399XtJWsu1G1Hac+iM8ufyT9J+gZSAc+LEe9A5cbHiT2nxN8v0+6ZtWv3L75r62SxFREQoR464p0dN6DnxXXxGjcchrnPi0+fv3Cc4u7/j7Rmz+nnHurr1Qe4/J76Lz6YfD8uvZF2+fHmcy202mzw8PFSgQAHlzZs33u379eunXr16OSwz6fmW0KMyxtjnur87wBp29KhmzpkvX9+H3zvjxo0bstkcx+7Tp0svY0ysb18s+/Yb+fn5x3u/ViCxNu44pELB2RyWFcydTWGnwmO1bdeskv7YG6a/DpxItnpsssndzfI/u4CDxOawRBYnhjFGI0cM09o1P2vW3M+VM2euh24TEXFRp0+fUtas2eJcnzdfPn29dIXDssmfjldkZKTe7zdAAf9/wlq6zNM6ctjxXhxHjxxRUFCORzwaIH6vNamks+FXtOq3PfZlC1Zu1dr77pe6YkoXLVi5RfOXbXKq/1KFc2r3P3e+ILBuy36VfXGEw/rPhryq/YfPaOzcnxUTE/83ggErJFcWX4/hfeejuHNOHBXnuksRETp75rSyZMka53rpzjlxunSO58Tp0qWX4jgnvuvWrVs6fPiQSj1d9tELB+KwcVeYCuXO4rCsYO4sCjt9UZK04IftWrv1oMP6FeNe14Iftmv+938maS1urulVJDir1u88kqT9AonFObG1nDkn9vb2liQdPXpEe/fsVpd3u8fZLqHnxHfxGTUeh7jOiY+cuKBT5y6p9jNFtHP/cUl37ttarWwBfThhmVP933tOHB8+m04elv9GmzVrJpvNFscl0XeW2Ww2Va1aVUuXLlXmzLEH+dzdY0+9cINZwRLk0/GfqGq16soeEKBrkZH6YdX32rZ1i6ZMn6nbt2/rvZ7dtG/fXk2cPF0x0dE6///z3Pv4+Mj1/+8/M6Df+8qWLbu69+wtSapRs5Y+nzdHRYoWU4mSJXUsLEyTJ05QjVrPKn369PZ9x8TEaNm336hx02ZycbH8ZYhUauIXa7Vubm/16fCclvz8p8oXz6MOLaqo67CFDu28M3qoed0y+uCTb+PsZ+aw13Ty7CUNmnjnjberS3oVzXfnDZmbq4uCsvmqZKEcunr9pg4dOy9JGtK1sX5av1fHTl+Ud0YPvVSvrKqXK6gmXaYk4xEDzktsDktkcWJ8NGyIVn3/ncZPnKKMnhntWevl7S0PDw9di4zU1CmTVKfuc8qSNatOnjihiRPGyTdzZj1bp469n3vz2N3d3eGerpLk7X3nW5H3Ln+1bTu1e7WVZn42Tc/Vq6/df+3S118v1qDBQx/DkSMtsdlsatv0GX353WZFR/97FVf4pUiFX4p0aBt1O1pnzl/WP0fP2pfdn8P9O9XXlr+O6GDYWWXK6KHOrWqqZKGc6jFysSTp6rWb2vu/Uw79Rl6/pfBLkbGWAylBcmVxzPXoZKs5tZjy6ThVqlpN2bMH6tq1SP38w/f6c9tWjZ/8ma5di9SMaZP1bO3n5J8lq06dPKGpE8fLxzezajz7bwYP/vADZc2WTV263flwvVr1mlrwxTwVKlJUT5W4c0782ZRPVa1GLfs58YRPQlWtei0FBAYqPPyC5syYrsjIq2rYuKklvwekXhO/Wq91099Sn7Y1tGTNXypfLKc6NCmvrqFLJUnhl6/Huj9q1O1onQm/qn/CztuXzfzwRZ08f1mDpv0k6f/PifPe+cKfm2t6BWXNpJIFA3X12k0dOnHnS80juzyvlev/1rEzl5Qtc0b1bVdL3hnd9eX32x/DkQMJxzmxtR52TixJP/24Spkz+ykwMEj//LNfoSM/Uq1n66hylar2fh7lnFjiM2o8HvGdE0vS5AXr1KfjczoYdlYHw87p/Y71dP1GlL5atc3extlzYonPph8ny/9y/PzzzxowYIBGjBihChUqSJK2bNmiDz/8UAMHDpSPj4/eeustvffee5o1a5bF1aYuFy6c14AP3te5c2fl5e2tQoUKa8r0mapUuYpOnDiuX9atlSS93MLxRG/mnPkqX6GiJOn0qVNKd8+Vq2++9Y5sNpsmfzpeZ8+eUebMfqpRs5a6du/p0MemjRt06tRJNWveIpmPEmnZH3vD9ErvGRr6bhP171RfR05cUJ+Pl2jRPSElSS/VKyubbFr8w7Y4+8kV4Odw1UtgVh9t/qqf/XHPdnXUs10d/XfbP6r35gRJUjZ/b80a3lYBWTLp0tUb2v3PCTXpMkVrN/+dDEcKPDpy2FqLv7rzpY+O7V9zWD50+Eg1faG50qVPr38OHNCK5Ut15fIVZc2aVeUrVFTomHHKmPHfKfzvz+OEeKpESX0yYZI+Hf+Jpk+drBw5c+r9vv3VsFGTxB8YcI9nKxZW7kA/zVvq3NWpd92fw77eGTR5YCtl9/fWpas3tPPv46r7xnht28M0m3gykcXWCQ+/oCEDPtD58+fk5eWtAoUKafzkz1SxUmXduHFD//vnH61asVxXrlxWlqxZVbZcRY0IHauMGTPa+zhzXwa//ubbstlsmj55gs6dPSvfzJlVtXotvdP136ttzp45o4H93lPExYvKnNlPxUuW0qz5CxXIbBJIYn/8fUKv9PtSQ99+Tv3b19KRUxfVZ8JKLfppp1P95Mruo5h7BqACs3hr89yu9sc9W1dTz9bV9N8/D6neu3f+TuXI5qP5Q16Rv4+nzkdc05Y9YarRaZrCzkQkybEBSYUcttbDzokl6dy5cxoTOkoXzl9Q1qxZ1ahJU731dmeH9o9yTizxGTUejwedE4+du1oe7m4a3+8VZc7kqa27j6jRO5N09dq/93l+lHNiPpt+fGzmQXfQfQyeeuopffbZZ6pcubLD8vXr16tTp07as2ePVq9erQ4dOijsvvnS48M3hZDaZS7f9eGNgCfc9e2TrC4hTUiOHJbIYqR+ZDFSO3L48UmuLI7gSlakcoF1BlldApCsrq8f8fBGSDTOiYFHwzkxUruEnhM7//WOJPa///1PmTJlirU8U6ZMOnTokCSpYMGCOn/+fKw2AAAgcchhAACsRRYDAGAdchgAkBiWD7KWLVtWffr00bn/n29dujMFwPvvv6/y5ctLkv755x/lzJnTqhIBAEi1yGEAAKxFFgMAYB1yGACQGJbfk3XWrFlq2rSpcubMqVy5cslmsyksLEz58uXTsmXLJElXr17VwIEDLa4UAIDUhxwGAMBaZDEAANYhhwEAiWH5PVklyRijH3/8UQcOHJAxRkWKFFHdunWVLt2jXWjLnPdI7ZjzHmkB94J7fJI6hyWyGKkfWYzUjhx+vJIji7knK1I77smK1I57sj4+nBMDzuOcGKldQs+JU8Qga1IjxJDaEWJIC/hw98lGFiO1I4uR2pHDTz4GWZHaMciK1I5B1icb58RI7TgnRmqX0HNiy6cLlqQ1a9ZozZo1Onv2rGJiYhzWzZ4926KqAABIG8hhAACsRRYDAGAdchgA8KgsH2QdMmSIhg4dqnLlyikwMFA2m83qkgAASDPIYQAArEUWAwBgHXIYAJAYlg+yTps2TXPnztVrr71mdSkAAKQ55DAAANYiiwEAsA45DABIjEe/e3cSuXXrlipXrmx1GQAApEnkMAAA1iKLAQCwDjkMAEgMywdZ33jjDS1YsMDqMgAASJPIYQAArEUWAwBgHXIYAJAYlk8XfOPGDX322WdavXq1SpYsKVdXV4f1n3zyiUWVAQCQ+pHDAABYiywGAMA65DAAIDEsH2TdtWuXSpcuLUnavXu3wzpuNA4AQPIihwEAsBZZDACAdchhAEBiWD7Ium7dOqtLAAAgzSKHAQCwFlkMAIB1yGEAQGJYfk/Wex0/flwnTpywugwAANIkchgAAGuRxQAAWIccBgA4y/JB1piYGA0dOlQ+Pj4KDg5W7ty55evrq2HDhikmJsbq8gAASNXIYQAArEUWAwBgHXIYAJAYlk8XPGDAAM2aNUujRo1SlSpVZIzR+vXrNXjwYN24cUMjRoywukQAAFItchgAAGuRxQAAWIccBgAkhs0YY6wsICgoSNOmTVOTJk0cli9btkydO3d+pCkabtxOquqAlClz+a5WlwAku+vbJ1ldQpqQHDkskcVI/chipHbk8OOTXFkccT06KcoDUqzAOoOsLgFIVtfXM7j3OHBODDwazomR2iX0nNjy6YLDw8NVpEiRWMuLFCmi8PBwCyoCACDtIIcBALAWWQwAgHXIYQBAYlg+yFqqVClNmhR7RHjSpEkqVaqUBRUBAJB2kMMAAFiLLAYAwDrkMAAgMSy/J2toaKgaNmyo1atXq1KlSrLZbNqwYYOOHTum77//3uryAABI1chhAACsRRYDAGAdchgAkBiWX8lao0YNHThwQC+88IIiIiIUHh6u5s2ba//+/apWrZrV5QEAkKqRwwAAWIssBgDAOuQwACAxLL+SVbpzg/ERIxxv5n7s2DF16NBBs2fPtqgqAADSBnIYAABrkcUAAFiHHAYAPCrLr2SNT3h4uObNm2d1GQAApEnkMAAA1iKLAQCwDjkMAEiIFDvICgAAAAAAAAAAAAApEYOsAAAAAAAAAAAAAOAEBlkBAAAAAAAAAAAAwAkuVu24efPmD1wfERHxeAoBACANIocBALAWWQwAgHXIYQBAUrBskNXHx+eh69u2bfuYqgEAIG0hhwEAsBZZDACAdchhAEBSsGyQdc6cOVbtGgCANI8cBgDAWmQxAADWIYcBAEmBe7ICAAAAAAAAAAAAgBMYZAUAAAAAAAAAAAAAJzDICgAAAAAAAAAAAABOYJAVAAAAAAAAAAAAAJzAICsAAAAAAAAAAAAAOIFBVgAAAAAAAAAAAABwAoOsAAAAAAAAAAAAAOAEBlkBAAAAAAAAAAAAwAkMsgIAAAAAAAAAAACAExhkBQAAAAAAAAAAAAAnMMgKAAAAAAAAAAAAAE5gkBUAAAAAAAAAAAAAnMAgKwAAAAAAAAAAAAA4gUFWAAAAAAAAAAAAAHACg6wAAAAAAAAAAAAA4AQGWQEAAAAAAAAAAADACQyyAgAAAAAAAAAAAIATGGQFAAAAAAAAAAAAACcwyAoAAAAAAAAAAAAATmCQFQAAAAAAAAAAAACcwCArAAAAAAAAAAAAADiBQVYAAAAAAAAAAAAAcAKDrAAAAAAAAAAAAADgBAZZAQAAAAAAAAAAAMAJDLICAAAAAAAAAAAAgBMYZAUAAAAAAAAAAAAAJzDICgAAAAAAAAAAAABOYJAVAAAAAAAAAAAAAJzAICsAAAAAAAAAAAAAOIFBVgAAAAAAAAAAAABwAoOsAAAAAAAAAAAAAOAEBlkBAAAAAAAAAAAAwAkMsgIAAAAAAAAAAACAExhkBQAAAAAAAAAAAAAnMMgKAAAAAAAAAAAAAE5gkBUAAAAAAAAAAAAAnMAgKwAAAAAAAAAAAAA4wWaMMVYXgSfbzZs3NXLkSPXr10/u7u5WlwMkOV7jAFIy/kYhLeB1DiAl428UUjte4wBSOv5OIbXjNZ5yMciKRLt8+bJ8fHx06dIlZcqUyepygCTHaxxASsbfKKQFvM4BpGT8jUJqx2scQErH3ymkdrzGUy6mCwYAAAAAAAAAAAAAJzDICgAAAAAAAAAAAABOYJAVAAAAAAAAAAAAAJzAICsSzd3dXSEhIdxwGakWr3EAKRl/o5AW8DoHkJLxNwqpHa9xACkdf6eQ2vEaT7lsxhhjdREAAAAAAAAAAAAA8KTgSlYAAAAAAAAAAAAAcAKDrAAAAAAAAAAAAADgBAZZAQAAAAAAAAAAAMAJDLKmETabTUuXLrW6DAAA0iRyGAAAa5HFAABYiywGkBoxyJoKnD17Vm+99ZZy584td3d3BQQEqF69etq4ceNj2X9CA/Jh7fbs2aOXX35ZWbNmlbu7uwoWLKiBAwfq2rVrDu22b9+uRo0aKVu2bPLw8FCePHn0yiuv6Pz584k8EqR07du3V7NmzawuI5aH1XX9+nWFhISocOHCcnd3V5YsWfTiiy9qz549Du0iIyPVt29f5cuXTx4eHsqaNatq1qyp7777LpmPAEBikMPkcFpBDgNIqchisjitIIsBpFRkMVmcFpDDiIuL1QUg8Vq0aKGoqCjNmzdP+fLl05kzZ7RmzRqFh4cn635v3bolNze3JOlr06ZNqlOnjurUqaOVK1cqe/bs2rJli3r37q21a9dq3bp1cnNz09mzZ1WnTh01btxYP/74o3x9fXX48GEtX748VtgBKcHNmzdVp04dhYWFaezYsapYsaLOnDmjkSNHqmLFilq9erWeeeYZSdLbb7+tLVu2aNKkSSpWrJguXLigDRs26MKFCxYfBYAHIYfJYaRc5DCQNpDFZDFSLrIYSBvIYrIYKRM5/BgYPNEuXrxoJJlffvnlge0kmRkzZphmzZqZDBkymAIFCphly5Y5tPnll19M+fLljZubmwkICDB9+/Y1UVFR9vU1atQwXbp0MT179jT+/v6mevXqJjg42Eiy/wQHBz+whm+//TbW8piYGFOsWDFTrlw5Ex0d7bBux44dxmazmVGjRhljjPn222+Ni4uLQ11IO9q1a2eaNm0a7/qEvIbfffdd06dPH5M5c2aTPXt2ExIS4tDHvn37TJUqVYy7u7spWrSo+fnnn+N97SakrlGjRhmbzWZ27NjhsDw6OtqUK1fOFCtWzMTExBhjjPHx8TFz58594O8AQMpCDiMtIYcBpERkMdISshhASkQWI60ghxEXpgt+wnl5ecnLy0tLly7VzZs3H9h2yJAhevnll7Vr1y41aNBAbdq0sX+b6MSJE2rQoIHKly+vnTt3aurUqZo1a5aGDx/u0Me8efPk4uKi9evXa/r06dq6daskac6cOTp16pT9sTN27NihvXv3qlevXkqXzvElWapUKdWpU0cLFy6UJAUEBOj27dv69ttvZYxxel9IvZx5DWfMmFGbN29WaGiohg4dqp9//lmSFBMTo2bNmsnT01ObN2/WZ599pgEDBiSqrgULFqhu3boqVaqUw/J06dKpZ8+e2rt3r3bu3Cnpzuv7+++/15UrVxK1TwCPDzkM3EEOA7AKWQzcQRYDsApZDJDDaZq1Y7xICl9//bXJnDmz8fDwMJUrVzb9+vUzO3fudGgjyXz44Yf2x1evXjU2m82sWrXKGGNM//79TeHChe3fWjDGmMmTJxsvLy/7t3dq1KhhSpcuHWv/esg3KR7WbtGiRUaS2b59e5zbdevWzWTIkMH+uH///sbFxcX4+fmZ559/3oSGhprTp08/dP948j3oWzkJfQ1XrVrVYbvy5cubvn37GmOMWbVqlXFxcTGnTp2yr0/st4U8PDxM9+7d41z3559/Gknmq6++MsYY8+uvv5qcOXMaV1dXU65cOdOjRw/z+++/x7tfACkDOUwOpxXkMICUiiwmi9MKshhASkUWk8VpATmMuHAlayrQokULnTx5UsuXL1e9evX0yy+/6Omnn9bcuXMd2pUsWdL+/xkzZpS3t7fOnj0rSdq3b58qVaokm81mb1OlShVdvXpVx48fty8rV65c8h5MHIwxDnWNGDFCp0+f1rRp01SsWDFNmzZNRYoU0V9//fXYa0PKkdDX8L3/DiQpMDDQ/u9g//79ypUrlwICAuzrK1SokGw1m///ttvdmqtXr65Dhw5pzZo1atGihfbs2aNq1app2LBhyVYDgMQjh8lhkMMArEUWk8UgiwFYiywmi9M6cjjtYpA1lfDw8FDdunU1aNAgbdiwQe3bt1dISIhDG1dXV4fHNptNMTExkmIHxd1ld9vdlTFjxiSvvVChQpKkvXv3xrn+77//VsGCBR2W+fv766WXXtLYsWO1b98+BQUFacyYMUleG54cCX0NO/vvILEKFSr0wNe2JIfXt6urq6pVq6YPPvhAP/30k4YOHaphw4bp1q1bSVoXgKRFDpPDaR05DMBqZDFZnNaRxQCsRhaTxWkZOZx2MciaShUrVkyRkZFOtd+wYYPDPPIbNmyQt7e3cuTI8cBtXV1dFR0d/ci1li5dWkWKFNG4cePsf1Du2rlzp1avXq1WrVrFu72bm5vy58/v1PEi9UnMa/iuIkWKKCwsTGfOnLEve5T7ONyrZcuWWr16tX1u+7tiYmI0btw4FStWLNac+PcqVqyYbt++rRs3biSqDgCPFzmMtIYcBpDSkMVIa8hiACkNWYy0hBxOu1ysLgCJc+HCBb300kvq0KGDSpYsKW9vb23btk2hoaFq2rRpgvvp3Lmzxo8fr3fffVddu3bV/v37FRISEufNvu+XJ08erVmzRlWqVJG7u7syZ84cb9vDhw9rx44dDssKFCigmTNn6rnnnlOLFi3Ur18/BQQEaPPmzerdu7cqVaqkHj16SJK+++47LVq0SC1btlShQoVkjNGKFSv0/fffa86cOQk+Xjy5Ll26FOs15Ofnl6jX8F1169ZV/vz51a5dO4WGhurKlSv2m4s/7FtE8dXVs2dPLVu2TI0bN9bYsWNVsWJFnTlzRh999JH27dun1atX2/uuWbOmWrVqpXLlysnf31979+5V//79VatWLWXKlClhvyAAjxU5TA6nNeQwgJSGLCaL0xqyGEBKQxaTxWkJOYxYku92r3gcbty4YT744APz9NNPGx8fH+Pp6WkKFy5sPvzwQ3Pt2jV7O8Vxc2QfHx8zZ84c++NffvnFlC9f3ri5uZmAgADTt29fExUVZV9fo0aNOG+SvHz5clOgQAHj4uJigoOD461VUpw/69atM8YYs2vXLtOiRQvj7+9vXF1dTf78+c2HH35oIiMj7X3873//M2+++aYpVKiQyZAhg/H19TXly5d3OA6kXu3atYvzNdSuXTtjzKO9hps2bWrf3hhj9u3bZ6pUqWLc3NxMkSJFzIoVK4wk88MPPzxyXZGRkebDDz80BQoUMK6ursbPz8+0aNHC/PXXXw79fPTRR6ZSpUrGz8/PeHh4mHz58plu3bqZ8+fPJ+r3BiD5kMPkcFpCDgNIichisjgtIYsBpERkMVmcVpDDiIvNmHuuXwYAOFi/fr2qVq2qgwcPKn/+/FaXAwBAmkIOAwBgLbIYAADrkMMpH4OsAHCPb7/9Vl5eXipYsKAOHjyo7t27K3PmzPr999+tLg0AgFSPHAYAwFpkMQAA1iGHnzzckxUA7nHlyhW9//77OnbsmLJkyaI6depo7NixVpcFAECaQA4DAGAtshgAAOuQw08ermQFAAAAAAAAAAAAACeks7oAAAAAAAAAAAAAAHiSMMgKAAAAAAAAAAAAAE5gkBUAAAAAAAAAAAAAnMAgKwAAAAAAAAAAAAA4gUFWAAAAAAAAAAAAAHACg6xAEhs8eLBKly5tf9y+fXs1a9bssddx5MgR2Ww27dixI9n2cf+xPorHUScAIO0gh51DDgMAkhpZ7ByyGACQ1Mhi55DFSAwGWZEmtG/fXjabTTabTa6ursqXL5/ee+89RUZGJvu+J0yYoLlz5yao7eP+g16zZk316NHjsewLAJB2kcNxI4cBAI8LWRw3shgA8LiQxXEji/Gkc7G6AOBxef755zVnzhxFRUXpt99+0xtvvKHIyEhNnTo1VtuoqCi5uromyX59fHySpB8AAJ5k5DAAANYiiwEAsBZZDKQ+XMmKNMPd3V0BAQHKlSuXWrdurTZt2mjp0qWS/p1WYPbs2cqXL5/c3d1ljNGlS5fUqVMnZcuWTZkyZdKzzz6rnTt3OvQ7atQoZc+eXd7e3urYsaNu3LjhsP7+6RhiYmI0evRoFShQQO7u7sqdO7dGjBghScqbN68kqUyZMrLZbKpZs6Z9uzlz5qho0aLy8PBQkSJFNGXKFIf9bNmyRWXKlJGHh4fKlSun7du3J/p31rdvXxUqVEienp7Kly+fBg4cqKioqFjtpk+frly5csnT01MvvfSSIiIiHNY/rHYAQOpHDjuPHAYAJCWy2HlkMQAgKZHFziOLkdJxJSvSrAwZMjj8QT548KAWL16sJUuWKH369JKkhg0bys/PT99//718fHw0ffp01a5dWwcOHJCfn58WL16skJAQTZ48WdWqVdPnn3+uTz/9VPny5Yt3v/369dOMGTM0btw4Va1aVadOndLff/8t6U4QVahQQatXr1bx4sXl5uYmSZoxY4ZCQkI0adIklSlTRtu3b9ebb76pjBkzql27doqMjFSjRo307LPP6osvvtDhw4fVvXv3RP+OvL29NXfuXAUFBemvv/7Sm2++KW9vb73//vuxfm8rVqzQ5cuX1bFjR3Xp0kVffvllgmoHAKRN5PDDkcMAgOREFj8cWQwASE5k8cORxUjxDJAGtGvXzjRt2tT+ePPmzcbf39+8/PLLxhhjQkJCjKurqzl79qy9zZo1a0ymTJnMjRs3HPrKnz+/mT59ujHGmEqVKpm3337bYX3FihVNqVKl4tz35cuXjbu7u5kxY0acdR4+fNhIMtu3b3dYnitXLrNgwQKHZcOGDTOVKlUyxhgzffp04+fnZyIjI+3rp06dGmdf96pRo4bp3r17vOvvFxoaasqWLWt/HBISYtKnT2+OHTtmX7Zq1SqTLl06c+rUqQTVHt8xAwBSD3I4buQwAOBxIYvjRhYDAB4XsjhuZDGedFzJijTju+++k5eXl27fvq2oqCg1bdpUEydOtK8PDg5W1qxZ7Y//+OMPXb16Vf7+/g79XL9+Xf/73/8kSfv27dPbb7/tsL5SpUpat25dnDXs27dPN2/eVO3atRNc97lz53Ts2DF17NhRb775pn357du37fPp79u3T6VKlZKnp6dDHYn19ddfa/z48Tp48KCuXr2q27dvK1OmTA5tcufOrZw5czrsNyYmRvv371f69OkfWjsAIG0gh51HDgMAkhJZ7DyyGACQlMhi55HFSOkYZEWaUatWLU2dOlWurq4KCgqKdePwjBkzOjyOiYlRYGCgfvnll1h9+fr6PlINGTJkcHqbmJgYSXemNahYsaLDurvTRhhjHqmeB9m0aZNatmypIUOGqF69evLx8dGiRYs0duzYB25ns9ns/01I7QCAtIEcdg45DABIamSxc8hiAEBSI4udQxbjScAgK9KMjBkzqkCBAglu//TTT+v06dNycXFRnjx54mxTtGhRbdq0SW3btrUv27RpU7x9FixYUBkyZNCaNWv0xhtvxFp/d4776Oho+7Ls2bMrR44cOnTokNq0aRNnv8WKFdPnn3+u69ev24PyQXUkxPr16xUcHKwBAwbYlx09ejRWu7CwMJ08eVJBQUGSpI0bNypdunQqVKhQgmoHAKQN5LBzyGEAQFIji51DFgMAkhpZ7ByyGE8CBlmBeNSpU0eVKlVSs2bNNHr0aBUuXFgnT57U999/r2bNmqlcuXLq3r272rVrp3Llyqlq1ar68ssvtWfPnnhvLO7h4aG+ffvq/fffl5ubm6pUqaJz585pz5496tixo7Jly6YMGTLohx9+UM6cOeXh4SEfHx8NHjxY3bp1U6ZMmVS/fn3dvHlT27Zt08WLF9WrVy+1bt1aAwYMUMeOHfXhhx/qyJEjGjNmTIKO89y5c9qxY4fDsoCAABUoUEBhYWFatGiRypcvr5UrV+rbb7+N85jatWunMWPG6PLly+rWrZtefvllBQQESNJDawcAIC7kMDkMALAWWUwWAwCsRRaTxXgCWHtLWODxuP/G4vcLCQlxuBn4XZcvXzbvvvuuCQoKMq6uriZXrlymTZs2JiwszN5mxIgRJkuWLMbLy8u0a9fOvP/++/HeWNwYY6Kjo83w4cNNcHCwcXV1Nblz5zYfffSRff2MGTNMrly5TLp06UyNGjXsy7/88ktTunRp4+bmZjJnzmyqV69uvvnmG/v6jRs3mlKlShk3NzdTunRps2TJkgTdWFxSrJ+QkBBjjDF9+vQx/v7+xsvLy7zyyitm3LhxxsfHJ9bvbcqUKSYoKMh4eHiY5s2bm/DwcIf9PKh2biwOAKkfORw3chgA8LiQxXEjiwEAjwtZHDeyGE86mzHJMFk2AAAAAAAAAAAAAKRS6awuAAAAAAAAAAAAAACeJAyyAgAAAAAAAAAAAIATGGQFAAAAAAAAAAAAACcwyAoAAAAAAAAAAAAATmCQFQAAAAAAAAAAAACcwCArAAAAAAAAAAAAADiBQVYAAAAAAAAAAAAAcAKDrAAAAAAAAAAAAADgBAZZAQAAAAAAAAAAAMAJDLICAAAAAAAAAAAAgBMYZAUAAAAAAAAAAAAAJzDICgAAAAAAAAAAAABOYJAVAAAAAAAAAAAAAJzAICsAAAAAAAAAAAAAOIFBVgAAAAAAAAAAAABwAoOsAAAAAAAAAAAAAOAEBlkBAAAAAAAAAAAAwAkMsgIAAAAAAAAAAACAExhkBQAAAAAAAAAAAAAnMMgKAAAAAAAAAAAAAE5gkBUAAAAAAAAAAAAAnMAgKwAAAAAAAAAAAAA4gUFWAAAAAAAAAAAAAHACg6wAAAAAAAAAAAAA4AQGWQEAAAAAAAAAAADACQyyAgAAAAAAAAAAAIATGGQFAAAAAAAAAAAAACcwyAoAAAAAAAAAAAAATmCQFQAAAAAAAAAAAACcwCArAAAAAAAAAAAAADiBQVYAAAAAAAAAAAAAcAKDrAAAAAAAAAAAAADgBAZZAQAAAAAAAAAAAMAJDLICAAAAAAAAAAAAgBMYZAUAAAAAAAAAAAAAJzDImgZs3rxZL7zwgnLnzi13d3dlz55dlSpVUu/evR3a1axZUzabTfny5ZMxJlY///3vf2Wz2WSz2TR37txY6zdt2qSXXnpJgYGBcnNzU0BAgF588UVt3LjRod3dPh7288svv+jIkSMPbDN48GB7v+3bt39g27vu7XPRokWxjmPw4MGy2Ww6f/58rL6LFy+u6OjoWNvYbDZ17do13ucgOdx9vu7+eHh4qFixYho+fLhu3br1WGu5V548edS+fXvL9h3f83/16lVLanqQDRs2aPDgwYqIiLC6FABOIFdTZ65KUkxMjL744gvVq1dP2bJlk6urq3x9ffXMM89ozJgxDseQ3O7P019++cX+PCanKVOmxPl6jOu1kylTJpUqVUrjx4+P83l83B5We1zrAKR85G7qzN2aNWvqqaeeeqz7fNQ8WLBggcaPHx/nuvufR2fquPuTLl06Zc6cWbVr19ZPP/3kVF9Pssf13gYAnMV7j9T73uNRnq+5c+fKZrNp27Zt8fYdV7b7+/urQYMGsZ5PpD4uVheA5LVy5Uo1adJENWvWVGhoqAIDA3Xq1Clt27ZNixYt0tixYx3ae3t76/Dhw1q7dq1q167tsG727NnKlCmTLl++HGs/EydOVI8ePVShQgWFhoYqODhYYWFhmjx5sqpWraoJEybY/3De/4dl2LBhWrdundauXeuwvFixYgoPD5ckvfvuu2rdunWs/ebMmdPhcYYMGWL18yADBgxQixYt5OrqmqD2e/fu1dy5c9WxY8cE7yM55cuXT19++aUk6dy5c5o5c6YGDhyosLAwffbZZxZXZ40qVapozJgxsZZ7enpaUM2DbdiwQUOGDFH79u3l6+trdTkAEoBcfbAnOVevX7+upk2bavXq1XrllVf06aefKigoSJcvX9aGDRv08ccfa9myZfrtt98sqe/pp5/Wxo0bVaxYsWTdz5QpU5QlS5Z4vzB172snIiJCy5cvV8+ePXXs2LFYr//HLb7aAwMDtXHjRuXPn9+awgA8MnL3wZ7k3LXCo+bBggULtHv3bvXo0SPWuo0bN8Z6HhPq7usiOjpaf//9t4YMGaIGDRpo7dq1ql69+iP1+SR5XO9tAMAZvPd4sCf9vcejPl8JdW+279mzR0OGDFGtWrW0ceNGlSlTJrHlI6UySNWqV69u8ufPb6KiomKti46Odnhco0YNU7x4cfPMM8+Y1q1bO6y7fPmy8fT0NG+++aaRZObMmWNf9/vvv5t06dKZRo0axdpPVFSUadSokUmXLp35/fff46yxXbt2JmPGjHGuO3z4sJFkPv7444ce64P6iavP+vXrG0nm008/dVgfEhJiJJlz587F6rtatWomR44c5tq1aw7bSDJdunR56L7vt27dOiPJHD582Olt7z5f94qKijIFCxY0bm5u5vr16073mRSCg4NNu3btLNt3w4YNk6XvmJiYWM97Yn388ceP/PwDsAa5Gn+fT3qudurUyUgyCxYsiHN9ZGSk+eyzzx7YR1JmhVV5Wrx4cVOjRo1Yyx/02qlWrZoJDAx8DNU9WHy1A3hykbvx9/mk525c57MpVcOGDU1wcHCS9Rff6+LXX381kkzbtm2TbF8JFRkZ+dj3CQApEe894u8ztbz3cPb5mjNnjpFktm7dGm/f8f3e16xZYySZN954w+l68eRguuBU7sKFC8qSJYtcXGJftJwuXdxPf4cOHfTNN984TGF6dyqAli1bxmo/cuRI2Ww2TZ06NdZ+XFxcNGXKFNlsNo0aNSoRR5L0nn32WdWrV0/Dhg3TlStXErTN6NGjdeLECU2YMCGZq3s0Li4uKl26tG7duuXw/G3btk0tW7ZUnjx5lCFDBuXJk0etWrXS0aNHHba/O/3BunXr9M477yhLlizy9/dX8+bNdfLkSYe2UVFRev/99xUQECBPT09VrVpVW7ZsibOu3bt3q2nTpsqcObM8PDxUunRpzZs3z6HN3amCFixYoL59+yowMFBeXl5q3Lixzpw5oytXrqhTp07KkiWLsmTJotdff/2RpgAODw9X586dlSNHDrm5uSlfvnwaMGCAbt686dDu7rQV06ZNU9GiReXu7m6v+Z9//lHr1q2VLVs2ubu7q2jRopo8ebLD9jExMRo+fLgKFy6sDBkyyNfXVyVLlrS/dgYPHqw+ffpIkvLmzeswtQeAlItcjd+TnKunTp3S7Nmz1bBhQ7Vq1SrONp6ennrzzTcdlj0oK4YMGaKKFSvKz89PmTJl0tNPP61Zs2bFmpYooXka35R627ZtU5MmTeTn5ycPDw+VKVNGixcvdmiT0HzPkyeP9uzZo19//dWeS3ny5Hno78/HxyfWN5ljYmIUGhqqIkWKyN3dXdmyZVPbtm11/PjxWNvPnj1bpUqVkoeHh/z8/PTCCy9o3759Dm0OHTqkli1bKigoyD5lV+3atbVjx46H1h7X9JB3p7Tas2ePWrVqJR8fH2XPnl0dOnTQpUuXHPYdERGhjh07ys/PT15eXmrYsKEOHTr0SFNEAnAOuRu/Jzl3EyqhWWKM0UcffaTg4GB5eHioXLly+vnnn1WzZk3VrFnT3i6uPDh37pw6deqkXLlyyd3dXVmzZlWVKlW0evVqSXemFly5cqWOHj0a5xSKcWXBiRMn7H26ubkpKChIL774os6cOfPA4y1XrpwkxWp3+vRpvfXWW8qZM6fc3NyUN29eDRkyRLdv33Zod/z4cb344ovy9vaWr6+v2rRpo61bt8Y65vbt28vLy0t//fWXnnvuOXl7e9uv5rl165aGDx9u/51nzZpVr7/+us6dO+ewr7Vr16pmzZry9/dXhgwZlDt3brVo0ULXrl2zt5k6dapKlSolLy8veXt7q0iRIurfv799fXzvbZYvX65KlSrJ09NT3t7eqlu3bqyruJzJcQBwBu894pda3ns4+3wlxjPPPCNJsT6DR+rCIGsqV6lSJW3evFndunXT5s2bFRUV9dBtWrZsqfTp02vhwoX2ZbNmzdKLL76oTJkyObSNjo7WunXrVK5cuXinyMmVK5fKli2rtWvXPvL9umJiYnT79u1YP3GJq11MTEycbUePHq3z58/r448/TlAdlSpV0gsvvKDRo0fbp19IaQ4fPixfX19lzZrVvuzIkSMqXLiwxo8frx9//FGjR4/WqVOnVL58+TjvL/fGG2/I1dVVCxYsUGhoqH755Re9+uqrDm3efPNNjRkzRm3bttWyZcvUokULNW/eXBcvXnRot3//flWuXFl79uzRp59+qm+++UbFihVT+/btFRoaGmvf/fv319mzZzV37lyNHTtWv/zyi1q1aqUWLVrIx8dHCxcu1Pvvv6/PP//c4QTtLmNMvM//jRs3VKtWLc2fP1+9evXSypUr9eqrryo0NFTNmzeP1dfSpUs1depUDRo0SD/++KOqVaumvXv3qnz58tq9e7fGjh2r7777Tg0bNlS3bt00ZMgQ+7ahoaEaPHiwWrVqpZUrV+qrr75Sx44d7QH+xhtv6N1335UkffPNN9q4caM2btyop59+Or6nFkAKQK6mzlxdt26dbt++rSZNmji9bVxZId3J3rfeekuLFy/WN998o+bNm+vdd9/VsGHDHLZPaJ7GV3eVKlUUERGhadOmadmyZSpdurReeeWVOO/587B8//bbb5UvXz6VKVPGnkvffvutQx/3vnYuXLig2bNn64cfftBrr73m0O6dd95R3759VbduXS1fvlzDhg3TDz/8oMqVKzu89xg5cqQ6duyo4sWL65tvvtGECRO0a9cuVapUSf/884+9XYMGDfTHH38oNDRUP//8s6ZOnaoyZcrYczUhtcelRYsWKlSokJYsWaIPPvhACxYsUM+ePR2Ot3HjxvYvgX377beqWLGinn/++Yf2DSDxyN3UmbsJldAsGTBggAYMGKDnn39ey5Yt09tvv6033nhDBw4ceOg+XnvtNS1dulSDBg3STz/9pJkzZ6pOnTq6cOGCpDtT0VepUkUBAQH2fHnQvdVOnDih8uXL69tvv1WvXr20atUqjR8/Xj4+Pg/N9sOHD0uSChUqZF92+vRpVahQQT/++KMGDRqkVatWqWPHjho5cqTDl78iIyNVq1YtrVu3TqNHj9bixYuVPXt2vfLKK3Hu69atW2rSpImeffZZLVu2TEOGDFFMTIyaNm2qUaNGqXXr1lq5cqVGjRplH7C+fv26pDvvcRo2bCg3Nzf7+4BRo0YpY8aMunXrlqQ7H1Z37txZNWrU0LfffqulS5eqZ8+eioyMfODvYMGCBWratKkyZcqkhQsXatasWbp48aJq1qyp33//PVb7h+U4ADiL9x6p/72HM89XYh08eFCSHD6nRypk8ZW0SGbnz583VatWNZKMJOPq6moqV65sRo4caa5cueLQ9t7petq1a2fKlStnjDFmz549RpL55ZdfzNatWx0umT99+rSRZFq2bPnAOl555RUjyZw5cybWuoRMcRDfz2+//ebQT3ztateuHavPu5fvt2nTxmTMmNGcOnXKGPPgKQ6MMebvv/826dOnN71797avVwKnOLh9+7aJioqy/6xevdpIMgcPHnRYfv/0E3G5+3zd3ebUqVNm0KBBRpKZNm3aQ+u4evWqyZgxo5kwYYJ9+d3pDzp37uzQPjQ01Eiy/4727dtnJJmePXs6tPvyyy+NJIfpDVu2bGnc3d1NWFiYQ9v69esbT09PExERYYz5d7qHxo0bO7Tr0aOHkWS6devmsLxZs2bGz8/PYVlwcHCcz/+AAQOMMcZMmzbNSDKLFy922G706NFGkvnpp5/syyQZHx8fEx4e7tC2Xr16JmfOnObSpUsOy7t27Wo8PDzs7Rs1amRKly5tHoTpgoEnD7maOnN11KhRRpL54YcfYq27t5/7p3KKLyvuFx0dbaKioszQoUONv7+/iYmJMcY4l6d3c3LdunX2ZUWKFDFlypSJVVejRo1MYGCg/bgTmu/GPHy64Lh+2rdvb27fvm1ve/e47t/f5s2bjSTTv39/Y4wxFy9eNBkyZDANGjRwaBcWFmbc3d3tUzidP3/eSDLjx4+PVde9Hlb7vVM+3X1dhoaGOrTt3Lmz8fDwsD9HK1euNJLM1KlTHdqNHDnSSDIhISEPrAlA4pC7qTN3jXn4dMEJzZLw8HDj7u5uXnnlFYd2GzduNJIcciGuPPDy8jI9evR4YK0Pmi74/izo0KGDcXV1NXv37o23v7t1jB492kRFRZkbN26YHTt2mEqVKpnAwECH88O33nrLeHl5maNHjzr0MWbMGCPJ7NmzxxhjzOTJk40ks2rVKod2b731Vqxjvvtamz17tkPbhQsXGklmyZIlDsvv/ruZMmWKMcaYr7/+2kgyO3bsiPcYu3btanx9feNdb0zs9zbR0dEmKCjIlChRwuE1dOXKFZMtWzZTuXJl+7KE5jgAOIv3HmnjvUdCny9jnJsu+N5s/+OPP0z58uWNJLNy5cqH1ocnF1eypnL+/v767bfftHXrVo0aNUpNmzbVgQMH1K9fP5UoUSLOqxilO5fNb9u2TX/99ZdmzZql/Pnzq3r16o9ch/n/qfHunVbHGd27d9fWrVtj/ZQuXdqhXYYMGeJsN2XKlHj7Hj58uKKiohyuQnyQwoULq2PHjpo0aZLCwsKcOo7atWvL1dXV/lOnTh1JUoECBRyWd+jQIUH97dmzx75NYGCghg4dqn79+umtt95yaHf16lX17dtXBQoUkIuLi1xcXOTl5aXIyMhY0/FJinUlT8mSJSX9O7XBunXrJElt2rRxaPfyyy/Hmubi7o3Ec+XK5bC8ffv2unbtWqxvATdq1MjhcdGiRSVJDRs2jLU8PDw81pTBVatWjfX8d+7c2V5LxowZ9eKLL8aqRZLWrFnjsPzZZ59V5syZ7Y9v3LihNWvW6IUXXpCnp6fDN7waNGigGzduaNOmTZKkChUqaOfOnercubN+/PHHRN00HUDKQa6m7ly9344dOxz6cXV1jfUc358Vd61du1Z16tSRj4+P0qdPL1dXVw0aNEgXLlzQ2bNnJTmXp/c7ePCg/v77b/u292fSqVOntH//fodtHpbvCXHva2fdunX66KOPtHjxYodplu8e1918vatChQoqWrSoPW83btyo69evx2qXK1cuPfvss/Z2fn5+yp8/vz7++GN98skn2r59e7zfrHZWXL+TGzdu2J+jX3/9VdKd5+Re8U0rDSBpkbtpK3fvldAs2bRpk27evBnr7/QzzzyToCnvK1SooLlz52r48OHatGlTgq5YepBVq1apVq1a9vPYB+nbt69cXV3tt9TZvXu3VqxY4VD3d999p1q1aikoKMgh6+vXry/p35z69ddf5e3tHWumhQflVYsWLRwef/fdd/L19VXjxo0d9lW6dGkFBATYp/UtXbq03Nzc1KlTJ82bN0+HDh2K1XeFChUUERGhVq1aadmyZfH+W73X/v37dfLkSb322msOU3J6eXmpRYsW2rRpk8N0xNLDcxwAnMV7j7Tx3iOpn6+77s32smXLKiwsTNOnT1eDBg0S3TdSrgd/eoNUo1y5cvb7e0RFRalv374aN26cQkND45yytXr16ipYsKCmT5+uxYsXq0ePHnH+Uc+SJYs8PT3t09rE58iRI/L09JSfn98j1Z8zZ057/Q+SLl26BLW7V548edS5c2dNmjRJvXr1StA2gwcP1hdffKGBAwfGurfog0yfPt1hzvo//vhDb7/9tpYvX67AwED78ixZsiSov/z582vRokUyxujo0aMaPny4Ro4cqZIlSzrMId+6dWutWbNGAwcOVPny5ZUpUybZbDY1aNDAPuXPvfz9/R0eu7u7S5K97d2pkwICAhzaubi4xNr2woULDsd2V1BQkENfd93/GnFzc3vg8hs3bsjLy8u+3MfHJ97XwIULFxQQEBDrtZwtWza5uLjEquX+ui9cuKDbt29r4sSJmjhxYpz7uPtmq1+/fsqYMaO++OILTZs2TenTp1f16tU1evRop1+jAFIecjV+T2Ku5s6dW1LswcbChQtr69atkqTPPvtMM2bMiLVtXBm3ZcsWPffcc6pZs6ZmzJhhv4fa0qVLNWLEiEfK0/vdvV/be++9p/feey/ONvd/APCwfE+I+187NWvWlM1mU79+/fTjjz+qXr169uOKL//v/p4f1u7nn3+WdOeDhTVr1mjo0KEKDQ1V79695efnpzZt2mjEiBHy9vZOcP33S8h7HhcXl1j/1rJnz/7I+wTgPHI3fk9i7iaEs1kS19/lhPyt/uqrrzR8+HDNnDlTAwcOlJeXl1544QWFhobGyueEOHfuXLzTP96ve/fuevXVV3Xz5k1t2rRJH374oZo2baqdO3fa8+nMmTNasWJFrHuf33U36y9cuODU78DT0zPWlIhnzpxRRESE/Vw7vn3lz59fq1evVmhoqLp06aLIyEjly5dP3bp1U/fu3SXdmYb59u3bmjFjhlq0aKGYmBiVL19ew4cPV926dePs/2HPeUxMjC5evChPT0/78qR4bwMAceG9R/xSw3uPhD5fzrqb7enSpZOvr6/y5s2bJP0iZWOQNQ1ydXVVSEiIxo0bp927d8fb7vXXX9eHH34om82mdu3axdkmffr0qlWrln744QcdP348zpOJ48eP648//lD9+vWVPn36JDuOpPThhx9q9uzZ6t+/v4oXL/7Q9oGBgerRo4dGjRql3r17J3g/hQsXdnh89yrMEiVKJOhbtvfz8PCwB2H58uVVq1YtFS9eXD169FCjRo3k5eWlS5cu6bvvvlNISIg++OAD+7Y3b9585Lnw757InD59Wjly5LAvv3t/tvvbnjp1KlYfJ0+elJQ0J+AJ5e/vr82bN8sY4xBwZ8+e1e3bt2PVcn8IZs6cWenTp9drr72mLl26xLmPvHnzSrrzAXmvXr3Uq1cvRUREaPXq1erfv7/q1aunY8eOOZwYAniykauxPWm5WrNmTbm4uGj58uXq1KmTfXmGDBnsOfvdd9/FuW1cJ0yLFi2Sq6urvvvuO3l4eNiXL1261KGdM3l6v7uZ1a9fvzjvKy7F/v0kl7tXxO7cuVP16tWzH9epU6divYZPnjxpr/3edve7t50kBQcHa9asWZKkAwcOaPHixRo8eLBu3bqladOmJf1B/T9/f3/dvn1b4eHhDh9wnD59Otn2CeDByN3YnrTcTQhns+Tul4/udfr06YfWlSVLFo0fP17jx49XWFiYli9frg8++EBnz57VDz/84HTdWbNm1fHjxxPU9t4PwO/e9/XVV19VSEiIJk2aZK+vZMmSGjFiRJx93P3ysr+/v7Zs2RJrfXx5Fd8H//7+/vEe971faqpWrZqqVaum6Ohobdu2TRMnTlSPHj2UPXt2+xe+X3/9db3++uuKjIzUf//7X4WEhKhRo0Y6cOCAgoODY/X/sPcF6dKli3P2EABIbrz3iC01vPdIyPPlrIQObiN1YbrgVC6uN6eS7FPE3n1DHpd27dqpcePG6tOnj8MHf/fr16+fjDHq3LlzrJtxR0dH65133pExRv369XuEI3g8/P391bdvX3399ddxnpjEpW/fvvLz83MYuLSav7+/Ro0apTNnztivtLTZbDLG2L/RedfMmTMf+ebpNWvWlCR9+eWXDssXL14c6ybqtWvX1tq1a+2DqnfNnz9fnp6eeuaZZx6phkdRu3ZtXb16NdaH3PPnz7evfxBPT0/VqlVL27dvV8mSJe3farv3J64rj3x9ffXiiy+qS5cuCg8P15EjRyTxLVvgSUSuJsyTlquBgYHq0KGDVq5cqUWLFiW6P5vNJhcXF4cT4uvXr+vzzz93aOdMnt6vcOHCKliwoHbu3BlnHpUrV+6RrvB0d3d3Opd27Ngh6c7MENKdKZQl6YsvvnBot3XrVu3bt8+et5UqVVKGDBlitTt+/Lj9dgNxKVSokD788EOVKFFCf/75Z6Jqf5gaNWpIunOl072S4nUC4OHI3YR50nI3IRKaJRUrVpS7u3usv9ObNm1yajp86c7MFl27dlXdunUfOV/q16+vdevWxZqyPyHatGljnwXjbu2NGjXS7t27lT9//jiz/u6/gRo1aujKlStatWqVQ5/O5FWjRo104cIFRUdHx7mvuL68lT59elWsWFGTJ0+WJIff210ZM2ZU/fr1NWDAAN26dUt79uyJc/+FCxdWjhw5tGDBAvs0mZIUGRmpJUuWqFKlSnxZGUCy471HwqSG9x4Jfb6Ah+FK1lSuXr16ypkzpxo3bqwiRYooJiZGO3bs0NixY+Xl5WWfyiUuQUFBsQaj4lKlShWNHz9ePXr0UNWqVdW1a1flzp1bYWFhmjx5sjZv3qzx48ercuXKj3wcYWFh9ntd3itr1qzKnz+//XFMTEyc7SSpTJkysQYa79WjRw9Nnjw51klJfDJlyqQBAwaoZ8+eCWr/uLRt21affPKJxowZoy5duihTpkyqXr26Pv74Y2XJkkV58uTRr7/+qlmzZsnX1/eR9lG0aFG9+uqrGj9+vH0+/N27d2vMmDGxphwKCQmx30dm0KBB8vPz05dffqmVK1cqNDRUPj4+SXDUCdO2bVtNnjxZ7dq105EjR1SiRAn9/vvv+uijj9SgQQP7vP4PMmHCBFWtWlXVqlXTO++8ozx58ujKlSs6ePCgVqxYobVr10qSGjdurKeeekrlypVT1qxZdfToUY0fP17BwcEqWLCgpDvfurrbZ7t27eTq6qrChQsnatpDAMmLXP1XasvV8ePH6/Dhw2rTpo2WL1+upk2bKigoSNeuXdPff/+tRYsWycPDI97p+u7VsGFDffLJJ2rdurU6deqkCxcuaMyYMbF+X87kaVymT5+u+vXrq169emrfvr1y5Mih8PBw7du3T3/++af+85//OP17KFGihBYtWqSvvvpK+fLlk4eHhz2vJMfXTmRkpDZu3KiRI0cqODjYfkVt4cKF1alTJ02cOFHp0qVT/fr1deTIEQ0cOFC5cuWyP8e+vr4aOHCg+vfvr7Zt26pVq1a6cOGChgwZIg8PD4WEhEiSdu3apa5du+qll15SwYIF5ebmprVr12rXrl0OJ+gPq/1RPP/886pSpYp69+6ty5cvq2zZstq4caP9C1r33jMOQNIjd/+V2nJXki5fvqyvv/461vKsWbOqRo0aCcoSPz8/9erVSyNHjlTmzJn1wgsv6Pjx4xoyZIgCAwMf+Hf60qVLqlWrllq3bq0iRYrI29tbW7du1Q8//OAwS0SJEiX0zTffaOrUqSpbtuwDp1YcOnSoVq1aperVq6t///4qUaKEIiIi9MMPP6hXr14qUqTIA38no0ePVsWKFTVs2DDNnDlTQ4cO1c8//6zKlSurW7duKly4sG7cuKEjR47o+++/17Rp05QzZ061a9dO48aN06uvvqrhw4erQIECWrVqlX788UdJCcurli1b6ssvv1SDBg3UvXt3VahQQa6urjp+/LjWrVunpk2b6oUXXtC0adO0du1aNWzYULlz59aNGzc0e/ZsSbKfU7/55pvKkCGDqlSposDAQJ0+fVojR46Uj4+PypcvH+f+06VLp9DQULVp00aNGjXSW2+9pZs3b+rjjz9WRESERo0a9dBjAIDE4r3Hv1Lje497JfT5umvt2rX2C2fuxf1WIYNU7auvvjKtW7c2BQsWNF5eXsbV1dXkzp3bvPbaa2bv3r0ObWvUqGGKFy/+wP62bt1qJJk5c+bEWrdx40bz4osvmuzZsxsXFxeTLVs207x5c7Nhw4YH9tmuXTuTMWPGONcdPnzYSIr3p02bNg79PKjtP//849Dnxx9/HGt/n332mb39uXPnHlrjzZs3Td68eY0k06VLlwceZ1zWrVtnJJnDhw87ve2Dnq+VK1caSWbIkCHGGGOOHz9uWrRoYTJnzmy8vb3N888/b3bv3m2Cg4NNu3bt7NvNmTPHSDJbt26Ns85169bZl928edP07t3bZMuWzXh4eJhnnnnGbNy4MVafxhjz119/mcaNGxsfHx/j5uZmSpUqFes1dHcf//nPfxyWx1dTSEhIrOcpODjYNGzY8EG/NnPhwgXz9ttvm8DAQOPi4mKCg4NNv379zI0bNxzaPeg5PXz4sOnQoYPJkSOHcXV1NVmzZjWVK1c2w4cPt7cZO3asqVy5ssmSJYtxc3MzuXPnNh07djRHjhxx6Ktfv34mKCjIpEuXLtbvGEDKQ66m3lw1xpjo6Ggzf/58U7duXZMlSxbj4uJifHx8TIUKFczAgQPN8ePHHdo/qM7Zs2ebwoULG3d3d5MvXz4zcuRIM2vWrFj1JTRP48piY4zZuXOnefnll022bNmMq6urCQgIMM8++6yZNm2avY0z+X7kyBHz3HPPGW9vbyPJBAcHG2Pifu14eHiYQoUKmR49ephTp07F+l2OHj3aFCpUyLi6uposWbKYV1991Rw7dizW72rmzJmmZMmSxs3Nzfj4+JimTZuaPXv22NefOXPGtG/f3hQpUsRkzJjReHl5mZIlS5px48aZ27dvJ7j2e/+dxfU+4t7f1b3PUXh4uHn99deNr6+v8fT0NHXr1jWbNm0yksyECRNiHQ+ApEPupt7crVGjRrzHWqNGDWNMwrMkJibGDB8+3OTMmdO4ubmZkiVLmu+++86UKlXKvPDCC/Z29+fBjRs3zNtvv21KlixpMmXKZDJkyGAKFy5sQkJCTGRkpH278PBw8+KLLxpfX19js9nMvR+lSTIhISEO9Rw7dsx06NDBBAQEGFdXVxMUFGRefvllc+bMGYc64noOjTHmpZdeMi4uLubgwYPGGGPOnTtnunXrZvLmzWtcXV2Nn5+fKVu2rBkwYIC5evWqfbuwsDDTvHlz4+XlZby9vU2LFi3M999/bySZZcuW2ds96DUbFRVlxowZY0qVKmU8PDyMl5eXKVKkiHnrrbfsr8GNGzeaF154wQQHBxt3d3fj7+9vatSoYZYvX27vZ968eaZWrVome/bsxs3Nzf472LVrl71NfO9tli5daipWrGg8PDxMxowZTe3atc369esd2jiT4wDgDN57pO73Ho/yfN3Nlvh+Dh8+/NBsR+pmM+aeOTgAAAAAAA+0YMECtWnTRuvXr0/UN8wBAMnj8OHDKlKkiEJCQtS/f3+ry7HMRx99pA8//FBhYWFx3vcPAAAAicN0wQAAAAAQj4ULF+rEiRMqUaKE0qVLp02bNunjjz9W9erVGWAFgBRg586dWrhwoSpXrqxMmTJp//79Cg0NVaZMmdSxY0ery3tsJk2aJEkqUqSIoqKitHbtWn366ad69dVXGWAFAABIJgyyAgAAAEA8vL29tWjRIg0fPlyRkZEKDAxU+/btNXz4cKtLAwBIypgxo7Zt26ZZs2YpIiJCPj4+qlmzpkaMGPF/7d13dBTl28bxa9MJ6SEkhN4RpIOISBXERhEs2EBB/fnaRVERFQURRRDsBRERFcQKKFhAsYCA9BJ67wmEhCSk77x/ICtrEpIlmzxh8/2cw5Gd8uw9nDVXZu+ZZxQdHW26vFITGBioiRMnavfu3crMzFSNGjX0xBNP6OmnnzZdGgAAgMdiumAAAAAAAAAAAAAAcIGX6QIAAAAAAAAAAAAA4HxCkxUAAAAAAAAAAAAAXECTFQAAAAAAAAAAAABcQJMVAAAAAAAAAAAAAFzgY7qAknDv13GmSwBKlI8X10fA873et5HpElAMryzaaboEoEQt3XncdAlAifpqcGvTJaCY7pq1wXQJQIkKC/Q1XQJQol65pqHpElAMoxdsN10CUKLiDqaaLgEoUTMGtijSdnRqAAAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAXGmqyJiYnav3+/07KNGzfqjjvu0A033KDPPvvMUGUAAHg+chgAALPIYgAAzCGHAQDuYKzJet999+nVV191vI6Pj1fHjh31999/KzMzU7fffrumT59uqjwAADwaOQwAgFlkMQAA5pDDAAB3MNZkXbp0qXr37u14/fHHHysiIkJr1qzR7Nmz9eKLL+qtt94yVR4AAB6NHAYAwCyyGAAAc8hhAIA7GGuyHj58WLVr13a8/uWXX3TttdfKx8dHktS7d29t27bNVHkAAHg0chgAALPIYgAAzCGHAQDuYKzJGhISoqSkJMfr5cuX6+KLL3a8ttlsyszMNFAZAACejxwGAMAsshgAAHPIYQCAOxhrsl500UV6/fXXZbfb9eWXXyolJUXdunVzrN+6dauqV69uqjwAADwaOQwAgFlkMQAA5pDDAAB38DH1xqNHj1b37t31ySefKCcnR0899ZTCw8Md62fOnKnOnTubKg8AAI9GDgMAYBZZDACAOeQwAMAdjDVZW7RooU2bNmnJkiWKiYlRu3btnNYPGDBAjRs3NlQdAACejRwGAMAsshgAAHPIYQCAO9gsy7JMF+Fu934dZ7oEoET5eBmb6RsoNa/3bWS6BBTDK4t2mi4BKFFLdx43XQJQor4a3Np0CSimu2ZtMF0CUKLCAn1NlwCUqFeuaWi6BBTD6AXbTZcAlKi4g6mmSwBK1IyBLYq0ndFOTU5Ojl555RW1atVKQUFBCg4OVqtWrTR+/HhlZ2ebLA0AAI9HDgMAYBZZDACAOeQwAKC4jE0XnJ6erh49euivv/5S9+7d1alTJ1mWpc2bN+uJJ57QnDlz9NNPPykgIMBUiQAAeCxyGAAAs8hiAADMIYcBAO5grMk6duxY7du3T6tXr1azZs2c1q1du1a9e/fWSy+9pOeee85MgQAAeDByGAAAs8hiAADMIYcBAO5gbLrgmTNn6tVXX80TYpLUvHlzjR8/Xp999pmBygAA8HzkMAAAZpHFAACYQw4DANzBWJN17969uuiiiwpcf/HFF2vv3r2lWBEAAOUHOQwAgFlkMQAA5pDDAAB3MNZkDQkJUXx8fIHrDx8+rJCQkFKsCACA8oMcBgDALLIYAABzyGEAgDsYa7J27dpVL774YoHrX3rpJXXp0qX0CgIAoBwhhwEAMIssBgDAHHIYAOAOPqbeeOTIkWrXrp0uvvhiDR06VI0aNZIkxcXFaeLEiYqLi9PSpUtNlQcAgEcjhwEAMIssBgDAHHIYAOAOxpqsjRs31s8//6whQ4ZowIABstlskiTLstSoUSP9+OOPatKkianyAADwaOQwAABmkcUAAJhDDgMA3MFYk1U69QDxjRs3as2aNdq6daskqUGDBmrRooXS0tL0+++/q1OnTiZLBADAY5HDAACYRRYDAGAOOQwAKC6jTdbTWrRooRYtWjgt2759u7p27arc3FwzRQEAUE6QwwAAmEUWAwBgDjkMADhXXqYLAAAAAAAAAAAAAIDzCU1WAAAAAAAAAAAAAHABTVYAAAAAAAAAAAAAcIGxZ7LOmTPnrOt37dpVSpUAAFD+kMMAAJhFFgMAYA45DABwB2NN1r59+xa6jc1mK/lCAAAoh8hhAADMIosBADCHHAYAuIOxJqvdbjf11gAAlHvkMAAAZpHFAACYQw4DANyBZ7ICAAAAAAAAAAAAgAuM3ckK866+IEpXXxDltCw5I0fD52112qZDrTAF+nlrd2K6Pl9zWIdSMgscs0VssHo2rKSoin7y9rIpPjVLC7cd0/J9yY5t6kUGqkeDSFUPC1BYBV+999c+rT2U4v4DBP6jR/0I9WpSWYt2JOrr9fGSpGB/b/VuUlmNogJVwddbO46d1JfrjighLfusY1Xw9dI1F0SpWWywAn29dOxktr7dEK+4I2mSJH8fL119QSU1qxKsIH9vHUjK0Ffr47U3KaPEjxPA+WnN/M+14tuP1KRbH7W/8Z486//85HVt/mO+Lr7+bl3Y/doCx/luwuM6vHV9nuXVL2yrng+McrzX7tWLlXx4v7z9/BRdp7Ha9hussJhq7jsgQNINLavoxpaxTsuOn8zWnTPXSZLu71hTXetXclq/NT5Vw7/bUuCY3RtUUud6EaoRXkGStPPYSX264oC2Hz3p2MbLJt3YMlYd60YorIKvktKz9eu2Y/pyzSFZ7jo4AOe9Xk0qq3eTyk7LktOz9djcUz+DWlYNUee64aoRXkHB/j4a9dN27XPh9/m21UN1d/vqWn3ghN5evNex/MpGldSqWohigv2VlWtpx7GT+mrdYR1JyXLPgQEF2LbwC22aN111OvbShX3vkiTlZKYr7vtpOrxhmbLSUhQYUVm1O16j2pdcVeA4e5cv1JrPX8uz/OqXvpS3r58kyZ6bqy0/zdCBVYuUcSJJASHhqt72MjXofoNsXtzzASB/G36cpTVzpqlR1z5qc93djuXJh/dq1bdTFb9tgyzLUliVGuo45ElVjKic7zhJB/do7fefKHHvdqUlxqt1/7t0Qbe+TttkZ5zU2u8+0b41S5SRmqzwanXU5vr/qVLNBiV5iChn+jeP0XXNY5yWJaVn6/++2OhY375WmCIDfZVjt7QrMV2frz6kHWec3+bnygui1L1BpCpV9FNKZo6W7UnSzFWHlG0/dcbbqHJFXdOksupEBio80FcTft2lFWf0aOA+NFnLuYPJGXr9zz2O1/YzvnXq0SBS3epFaPrKgzqSmqUrG1bSA5fW0PM/71BmTv5TaqRl5eqHLUd1JCVTOXZLTWOCdVvrWKVk5mhT/Knmk5+Pl/YnZ+ivPUm6++LqJXp8wGk1wgJ0Sa0wHUh2/lLkznbVlGu3NHnZAWXk2NW1brju61BDLy7cqazc/L+G9bZJ915SXamZufpw+QElpWcrvIKvMs74/+KmFjGqEuKv6SsPKjkjR22rh+q+DtX14sJdSs7IKdFjBXD+Sdi9RZv/mK+IarXzXb97zRLF79qiwLDIQsfqfs8zsuf8e6FIZlqKvh59r2q37uhYdnjrejXu0ktRtRrInpurFbOn6YfXRqj/c+/J1z+g+AcEnGHv8XQ9/8O/F/HZ/xOvq/Yn660/djte5xSQv6c1qRKkP3ce15b4fcrOtatP0xg927O+Hv4mToknT332r20Wo8sbRemN33dpX1KG6lYK1P0da+lkVq6+j4t327EBOP8dSM7Qq7/tdry2W//+DPL38dL2oye1Yt8JDWpb1aVxIwJ9dX3zGG1NSMuzrkFURf26PVG7E9PlZbPp2qaV9UinWnr2h20FnoMAxXV87zbtWfqjQqrUclq+YfYUHd2+Tq1uHqrAiMqK37Ja679+VwEhEapy4cUFjucTEKhuT7zjtOx0g1WStv/6lfYsma+WNz2s4JgaStq3Xas/f12+AYGq06m3W48NgGc4umerti3+QWFVnc+LUxIO6cdXH1e99per+dW3yrdCoJIP73P6mfNfOdmZCoqMUc2Wl2rFV5Pz3Wbpp68r6eAeXTLoMQWGRmjn379q4esj1OuZdxQYVinffYBzse94usb8vMPx+szfNw+dyNBHy/crPiVLft5eurJxlJ7qXlcPfxOnlMzcfMfrUDtcA1pV0XtL9mpr/ElVCfHX/3WoIUmavuKgpFO/x+49nq7fdiRqaJf8v2uCe3DpWDmXa0knMnMdf1Kz/v0ft1u9CP2w5ajWHEzRoROZ+njlQfl5e6lt9ZACx9t29KTWHkzR4ZQsHU3L1q87EnXgxKkvtk6LO5KquXEJWnOQu1dROvy8bRrYJlYz1hzWyex/G6FRFX1VO6KCZq09rL1JGYpPzdKstUfk7+Ol1tUK/pxfXDNMFf28NXnZfu1KTNfx9BztTEzXwROn7vL29bKpeWywZm+M145j6Tqalq35m4/q2MlsXVo7rKQPF8B5JjsjXb9OeUUdb3tIfoFBedanHT+qJTPeVtchj8vL27vQ8QIqBiswNMLx50DcKvn4+Ts1Wa946AU1uKSHwmNrKrJ6HXUa9IhSE+N1dM82tx4bIEm5dktJ6TmOPyf+c7FRTq7z+jN/H83Pa7/t1o+bE7Q7MV0HkjP17uI9stlsahob7NimQVRF/b03Sav2n1BCapaW7k7S2gMnnH4nBQBJststncjIcfxJPePLrKV7kvRdXII2HUl1aUyb7dTFnHM2xutoat67U1/7Y4+W7E7SwROZ2p+coal/H1BkRT/V/OcOfcDdcjLTterTCWp+/f3y/c/vm8f3bFb1tt1UqV5TBUZEq1b7KxQSW1vJ+7YXMqpNASHhTn+cxt29WTEXtlN047YKjIhWbPMOqtyghZL2FzYugPIoOyNdiz96RRff/ECe8+I1cz9W1cZt1OrawYqoXlfBlaqo2oUXKSA4rMDxKtVsoNb9hqhWm87y9vHNsz4nK1N71yxWy2vvUHT9CxVcOVbNr75FQZHR2vrHPHcfHsq5XOvUDKKn/5zZPF2yK0kbDqUqPjVL+5Mz9MmKAwr083bM3JSf+lGB2hqfpiW7knQ0LUvrD6Voya7jqhP57/nu2oMpmrXmsP7ey92rJY0mazlXOchPL15ZX6N61tPgtlUVGXgqdCIDfRUa4KtNR/696jbHbmnb0ZOqE1H0L6caRlVUdJC/0/RtQGm7vnmMNh5O1dYE58+hj/epH4Fn3jFj6dRn/cxQ+q8LY4K0KzFd1zeP0QtX1NOT3WqrR4NI2f5Z7+Vlk7eXLc+dONm5Zx8XQPm0ZMZbqtG0rape0DLPOstu16Kp49Xs8usUHlvznMbfsvgn1WnT+ax3qGaln/r56F8xuMBtgHNVJcRfkwc01dvXX6hHutRWdLDzFedNYoL04U3N9Eb/JrqnQw2FBLg22Y6ft5e8vWxOjZHN8alqWiVYVUL8JUk1IyqoUXSQVu3nBBOAs8rB/nqlV0ONvaqB7rq4mipVzPtFrKt6Na6s1Mxc/bnreJG2r+B76iKqtEIuMgHO1bqv31V04zaKatAiz7qI2o11ZONypScfk2VZOrp9nVITDiqqYauzjpmbla6fXxiin0bdoWUfjFLy/h1O6yNqN1bCtnVKTTggSUo+uEvHdsWpcqPWbjsuAJ7j71nvqGqTtqrSyPm82LLbdWDD3wqOrqqFbz6jL564WfPHPaJ9a/8q1vtZ9lxZdru8fZzPTbz9/BW/I65YYwP/FRPsp7eva6LXrr1AD3SsqcpB+d+F7e1lU7f6kUrLytXe4+kFjrclPk21IwNV95/vmSsH+alF1RCtPnCiROrH2RmfLrhOnTr6+++/FRnpPP1dUlKSWrVqpZ07d551/8zMTGVmOj8jNDc766zTBeCUXYnpmrbigOJTsxTs76MrG1XSY11q64UFOxT6z5dbKZnOdxqkZOYoIvDsJ50BPl568aoG8vWyyW5ZmrnmsDbH550iCSgNraoGq3qov8b/tifPuiMpmTp2Mlu9mkRp5prDysqxq2u9CIUG+CjEv+C7xSpV9FVEYKBW7D+h9/7ap6ggP13fPEbeNumHLceUmWPXrmMn1bNRJR1ecVApGTlqXS1ENcMDlJDPleyAScXNYSn/LM7JypSPn79ba/VEO/5epKN7d6jPU3mfaSVJa3/8Ql5eXmrSrc85jR+/a4uOH9ytjgMfLnAby7K07Iv3FV2viSKq1jqn9wEKsi0hTW/8vlsHT2QorIKv+jevojFXN9LD32xUamauVu0/oSW7jishNUvRwf4a0CpWz1/ZQMNmb1LOf+cVLsCtbasq8WSW1h3894Tym3VHFOjrrdf7N5HdOvWM1s9WHtSfO4vW8ABKU0llMefFhdt17KQ+XLZfR1IzFeLvo6sbV9aT3epo5I/bz7nhWTcyUJfWDteon4p+t94NzWO0LSHNMTMO4E4HVv+u5P071enhCfmub9r3Lq354k39POoO2by8ZbPZ1PyGBxRZp3GBYwZFV1WLAQ8ppEot5WSc1M4/5urPN59Q50dfV1DUqWex1+vWX9kZafrl5Xtls3nJsuy64MpbVa1V5xI5TuBccU5s3u4Vvylx33Zd+fikPOsyUpKUk5mujT99oRa9blPLPrfr4KaV+m3yGPV4aKyi6zc9p/f0DQhUpdqNtP6HmQqNqa6AkDDtXvGbju7eouB/fo4B7rA9IU3vLE7XoROZCq3go2ubxuj5K+tr2JzNjguFW1YN0YOdasrPx0tJ6dl68eftBU4VLEl/7U5SSICPnruinmSzycfLpp+3HNWcDTwaxwTjd7Lu3r1bubl5PzCZmZk6cOBAofuPHTtWoaGhTn9WfZ3/POtwFnckVWsOpujgiUxtSUjT20v2SpLa1Qh1bJPfV1uFfd2VmWPX2IU79PKvOzVnY7z6N41WfaZmgwFhFXzUr2m0Pl55KN8vau2W9OGy/YoK8tPLVzfQ+F4NVb9SoDYeTs3zvLgz2Ww2pWTmaubqw9qXnKlVB1L005aj6lD73+mRpq88JJukF66op1d7N1TnuuFauf+ELB6xhDKmuDks5Z/Fv3z2rrtL9TipiQn66/P31GXwMPnk8yX40T3btPGX2ep0+6Oy2Wz5jFC4rYt/VHhsLVWu3bDAbZbMeFuJB3ap251PnNN7AGezev8JLd2TpL3HM7TuYIpe/PlU06FrvVNfYi3ZdVyr9p/QvqQMrdiXrBd+2qYqIf5qXT30bMM69GkarUvrROiVhTuVfcYMEh1qh6tT3UhNWrRLw2bH6c3fd6vPhdHqUi/C/QcJFFNJZfGabz9wd6keZ8PhVK06cEIHkjO1KT5Nr//zfOhLaoWd03j+Pl66s101fbziQKFTn592c6sqqhYWoMlL953TewJnk348Qeu/naxWtwwt8KKLnX98p+N7tuqiwU+r0yOvqknvwVr39btK2LqmwHEjajZS9dZdFRpbW5F1mqjNbY+rYlRV7frzO8c2B9f8of0rf1PrWx5V56ET1XLAw9q+6Fvt/Xuhuw8TKJaSyuHfZ77n7lI9UtrxBK348n11GPRYvj+nrH++SKve7GJd0O1aRVSvqwsvv0FVL2xb7Gl9Owx6TLIsfT1ioGY81FdbFs1VrTad5eVlvGUCD7L2YIqW703WvqQMbTiUqnG/nLpwo1Odf89N446k6snvtmjk/G1aeyBFD3WqddYZni6IDlLfptH6cNl+PfXdFk34dZdaVgvRtU2jS/x4kJexO1nnzJnj+PuPP/6o0NB/v0jJzc3VwoULVatWrULHGT58uIYOHeq0bNj8wq8wQl5ZuZYOJmeocpCf1v7zvNQQfx+n52YF+/so5T/P0fovS1JCWrYkaX9ypmJC/NWzYSVtO7q3xGoH8lM9LEAhAT4a1qWWY5m3l011IyuoY+1wDZ2zRfuSMzXu190K8PGSj5dNqVm5GtqppvYlZRQ47omMHOXaLacLDg6nZCk0wEfetlPz7B89ma3X/9wrP2+bAny8dCIzV7e3idWxk9kld8CAC9yVw1L+WfzW0qKdjJZnR/duU0ZKkr598QHHMstu1+FtGxS3aK7a9hus9JQkzRw+0Gn9si8/0IZfvtWAF6eddfycrAzt+Ps3te59W4HbLJnxtvauW6prHntFFcOjin9QQCEyc+zaezxdVULyn746KT1HR1OzHNP8nk3vC6PVv1mMnv9hm/b8ZyqlgW2r6Zv1h7X4n6k69x7PUKUgP/VrVkWLticW/0AANyjpLH54Ls89dFVWrqUDyZkFTuFWmMpBfqoU5Kf7L/13iv/T10m9e10TPTN/mxLS/p3Z5qaWVdQ8NkSv/LpTx9PPfp4NnIuk/TuUlZqs3yc+4lhm2e06tnOjdi3+Xle+MFOb5k/XRbcPV3TjtpKk0NjaSj6wS9sXfZPv9ML5sXl5Kax6faUdPehYtnHuR6rfrb+qtuwkSQqpUkvpx+O1feGXqtH2MvcdJHCOSjqHJ/zJxTNFkbh3uzJSkjTv5Yccyyy7XfHbN2jLb3M14NWvZfPyVmhMDaf9QmOqK6GY0/oGR1XR5Y+8rJzMDGVlnFRgaIT+mPKSKkbSqELJycyxa9/xDMWccc6bmWPXkZQsHUnJ0vajJ/Vq3wvUtV6EZhdwZ+oNLWL0x87j+vWfc9t9SRkK8PHSne2r69v1Rwq9SQ7uZazJ2rdvX8ffBw0a5LTO19dXtWrV0oQJ+U9lciZ/f3/5+zt/CcOUSOfGx8ummBB/bT92UsdOZis5I1sXVK6o/cmnmk3eNql+pUB9u/GIS+Pa/hkbKG1bE05q7ELniy5ublVF8alZWrD1mFPgZOTYJUlRFX1VIzxA8zYlFDjuzmMn1bp6qGz6987uykF+Sk7P1n8ew6qsXEtZubmq4OulRtEVmbYBZYa7cljKP4t9/I4Wu0ZPF9uohfo9+47Tst+nvaqwmOpq1vN6BYZGqFpj52dW/fD606rXrpsaXHJ5oePvXPGH7DnZqteuW551lmXpr5nvaPeaJbp66MsKrhRTvIMBisjHy6ZqYQHadCQ13/VB/t6KrOin4+lnvyipz4XR6t+iikb/uE07jp3Ms97fx8tx1ftpduvfZgdQFpR0FnNe7DofL5uqhPhr29Fze9zNoROZGvnDNqdlfZtGK8DHSzNXH1LiGT/bbmpZRS2rhmj8ol06msaFmCgZUfWbqctjbzgtW/P5awqqXE31uvaXZdll5eZINue7tmxeXnJlGibLsnTi4E4Fx/x7gUFuduap+fr/M+5/8xkwpeTPiZkquChiGjbXNSPeclq2ZPokhUZXU5PLr5O3r68ia9bXiSP7nbZJiT+oihGV3VKDj3+AfPwDlHkyRQc3rVKrvne4ZVwgPz5eNsWG+mtzfP7nxNI//RTvgu+o9sv3fNeS7fTORG2pMtZktdtPNTRq166tFStW5Jn3HiWv34XRWn84RYknsx3PZA3w8dKyPcmSpF+2J6pnw0qKT8tSfGqWrmhYSVm5dv2979/nXQ1qHaukjBzN3niqcdSzQaT2JGUoITVLPl42NYkJUrsaYZqx5pBjH39vm6LOuDI4sqKvqoX6Ky0rl6t34VaZOXYdSnF+BmpWrqW0rFzH8haxwUrNytXxk9mKDfFXv2bRWncoVZsT/v3C9tZWVZSckaO5cacar3/uTlKnOuHq1yxav+9IVFSQn3o0iNTvZzznrVHlirJJOpKapaiKvupzYWXFp2Rp6d7kkj9woAjIYfP8AgLzPAPVxz9A/hWDHcsDgkKc1nt5eyswJFxhMdUcyxZNHa+KYZFqe63zieCWxT+qZov2ecaQpCUz3tKO5YvU495n5RtQQSeTT1396FehIl8GwK0Gtq2qFfuSdTQ1S6EVfHRd8yqq4OutRduOKcDHSze0rKKlu5N0PD1blYP8dHPrqkrJzNGy3UmOMR7oVEuJaVn6dOWpu2P6NI3WTa1iNWnRLiWkZiqswqlTmoxsu+OiqRX7ktS/eRUlpGZpX1KGakcGqleTyvpl27FS/zcACkIWm3dd8xitO3jCcU58deMoBfh6ack/P4MC/bwVGeir0H+ma4sOPnUem5yR45jxafBFVXU8PUffrD+iHLuV57mq6f9MG3zm8ptbVVG7GmF6a/EeZeTYHdPBpWfnOk19DhSXT0CgQqrUdFrm7Rcgv8Bgx/LIuhcq7rup8vb1U4XwKB3bsVH7VvyqJn0GO/ZZ9dlEBYRGqPHVpxpRW36cofCaDVUxKtbxTNbkA7vUtN89jn1iGrfVtgVfKDAsSsExNZR8YKd2/DZbNS7qXgpHDhSOHC4bfAMCFRZby2mZj3+A/INCHMsbd++vPz98WZXrX6iY+s10MG6l9q9fph4PveTYZ/G0CQoMi1TLPrdLknJzspV86NSsivbcHJ1MOqbEfTvk619BwZVPPXP1YNxKybIUEl1NKQmHtOqbKQqpXFV12/co8eNG+XFL61it2p+so2nZCgnw0bVNo1XB11u/70iUv4+X+jaN1sp9yUpKz1aQv496NKykiIq+TufE/9ehho6fzNbM1ad6LKv2n9BVF0Rpd2K6th89qZhgP13foopW7k92XCPl7+OlmOB/v9+JCvJTzfAKSs3K0TEu8HMrY01WScrOzlatWrV07NgxgsyAsAo+uqNtVQX5+yg1M0e7EtP1yqJdjqtrf956TH7eXhrQIkaBvt7anZiuNxbvVeY/X15JUnigr+xnjOnnc2r7sAq+ys61dCQlUx/9fUArD/zbmK0RXkGPdKrleH1ds1N3z/y1J0nTVx4UUJpCAnx07YWVFRxwamrs5fuS9eNm5zvwwgN9nS4ASkrP0dtL9qlf02g92a22kjNy9NvO41qw9d8vbiv4eKlXkyiFBfgoLduutQdT9F1cwlmf9QqUNnLYM6Qmxud5Zmvykf06sn2jrnhoTL77bPrte0nS9xOcn8PaadBQNbiEE0q4T2RFPz3SpbaC/3kExbaENA3/brMS0rLk521TzfAK6lIvUoF+3kpKz9aGQyl6ddFOR7NUkipV9HO6SveKRlHy9fbSsMvqOr3X56sPatY/J50f/LVPN7WO1d2X1FBIgK+On8zWz1uO6oszLvwDygKy2KzwCj666+LqCvLzVkpmrnYmnpoJJ/GfR3y0iA3WHRf9e2HT/9qfmqpwzsZ4zf3nQuOIQD9XbviT9O9zqYd1reO0fOry/Y4GL1BaWt86TJvmfaxVn05Q1slUBYZH6YKrblWt9lc6tklPSnD6fTM7I01rv3xLmSeOy6dCRYXG1lGH+8YqvEYDxzZNr71bm3/4VOu+fleZKckKCI1QzfZXqGGPG0v1+ICzIYfPDzVaXKKLBtynjT99oRVfvKeQylXV6c6nVLleE8c2acedf06lJydq3ksPOl5vWvi1Ni38WpXrN9XlD59qzmann9TqOR/pZNJR+QUGq0aLDmrRe6C8vI22TOBhIgJ99UDHWgr299aJzBxtSzipZ+dv1dG0bPl62RQb4q9OXWop2N9HqZm52nHspJ7/YZtjdlHp9Dnxv2N+s+6wZFm6oUUVRQT66kRmjlbtS9bnqw87tqkTGahne9ZzvB7Ytqok6bftiXp3CY91dCebZXiejqioKC1ZskT169d325j3fl28+diBss6HB7CjHHi9byPTJZQLJZHDkvTKIp6PDs+29IzZCwBP9NXg1oVvBLcoqSy+a9YGt44HlDVhgb6mSwBK1CvXNDRdQrlQUjk8egHPRodniztY8HS3gCeYMbBFkbYz3qkZOHCgpkyZYroMAADKJXIYAACzyGIAAMwhhwEAxWH83vesrCx98MEH+vnnn9WmTRtVrFjRaf2rr75qqDIAADwfOQwAgFlkMQAA5pDDAIDiMN5k3bBhg1q1aiVJ2rp1q9O6/z5fDAAAuBc5DACAWWQxAADmkMMAgOIw3mT99ddfTZcAAEC5RQ4DAGAWWQwAgDnkMACgOIw/k/VM+/fv14EDB0yXAQBAuUQOAwBgFlkMAIA55DAAwFXGm6x2u12jRo1SaGioatasqRo1aigsLEyjR4+W3W43XR4AAB6NHAYAwCyyGAAAc8hhAEBxGJ8ueMSIEZoyZYpeeukldejQQZZlafHixXruueeUkZGhMWPGmC4RAACPRQ4DAGAWWQwAgDnkMACgOIw3WadNm6YPPvhAvXv3dixr3ry5qlatqnvvvZcgAwCgBJHDAACYRRYDAGAOOQwAKA7j0wUnJiaqUaNGeZY3atRIiYmJBioCAKD8IIcBADCLLAYAwBxyGABQHMabrM2bN9ebb76ZZ/mbb76p5s2bG6gIAIDygxwGAMAsshgAAHPIYQBAcRifLnjcuHG6+uqrtWDBArVv3142m01LlizRvn37NG/ePNPlAQDg0chhAADMIosBADCHHAYAFIfxO1k7d+6srVu36tprr1VSUpISExPVr18/bdmyRR07djRdHgAAHo0cBgDALLIYAABzyGEAQHEYv5NVkmJjY3mIOAAAhpDDAACYRRYDAGAOOQwAOFdlosmalJSk5cuXKz4+Xna73WndwIEDDVUFAED5QA4DAGAWWQwAgDnkMADgXBlvss6dO1e33HKL0tLSFBwcLJvN5lhns9kIMgAAShA5DACAWWQxAADmkMMAgOIw/kzWRx99VIMHD1ZKSoqSkpJ0/Phxx5/ExETT5QEA4NHIYQAAzCKLAQAwhxwGABSH8SbrgQMH9OCDDyowMNB0KQAAlDvkMAAAZpHFAACYQw4DAIrDeJO1Z8+eWrFihekyAAAol8hhAADMIosBADCHHAYAFIeRZ7LOmTPH8ferr75aw4YNU1xcnJo2bSpfX1+nbXv37l3a5QEA4NHIYQAAzCKLAQAwhxwGALiLzbIsq7Tf1MuraDfQ2mw25ebmujz+vV/HubwPcD7xKeL/Q8D57PW+jUyX4LFKOocl6ZVFO89pP+B8sXTncdMlACXqq8GtTZfg0Uoji++ateGc9gPOF2GBvoVvBJzHXrmmoekSPFZp5PDoBdvPaT/gfBF3MNV0CUCJmjGwRZG2M3Inq91uN/G2AABA5DAAAKaRxQAAmEMOAwDchdvhAAAAAAAAAAAAAMAFxpqsy5Yt0/z5852Wffzxx6pdu7YqV66su+++W5mZmYaqAwDAs5HDAACYRRYDAGAOOQwAcAdjTdbnnntO69atc7xev369hgwZou7du+vJJ5/U3LlzNXbsWFPlAQDg0chhAADMIosBADCHHAYAuIOxJuuaNWt02WWXOV7PnDlT7dq10+TJkzV06FC9/vrrmjVrlqnyAADwaOQwAABmkcUAAJhDDgMA3MFYk/X48eOKjo52vP7tt990xRVXOF63bdtW+/btM1EaAAAejxwGAMAsshgAAHPIYQCAOxhrskZHR2vXrl2SpKysLK1atUrt27d3rE9JSZGvr6+p8gAA8GjkMAAAZpHFAACYQw4DANzBWJP1iiuu0JNPPqk//vhDw4cPV2BgoDp27OhYv27dOtWtW9dUeQAAeDRyGAAAs8hiAADMIYcBAO7gY+qNX3jhBfXr10+dO3dWUFCQpk2bJj8/P8f6Dz/8UJdffrmp8gAA8GjkMAAAZpHFAACYQw4DANzBWJM1KipKf/zxh5KTkxUUFCRvb2+n9V988YWCgoIMVQcAgGcjhwEAMIssBgDAHHIYAOAOxpqsp4WGhua7PCIiopQrAQCg/CGHAQAwiywGAMAcchgAUBxFarLOmTOnyAP27t37nIsBAAD5I4sBADCHHAYAwCyyGABQFhWpydq3b98iDWaz2ZSbm1ucegAAQD7IYgAAzCGHAQAwiywGAJRFRWqy2u32kq4DAACcBVkMAIA55DAAAGaRxQCAssirODtnZGS4qw4AAHAOyGIAAMwhhwEAMIssBgCY5HKTNTc3V6NHj1bVqlUVFBSknTt3SpKeeeYZTZkyxe0FAgAAZ2QxAADmkMMAAJhFFgMAygqXm6xjxozRRx99pHHjxsnPz8+xvGnTpvrggw/cWhwAAMiLLAYAwBxyGAAAs8hiAEBZ4XKT9eOPP9b777+vW265Rd7e3o7lzZo10+bNm91aHAAAyIssBgDAHHIYAACzyGIAQFnhcpP1wIEDqlevXp7ldrtd2dnZbikKAAAUjCwGAMAcchgAALPIYgBAWeFyk7VJkyb6448/8iz/4osv1LJlS7cUBQAACkYWAwBgDjkMAIBZZDEAoKzwcXWHkSNH6rbbbtOBAwdkt9v19ddfa8uWLfr444/13XfflUSNAADgDGQxAADmkMMAAJhFFgMAygqX72Tt1auXPv/8c82bN082m03PPvusNm3apLlz56pHjx4lUSMAADgDWQwAgDnkMAAAZpHFAICywuU7WSWpZ8+e6tmzp7trAQAARUQWAwBgDjkMAIBZZDEAoCw4pyarJK1YsUKbNm2SzWbTBRdcoNatW7uzLgAAUAiyGAAAc8hhAADMIosBAKa53GTdv3+/brrpJi1evFhhYWGSpKSkJF1yySWaMWOGqlev7u4aAQDAGchiAADMIYcBADCLLAYAlBUuP5N18ODBys7O1qZNm5SYmKjExERt2rRJlmVpyJAhJVEjAAA4A1kMAIA55DAAAGaRxQCAssLlO1n/+OMPLVmyRA0bNnQsa9iwod544w116NDBrcUBAIC8yGIAAMwhhwEAMIssBgCUFS7fyVqjRg1lZ2fnWZ6Tk6OqVau6pSgAAFAwshgAAHPIYQAAzCKLAQBlhctN1nHjxumBBx7QihUrZFmWpFMPGX/ooYc0fvx4txcIAACckcUAAJhDDgMAYBZZDAAoK2zW6SQ6i/DwcNlsNsfrtLQ05eTkyMfn1GzDp/9esWJFJSYmlly1RXTv13GmSwBKlI+Xy9dHAOed1/s2Ml1CmXK+ZfEri3aaLgEoUUt3HjddAlCivhrc2nQJZcr5lsOSdNesDaZLAEpUWKCv6RKAEvXKNQ0L36gcOd+yePSC7aZLAEpU3MFU0yUAJWrGwBZF2q5Iz2SdNGlSMUoBAADFRRYDAGAOOQwAgFlkMQCgLCpSk3XQoEElXQcAADgLshgAAHPIYQAAzCKLAQBlUZGarAVJT0/P85DxkJCQYhUEAACKjiwGAMAcchgAALPIYgCASS4/2DEtLU3333+/KleurKCgIIWHhzv9AQAAJYssBgDAHHIYAACzyGIAQFnhcpP18ccf1y+//KK3335b/v7++uCDD/T8888rNjZWH3/8cUnUCAAAzkAWAwBgDjkMAIBZZDEAoKxwebrguXPn6uOPP1aXLl00ePBgdezYUfXq1VPNmjX16aef6pZbbimJOgEAwD/IYgAAzCGHAQAwiywGAJQVLt/JmpiYqNq1a0s6Nb99YmKiJOnSSy/V77//7t7qAABAHmQxAADmkMMAAJhFFgMAygqXm6x16tTR7t27JUmNGzfWrFmzJJ26gigsLMydtQEAgHyQxQAAmEMOAwBgFlkMACgrXG6y3nHHHVq7dq0kafjw4Y657x955BENGzbM7QUCAABnZDEAAOaQwwAAmEUWAwDKCptlWVZxBti7d69WrFihunXrqnnz5u6qq1ju/TrOdAlAifLxcvn6COC883rfRqZLOG+UxSx+ZdFO0yUAJWrpzuOmSwBK1FeDW5su4bxRFnNYku6atcF0CUCJCgv0NV0CUKJeuaah6RLOG2Uxi0cv2G66BKBExR1MNV0CUKJmDGxRpO2K3ampUaOG+vXrp4iICA0ePLi4wwEAABeRxQAAmEMOAwBgFlkMADDFbbfDJSYmatq0ae4aDgAAuIgsBgDAHHIYAACzyGIAQGljzlEAAAAAAAAAAAAAcAFNVgAAAAAAAAAAAABwAU1WAAAAAAAAAAAAAHCBzbIsqygb9uvX76zrk5KS9Ntvvyk3N9cthRVHRo7pCoCSFd72ftMlACUuffWbpksoc8hioOwgi+HpyOG8zqcclshieD6yGJ6OLM7rfMpichiejhyGpytqDvsUdcDQ0NBC1w8cOLCowwEAABeRxQAAmEMOAwBgFlkMAChritxknTp1aknWAQAACkEWAwBgDjkMAIBZZDEAoKzhmawAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgApqsAAAAAAAAAAAAAOACmqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADggnNqsk6fPl0dOnRQbGys9uzZI0maNGmSZs+e7dbiAABA/shiAADMIYcBADCLLAYAlAUuN1nfeecdDR06VFdddZWSkpKUm5srSQoLC9OkSZPcXR8AAPgPshgAAHPIYQAAzCKLAQBlhctN1jfeeEOTJ0/WiBEj5O3t7Vjepk0brV+/3q3FAQCAvMhiAADMIYcBADCLLAYAlBUuN1l37dqlli1b5lnu7++vtLQ0txQFAAAKRhYDAGAOOQwAgFlkMQCgrHC5yVq7dm2tWbMmz/L58+ercePG7qgJAACcBVkMAIA55DAAAGaRxQCAssLH1R2GDRum++67TxkZGbIsS8uXL9eMGTM0duxYffDBByVRIwAAOANZDACAOeQwAABmkcUAgLLC5SbrHXfcoZycHD3++OM6efKkbr75ZlWtWlWvvfaaBgwYUBI1AgCAM5DFAACYQw4DAGAWWQwAKCtslmVZ57rz0aNHZbfbVblyZXfWVGwZOaYrAEpWeNv7TZcAlLj01W+aLuG8QBYDZpDF8HTkcNGU1RyWyGJ4PrIYno4sLpqymsXkMDwdOQxPV9QcdvlO1jNVqlSpOLsDAIBiIosBADCHHAYAwCyyGABgkstN1tq1a8tmsxW4fufOncUqCAAAnB1ZDACAOeQwAABmkcUAgLLC5Sbrww8/7PQ6Oztbq1ev1g8//KBhw4a5qy4AAFAAshgAAHPIYQAAzCKLAQBlhctN1oceeijf5W+99ZZWrFhR7IIAAMDZkcUAAJhDDgMAYBZZDAAoK7zcNdCVV16pr776yl3DAQAAF5HFAACYQw4DAGAWWQwAKG1ua7J++eWXioiIcNdwAADARWQxAADmkMMAAJhFFgMASpvL0wW3bNnS6cHilmXp8OHDSkhI0Ntvv+3W4gAAQF5kMQAA5pDDAACYRRYDAMoKl5usffv2dXrt5eWlqKgodenSRY0aNXJXXQAAoABkMQAA5pDDAACYRRYDAMoKl5qsOTk5qlWrlnr27KmYmJiSqgkAABSALAYAwBxyGAAAs8hiAEBZ4tIzWX18fPR///d/yszMLKl6AADAWZDFAACYQw4DAGAWWQwAKEtcarJKUrt27bR69eqSqAUAABQBWQwAgDnkMAAAZpHFAICywuVnst5777169NFHtX//frVu3VoVK1Z0Wt+sWTO3FQcAAPIiiwEAMIccBgDALLIYAFBW2CzLsoqy4eDBgzVp0iSFhYXlHcRmk2VZstlsys3NdXeNLsvIMV0BULLC295vugSgxKWvftN0CWUOWQyUHWQxPB05nNf5lMMSWQzPRxbD05HFeZ1PWUwOw9ORw/B0Rc3hIjdZvb29dejQIaWnp591u5o1axbpjUsSIQZPR4ihPOCEMi+yGCg7yGJ4OnI4r/MphyWyGJ6PLIanI4vzOp+ymByGpyOH4emKmsNFni74dC+2LIQUAADlEVkMAIA55DAAAGaRxQCAssbLlY1tNltJ1QEAAIqALAYAwBxyGAAAs8hiAEBZUuQ7WSWpQYMGhQZZYmJisQoCAAAFI4sBADCHHAYAwCyyGABQlrjUZH3++ecVGhpaUrUAAIBCkMUAAJhDDgMAYBZZDAAoS1xqsg4YMECVK1cuqVoAAEAhyGIAAMwhhwEAMIssBgCUJUV+Jivz3QMAYBZZDACAOeQwAABmkcUAgLKmyE1Wy7JKsg4AAFAIshgAAHPIYQAAzCKLAQBlTZGnC7bb7SVZBwAAKARZDACAOeQwAABmkcUAgLKmyHeyAgAAAAAAAAAAAABosgIAAAAAAAAAAACAS8pckzUnJ0epqammywAAoFwihwEAMIssBgDAHHIYAOAKY03WefPmafr06U7LxowZo6CgIIWFhenyyy/X8ePHDVUHAIBnI4cBADCLLAYAwBxyGADgDsaarOPHj9eJEyccr5csWaJnn31WzzzzjGbNmqV9+/Zp9OjRpsoDAMCjkcMAAJhFFgMAYA45DABwB2NN1g0bNuiSSy5xvP7yyy/Vo0cPjRgxQv369dOECRM0d+5cU+UBAODRyGEAAMwiiwEAMIccBgC4g7Ema0pKiiIjIx2v//zzT3Xr1s3xukmTJjp48KCJ0gAA8HjkMAAAZpHFAACYQw4DANzBWJM1NjZWmzZtkiSlpqZq7dq16tChg2P9sWPHFBgYaKo8AAA8GjkMAIBZZDEAAOaQwwAAdzDWZL3uuuv08MMPa/r06brrrrsUExOjiy++2LF+xYoVatiwoanyAADwaOQwAABmkcUAAJhDDgMA3MHH1BuPHDlSBw8e1IMPPqiYmBh98skn8vb2dqyfMWOGevXqZao8AAA8GjkMAIBZZDEAAOaQwwAAd7BZlmWZLsLdMnJMVwCUrPC295suAShx6avfNF0CioEshqcji+HpyOHzH1kMT0cWw9ORxec3chiejhyGpytqDhu7k/VM69at09atW2Wz2VS/fn01a9bMdEkAAJQb5DAAAGaRxQAAmEMOAwDOldEm6/LlyzVkyBDFxcXp9A21NptNTZo00ZQpU9S2bVuT5QEA4NHIYQAAzCKLAQAwhxwGABSXl6k3jouL02WXXaYKFSrok08+0apVq7Ry5UpNnz5d/v7+uuyyyxQXF2eqPAAAPBo5DACAWWQxAADmkMMAAHcw9kzW66+/Xrm5ufrqq69ks9mc1lmWpX79+snX11ezZs1yeWzmvIenY857lAc8f6ZklWQOS2QxPB9ZDE9HDpc8shgoHrIYno4sLlnkMFA85DA8XZl/JuuiRYs0f/78PCEmnZqW4amnntJVV11loDIAADwfOQwAgFlkMQAA5pDDAAB3MDZdcEpKiqKjowtcHxMTo5SUlFKsCACA8oMcBgDALLIYAABzyGEAgDsYa7LWqlVLy5cvL3D9smXLVLNmzVKsCACA8oMcBgDALLIYAABzyGEAgDsYa7LeeOONGjp0qDZs2JBn3fr16/XYY49pwIABBioDAMDzkcMAAJhFFgMAYA45DABwB5tlWZaJN87IyNBll12mZcuWqUePHrrgggskSXFxcVqwYIEuuugi/fLLLwoICHB9bB4sDg/Hg8VRHhT14eI4NyWZwxJZDM9HFsPTkcMljywGiocshqcji0sWOQwUDzkMT1fUHDbWZJWkrKwsTZw4UTNmzNDWrVslSQ0aNNCAAQP0yCOPyN/f/5zGJcTg6QgxlAecUJa8ksphiSyG5yOL4enI4dJBFgPnjiyGpyOLSx45DJw7chie7rxosp7Nvn37NHLkSH344Ycu70uIwdMRYigPOKE0qzg5LJHF8HxkMTwdOWweWQycHVkMT0cWm0UOA2dHDsPTFTWHjT2TtTCJiYmaNm2a6TIAACiXyGEAAMwiiwEAMIccBgAURZltsgIAAAAAAAAAAABAWUSTFQAAAAAAAAAAAABcQJMVAAAAAAAAAAAAAFzgY+qN+/Xrd9b1SUlJpVMIAADlEDkMAIBZZDEAAOaQwwAAdzDWZA0NDS10/cCBA0upmvJpyuT3tPDnn7Rr1075BwSoRYuWenjoY6pVu44kKTs7W2++Pkl//vG79u/fp+CgILVrf4keeuRRVa4cfdaxT5w4oTdfm6iFC37WiRPJqlqtmh4d9qQ6durs2ObIkSOa9OorWvzHH8rMzFDNmrX03OgxatzkwhI9bpQfm79/XjVjI/Msf/fz3/XIS7OUvvrNfPd7auI3mvjxwnzX9enWXMOG9FTd6pXk6+Ot7XsT9Nr0hZrx/d/5bv/Y4Ms1+oHeevPTXzVs/FfnfjCAm5HDZcPKFX/row+naFPcBiUkJGji62+p22Xd89121HPP6qsvPtewJ4br1oG3F2n8+fO+15PDhqprt8s06Y23ndaRwygN3t5eevp/V2nAVW0UHRmiw0dPaPrcpXpp8o+yLEuS9P7zt+q23hc77bd83S51HjShwHFv7dVOk0fdlmd5WLuHlZmVk2c5eYyyiCwuGwrL4mNHj2rSq+P115I/lZKSolat2+jJEc+oZs1aBY45+5uv9ezTw/MsX75qnfz9/SVJOTk5evetN/T993N17OhRVYqKUu8+1+rue+6VlxeTjsE9ipLDkjTif1dpSP8OCguuoL837NHDYz/Xpp2Hi/Qe1/dsrY9fukNzf12rG4ZOdix/bPDl6tutuRrUilZ6ZraWrd2pEa/N1rY98W4/TuBckMNlQ2E5/MxTT2rO7G+c9mnarLk+mTGrwDGLksOFfS8OuEtRs/i0N0YM0J3XXaphr3ypNz9bVKT3KCiLXX1vnBtjTdapU6eaemv8Y8Xfy3XjTbeoSdOmys3J1RuvT9Q9dw3R13O+V2BgoDIyMrR5U5zuvuf/1LBhI504cULjXnpRD93/f5ox6+sCx83OytI9d96hiMhIjZ/4mqJjYnT40CFVrBjk2OZEcrJuv/Umtbmond56d7IiIiO0f98+BQeHlMaho5y49NZX5O1lc7xuXC9W8959QF//vFqSVKu78y9cl3doondH3qxvFq4pcMzE5JMa98EP2rL7iLKyc3VVxwv1/nO3KiExVQv+2uS0bevGNTSk3yVat3W/+w4KcBNyuGxITz+phg0bqs+1/fToww8UuN0vCxdow7q1iqpcuchjHzx4QK+Of1mtWrfJs44cRml59PYeuvO6S3XXs9MVt+OQWjepofeeu1UnUjL01oxFju1+XLxR/xv5ieN1VnZuoWMnp6Sr+bWjnJbl12Alj1FWkcVlw9my2LIsPfzgffLx8dGkN95WUFCQPp72kf435A7HeXNBgoKCNPu7H5yWnf5iV5KmTpmsL2bN1OgXX1bdevUUt2GDnn16uIKDg3XLbYPce5Aot4qSw4/e3l0P3tpVd4/8RNv2xOvJu67Q9+8+oGZ9Ryn1ZOZZx69RJVxjH+mrP1dtz7OuY6t6evfz37Vy4x75+Hjruft66bt37lfLfi/oZEZWSRwu4BJyuGwoyjlxh0s7atQLYx2vfX19Cx23sBwu7HtxwF2Kek4sSb26NFPbprV0MD6pyOOfLYtdeW+cO2NNVpj3zvtTnF6PemGsunZsr01xG9W6TVsFBwfrvQ+cf+F48qmndcuA63Xo4EFViY3Nd9xvvvlKySeSNe3TmY7Qi42t6rTNh1MmKzomRqPH/BuQVatWc8dhAQ5Hj6c6vX7sjgu1Y2+C/li5TZJ05FiK0/peXZrqt7+3afeBYwWOeXrf096asUi39GqnS1rWcWqyVqzgp6kv3q57R8/Qk3deUdxDAeChLu3YWZd27HzWbY4cOaKxY0bpnfen6IH/+1+Rxs3NzdXwxx/T/933gFavXKmUlBNO68lhlJZ2zWrru9/W6Yc/N0qS9h5K1A1XtFGrxjWctsvKysmTy4WxZBW6D3kMoDBny+I9e3Zr3do1+mr2d6pXr74kacQzI9W14yX6Yd736nfd9QWOa7PZVCkqqsD1a9euUZdul6lT5y6STuXw/Hnfa+PGDed+MMB/FCWH77u5q8ZN+VGzf1krSbrzmenas/BF3XhlG035anGBY3t52TR1zO0a/e48dWhZV2HBFZzW97nfeRaV/z33ifb98pJaNq6uxat2uOsQAZzninJO7Ofnd9ZMzU9hOVzY9+KAuxT1nDg2KlQTn7xeve59S9+88X9FGruwLC7qe6N4mIMGDqkpp76kCjnLdBmpqamy2WwKDin4Tpfffv1FzZq30NgXRqlrp0vUr881+uD9d5Wbm+u0TZMmF+qxRx5Ul47tdUP/vvrqi4KneQCKy9fHWwOuaqtps//Kd33liGBdcemFmvZt/usL0uWiBmpQq7L+XOl8kjhp+I364Y8N+nXZlnOuGQDsdrtGPDlMt98xxPHlblG8985bCo+IUL/++X/5Sw6jtPy1Zoe6XtRQ9Wqcugu7aYOqat+ijn5cvNFpu45t6mvPwrFa9+2zeuuZmxQVHpTfcE6CKvhry7xR2v7DaH312j1q3jDvhQLkMYDiyM46dbedv9+/d754e3vL19dXq1etPOu+J0+e1BXdu6pHt066/97/adOmOKf1LVu21vKlS7V79y5J0pbNm7V69Up1LOSLZsAVheVwraqRqhIVqgV/bXbsk5Wdoz9WbtfFzc8+ZeZTd1+po8dTi3wOHRIUIEk6nnzyXA4FQDm24u/l6tKxvXpd1VPPP/u0jh0r+OaI0wrL4f8qyvfiwLkoyjmxzWbTlBcGauK0hUWerl8qPIuLej6O4uFOVkg6NQ3S+HFj1bJVa9Wv3yDfbTIzM/XaxPG68uprFBRU8Bdf+/fv08FlS3XVNb301jvva8+ePRr7wijl5OTonnvvd2wz6/MZum3QHRpy9z3asH6dXh77gvz8/NSrT9+SOESUc727NlNYcAV9MndZvutv7dVOKScz9O0vawodKyQoQDt+HCN/Xx/l2u16aOzn+mXZvyel1/dsrRaNquvSW8e5q3wA5dTUKZPl7eOjm28t+rOAVq9aqW++/lKzvvq2wG3IYZSW8VN/VkhQBa395mnl5lry9rZp5FvfadYP/zYnflocp69/Xq29hxJVq2qknr33Gs1//0FdcvM4ZWXnnf5XkrbuPqK7Rn6ijdsPKqRigO67uYt+mTpUFw0Yqx17EySRxwCKr1btOoqNrarXJ03QMyNHqUKFCvp42kc6ejRBCQkJBe5Xu04djRozVvXrN1RaWqo+nf6xbr/1Js36erbjWa6D77xLqakp6nvNlfL29lZubq4eeOgRXXn1NaV0dCgPCsvhmEqnLqCPT3SeGSL+WIpqVIkocNz2zevo9r7t1W7AS0Wu5eVH+2vxqu2K23HoHI4EQHnVoWMn9eh5harExurA/v16+43XdNfgQZr5xdfy8/PLd5+i5PCZivK9OHCuinJO/OgdPZSTa3dpCt+iZHFR3hvFd943WTMzM5WZ6fyMCMvb32mOdRRu7AujtG3rVn00/bN812dnZ+uJxx6R3W5pxDPPnXUsu91SRESknn1utLy9vdW4yYVKiI/XtKlTHE1Wu91Skwsv1IMPD5UkXXBBY+3Yvl2zPp/Bl7soEYP6XqIfF8fpUEJyvusH9rlYn89fke+z3P4rJS1T7QaMVVAFf3Vt11AvP9pPu/Yf0x8rt6ladJheGdZfve59q0hjAZ6ALC4ZcRs36NPpH2vml1/LZrMVvoOktLRUPfXkMI18frTCwwv+YowcRmm5vmdr3XRVW93+1DTF7TikZg2r6pXHrtOhhGR9+s+FT1/+tMqxfdyOQ1oVt1db5o3SlR2bOKYu/K/l63dr+frdjtdL1uzUXzOe0L0DOuvRcV+Sxyh3yOKS4evrqwmTXtdzz4xQx0sukre3t9pd3F6Xdux01v2aNW+hZs1bOF63aNlKA667VjM+/URPPvW0JOmH+fP0/XdzNHbcBNWrV0+bN2/SKy+NVVRUZfXue21JHhbKkaLksHSqwXAmmy3vstOCAv314ZiBunf0DB1LSitSHROfvEFN68fqsjsmnvvBAGUYOVxyrrjyKsff69dvoCYXXqgrunfT778tUvcel+e7T1Fy+EyFfS8OFEdhWdzyguq676YuuuTml4s8ZlGzuKi/B6B4zvsm69ixY/X88887LRvxzEg9/exzZgo6D40dM1qLFv2iD6d9ouiYmDzrs7OzNezRh3Vg/35NnjrtrHexSlJUVJR8fHzk7e3tWFanbh0dPZqg7Kws+fr5KSoqSnXq1nXar06dOlrw84/uOSjgDDWqhKtbu4Ya8NjkfNd3aFlXDWvH6LYnp+a7/r8sy9LOfUclSeu2HlDD2jEaNvhy/bFym1peUEPRkSFa8unjju19fLx1aau6uufGTgpt97Ds9vxPVoHzFVlcMlatXKHExGO6ontXx7Lc3FxNeOVlfTr9Y83/+Zc8++zbu08HDxzQg/f9+/wOu90uSWrVrLFmf/eDqteoQQ6j1Lz4cF+Nn/qzvvjx1JWyG7cfVI0qERp2R48CT+oOHz2hvYcSVa9G0Z+7ZFmWVm7co7r/7EMeo7whi0tO4yYXatbXs5WSkqLs7GxFRETolgHXq0mTC4s8hpeXl5pc2FR79+x2LJs4YZwGD7lbV151tSSpfoOGOnTwoKZ88B5NVrhNYTl8+OgJSVJ0ZIjj75IUFRGc5+7W0+pUq6RaVSvpq0n/cyzz8jp1QWDK36+p2bWjtWv/Uce6V5+4Xtd0bqruQybpQHySuw8RKBPI4dITFVVZsbGxTplamPxy+LTCvhcHiquwLO7Qsq4qRwRp67xRjn18fLz10tB+uv+Wrmp09cg8YxY1i8/lfByuM95knTNnTr7LbTabAgICVK9ePdWuXbvA/YcPH66hQ4c6LbO8uUqoKCzL0tgxo/XLwp815aPpqlatep5tTjdY9+7Zow+mfqywsPBCx23RspXmf/+d7Ha7vLxOPfZ3z+7dioqKku8/0zi0aNlKu3ftctpvz+7dio2t6oYjA5zd1ru94hNTNP+P/OebH9S3vVbG7dX6rQfOaXybTfL3O/Xj9NflW9T6ujFO699//lZt2XVEEz76mS90UeYUN4clsrikXNO7j9q1v8Rp2f/dPUTX9Oqjvtf2y3ef2nXq6Mtv5zote+v1SUpLS9Pjw0co5p+TRnIYpaVCgJ/slt1pWa7dcvyOmJ+I0IqqFh2uQ2d82VsUzRtW04ZtByWRxzi/kMXnh+DgYEnSnj27Fbdxg+574KEi72tZlrZs3qR6Df6dgjAjPcPxZdhp3t7e/HyCWxWWw7sPHNOhhGRddnEjrd2yX5Lk6+Otjq3r6enXZuc75pbdR/Jk7HP3XaOgwAA99sqX2n/4uGP5xCeuV+9uzXX5Xa9pz8HCn6EImEAOn1+Sko7r8OFDioqqXOR98svhonwvDrhDYVn82fd/65dlW5zWz337Pn32/XJ9PHtpvmMWNYvP5XwcrjPeZO3bt69sNls+U5OcWmaz2XTppZfq22+/VXh43gafv3/eqRcymBGsSF4c/bzmz/tOk954WxUDK+roP8+UCQoOVkBAgHJycvTYIw9q06Y4vfHWe7Ln5jq2CQ0NdTRMRwx/XJUrR+uhRx6VJN1w402a8el0vTx2jG665dZTDdrJ7+nmW25zvPetAwdp0K036YP339XlPa/UhvXr9OWXs/Tsc6MEuJPNZtPAPhfr0++WKTfXnmd9cMUA9evRUk+++k2++38w+jYdjE/Ws2+c+qX7scGXa9XGvdq5P0F+vj664tImuuXqdnpw7ExJUurJzDzPmElLz1JichrPnkGZVNwclsji4jiZlqa9e/c6Xh/Yv1+bN21SaGioqsTG5rm4ydfHV5UqVVKt2nUcy87MYX9//zzPkAkOPvWsrTOXk8MoLfN+X68nhvTUvkPHFbfjkFo0qqYHb+2qj789dbJYsYKfnr7nan27cI0OJSSrZmykRj3QS8eSUjXnjKmC/5vHT919pZav363te+MVUjFA997URc0aVNPDY2dJIo9xfiGLzSosi3/6cb7CwyNUpUqstm3bonFjX1TXbt11SYdLHfv895z43bffVNNmzVWzZi2lpqbqs08/1pYtmzX86X/vROjcpasmv/+uYqrEqm69etq8aZOmT5uqPtf2L72Dh8crLIcl6a3PftWwIZdr+954bd+boMeH9FR6RrY+n7/Csc2ZOZyZlZMnS5NS0iXJafmk4Tfoxivb6PpH3ldqWoaiI09dqJCcmqGMzOySPGzAJeSwWWfL4dDQUL3z9pvq3uNyVYqK0sEDB/TGaxMVFh6ubt27O/Y5lxwu7HtxwF0Ky+LE5DQlJjtP+Zudk6sjR09o2554x7JzyeKi/B6A4jPeZP355581YsQIjRkzRhdddJEkafny5Xr66af1zDPPKDQ0VP/73//02GOPacqUKYar9SyzPp8hSRpy+21Oy0e9MFZ9ru2nI0cOa9Gvp6YivKF/H6dtPpj6sdpe1E6SdPjQIXnZ/r36IaZKFb07+UO98vJYXX9tb1WOjtYttw7UHUPucmxzYdNmevW1N/X6pFf13jtvqWq1anr8iad09TW9S+RYUX51a9dQNapEaFoB4XF9z9ayyaZZP6zId331mAinq8krBvjptaduUNXKYUrPzNbW3Uc0+OlpTs+TA84n5LBZGzdu0J13DHS8Hj9urCSpd59rNfrFl4o0xn9zuCjIYZSWoS9/oZH3XqPXnrpRUeFBOpSQrClfLtaL78+XdOoq2ib1YnXzNRcpLLiCDh89od/+3qrbnvhQqSf/fa7Vf/M4LLiC3nrmJkVHBis5NUNrN+9XjzsnacXGPaV+jEBxkcVmFZbFCQkJGj/uJR07ekxRUVG6pncf/e+ee53G+G8Wp5w4odHPPaujRxMUFBysRo0a68Npn6hps2aObZ4c8bTeev01vTj6eSUmHlNU5cq67vob9b//u6+EjxjlSWE5LEkTPlqgAH8/TRp+o8JDAvX3ht265v/ePGsOF8X/bjj17OKfP3jYafldz07XJ0xRiDKEHDbrbDk84tnntG3rVs2d861STqQoKipKbS9qp3HjJ6pixX8fZ3cuOVzY9+KAuxQli4viXLLYXe+Ns7NZBT3JvpRceOGFev/993XJJc7T4S1evFh33323Nm7cqAULFmjw4MFOV7WcDVcKwdOFt73fdAlAiUtf/abpEsqFkshhiSyG5yOL4enI4dJDFgPnhiyGpyOLSwc5DJwbchierqg5bHzy5R07digkJCTP8pCQEO3cuVOSVL9+fR09erS0SwMAwOORwwAAmEUWAwBgDjkMACgO403W1q1ba9iwYUr4Z95zSUpISNDjjz+utm3bSpK2bdumatWqmSoRAACPRQ4DAGAWWQwAgDnkMACgOIw/k3XKlCnq06ePqlWrpurVq8tms2nv3r2qU6eOZs+eLUlKTU3VM888Y7hSAAA8DzkMAIBZZDEAAOaQwwCA4jD+TFZJsixLP/74o7Zu3SrLstSoUSP16NFDXl7ndqMtc97D0zHnPcoDnj9TetydwxJZDM9HFsPTkcOliywGXEcWw9ORxaWHHAZcRw7D0xU1h8tEk9XdCDF4OkIM5QEnlOc3shiejiyGpyOHz39kMTwdWQxPRxaf38hheDpyGJ6uqDlsfLpgSVq4cKEWLlyo+Ph42e12p3UffvihoaoAACgfyGEAAMwiiwEAMIccBgCcK+NN1ueff16jRo1SmzZtVKVKFdlsNtMlAQBQbpDDAACYRRYDAGAOOQwAKA7jTdZ3331XH330kW677TbTpQAAUO6QwwAAmEUWAwBgDjkMACiOc396t5tkZWXpkksuMV0GAADlEjkMAIBZZDEAAOaQwwCA4jDeZL3zzjv12WefmS4DAIByiRwGAMAsshgAAHPIYQBAcRifLjgjI0Pvv/++FixYoGbNmsnX19dp/auvvmqoMgAAPB85DACAWWQxAADmkMMAgOIw3mRdt26dWrRoIUnasGGD0zoeNA4AQMkihwEAMIssBgDAHHIYAFAcxpusv/76q+kSAAAot8hhAADMIosBADCHHAYAFIfxZ7Keaf/+/Tpw4IDpMgAAKJfIYQAAzCKLAQAwhxwGALjKeJPVbrdr1KhRCg0NVc2aNVWjRg2FhYVp9OjRstvtpssDAMCjkcMAAJhFFgMAYA45DAAoDuPTBY8YMUJTpkzRSy+9pA4dOsiyLC1evFjPPfecMjIyNGbMGNMlAgDgschhAADMIosBADCHHAYAFIfNsizLZAGxsbF699131bt3b6fls2fP1r333ntOUzRk5LirOqBsCm97v+kSgBKXvvpN0yWUCyWRwxJZDM9HFsPTkcOlhywGzg1ZDE9HFpcOchg4N+QwPF1Rc9j4dMGJiYlq1KhRnuWNGjVSYmKigYoAACg/yGEAAMwiiwEAMIccBgAUh/Ema/PmzfXmm3k7wm+++aaaN29uoCIAAMoPchgAALPIYgAAzCGHAQDFYfyZrOPGjdPVV1+tBQsWqH379rLZbFqyZIn27dunefPmmS4PAACPRg4DAGAWWQwAgDnkMACgOIzfydq5c2dt3bpV1157rZKSkpSYmKh+/fppy5Yt6tixo+nyAADwaOQwAABmkcUAAJhDDgMAisNmWZZluoj87Nu3TyNHjtSHH37o8r48WByejgeLozwo6sPFUTKKk8MSWQzPRxbD05HD5pHFwNmRxfB0ZLFZ5DBwduQwPF1Rc9j4nawFSUxM1LRp00yXAQBAuUQOAwBgFlkMAIA55DAAoCjKbJMVAAAAAAAAAAAAAMoimqwAAAAAAAAAAAAA4AKarAAAAAAAAAAAAADgAh9Tb9yvX7+zrk9KSiqdQgAAKIfIYQAAzCKLAQAwhxwGALiDsSZraGhooesHDhxYStUAAFC+kMMAAJhFFgMAYA45DABwB2NN1qlTp5p6awAAyj1yGAAAs8hiAADMIYcBAO7AM1kBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU0WQEAAAAAAAAAAADABTRZAQAAAAAAAAAAAMAFNFkBAAAAAAAAAAAAwAU2y7Is00Xg/JaZmamxY8dq+PDh8vf3N10O4HZ8xgGUZfyMQnnA5xxAWcbPKHg6PuMAyjp+TsHT8Rkvu2iyothOnDih0NBQJScnKyQkxHQ5gNvxGQdQlvEzCuUBn3MAZRk/o+Dp+IwDKOv4OQVPx2e87GK6YAAAAAAAAAAAAABwAU1WAAAAAAAAAAAAAHABTVYAAAAAAAAAAAAAcAFNVhSbv7+/Ro4cyQOX4bH4jAMoy/gZhfKAzzmAsoyfUfB0fMYBlHX8nIKn4zNedtksy7JMFwEAAAAAAAAAAAAA5wvuZAUAAAAAAAAAAAAAF9BkBQAAAAAAAAAAAAAX0GQFAAAAAAAAAAAAABfQZC0nbDabvv32W9NlAABQLpHDAACYRRYDAGAWWQzAE9Fk9QDx8fH63//+pxo1asjf318xMTHq2bOn/vrrr1J5/6IGZGHbbdy4UTfccIOioqLk7++v+vXr65lnntHJkyedtlu9erWuueYaVa5cWQEBAapVq5ZuvPFGHT16tJhHgrLu9ttvV9++fU2XkUdhdaWnp2vkyJFq2LCh/P39ValSJV133XXauHGj03ZpaWl64oknVKdOHQUEBCgqKkpdunTRd999V8JHAKA4yGFyuLwghwGUVWQxWVxekMUAyiqymCwuD8hh5MfHdAEovv79+ys7O1vTpk1TnTp1dOTIES1cuFCJiYkl+r5ZWVny8/Nzy1hLly5V9+7d1b17d33//feKjo7W8uXL9eijj+qXX37Rr7/+Kj8/P8XHx6t79+7q1auXfvzxR4WFhWnXrl2aM2dOnrADyoLMzEx1795de/fu1YQJE9SuXTsdOXJEY8eOVbt27bRgwQJdfPHFkqR77rlHy5cv15tvvqnGjRvr2LFjWrJkiY4dO2b4KACcDTlMDqPsIoeB8oEsJotRdpHFQPlAFpPFKJvI4VJg4bx2/PhxS5K1aNGis24nyZo8ebLVt29fq0KFCla9evWs2bNnO22zaNEiq23btpafn58VExNjPfHEE1Z2drZjfefOna377rvPeuSRR6zIyEirU6dOVs2aNS1Jjj81a9Y8aw3ffPNNnuV2u91q3Lix1aZNGys3N9dp3Zo1ayybzWa99NJLlmVZ1jfffGP5+Pg41YXyY9CgQVafPn0KXF+Uz/ADDzxgDRs2zAoPD7eio6OtkSNHOo2xadMmq0OHDpa/v791wQUXWD///HOBn92i1PXSSy9ZNpvNWrNmjdPy3Nxcq02bNlbjxo0tu91uWZZlhYaGWh999NFZ/w0AlC3kMMoTchhAWUQWozwhiwGURWQxygtyGPlhuuDzXFBQkIKCgvTtt98qMzPzrNs+//zzuuGGG7Ru3TpdddVVuuWWWxxXEx04cEBXXXWV2rZtq7Vr1+qdd97RlClT9MILLziNMW3aNPn4+Gjx4sV677339Pfff0uSpk6dqkOHDjleu2LNmjWKi4vT0KFD5eXl/JFs3ry5unfvrhkzZkiSYmJilJOTo2+++UaWZbn8XvBcrnyGK1asqGXLlmncuHEaNWqUfv75Z0mS3W5X3759FRgYqGXLlun999/XiBEjilXXZ599ph49eqh58+ZOy728vPTII48oLi5Oa9eulXTq8z1v3jylpKQU6z0BlB5yGDiFHAZgClkMnEIWAzCFLAbI4XLNbI8X7vDll19a4eHhVkBAgHXJJZdYw4cPt9auXeu0jSTr6aefdrxOTU21bDabNX/+fMuyLOupp56yGjZs6LhqwbIs66233rKCgoIcV+907tzZatGiRZ73VyFXUhS23cyZMy1J1urVq/Pd78EHH7QqVKjgeP3UU09ZPj4+VkREhHXFFVdY48aNsw4fPlzo++P8d7arcor6Gb700kud9mvbtq31xBNPWJZlWfPnz7d8fHysQ4cOOdYX92qhgIAA66GHHsp33apVqyxJ1ueff25ZlmX99ttvVrVq1SxfX1+rTZs21sMPP2z9+eefBb4vgLKBHCaHywtyGEBZRRaTxeUFWQygrCKLyeLygBxGfriT1QP0799fBw8e1Jw5c9SzZ08tWrRIrVq10kcffeS0XbNmzRx/r1ixooKDgxUfHy9J2rRpk9q3by+bzebYpkOHDkpNTdX+/fsdy9q0aVOyB5MPy7Kc6hozZowOHz6sd999V40bN9a7776rRo0aaf369aVeG8qOon6Gz/z/QJKqVKni+P9gy5Ytql69umJiYhzrL7roohKr2frnarfTNXfq1Ek7d+7UwoUL1b9/f23cuFEdO3bU6NGjS6wGAMVHDpPDIIcBmEUWk8UgiwGYRRaTxeUdOVx+0WT1EAEBAerRo4eeffZZLVmyRLfffrtGjhzptI2vr6/Ta5vNJrvdLilvUJxednq70ypWrOj22hs0aCBJiouLy3f95s2bVb9+fadlkZGRuv766zVhwgRt2rRJsbGxGj9+vNtrw/mjqJ9hV/8/KK4GDRqc9bMtyenz7evrq44dO+rJJ5/UTz/9pFGjRmn06NHKyspya10A3IscJofLO3IYgGlkMVlc3pHFAEwji8ni8owcLr9osnqoxo0bKy0tzaXtlyxZ4jSP/JIlSxQcHKyqVauedV9fX1/l5uaec60tWrRQo0aNNHHiRMcPlNPWrl2rBQsW6Kabbipwfz8/P9WtW9el44XnKc5n+LRGjRpp7969OnLkiGPZuTzH4UwDBgzQggULHHPbn2a32zVx4kQ1btw4z5z4Z2rcuLFycnKUkZFRrDoAlC5yGOUNOQygrCGLUd6QxQDKGrIY5Qk5XH75mC4AxXPs2DFdf/31Gjx4sJo1a6bg4GCtWLFC48aNU58+fYo8zr333qtJkybpgQce0P33368tW7Zo5MiR+T7s+79q1aqlhQsXqkOHDvL391d4eHiB2+7atUtr1qxxWlavXj198MEHuvzyy9W/f38NHz5cMTExWrZsmR599FG1b99eDz/8sCTpu+++08yZMzVgwAA1aNBAlmVp7ty5mjdvnqZOnVrk48X5Kzk5Oc9nKCIiolif4dN69OihunXratCgQRo3bpxSUlIcDxcv7Cqigup65JFHNHv2bPXq1UsTJkxQu3btdOTIEb344ovatGmTFixY4Bi7S5cuuummm9SmTRtFRkYqLi5OTz31lLp27aqQkJCi/QMBKFXkMDlc3pDDAMoaspgsLm/IYgBlDVlMFpcn5DDyKLnHvaI0ZGRkWE8++aTVqlUrKzQ01AoMDLQaNmxoPf3009bJkycd2ymfhyOHhoZaU6dOdbxetGiR1bZtW8vPz8+KiYmxnnjiCSs7O9uxvnPnzvk+JHnOnDlWvXr1LB8fH6tmzZoF1iop3z+//vqrZVmWtW7dOqt///5WZGSk5evra9WtW9d6+umnrbS0NMcYO3bssO666y6rQYMGVoUKFaywsDCrbdu2TscBzzVo0KB8P0ODBg2yLOvcPsN9+vRx7G9ZlrVp0yarQ4cOlp+fn9WoUSNr7ty5liTrhx9+OOe60tLSrKefftqqV6+e5evra0VERFj9+/e31q9f7zTOiy++aLVv396KiIiwAgICrDp16lgPPvigdfTo0WL9uwEoOeQwOVyekMMAyiKymCwuT8hiAGURWUwWlxfkMPJjs6wz7l8GADhZvHixLr30Um3fvl1169Y1XQ4AAOUKOQwAgFlkMQAA5pDDZR9NVgA4wzfffKOgoCDVr19f27dv10MPPaTw8HD9+eefpksDAMDjkcMAAJhFFgMAYA45fP7hmawAcIaUlBQ9/vjj2rdvnypVqqTu3btrwoQJpssCAKBcIIcBADCLLAYAwBxy+PzDnawAAAAAAAAAAAAA4AIv0wUAAAAAAAAAAAAAwPmEJisAAAAAAAAAAAAAuIAmKwAAAAAAAAAAAAC4gCYrAAAAAAAAAAAAALiAJivgZs8995xatGjheH377berb9++pV7H7t27ZbPZtGbNmhJ7j/8e67kojToBAOUHOewachgA4G5ksWvIYgCAu5HFriGLURw0WVEu3H777bLZbLLZbPL19VWdOnX02GOPKS0trcTf+7XXXtNHH31UpG1L+wd6ly5d9PDDD5fKewEAyi9yOH/kMACgtJDF+SOLAQClhSzOH1mM852P6QKA0nLFFVdo6tSpys7O1h9//KE777xTaWlpeuedd/Jsm52dLV9fX7e8b2hoqFvGAQDgfEYOAwBgFlkMAIBZZDHgebiTFeWGv7+/YmJiVL16dd1888265ZZb9O2330r6d1qBDz/8UHXq1JG/v78sy1JycrLuvvtuVa5cWSEhIerWrZvWrl3rNO5LL72k6OhoBQcHa8iQIcrIyHBa/9/pGOx2u15++WXVq1dP/v7+qlGjhsaMGSNJql27tiSpZcuWstls6tKli2O/qVOn6oILLlBAQIAaNWqkt99+2+l9li9frpYtWyogIEBt2rTR6tWri/1v9sQTT6hBgwYKDAxUnTp19Mwzzyg7OzvPdu+9956qV6+uwMBAXX/99UpKSnJaX1jtAADPRw67jhwGALgTWew6shgA4E5ksevIYpR13MmKcqtChQpOP5C3b9+uWbNm6auvvpK3t7ck6eqrr1ZERITmzZun0NBQvffee7rsssu0detWRUREaNasWRo5cqTeeustdezYUdOnT9frr7+uOnXqFPi+w4cP1+TJkzVx4kRdeumlOnTokDZv3izpVBBddNFFWrBggZo0aSI/Pz9J0uTJkzVy5Ei9+eabatmypVavXq277rpLFStW1KBBg5SWlqZrrrlG3bp10yeffKJdu3bpoYceKva/UXBwsD766CPFxsZq/fr1uuuuuxQcHKzHH388z7/b3LlzdeLECQ0ZMkT33XefPv300yLVDgAon8jhwpHDAICSRBYXjiwGAJQksrhwZDHKPAsoBwYNGmT16dPH8XrZsmVWZGSkdcMNN1iWZVkjR460fH19rfj4eMc2CxcutEJCQqyMjAynserWrWu99957lmVZVvv27a177rnHaX27du2s5s2b5/veJ06csPz9/a3JkyfnW+euXbssSdbq1audllevXt367LPPnJaNHj3aat++vWVZlvXee+9ZERERVlpammP9O++8k+9YZ+rcubP10EMPFbj+v8aNG2e1bt3a8XrkyJGWt7e3tW/fPsey+fPnW15eXtahQ4eKVHtBxwwA8BzkcP7IYQBAaSGL80cWAwBKC1mcP7IY5zvuZEW58d133ykoKEg5OTnKzs5Wnz599MYbbzjW16xZU1FRUY7XK1euVGpqqiIjI53GSU9P144dOyRJmzZt0j333OO0vn379vr111/zrWHTpk3KzMzUZZddVuS6ExIStG/fPg0ZMkR33XWXY3lOTo5jPv1NmzapefPmCgwMdKqjuL788ktNmjRJ27dvV2pqqnJychQSEuK0TY0aNVStWjWn97Xb7dqyZYu8vb0LrR0AUD6Qw64jhwEA7kQWu44sBgC4E1nsOrIYZR1NVpQbXbt21TvvvCNfX1/FxsbmeXB4xYoVnV7b7XZVqVJFixYtyjNWWFjYOdVQoUIFl/ex2+2STk1r0K5dO6d1p6eNsCzrnOo5m6VLl2rAgAF6/vnn1bNnT4WGhmrmzJmaMGHCWfez2WyO/xaldgBA+UAOu4YcBgC4G1nsGrIYAOBuZLFryGKcD2iyotyoWLGi6tWrV+TtW7VqpcOHD8vHx0e1atXKd5sLLrhAS5cu1cCBAx3Lli5dWuCY9evXV4UKFbRw4ULdeeededafnuM+NzfXsSw6OlpVq1bVzp07dcstt+Q7buPGjTV9+nSlp6c7gvJsdRTF4sWLVbNmTY0YMcKxbM+ePXm227t3rw4ePKjY2FhJ0l9//SUvLy81aNCgSLUDAMoHctg15DAAwN3IYteQxQAAdyOLXUMW43xAkxUoQPfu3dW+fXv17dtXL7/8sho2bKiDBw9q3rx56tu3r9q0aaOHHnpIgwYNUps2bXTppZfq008/1caNGwt8sHhAQICeeOIJPf744/Lz81OHDh2UkJCgjRs3asiQIapcubIqVKigH374QdWqVVNAQIBCQ0P13HPP6cEHH1RISIiuvPJKZWZmasWKFTp+/LiGDh2qm2++WSNGjNCQIUP09NNPa/fu3Ro/fnyRjjMhIUFr1qxxWhYTE6N69epp7969mjlzptq2bavvv/9e33zzTb7HNGjQII0fP14nTpzQgw8+qBtuuEExMTGSVGjtAADkhxwmhwEAZpHFZDEAwCyymCzGecDsI2GB0vHfB4v/18iRI50eBn7aiRMnrAceeMCKjY21fH19rerVq1u33HKLtXfvXsc2Y8aMsSpVqmQFBQVZgwYNsh5//PECHyxuWZaVm5trvfDCC1bNmjUtX19fq0aNGtaLL77oWD958mSrevXqlpeXl9W5c2fH8k8//dRq0aKF5efnZ4WHh1udOnWyvv76a8f6v/76y2revLnl5+dntWjRwvrqq6+K9GBxSXn+jBw50rIsyxo2bJgVGRlpBQUFWTfeeKM1ceJEKzQ0NM+/29tvv23FxsZaAQEBVr9+/azExESn9zlb7TxYHAA8HzmcP3IYAFBayOL8kcUAgNJCFuePLMb5zmZZJTBZNgAAAAAAAAAAAAB4KC/TBQAAAAAAAAAAAADA+YQmKwAAAAAAAAAAAAC4gCYrAAAAAAAAAAAAALiAJisAAAAAAAAAAAAAuIAmKwAAAAAAAAAAAAC4gCYrAAAAAAAAAAAAALiAJisAAAAAAAAAAAAAuIAmKwAAAAAAAAAAAAC4gCYrAAAAAAAAAAAAALiAJisAAAAAAAAAAAAAuIAmKwAAAAAAAAAAAAC4gCYrAAAAAAAAAAAAALjg/wG73bowcNjL7gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x2000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "# X = df.drop(columns=['target'])\n",
    "# y = df['target']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize sampling techniques\n",
    "sampling_techniques = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to create the MLP model\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Initialize the classifiers\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'MLP': create_mlp()  # Include MLP\n",
    "}\n",
    "\n",
    "# Define 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each sampling technique\n",
    "for technique_name, sampler in sampling_techniques.items():\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        # Store metrics for each fold\n",
    "        accuracy_list = []\n",
    "        auc_list = []\n",
    "        specificity_list = []\n",
    "        sensitivity_list = []\n",
    "        f1_list = []\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            # Split the data into training and validation sets\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            # Apply the sampling technique to the training set\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Train the model\n",
    "            if classifier_name == 'MLP':\n",
    "                classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "            else:\n",
    "                classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            # Predict on the validation set\n",
    "            y_val_pred = (classifier.predict(X_val_fold) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_val_fold)\n",
    "            y_val_pred_prob = classifier.predict_proba(X_val_fold)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_val_fold)\n",
    "\n",
    "            # Calculate metrics for the fold\n",
    "            accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "            auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Store metrics\n",
    "            accuracy_list.append(accuracy)\n",
    "            auc_list.append(auc_score)\n",
    "            specificity_list.append(specificity)\n",
    "            sensitivity_list.append(sensitivity)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        results[f\"{technique_name}_{classifier_name}\"] = {\n",
    "            'Accuracy': (np.mean(accuracy_list), np.std(accuracy_list)),\n",
    "            'AUC': (np.mean(auc_list), np.std(auc_list)),\n",
    "            'Specificity': (np.mean(specificity_list), np.std(specificity_list)),\n",
    "            'Sensitivity': (np.mean(sensitivity_list), np.std(sensitivity_list)),\n",
    "            'F1 Score': (np.mean(f1_list), np.std(f1_list))\n",
    "        }\n",
    "\n",
    "# Set up subplots for confusion matrices\n",
    "fig, axes = plt.subplots(len(sampling_techniques), len(classifiers), figsize=(20, 20))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "# Evaluate on the test set using each sampling technique and classifier\n",
    "for i, (technique_name, sampler) in enumerate(sampling_techniques.items()):\n",
    "    for j, (classifier_name, classifier) in enumerate(classifiers.items()):\n",
    "        # Apply the sampling technique to the entire training set\n",
    "        X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the resampled training set\n",
    "        if classifier_name == 'MLP':\n",
    "            classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "        else:\n",
    "            classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_test_pred = (classifier.predict(X_test) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_test)\n",
    "\n",
    "        # Confusion matrix for final test set in percentage form\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        ax = axes[i, j]\n",
    "        sns.heatmap(cm_percentage, annot=True, fmt=\".2f\", cmap='Blues', cbar=False, ax=ax,\n",
    "                    xticklabels=['Short LOS', 'Long LOS'], yticklabels=['Short LOS', 'Long LOS'])\n",
    "        ax.set_title(f'{technique_name} + {classifier_name}')\n",
    "        ax.set_xlabel('Predicted Label')\n",
    "        ax.set_ylabel('True Label')\n",
    "\n",
    "# Adjust the layout and save the plot\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.savefig('confusion_matrices_percentage_all_new.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37e822c9-366d-4d3f-bb83-27283ac99566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks, NearMiss\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize sampling techniques\n",
    "sampling_techniques = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "    'NearMiss': NearMiss(version=1),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to create the MLP model\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Initialize the classifiers\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'MLP': create_mlp()  # Include MLP\n",
    "}\n",
    "\n",
    "# Define 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store results for each technique\n",
    "results = {}\n",
    "\n",
    "# Loop over each sampling technique\n",
    "for technique_name, sampler in sampling_techniques.items():\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        # Store metrics for each fold\n",
    "        accuracy_list = []\n",
    "        auc_list = []\n",
    "        specificity_list = []\n",
    "        sensitivity_list = []\n",
    "        f1_list = []\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            # Split the data into training and validation sets\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            # Apply the sampling technique to the training set\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Train the model\n",
    "            if classifier_name == 'MLP':\n",
    "                classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "            else:\n",
    "                classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            # Predict on the validation set\n",
    "            y_val_pred = (classifier.predict(X_val_fold) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_val_fold)\n",
    "            y_val_pred_prob = classifier.predict_proba(X_val_fold)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_val_fold)\n",
    "\n",
    "            # Calculate metrics for the fold\n",
    "            accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "            auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Store metrics\n",
    "            accuracy_list.append(accuracy)\n",
    "            auc_list.append(auc_score)\n",
    "            specificity_list.append(specificity)\n",
    "            sensitivity_list.append(sensitivity)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        results[f\"{technique_name}_{classifier_name}\"] = {\n",
    "            'Accuracy': (np.mean(accuracy_list), np.std(accuracy_list)),\n",
    "            'AUC': (np.mean(auc_list), np.std(auc_list)),\n",
    "            'Specificity': (np.mean(specificity_list), np.std(specificity_list)),\n",
    "            'Sensitivity': (np.mean(sensitivity_list), np.std(sensitivity_list)),\n",
    "            'F1 Score': (np.mean(f1_list), np.std(f1_list))\n",
    "        }\n",
    "\n",
    "# Evaluate on the test set using each sampling technique and classifier\n",
    "for technique_name, sampler in sampling_techniques.items():\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        # Apply the sampling technique to the entire training set\n",
    "        X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the resampled training set\n",
    "        if classifier_name == 'MLP':\n",
    "            classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "        else:\n",
    "            classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        y_test_pred = (classifier.predict(X_test) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_test)\n",
    "        y_test_pred_prob = classifier.predict_proba(X_test)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics on the test set\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_auc_score = roc_auc_score(y_test, y_test_pred_prob)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "        test_specificity = tn / (tn + fp)\n",
    "        test_sensitivity = tp / (tp + fn)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        # Store test set metrics with errors (set standard deviation to zero as there is no cross-validation for the test set)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Accuracy'] = (test_accuracy, np.std([test_accuracy]))\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test AUC'] = (test_auc_score, np.std([test_auc_score]))\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Specificity'] = (test_specificity, np.std([test_specificity]))\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Sensitivity'] = (test_sensitivity, np.std([test_sensitivity]))\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test F1 Score'] = (test_f1, np.std([test_f1]))\n",
    "\n",
    "# Create a DataFrame to present the results for comparison\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Display the results DataFrame for easy comparison of metrics across techniques and classifiers\n",
    "#print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fcdcb3b7-49e9-4b3f-a0fd-48e56da29955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_df160_row0_col1, #T_df160_row0_col16, #T_df160_row0_col17, #T_df160_row1_col19, #T_df160_row3_col10, #T_df160_row3_col14, #T_df160_row4_col18, #T_df160_row5_col0, #T_df160_row5_col2, #T_df160_row5_col3, #T_df160_row5_col4, #T_df160_row5_col5, #T_df160_row5_col6, #T_df160_row5_col7, #T_df160_row5_col8, #T_df160_row5_col9, #T_df160_row5_col11, #T_df160_row5_col12, #T_df160_row5_col13, #T_df160_row5_col15 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_df160\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df160_level0_col0\" class=\"col_heading level0 col0\" colspan=\"4\">Test AUC Mean</th>\n",
       "      <th id=\"T_df160_level0_col4\" class=\"col_heading level0 col4\" colspan=\"4\">Test Accuracy Mean</th>\n",
       "      <th id=\"T_df160_level0_col8\" class=\"col_heading level0 col8\" colspan=\"4\">Test F1 Score Mean</th>\n",
       "      <th id=\"T_df160_level0_col12\" class=\"col_heading level0 col12\" colspan=\"4\">Test Sensitivity Mean</th>\n",
       "      <th id=\"T_df160_level0_col16\" class=\"col_heading level0 col16\" colspan=\"4\">Test Specificity Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >Classifier</th>\n",
       "      <th id=\"T_df160_level1_col0\" class=\"col_heading level1 col0\" >GradientBoosting</th>\n",
       "      <th id=\"T_df160_level1_col1\" class=\"col_heading level1 col1\" >LogisticRegression</th>\n",
       "      <th id=\"T_df160_level1_col2\" class=\"col_heading level1 col2\" >MLP</th>\n",
       "      <th id=\"T_df160_level1_col3\" class=\"col_heading level1 col3\" >RandomForest</th>\n",
       "      <th id=\"T_df160_level1_col4\" class=\"col_heading level1 col4\" >GradientBoosting</th>\n",
       "      <th id=\"T_df160_level1_col5\" class=\"col_heading level1 col5\" >LogisticRegression</th>\n",
       "      <th id=\"T_df160_level1_col6\" class=\"col_heading level1 col6\" >MLP</th>\n",
       "      <th id=\"T_df160_level1_col7\" class=\"col_heading level1 col7\" >RandomForest</th>\n",
       "      <th id=\"T_df160_level1_col8\" class=\"col_heading level1 col8\" >GradientBoosting</th>\n",
       "      <th id=\"T_df160_level1_col9\" class=\"col_heading level1 col9\" >LogisticRegression</th>\n",
       "      <th id=\"T_df160_level1_col10\" class=\"col_heading level1 col10\" >MLP</th>\n",
       "      <th id=\"T_df160_level1_col11\" class=\"col_heading level1 col11\" >RandomForest</th>\n",
       "      <th id=\"T_df160_level1_col12\" class=\"col_heading level1 col12\" >GradientBoosting</th>\n",
       "      <th id=\"T_df160_level1_col13\" class=\"col_heading level1 col13\" >LogisticRegression</th>\n",
       "      <th id=\"T_df160_level1_col14\" class=\"col_heading level1 col14\" >MLP</th>\n",
       "      <th id=\"T_df160_level1_col15\" class=\"col_heading level1 col15\" >RandomForest</th>\n",
       "      <th id=\"T_df160_level1_col16\" class=\"col_heading level1 col16\" >GradientBoosting</th>\n",
       "      <th id=\"T_df160_level1_col17\" class=\"col_heading level1 col17\" >LogisticRegression</th>\n",
       "      <th id=\"T_df160_level1_col18\" class=\"col_heading level1 col18\" >MLP</th>\n",
       "      <th id=\"T_df160_level1_col19\" class=\"col_heading level1 col19\" >RandomForest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Sampling Technique</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "      <th class=\"blank col16\" >&nbsp;</th>\n",
       "      <th class=\"blank col17\" >&nbsp;</th>\n",
       "      <th class=\"blank col18\" >&nbsp;</th>\n",
       "      <th class=\"blank col19\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row0\" class=\"row_heading level0 row0\" >ADASYN</th>\n",
       "      <td id=\"T_df160_row0_col0\" class=\"data row0 col0\" >0.729463</td>\n",
       "      <td id=\"T_df160_row0_col1\" class=\"data row0 col1\" >0.699841</td>\n",
       "      <td id=\"T_df160_row0_col2\" class=\"data row0 col2\" >0.731180</td>\n",
       "      <td id=\"T_df160_row0_col3\" class=\"data row0 col3\" >0.695315</td>\n",
       "      <td id=\"T_df160_row0_col4\" class=\"data row0 col4\" >0.684934</td>\n",
       "      <td id=\"T_df160_row0_col5\" class=\"data row0 col5\" >0.639099</td>\n",
       "      <td id=\"T_df160_row0_col6\" class=\"data row0 col6\" >0.682233</td>\n",
       "      <td id=\"T_df160_row0_col7\" class=\"data row0 col7\" >0.646959</td>\n",
       "      <td id=\"T_df160_row0_col8\" class=\"data row0 col8\" >0.740946</td>\n",
       "      <td id=\"T_df160_row0_col9\" class=\"data row0 col9\" >0.678754</td>\n",
       "      <td id=\"T_df160_row0_col10\" class=\"data row0 col10\" >0.734836</td>\n",
       "      <td id=\"T_df160_row0_col11\" class=\"data row0 col11\" >0.692628</td>\n",
       "      <td id=\"T_df160_row0_col12\" class=\"data row0 col12\" >0.734655</td>\n",
       "      <td id=\"T_df160_row0_col13\" class=\"data row0 col13\" >0.621652</td>\n",
       "      <td id=\"T_df160_row0_col14\" class=\"data row0 col14\" >0.717911</td>\n",
       "      <td id=\"T_df160_row0_col15\" class=\"data row0 col15\" >0.648554</td>\n",
       "      <td id=\"T_df160_row0_col16\" class=\"data row0 col16\" >0.606073</td>\n",
       "      <td id=\"T_df160_row0_col17\" class=\"data row0 col17\" >0.666772</td>\n",
       "      <td id=\"T_df160_row0_col18\" class=\"data row0 col18\" >0.625645</td>\n",
       "      <td id=\"T_df160_row0_col19\" class=\"data row0 col19\" >0.644430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row1\" class=\"row_heading level0 row1\" >NearMiss</th>\n",
       "      <td id=\"T_df160_row1_col0\" class=\"data row1 col0\" >0.630764</td>\n",
       "      <td id=\"T_df160_row1_col1\" class=\"data row1 col1\" >0.625349</td>\n",
       "      <td id=\"T_df160_row1_col2\" class=\"data row1 col2\" >0.624416</td>\n",
       "      <td id=\"T_df160_row1_col3\" class=\"data row1 col3\" >0.551472</td>\n",
       "      <td id=\"T_df160_row1_col4\" class=\"data row1 col4\" >0.598009</td>\n",
       "      <td id=\"T_df160_row1_col5\" class=\"data row1 col5\" >0.589614</td>\n",
       "      <td id=\"T_df160_row1_col6\" class=\"data row1 col6\" >0.596926</td>\n",
       "      <td id=\"T_df160_row1_col7\" class=\"data row1 col7\" >0.549412</td>\n",
       "      <td id=\"T_df160_row1_col8\" class=\"data row1 col8\" >0.652882</td>\n",
       "      <td id=\"T_df160_row1_col9\" class=\"data row1 col9\" >0.635389</td>\n",
       "      <td id=\"T_df160_row1_col10\" class=\"data row1 col10\" >0.648673</td>\n",
       "      <td id=\"T_df160_row1_col11\" class=\"data row1 col11\" >0.565739</td>\n",
       "      <td id=\"T_df160_row1_col12\" class=\"data row1 col12\" >0.616395</td>\n",
       "      <td id=\"T_df160_row1_col13\" class=\"data row1 col13\" >0.583026</td>\n",
       "      <td id=\"T_df160_row1_col14\" class=\"data row1 col14\" >0.606713</td>\n",
       "      <td id=\"T_df160_row1_col15\" class=\"data row1 col15\" >0.478554</td>\n",
       "      <td id=\"T_df160_row1_col16\" class=\"data row1 col16\" >0.568848</td>\n",
       "      <td id=\"T_df160_row1_col17\" class=\"data row1 col17\" >0.600063</td>\n",
       "      <td id=\"T_df160_row1_col18\" class=\"data row1 col18\" >0.581403</td>\n",
       "      <td id=\"T_df160_row1_col19\" class=\"data row1 col19\" >0.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row2\" class=\"row_heading level0 row2\" >SMOTE</th>\n",
       "      <td id=\"T_df160_row2_col0\" class=\"data row2 col0\" >0.730414</td>\n",
       "      <td id=\"T_df160_row2_col1\" class=\"data row2 col1\" >0.698319</td>\n",
       "      <td id=\"T_df160_row2_col2\" class=\"data row2 col2\" >0.730844</td>\n",
       "      <td id=\"T_df160_row2_col3\" class=\"data row2 col3\" >0.703491</td>\n",
       "      <td id=\"T_df160_row2_col4\" class=\"data row2 col4\" >0.687672</td>\n",
       "      <td id=\"T_df160_row2_col5\" class=\"data row2 col5\" >0.644660</td>\n",
       "      <td id=\"T_df160_row2_col6\" class=\"data row2 col6\" >0.682939</td>\n",
       "      <td id=\"T_df160_row2_col7\" class=\"data row2 col7\" >0.657910</td>\n",
       "      <td id=\"T_df160_row2_col8\" class=\"data row2 col8\" >0.746206</td>\n",
       "      <td id=\"T_df160_row2_col9\" class=\"data row2 col9\" >0.687055</td>\n",
       "      <td id=\"T_df160_row2_col10\" class=\"data row2 col10\" >0.735172</td>\n",
       "      <td id=\"T_df160_row2_col11\" class=\"data row2 col11\" >0.706116</td>\n",
       "      <td id=\"T_df160_row2_col12\" class=\"data row2 col12\" >0.748641</td>\n",
       "      <td id=\"T_df160_row2_col13\" class=\"data row2 col13\" >0.635996</td>\n",
       "      <td id=\"T_df160_row2_col14\" class=\"data row2 col14\" >0.717553</td>\n",
       "      <td id=\"T_df160_row2_col15\" class=\"data row2 col15\" >0.670079</td>\n",
       "      <td id=\"T_df160_row2_col16\" class=\"data row2 col16\" >0.590969</td>\n",
       "      <td id=\"T_df160_row2_col17\" class=\"data row2 col17\" >0.658402</td>\n",
       "      <td id=\"T_df160_row2_col18\" class=\"data row2 col18\" >0.628037</td>\n",
       "      <td id=\"T_df160_row2_col19\" class=\"data row2 col19\" >0.638609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row3\" class=\"row_heading level0 row3\" >SMOTEENN</th>\n",
       "      <td id=\"T_df160_row3_col0\" class=\"data row3 col0\" >0.723850</td>\n",
       "      <td id=\"T_df160_row3_col1\" class=\"data row3 col1\" >0.696839</td>\n",
       "      <td id=\"T_df160_row3_col2\" class=\"data row3 col2\" >0.728183</td>\n",
       "      <td id=\"T_df160_row3_col3\" class=\"data row3 col3\" >0.675375</td>\n",
       "      <td id=\"T_df160_row3_col4\" class=\"data row3 col4\" >0.697588</td>\n",
       "      <td id=\"T_df160_row3_col5\" class=\"data row3 col5\" >0.692028</td>\n",
       "      <td id=\"T_df160_row3_col6\" class=\"data row3 col6\" >0.698902</td>\n",
       "      <td id=\"T_df160_row3_col7\" class=\"data row3 col7\" >0.668885</td>\n",
       "      <td id=\"T_df160_row3_col8\" class=\"data row3 col8\" >0.776276</td>\n",
       "      <td id=\"T_df160_row3_col9\" class=\"data row3 col9\" >0.762068</td>\n",
       "      <td id=\"T_df160_row3_col10\" class=\"data row3 col10\" >0.773712</td>\n",
       "      <td id=\"T_df160_row3_col11\" class=\"data row3 col11\" >0.741270</td>\n",
       "      <td id=\"T_df160_row3_col12\" class=\"data row3 col12\" >0.855434</td>\n",
       "      <td id=\"T_df160_row3_col13\" class=\"data row3 col13\" >0.804150</td>\n",
       "      <td id=\"T_df160_row3_col14\" class=\"data row3 col14\" >0.839285</td>\n",
       "      <td id=\"T_df160_row3_col15\" class=\"data row3 col15\" >0.773380</td>\n",
       "      <td id=\"T_df160_row3_col16\" class=\"data row3 col16\" >0.447231</td>\n",
       "      <td id=\"T_df160_row3_col17\" class=\"data row3 col17\" >0.514191</td>\n",
       "      <td id=\"T_df160_row3_col18\" class=\"data row3 col18\" >0.476243</td>\n",
       "      <td id=\"T_df160_row3_col19\" class=\"data row3 col19\" >0.503147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row4\" class=\"row_heading level0 row4\" >SMOTETomek</th>\n",
       "      <td id=\"T_df160_row4_col0\" class=\"data row4 col0\" >0.729317</td>\n",
       "      <td id=\"T_df160_row4_col1\" class=\"data row4 col1\" >0.699020</td>\n",
       "      <td id=\"T_df160_row4_col2\" class=\"data row4 col2\" >0.732864</td>\n",
       "      <td id=\"T_df160_row4_col3\" class=\"data row4 col3\" >0.704144</td>\n",
       "      <td id=\"T_df160_row4_col4\" class=\"data row4 col4\" >0.686285</td>\n",
       "      <td id=\"T_df160_row4_col5\" class=\"data row4 col5\" >0.646302</td>\n",
       "      <td id=\"T_df160_row4_col6\" class=\"data row4 col6\" >0.679556</td>\n",
       "      <td id=\"T_df160_row4_col7\" class=\"data row4 col7\" >0.658762</td>\n",
       "      <td id=\"T_df160_row4_col8\" class=\"data row4 col8\" >0.744548</td>\n",
       "      <td id=\"T_df160_row4_col9\" class=\"data row4 col9\" >0.689894</td>\n",
       "      <td id=\"T_df160_row4_col10\" class=\"data row4 col10\" >0.729493</td>\n",
       "      <td id=\"T_df160_row4_col11\" class=\"data row4 col11\" >0.707001</td>\n",
       "      <td id=\"T_df160_row4_col12\" class=\"data row4 col12\" >0.745427</td>\n",
       "      <td id=\"T_df160_row4_col13\" class=\"data row4 col13\" >0.641491</td>\n",
       "      <td id=\"T_df160_row4_col14\" class=\"data row4 col14\" >0.704499</td>\n",
       "      <td id=\"T_df160_row4_col15\" class=\"data row4 col15\" >0.671269</td>\n",
       "      <td id=\"T_df160_row4_col16\" class=\"data row4 col16\" >0.592480</td>\n",
       "      <td id=\"T_df160_row4_col17\" class=\"data row4 col17\" >0.653933</td>\n",
       "      <td id=\"T_df160_row4_col18\" class=\"data row4 col18\" >0.639994</td>\n",
       "      <td id=\"T_df160_row4_col19\" class=\"data row4 col19\" >0.638924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df160_level0_row5\" class=\"row_heading level0 row5\" >TomekLinks</th>\n",
       "      <td id=\"T_df160_row5_col0\" class=\"data row5 col0\" >0.731438</td>\n",
       "      <td id=\"T_df160_row5_col1\" class=\"data row5 col1\" >0.699001</td>\n",
       "      <td id=\"T_df160_row5_col2\" class=\"data row5 col2\" >0.734011</td>\n",
       "      <td id=\"T_df160_row5_col3\" class=\"data row5 col3\" >0.705039</td>\n",
       "      <td id=\"T_df160_row5_col4\" class=\"data row5 col4\" >0.699511</td>\n",
       "      <td id=\"T_df160_row5_col5\" class=\"data row5 col5\" >0.693987</td>\n",
       "      <td id=\"T_df160_row5_col6\" class=\"data row5 col6\" >0.699888</td>\n",
       "      <td id=\"T_df160_row5_col7\" class=\"data row5 col7\" >0.682209</td>\n",
       "      <td id=\"T_df160_row5_col8\" class=\"data row5 col8\" >0.783744</td>\n",
       "      <td id=\"T_df160_row5_col9\" class=\"data row5 col9\" >0.773676</td>\n",
       "      <td id=\"T_df160_row5_col10\" class=\"data row5 col10\" >0.769716</td>\n",
       "      <td id=\"T_df160_row5_col11\" class=\"data row5 col11\" >0.754834</td>\n",
       "      <td id=\"T_df160_row5_col12\" class=\"data row5 col12\" >0.887811</td>\n",
       "      <td id=\"T_df160_row5_col13\" class=\"data row5 col13\" >0.852815</td>\n",
       "      <td id=\"T_df160_row5_col14\" class=\"data row5 col14\" >0.817780</td>\n",
       "      <td id=\"T_df160_row5_col15\" class=\"data row5 col15\" >0.797663</td>\n",
       "      <td id=\"T_df160_row5_col16\" class=\"data row5 col16\" >0.400850</td>\n",
       "      <td id=\"T_df160_row5_col17\" class=\"data row5 col17\" >0.442070</td>\n",
       "      <td id=\"T_df160_row5_col18\" class=\"data row5 col18\" >0.512901</td>\n",
       "      <td id=\"T_df160_row5_col19\" class=\"data row5 col19\" >0.499087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ce3fc270990>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FOR TEST SCORES\n",
    "\n",
    "# Assume results is already populated as a dictionary from previous runs\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "results_df.rename(columns={'index': 'Sampling_Technique_Classifier'}, inplace=True)\n",
    "\n",
    "# Split Sampling_Technique_Classifier into Sampling Technique and Classifier columns\n",
    "split_df = results_df['Sampling_Technique_Classifier'].str.split('_', n=1, expand=True)\n",
    "results_df['Sampling Technique'] = split_df[0]\n",
    "results_df['Classifier'] = split_df[1]\n",
    "\n",
    "# Separate mean and std into different columns for each metric\n",
    "for metric in ['Test Accuracy', 'Test AUC', 'Test Specificity', 'Test Sensitivity', 'Test F1 Score']:\n",
    "    results_df[[f'{metric} Mean', f'{metric} Std']] = pd.DataFrame(results_df[metric].tolist(), index=results_df.index)\n",
    "\n",
    "# Select only the mean values for the pivot table\n",
    "mean_columns = [col for col in results_df.columns if 'Mean' in col or col in ['Sampling Technique', 'Classifier']]\n",
    "results_df_mean = results_df[mean_columns]\n",
    "\n",
    "# Create the pivot table with Sampling Technique as index and Classifier as columns\n",
    "pivot_table = results_df_mean.pivot_table(index='Sampling Technique', columns='Classifier', values=[\n",
    "    'Test Accuracy Mean', 'Test AUC Mean', 'Test Specificity Mean', 'Test Sensitivity Mean', 'Test F1 Score Mean'\n",
    "])\n",
    "\n",
    "# Highlight the highest value in each column\n",
    "styled_table = pivot_table.style.highlight_max(color='lightgreen', axis=0)\n",
    "\n",
    "# Display the styled pivot table\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b350f605-b176-4f78-b86f-e6d7f17b3af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3203a_row0_col5, #T_3203a_row1_col0, #T_3203a_row2_col5, #T_3203a_row3_col5, #T_3203a_row4_col5, #T_3203a_row5_col5, #T_3203a_row6_col5, #T_3203a_row7_col5, #T_3203a_row8_col5, #T_3203a_row9_col5, #T_3203a_row10_col3, #T_3203a_row11_col5, #T_3203a_row12_col5, #T_3203a_row13_col5, #T_3203a_row14_col3, #T_3203a_row15_col5, #T_3203a_row16_col0, #T_3203a_row17_col0, #T_3203a_row18_col4, #T_3203a_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3203a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >Sampling Technique</th>\n",
       "      <th id=\"T_3203a_level0_col0\" class=\"col_heading level0 col0\" >ADASYN</th>\n",
       "      <th id=\"T_3203a_level0_col1\" class=\"col_heading level0 col1\" >NearMiss</th>\n",
       "      <th id=\"T_3203a_level0_col2\" class=\"col_heading level0 col2\" >SMOTE</th>\n",
       "      <th id=\"T_3203a_level0_col3\" class=\"col_heading level0 col3\" >SMOTEENN</th>\n",
       "      <th id=\"T_3203a_level0_col4\" class=\"col_heading level0 col4\" >SMOTETomek</th>\n",
       "      <th id=\"T_3203a_level0_col5\" class=\"col_heading level0 col5\" >TomekLinks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >&nbsp;</th>\n",
       "      <th class=\"index_name level1\" >Classifier</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">Test AUC Mean</th>\n",
       "      <th id=\"T_3203a_level1_row0\" class=\"row_heading level1 row0\" >GradientBoosting</th>\n",
       "      <td id=\"T_3203a_row0_col0\" class=\"data row0 col0\" >0.729463</td>\n",
       "      <td id=\"T_3203a_row0_col1\" class=\"data row0 col1\" >0.630764</td>\n",
       "      <td id=\"T_3203a_row0_col2\" class=\"data row0 col2\" >0.730414</td>\n",
       "      <td id=\"T_3203a_row0_col3\" class=\"data row0 col3\" >0.723850</td>\n",
       "      <td id=\"T_3203a_row0_col4\" class=\"data row0 col4\" >0.729317</td>\n",
       "      <td id=\"T_3203a_row0_col5\" class=\"data row0 col5\" >0.731438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row1\" class=\"row_heading level1 row1\" >LogisticRegression</th>\n",
       "      <td id=\"T_3203a_row1_col0\" class=\"data row1 col0\" >0.699841</td>\n",
       "      <td id=\"T_3203a_row1_col1\" class=\"data row1 col1\" >0.625349</td>\n",
       "      <td id=\"T_3203a_row1_col2\" class=\"data row1 col2\" >0.698319</td>\n",
       "      <td id=\"T_3203a_row1_col3\" class=\"data row1 col3\" >0.696839</td>\n",
       "      <td id=\"T_3203a_row1_col4\" class=\"data row1 col4\" >0.699020</td>\n",
       "      <td id=\"T_3203a_row1_col5\" class=\"data row1 col5\" >0.699001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row2\" class=\"row_heading level1 row2\" >MLP</th>\n",
       "      <td id=\"T_3203a_row2_col0\" class=\"data row2 col0\" >0.731180</td>\n",
       "      <td id=\"T_3203a_row2_col1\" class=\"data row2 col1\" >0.624416</td>\n",
       "      <td id=\"T_3203a_row2_col2\" class=\"data row2 col2\" >0.730844</td>\n",
       "      <td id=\"T_3203a_row2_col3\" class=\"data row2 col3\" >0.728183</td>\n",
       "      <td id=\"T_3203a_row2_col4\" class=\"data row2 col4\" >0.732864</td>\n",
       "      <td id=\"T_3203a_row2_col5\" class=\"data row2 col5\" >0.734011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row3\" class=\"row_heading level1 row3\" >RandomForest</th>\n",
       "      <td id=\"T_3203a_row3_col0\" class=\"data row3 col0\" >0.695315</td>\n",
       "      <td id=\"T_3203a_row3_col1\" class=\"data row3 col1\" >0.551472</td>\n",
       "      <td id=\"T_3203a_row3_col2\" class=\"data row3 col2\" >0.703491</td>\n",
       "      <td id=\"T_3203a_row3_col3\" class=\"data row3 col3\" >0.675375</td>\n",
       "      <td id=\"T_3203a_row3_col4\" class=\"data row3 col4\" >0.704144</td>\n",
       "      <td id=\"T_3203a_row3_col5\" class=\"data row3 col5\" >0.705039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">Test Accuracy Mean</th>\n",
       "      <th id=\"T_3203a_level1_row4\" class=\"row_heading level1 row4\" >GradientBoosting</th>\n",
       "      <td id=\"T_3203a_row4_col0\" class=\"data row4 col0\" >0.684934</td>\n",
       "      <td id=\"T_3203a_row4_col1\" class=\"data row4 col1\" >0.598009</td>\n",
       "      <td id=\"T_3203a_row4_col2\" class=\"data row4 col2\" >0.687672</td>\n",
       "      <td id=\"T_3203a_row4_col3\" class=\"data row4 col3\" >0.697588</td>\n",
       "      <td id=\"T_3203a_row4_col4\" class=\"data row4 col4\" >0.686285</td>\n",
       "      <td id=\"T_3203a_row4_col5\" class=\"data row4 col5\" >0.699511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row5\" class=\"row_heading level1 row5\" >LogisticRegression</th>\n",
       "      <td id=\"T_3203a_row5_col0\" class=\"data row5 col0\" >0.639099</td>\n",
       "      <td id=\"T_3203a_row5_col1\" class=\"data row5 col1\" >0.589614</td>\n",
       "      <td id=\"T_3203a_row5_col2\" class=\"data row5 col2\" >0.644660</td>\n",
       "      <td id=\"T_3203a_row5_col3\" class=\"data row5 col3\" >0.692028</td>\n",
       "      <td id=\"T_3203a_row5_col4\" class=\"data row5 col4\" >0.646302</td>\n",
       "      <td id=\"T_3203a_row5_col5\" class=\"data row5 col5\" >0.693987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row6\" class=\"row_heading level1 row6\" >MLP</th>\n",
       "      <td id=\"T_3203a_row6_col0\" class=\"data row6 col0\" >0.682233</td>\n",
       "      <td id=\"T_3203a_row6_col1\" class=\"data row6 col1\" >0.596926</td>\n",
       "      <td id=\"T_3203a_row6_col2\" class=\"data row6 col2\" >0.682939</td>\n",
       "      <td id=\"T_3203a_row6_col3\" class=\"data row6 col3\" >0.698902</td>\n",
       "      <td id=\"T_3203a_row6_col4\" class=\"data row6 col4\" >0.679556</td>\n",
       "      <td id=\"T_3203a_row6_col5\" class=\"data row6 col5\" >0.699888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row7\" class=\"row_heading level1 row7\" >RandomForest</th>\n",
       "      <td id=\"T_3203a_row7_col0\" class=\"data row7 col0\" >0.646959</td>\n",
       "      <td id=\"T_3203a_row7_col1\" class=\"data row7 col1\" >0.549412</td>\n",
       "      <td id=\"T_3203a_row7_col2\" class=\"data row7 col2\" >0.657910</td>\n",
       "      <td id=\"T_3203a_row7_col3\" class=\"data row7 col3\" >0.668885</td>\n",
       "      <td id=\"T_3203a_row7_col4\" class=\"data row7 col4\" >0.658762</td>\n",
       "      <td id=\"T_3203a_row7_col5\" class=\"data row7 col5\" >0.682209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"4\">Test F1 Score Mean</th>\n",
       "      <th id=\"T_3203a_level1_row8\" class=\"row_heading level1 row8\" >GradientBoosting</th>\n",
       "      <td id=\"T_3203a_row8_col0\" class=\"data row8 col0\" >0.740946</td>\n",
       "      <td id=\"T_3203a_row8_col1\" class=\"data row8 col1\" >0.652882</td>\n",
       "      <td id=\"T_3203a_row8_col2\" class=\"data row8 col2\" >0.746206</td>\n",
       "      <td id=\"T_3203a_row8_col3\" class=\"data row8 col3\" >0.776276</td>\n",
       "      <td id=\"T_3203a_row8_col4\" class=\"data row8 col4\" >0.744548</td>\n",
       "      <td id=\"T_3203a_row8_col5\" class=\"data row8 col5\" >0.783744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row9\" class=\"row_heading level1 row9\" >LogisticRegression</th>\n",
       "      <td id=\"T_3203a_row9_col0\" class=\"data row9 col0\" >0.678754</td>\n",
       "      <td id=\"T_3203a_row9_col1\" class=\"data row9 col1\" >0.635389</td>\n",
       "      <td id=\"T_3203a_row9_col2\" class=\"data row9 col2\" >0.687055</td>\n",
       "      <td id=\"T_3203a_row9_col3\" class=\"data row9 col3\" >0.762068</td>\n",
       "      <td id=\"T_3203a_row9_col4\" class=\"data row9 col4\" >0.689894</td>\n",
       "      <td id=\"T_3203a_row9_col5\" class=\"data row9 col5\" >0.773676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row10\" class=\"row_heading level1 row10\" >MLP</th>\n",
       "      <td id=\"T_3203a_row10_col0\" class=\"data row10 col0\" >0.734836</td>\n",
       "      <td id=\"T_3203a_row10_col1\" class=\"data row10 col1\" >0.648673</td>\n",
       "      <td id=\"T_3203a_row10_col2\" class=\"data row10 col2\" >0.735172</td>\n",
       "      <td id=\"T_3203a_row10_col3\" class=\"data row10 col3\" >0.773712</td>\n",
       "      <td id=\"T_3203a_row10_col4\" class=\"data row10 col4\" >0.729493</td>\n",
       "      <td id=\"T_3203a_row10_col5\" class=\"data row10 col5\" >0.769716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row11\" class=\"row_heading level1 row11\" >RandomForest</th>\n",
       "      <td id=\"T_3203a_row11_col0\" class=\"data row11 col0\" >0.692628</td>\n",
       "      <td id=\"T_3203a_row11_col1\" class=\"data row11 col1\" >0.565739</td>\n",
       "      <td id=\"T_3203a_row11_col2\" class=\"data row11 col2\" >0.706116</td>\n",
       "      <td id=\"T_3203a_row11_col3\" class=\"data row11 col3\" >0.741270</td>\n",
       "      <td id=\"T_3203a_row11_col4\" class=\"data row11 col4\" >0.707001</td>\n",
       "      <td id=\"T_3203a_row11_col5\" class=\"data row11 col5\" >0.754834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"4\">Test Sensitivity Mean</th>\n",
       "      <th id=\"T_3203a_level1_row12\" class=\"row_heading level1 row12\" >GradientBoosting</th>\n",
       "      <td id=\"T_3203a_row12_col0\" class=\"data row12 col0\" >0.734655</td>\n",
       "      <td id=\"T_3203a_row12_col1\" class=\"data row12 col1\" >0.616395</td>\n",
       "      <td id=\"T_3203a_row12_col2\" class=\"data row12 col2\" >0.748641</td>\n",
       "      <td id=\"T_3203a_row12_col3\" class=\"data row12 col3\" >0.855434</td>\n",
       "      <td id=\"T_3203a_row12_col4\" class=\"data row12 col4\" >0.745427</td>\n",
       "      <td id=\"T_3203a_row12_col5\" class=\"data row12 col5\" >0.887811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row13\" class=\"row_heading level1 row13\" >LogisticRegression</th>\n",
       "      <td id=\"T_3203a_row13_col0\" class=\"data row13 col0\" >0.621652</td>\n",
       "      <td id=\"T_3203a_row13_col1\" class=\"data row13 col1\" >0.583026</td>\n",
       "      <td id=\"T_3203a_row13_col2\" class=\"data row13 col2\" >0.635996</td>\n",
       "      <td id=\"T_3203a_row13_col3\" class=\"data row13 col3\" >0.804150</td>\n",
       "      <td id=\"T_3203a_row13_col4\" class=\"data row13 col4\" >0.641491</td>\n",
       "      <td id=\"T_3203a_row13_col5\" class=\"data row13 col5\" >0.852815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row14\" class=\"row_heading level1 row14\" >MLP</th>\n",
       "      <td id=\"T_3203a_row14_col0\" class=\"data row14 col0\" >0.717911</td>\n",
       "      <td id=\"T_3203a_row14_col1\" class=\"data row14 col1\" >0.606713</td>\n",
       "      <td id=\"T_3203a_row14_col2\" class=\"data row14 col2\" >0.717553</td>\n",
       "      <td id=\"T_3203a_row14_col3\" class=\"data row14 col3\" >0.839285</td>\n",
       "      <td id=\"T_3203a_row14_col4\" class=\"data row14 col4\" >0.704499</td>\n",
       "      <td id=\"T_3203a_row14_col5\" class=\"data row14 col5\" >0.817780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row15\" class=\"row_heading level1 row15\" >RandomForest</th>\n",
       "      <td id=\"T_3203a_row15_col0\" class=\"data row15 col0\" >0.648554</td>\n",
       "      <td id=\"T_3203a_row15_col1\" class=\"data row15 col1\" >0.478554</td>\n",
       "      <td id=\"T_3203a_row15_col2\" class=\"data row15 col2\" >0.670079</td>\n",
       "      <td id=\"T_3203a_row15_col3\" class=\"data row15 col3\" >0.773380</td>\n",
       "      <td id=\"T_3203a_row15_col4\" class=\"data row15 col4\" >0.671269</td>\n",
       "      <td id=\"T_3203a_row15_col5\" class=\"data row15 col5\" >0.797663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"4\">Test Specificity Mean</th>\n",
       "      <th id=\"T_3203a_level1_row16\" class=\"row_heading level1 row16\" >GradientBoosting</th>\n",
       "      <td id=\"T_3203a_row16_col0\" class=\"data row16 col0\" >0.606073</td>\n",
       "      <td id=\"T_3203a_row16_col1\" class=\"data row16 col1\" >0.568848</td>\n",
       "      <td id=\"T_3203a_row16_col2\" class=\"data row16 col2\" >0.590969</td>\n",
       "      <td id=\"T_3203a_row16_col3\" class=\"data row16 col3\" >0.447231</td>\n",
       "      <td id=\"T_3203a_row16_col4\" class=\"data row16 col4\" >0.592480</td>\n",
       "      <td id=\"T_3203a_row16_col5\" class=\"data row16 col5\" >0.400850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row17\" class=\"row_heading level1 row17\" >LogisticRegression</th>\n",
       "      <td id=\"T_3203a_row17_col0\" class=\"data row17 col0\" >0.666772</td>\n",
       "      <td id=\"T_3203a_row17_col1\" class=\"data row17 col1\" >0.600063</td>\n",
       "      <td id=\"T_3203a_row17_col2\" class=\"data row17 col2\" >0.658402</td>\n",
       "      <td id=\"T_3203a_row17_col3\" class=\"data row17 col3\" >0.514191</td>\n",
       "      <td id=\"T_3203a_row17_col4\" class=\"data row17 col4\" >0.653933</td>\n",
       "      <td id=\"T_3203a_row17_col5\" class=\"data row17 col5\" >0.442070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row18\" class=\"row_heading level1 row18\" >MLP</th>\n",
       "      <td id=\"T_3203a_row18_col0\" class=\"data row18 col0\" >0.625645</td>\n",
       "      <td id=\"T_3203a_row18_col1\" class=\"data row18 col1\" >0.581403</td>\n",
       "      <td id=\"T_3203a_row18_col2\" class=\"data row18 col2\" >0.628037</td>\n",
       "      <td id=\"T_3203a_row18_col3\" class=\"data row18 col3\" >0.476243</td>\n",
       "      <td id=\"T_3203a_row18_col4\" class=\"data row18 col4\" >0.639994</td>\n",
       "      <td id=\"T_3203a_row18_col5\" class=\"data row18 col5\" >0.512901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3203a_level1_row19\" class=\"row_heading level1 row19\" >RandomForest</th>\n",
       "      <td id=\"T_3203a_row19_col0\" class=\"data row19 col0\" >0.644430</td>\n",
       "      <td id=\"T_3203a_row19_col1\" class=\"data row19 col1\" >0.661800</td>\n",
       "      <td id=\"T_3203a_row19_col2\" class=\"data row19 col2\" >0.638609</td>\n",
       "      <td id=\"T_3203a_row19_col3\" class=\"data row19 col3\" >0.503147</td>\n",
       "      <td id=\"T_3203a_row19_col4\" class=\"data row19 col4\" >0.638924</td>\n",
       "      <td id=\"T_3203a_row19_col5\" class=\"data row19 col5\" >0.499087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ce5312d00d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the pivot table for better readability\n",
    "transposed_table = pivot_table.transpose()\n",
    "\n",
    "# Highlight the highest value in each row of the transposed table\n",
    "styled_table = transposed_table.style.highlight_max(color='lightgreen', axis=1)\n",
    "\n",
    "# Display the styled pivot table\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7271371-2dd2-48b5-8335-cb4a167bb7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2f9f1_row0_col16, #T_2f9f1_row0_col18, #T_2f9f1_row1_col19, #T_2f9f1_row2_col17, #T_2f9f1_row4_col1, #T_2f9f1_row5_col0, #T_2f9f1_row5_col2, #T_2f9f1_row5_col3, #T_2f9f1_row5_col4, #T_2f9f1_row5_col5, #T_2f9f1_row5_col6, #T_2f9f1_row5_col7, #T_2f9f1_row5_col8, #T_2f9f1_row5_col9, #T_2f9f1_row5_col10, #T_2f9f1_row5_col11, #T_2f9f1_row5_col12, #T_2f9f1_row5_col13, #T_2f9f1_row5_col14, #T_2f9f1_row5_col15 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2f9f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2f9f1_level0_col0\" class=\"col_heading level0 col0\" colspan=\"4\">AUC Mean</th>\n",
       "      <th id=\"T_2f9f1_level0_col4\" class=\"col_heading level0 col4\" colspan=\"4\">Accuracy Mean</th>\n",
       "      <th id=\"T_2f9f1_level0_col8\" class=\"col_heading level0 col8\" colspan=\"4\">F1 Score Mean</th>\n",
       "      <th id=\"T_2f9f1_level0_col12\" class=\"col_heading level0 col12\" colspan=\"4\">Sensitivity Mean</th>\n",
       "      <th id=\"T_2f9f1_level0_col16\" class=\"col_heading level0 col16\" colspan=\"4\">Specificity Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >Classifier</th>\n",
       "      <th id=\"T_2f9f1_level1_col0\" class=\"col_heading level1 col0\" >GradientBoosting</th>\n",
       "      <th id=\"T_2f9f1_level1_col1\" class=\"col_heading level1 col1\" >LogisticRegression</th>\n",
       "      <th id=\"T_2f9f1_level1_col2\" class=\"col_heading level1 col2\" >MLP</th>\n",
       "      <th id=\"T_2f9f1_level1_col3\" class=\"col_heading level1 col3\" >RandomForest</th>\n",
       "      <th id=\"T_2f9f1_level1_col4\" class=\"col_heading level1 col4\" >GradientBoosting</th>\n",
       "      <th id=\"T_2f9f1_level1_col5\" class=\"col_heading level1 col5\" >LogisticRegression</th>\n",
       "      <th id=\"T_2f9f1_level1_col6\" class=\"col_heading level1 col6\" >MLP</th>\n",
       "      <th id=\"T_2f9f1_level1_col7\" class=\"col_heading level1 col7\" >RandomForest</th>\n",
       "      <th id=\"T_2f9f1_level1_col8\" class=\"col_heading level1 col8\" >GradientBoosting</th>\n",
       "      <th id=\"T_2f9f1_level1_col9\" class=\"col_heading level1 col9\" >LogisticRegression</th>\n",
       "      <th id=\"T_2f9f1_level1_col10\" class=\"col_heading level1 col10\" >MLP</th>\n",
       "      <th id=\"T_2f9f1_level1_col11\" class=\"col_heading level1 col11\" >RandomForest</th>\n",
       "      <th id=\"T_2f9f1_level1_col12\" class=\"col_heading level1 col12\" >GradientBoosting</th>\n",
       "      <th id=\"T_2f9f1_level1_col13\" class=\"col_heading level1 col13\" >LogisticRegression</th>\n",
       "      <th id=\"T_2f9f1_level1_col14\" class=\"col_heading level1 col14\" >MLP</th>\n",
       "      <th id=\"T_2f9f1_level1_col15\" class=\"col_heading level1 col15\" >RandomForest</th>\n",
       "      <th id=\"T_2f9f1_level1_col16\" class=\"col_heading level1 col16\" >GradientBoosting</th>\n",
       "      <th id=\"T_2f9f1_level1_col17\" class=\"col_heading level1 col17\" >LogisticRegression</th>\n",
       "      <th id=\"T_2f9f1_level1_col18\" class=\"col_heading level1 col18\" >MLP</th>\n",
       "      <th id=\"T_2f9f1_level1_col19\" class=\"col_heading level1 col19\" >RandomForest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Sampling Technique</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "      <th class=\"blank col16\" >&nbsp;</th>\n",
       "      <th class=\"blank col17\" >&nbsp;</th>\n",
       "      <th class=\"blank col18\" >&nbsp;</th>\n",
       "      <th class=\"blank col19\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row0\" class=\"row_heading level0 row0\" >ADASYN</th>\n",
       "      <td id=\"T_2f9f1_row0_col0\" class=\"data row0 col0\" >0.728176</td>\n",
       "      <td id=\"T_2f9f1_row0_col1\" class=\"data row0 col1\" >0.698583</td>\n",
       "      <td id=\"T_2f9f1_row0_col2\" class=\"data row0 col2\" >0.729621</td>\n",
       "      <td id=\"T_2f9f1_row0_col3\" class=\"data row0 col3\" >0.689984</td>\n",
       "      <td id=\"T_2f9f1_row0_col4\" class=\"data row0 col4\" >0.684989</td>\n",
       "      <td id=\"T_2f9f1_row0_col5\" class=\"data row0 col5\" >0.643175</td>\n",
       "      <td id=\"T_2f9f1_row0_col6\" class=\"data row0 col6\" >0.677156</td>\n",
       "      <td id=\"T_2f9f1_row0_col7\" class=\"data row0 col7\" >0.641797</td>\n",
       "      <td id=\"T_2f9f1_row0_col8\" class=\"data row0 col8\" >0.741941</td>\n",
       "      <td id=\"T_2f9f1_row0_col9\" class=\"data row0 col9\" >0.685382</td>\n",
       "      <td id=\"T_2f9f1_row0_col10\" class=\"data row0 col10\" >0.726076</td>\n",
       "      <td id=\"T_2f9f1_row0_col11\" class=\"data row0 col11\" >0.687859</td>\n",
       "      <td id=\"T_2f9f1_row0_col12\" class=\"data row0 col12\" >0.738383</td>\n",
       "      <td id=\"T_2f9f1_row0_col13\" class=\"data row0 col13\" >0.633822</td>\n",
       "      <td id=\"T_2f9f1_row0_col14\" class=\"data row0 col14\" >0.698814</td>\n",
       "      <td id=\"T_2f9f1_row0_col15\" class=\"data row0 col15\" >0.643533</td>\n",
       "      <td id=\"T_2f9f1_row0_col16\" class=\"data row0 col16\" >0.600301</td>\n",
       "      <td id=\"T_2f9f1_row0_col17\" class=\"data row0 col17\" >0.658011</td>\n",
       "      <td id=\"T_2f9f1_row0_col18\" class=\"data row0 col18\" >0.642804</td>\n",
       "      <td id=\"T_2f9f1_row0_col19\" class=\"data row0 col19\" >0.639044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row1\" class=\"row_heading level0 row1\" >NearMiss</th>\n",
       "      <td id=\"T_2f9f1_row1_col0\" class=\"data row1 col0\" >0.624975</td>\n",
       "      <td id=\"T_2f9f1_row1_col1\" class=\"data row1 col1\" >0.618501</td>\n",
       "      <td id=\"T_2f9f1_row1_col2\" class=\"data row1 col2\" >0.614691</td>\n",
       "      <td id=\"T_2f9f1_row1_col3\" class=\"data row1 col3\" >0.560225</td>\n",
       "      <td id=\"T_2f9f1_row1_col4\" class=\"data row1 col4\" >0.595749</td>\n",
       "      <td id=\"T_2f9f1_row1_col5\" class=\"data row1 col5\" >0.585805</td>\n",
       "      <td id=\"T_2f9f1_row1_col6\" class=\"data row1 col6\" >0.587776</td>\n",
       "      <td id=\"T_2f9f1_row1_col7\" class=\"data row1 col7\" >0.547562</td>\n",
       "      <td id=\"T_2f9f1_row1_col8\" class=\"data row1 col8\" >0.655257</td>\n",
       "      <td id=\"T_2f9f1_row1_col9\" class=\"data row1 col9\" >0.630760</td>\n",
       "      <td id=\"T_2f9f1_row1_col10\" class=\"data row1 col10\" >0.633846</td>\n",
       "      <td id=\"T_2f9f1_row1_col11\" class=\"data row1 col11\" >0.566279</td>\n",
       "      <td id=\"T_2f9f1_row1_col12\" class=\"data row1 col12\" >0.626437</td>\n",
       "      <td id=\"T_2f9f1_row1_col13\" class=\"data row1 col13\" >0.576839</td>\n",
       "      <td id=\"T_2f9f1_row1_col14\" class=\"data row1 col14\" >0.583748</td>\n",
       "      <td id=\"T_2f9f1_row1_col15\" class=\"data row1 col15\" >0.481607</td>\n",
       "      <td id=\"T_2f9f1_row1_col16\" class=\"data row1 col16\" >0.547074</td>\n",
       "      <td id=\"T_2f9f1_row1_col17\" class=\"data row1 col17\" >0.600025</td>\n",
       "      <td id=\"T_2f9f1_row1_col18\" class=\"data row1 col18\" >0.594165</td>\n",
       "      <td id=\"T_2f9f1_row1_col19\" class=\"data row1 col19\" >0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row2\" class=\"row_heading level0 row2\" >SMOTE</th>\n",
       "      <td id=\"T_2f9f1_row2_col0\" class=\"data row2 col0\" >0.729038</td>\n",
       "      <td id=\"T_2f9f1_row2_col1\" class=\"data row2 col1\" >0.698826</td>\n",
       "      <td id=\"T_2f9f1_row2_col2\" class=\"data row2 col2\" >0.730995</td>\n",
       "      <td id=\"T_2f9f1_row2_col3\" class=\"data row2 col3\" >0.699964</td>\n",
       "      <td id=\"T_2f9f1_row2_col4\" class=\"data row2 col4\" >0.688232</td>\n",
       "      <td id=\"T_2f9f1_row2_col5\" class=\"data row2 col5\" >0.645201</td>\n",
       "      <td id=\"T_2f9f1_row2_col6\" class=\"data row2 col6\" >0.682477</td>\n",
       "      <td id=\"T_2f9f1_row2_col7\" class=\"data row2 col7\" >0.654026</td>\n",
       "      <td id=\"T_2f9f1_row2_col8\" class=\"data row2 col8\" >0.747344</td>\n",
       "      <td id=\"T_2f9f1_row2_col9\" class=\"data row2 col9\" >0.687629</td>\n",
       "      <td id=\"T_2f9f1_row2_col10\" class=\"data row2 col10\" >0.734686</td>\n",
       "      <td id=\"T_2f9f1_row2_col11\" class=\"data row2 col11\" >0.702330</td>\n",
       "      <td id=\"T_2f9f1_row2_col12\" class=\"data row2 col12\" >0.751859</td>\n",
       "      <td id=\"T_2f9f1_row2_col13\" class=\"data row2 col13\" >0.636748</td>\n",
       "      <td id=\"T_2f9f1_row2_col14\" class=\"data row2 col14\" >0.717631</td>\n",
       "      <td id=\"T_2f9f1_row2_col15\" class=\"data row2 col15\" >0.665480</td>\n",
       "      <td id=\"T_2f9f1_row2_col16\" class=\"data row2 col16\" >0.587313</td>\n",
       "      <td id=\"T_2f9f1_row2_col17\" class=\"data row2 col17\" >0.658609</td>\n",
       "      <td id=\"T_2f9f1_row2_col18\" class=\"data row2 col18\" >0.626717</td>\n",
       "      <td id=\"T_2f9f1_row2_col19\" class=\"data row2 col19\" >0.635858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row3\" class=\"row_heading level0 row3\" >SMOTEENN</th>\n",
       "      <td id=\"T_2f9f1_row3_col0\" class=\"data row3 col0\" >0.721608</td>\n",
       "      <td id=\"T_2f9f1_row3_col1\" class=\"data row3 col1\" >0.696595</td>\n",
       "      <td id=\"T_2f9f1_row3_col2\" class=\"data row3 col2\" >0.723850</td>\n",
       "      <td id=\"T_2f9f1_row3_col3\" class=\"data row3 col3\" >0.674302</td>\n",
       "      <td id=\"T_2f9f1_row3_col4\" class=\"data row3 col4\" >0.696926</td>\n",
       "      <td id=\"T_2f9f1_row3_col5\" class=\"data row3 col5\" >0.690145</td>\n",
       "      <td id=\"T_2f9f1_row3_col6\" class=\"data row3 col6\" >0.696083</td>\n",
       "      <td id=\"T_2f9f1_row3_col7\" class=\"data row3 col7\" >0.666519</td>\n",
       "      <td id=\"T_2f9f1_row3_col8\" class=\"data row3 col8\" >0.774397</td>\n",
       "      <td id=\"T_2f9f1_row3_col9\" class=\"data row3 col9\" >0.760297</td>\n",
       "      <td id=\"T_2f9f1_row3_col10\" class=\"data row3 col10\" >0.765662</td>\n",
       "      <td id=\"T_2f9f1_row3_col11\" class=\"data row3 col11\" >0.739211</td>\n",
       "      <td id=\"T_2f9f1_row3_col12\" class=\"data row3 col12\" >0.848187</td>\n",
       "      <td id=\"T_2f9f1_row3_col13\" class=\"data row3 col13\" >0.801263</td>\n",
       "      <td id=\"T_2f9f1_row3_col14\" class=\"data row3 col14\" >0.809610</td>\n",
       "      <td id=\"T_2f9f1_row3_col15\" class=\"data row3 col15\" >0.770691</td>\n",
       "      <td id=\"T_2f9f1_row3_col16\" class=\"data row3 col16\" >0.457009</td>\n",
       "      <td id=\"T_2f9f1_row3_col17\" class=\"data row3 col17\" >0.513901</td>\n",
       "      <td id=\"T_2f9f1_row3_col18\" class=\"data row3 col18\" >0.516017</td>\n",
       "      <td id=\"T_2f9f1_row3_col19\" class=\"data row3 col19\" >0.501290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row4\" class=\"row_heading level0 row4\" >SMOTETomek</th>\n",
       "      <td id=\"T_2f9f1_row4_col0\" class=\"data row4 col0\" >0.729255</td>\n",
       "      <td id=\"T_2f9f1_row4_col1\" class=\"data row4 col1\" >0.699083</td>\n",
       "      <td id=\"T_2f9f1_row4_col2\" class=\"data row4 col2\" >0.731262</td>\n",
       "      <td id=\"T_2f9f1_row4_col3\" class=\"data row4 col3\" >0.700267</td>\n",
       "      <td id=\"T_2f9f1_row4_col4\" class=\"data row4 col4\" >0.688557</td>\n",
       "      <td id=\"T_2f9f1_row4_col5\" class=\"data row4 col5\" >0.646348</td>\n",
       "      <td id=\"T_2f9f1_row4_col6\" class=\"data row4 col6\" >0.686553</td>\n",
       "      <td id=\"T_2f9f1_row4_col7\" class=\"data row4 col7\" >0.654263</td>\n",
       "      <td id=\"T_2f9f1_row4_col8\" class=\"data row4 col8\" >0.747970</td>\n",
       "      <td id=\"T_2f9f1_row4_col9\" class=\"data row4 col9\" >0.689405</td>\n",
       "      <td id=\"T_2f9f1_row4_col10\" class=\"data row4 col10\" >0.742662</td>\n",
       "      <td id=\"T_2f9f1_row4_col11\" class=\"data row4 col11\" >0.702672</td>\n",
       "      <td id=\"T_2f9f1_row4_col12\" class=\"data row4 col12\" >0.753550</td>\n",
       "      <td id=\"T_2f9f1_row4_col13\" class=\"data row4 col13\" >0.639967</td>\n",
       "      <td id=\"T_2f9f1_row4_col14\" class=\"data row4 col14\" >0.737535</td>\n",
       "      <td id=\"T_2f9f1_row4_col15\" class=\"data row4 col15\" >0.666114</td>\n",
       "      <td id=\"T_2f9f1_row4_col16\" class=\"data row4 col16\" >0.585472</td>\n",
       "      <td id=\"T_2f9f1_row4_col17\" class=\"data row4 col17\" >0.656469</td>\n",
       "      <td id=\"T_2f9f1_row4_col18\" class=\"data row4 col18\" >0.605689</td>\n",
       "      <td id=\"T_2f9f1_row4_col19\" class=\"data row4 col19\" >0.635465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f1_level0_row5\" class=\"row_heading level0 row5\" >TomekLinks</th>\n",
       "      <td id=\"T_2f9f1_row5_col0\" class=\"data row5 col0\" >0.730024</td>\n",
       "      <td id=\"T_2f9f1_row5_col1\" class=\"data row5 col1\" >0.698815</td>\n",
       "      <td id=\"T_2f9f1_row5_col2\" class=\"data row5 col2\" >0.732756</td>\n",
       "      <td id=\"T_2f9f1_row5_col3\" class=\"data row5 col3\" >0.700943</td>\n",
       "      <td id=\"T_2f9f1_row5_col4\" class=\"data row5 col4\" >0.699323</td>\n",
       "      <td id=\"T_2f9f1_row5_col5\" class=\"data row5 col5\" >0.692128</td>\n",
       "      <td id=\"T_2f9f1_row5_col6\" class=\"data row5 col6\" >0.699532</td>\n",
       "      <td id=\"T_2f9f1_row5_col7\" class=\"data row5 col7\" >0.679784</td>\n",
       "      <td id=\"T_2f9f1_row5_col8\" class=\"data row5 col8\" >0.782967</td>\n",
       "      <td id=\"T_2f9f1_row5_col9\" class=\"data row5 col9\" >0.773422</td>\n",
       "      <td id=\"T_2f9f1_row5_col10\" class=\"data row5 col10\" >0.778904</td>\n",
       "      <td id=\"T_2f9f1_row5_col11\" class=\"data row5 col11\" >0.752233</td>\n",
       "      <td id=\"T_2f9f1_row5_col12\" class=\"data row5 col12\" >0.884304</td>\n",
       "      <td id=\"T_2f9f1_row5_col13\" class=\"data row5 col13\" >0.856748</td>\n",
       "      <td id=\"T_2f9f1_row5_col14\" class=\"data row5 col14\" >0.863240</td>\n",
       "      <td id=\"T_2f9f1_row5_col15\" class=\"data row5 col15\" >0.792558</td>\n",
       "      <td id=\"T_2f9f1_row5_col16\" class=\"data row5 col16\" >0.405922</td>\n",
       "      <td id=\"T_2f9f1_row5_col17\" class=\"data row5 col17\" >0.431025</td>\n",
       "      <td id=\"T_2f9f1_row5_col18\" class=\"data row5 col18\" >0.439875</td>\n",
       "      <td id=\"T_2f9f1_row5_col19\" class=\"data row5 col19\" >0.500913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ce3cf37ca50>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FOR TRAIN SCORES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume results is already populated as a dictionary from previous runs\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "results_df.rename(columns={'index': 'Sampling_Technique_Classifier'}, inplace=True)\n",
    "\n",
    "# Split Sampling_Technique_Classifier into Sampling Technique and Classifier columns\n",
    "split_df = results_df['Sampling_Technique_Classifier'].str.split('_', n=1, expand=True)\n",
    "results_df['Sampling Technique'] = split_df[0]\n",
    "results_df['Classifier'] = split_df[1]\n",
    "\n",
    "# Separate mean and std into different columns for each metric (including both train and test metrics)\n",
    "metrics = ['Accuracy', 'AUC', 'Specificity', 'Sensitivity', 'F1 Score', \n",
    "           'Test Accuracy', 'Test AUC', 'Test Specificity', 'Test Sensitivity', 'Test F1 Score']\n",
    "for metric in metrics:\n",
    "    if metric in results_df.columns:\n",
    "        results_df[[f'{metric} Mean', f'{metric} Std']] = pd.DataFrame(results_df[metric].tolist(), index=results_df.index)\n",
    "\n",
    "# Select only the mean values for the test pivot table\n",
    "test_mean_columns = [col for col in results_df.columns if 'Test' in col and 'Mean' in col or col in ['Sampling Technique', 'Classifier']]\n",
    "results_df_test_mean = results_df[test_mean_columns]\n",
    "\n",
    "# Create the pivot table with Sampling Technique as index and Classifier as columns for test metrics\n",
    "test_pivot_table = results_df_test_mean.pivot_table(index='Sampling Technique', columns='Classifier', values=[\n",
    "    'Test Accuracy Mean', 'Test AUC Mean', 'Test Specificity Mean', 'Test Sensitivity Mean', 'Test F1 Score Mean'\n",
    "])\n",
    "\n",
    "# Highlight the highest value in each column for test metrics\n",
    "test_styled_table = test_pivot_table.style.highlight_max(color='lightgreen', axis=0)\n",
    "\n",
    "# Display the styled test pivot table\n",
    "test_styled_table\n",
    "\n",
    "# Create a similar pivot table for training metrics\n",
    "# Select only the mean values for the training pivot table\n",
    "train_mean_columns = [col for col in results_df.columns if 'Train' not in col and 'Test' not in col and 'Mean' in col or col in ['Sampling Technique', 'Classifier']]\n",
    "results_df_train_mean = results_df[train_mean_columns]\n",
    "\n",
    "# Create the pivot table with Sampling Technique as index and Classifier as columns for training metrics\n",
    "train_pivot_table = results_df_train_mean.pivot_table(index='Sampling Technique', columns='Classifier', values=[\n",
    "    'Accuracy Mean', 'AUC Mean', 'Specificity Mean', 'Sensitivity Mean', 'F1 Score Mean'\n",
    "])\n",
    "\n",
    "# Highlight the highest value in each column for training metrics\n",
    "train_styled_table = train_pivot_table.style.highlight_max(color='lightblue', axis=0)\n",
    "\n",
    "# Display the styled training pivot table\n",
    "train_styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed39d88b-9e3a-477b-931b-16c399d9e20b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e141_row0_col5, #T_8e141_row1_col4, #T_8e141_row2_col5, #T_8e141_row3_col5, #T_8e141_row4_col5, #T_8e141_row5_col5, #T_8e141_row6_col5, #T_8e141_row7_col5, #T_8e141_row8_col5, #T_8e141_row9_col5, #T_8e141_row10_col5, #T_8e141_row11_col5, #T_8e141_row12_col5, #T_8e141_row13_col5, #T_8e141_row14_col5, #T_8e141_row15_col5, #T_8e141_row16_col0, #T_8e141_row17_col2, #T_8e141_row18_col0, #T_8e141_row19_col1 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e141\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >Sampling Technique</th>\n",
       "      <th id=\"T_8e141_level0_col0\" class=\"col_heading level0 col0\" >ADASYN</th>\n",
       "      <th id=\"T_8e141_level0_col1\" class=\"col_heading level0 col1\" >NearMiss</th>\n",
       "      <th id=\"T_8e141_level0_col2\" class=\"col_heading level0 col2\" >SMOTE</th>\n",
       "      <th id=\"T_8e141_level0_col3\" class=\"col_heading level0 col3\" >SMOTEENN</th>\n",
       "      <th id=\"T_8e141_level0_col4\" class=\"col_heading level0 col4\" >SMOTETomek</th>\n",
       "      <th id=\"T_8e141_level0_col5\" class=\"col_heading level0 col5\" >TomekLinks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >&nbsp;</th>\n",
       "      <th class=\"index_name level1\" >Classifier</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">AUC Mean</th>\n",
       "      <th id=\"T_8e141_level1_row0\" class=\"row_heading level1 row0\" >GradientBoosting</th>\n",
       "      <td id=\"T_8e141_row0_col0\" class=\"data row0 col0\" >0.728176</td>\n",
       "      <td id=\"T_8e141_row0_col1\" class=\"data row0 col1\" >0.624975</td>\n",
       "      <td id=\"T_8e141_row0_col2\" class=\"data row0 col2\" >0.729038</td>\n",
       "      <td id=\"T_8e141_row0_col3\" class=\"data row0 col3\" >0.721608</td>\n",
       "      <td id=\"T_8e141_row0_col4\" class=\"data row0 col4\" >0.729255</td>\n",
       "      <td id=\"T_8e141_row0_col5\" class=\"data row0 col5\" >0.730024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row1\" class=\"row_heading level1 row1\" >LogisticRegression</th>\n",
       "      <td id=\"T_8e141_row1_col0\" class=\"data row1 col0\" >0.698583</td>\n",
       "      <td id=\"T_8e141_row1_col1\" class=\"data row1 col1\" >0.618501</td>\n",
       "      <td id=\"T_8e141_row1_col2\" class=\"data row1 col2\" >0.698826</td>\n",
       "      <td id=\"T_8e141_row1_col3\" class=\"data row1 col3\" >0.696595</td>\n",
       "      <td id=\"T_8e141_row1_col4\" class=\"data row1 col4\" >0.699083</td>\n",
       "      <td id=\"T_8e141_row1_col5\" class=\"data row1 col5\" >0.698815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row2\" class=\"row_heading level1 row2\" >MLP</th>\n",
       "      <td id=\"T_8e141_row2_col0\" class=\"data row2 col0\" >0.729621</td>\n",
       "      <td id=\"T_8e141_row2_col1\" class=\"data row2 col1\" >0.614691</td>\n",
       "      <td id=\"T_8e141_row2_col2\" class=\"data row2 col2\" >0.730995</td>\n",
       "      <td id=\"T_8e141_row2_col3\" class=\"data row2 col3\" >0.723850</td>\n",
       "      <td id=\"T_8e141_row2_col4\" class=\"data row2 col4\" >0.731262</td>\n",
       "      <td id=\"T_8e141_row2_col5\" class=\"data row2 col5\" >0.732756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row3\" class=\"row_heading level1 row3\" >RandomForest</th>\n",
       "      <td id=\"T_8e141_row3_col0\" class=\"data row3 col0\" >0.689984</td>\n",
       "      <td id=\"T_8e141_row3_col1\" class=\"data row3 col1\" >0.560225</td>\n",
       "      <td id=\"T_8e141_row3_col2\" class=\"data row3 col2\" >0.699964</td>\n",
       "      <td id=\"T_8e141_row3_col3\" class=\"data row3 col3\" >0.674302</td>\n",
       "      <td id=\"T_8e141_row3_col4\" class=\"data row3 col4\" >0.700267</td>\n",
       "      <td id=\"T_8e141_row3_col5\" class=\"data row3 col5\" >0.700943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">Accuracy Mean</th>\n",
       "      <th id=\"T_8e141_level1_row4\" class=\"row_heading level1 row4\" >GradientBoosting</th>\n",
       "      <td id=\"T_8e141_row4_col0\" class=\"data row4 col0\" >0.684989</td>\n",
       "      <td id=\"T_8e141_row4_col1\" class=\"data row4 col1\" >0.595749</td>\n",
       "      <td id=\"T_8e141_row4_col2\" class=\"data row4 col2\" >0.688232</td>\n",
       "      <td id=\"T_8e141_row4_col3\" class=\"data row4 col3\" >0.696926</td>\n",
       "      <td id=\"T_8e141_row4_col4\" class=\"data row4 col4\" >0.688557</td>\n",
       "      <td id=\"T_8e141_row4_col5\" class=\"data row4 col5\" >0.699323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row5\" class=\"row_heading level1 row5\" >LogisticRegression</th>\n",
       "      <td id=\"T_8e141_row5_col0\" class=\"data row5 col0\" >0.643175</td>\n",
       "      <td id=\"T_8e141_row5_col1\" class=\"data row5 col1\" >0.585805</td>\n",
       "      <td id=\"T_8e141_row5_col2\" class=\"data row5 col2\" >0.645201</td>\n",
       "      <td id=\"T_8e141_row5_col3\" class=\"data row5 col3\" >0.690145</td>\n",
       "      <td id=\"T_8e141_row5_col4\" class=\"data row5 col4\" >0.646348</td>\n",
       "      <td id=\"T_8e141_row5_col5\" class=\"data row5 col5\" >0.692128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row6\" class=\"row_heading level1 row6\" >MLP</th>\n",
       "      <td id=\"T_8e141_row6_col0\" class=\"data row6 col0\" >0.677156</td>\n",
       "      <td id=\"T_8e141_row6_col1\" class=\"data row6 col1\" >0.587776</td>\n",
       "      <td id=\"T_8e141_row6_col2\" class=\"data row6 col2\" >0.682477</td>\n",
       "      <td id=\"T_8e141_row6_col3\" class=\"data row6 col3\" >0.696083</td>\n",
       "      <td id=\"T_8e141_row6_col4\" class=\"data row6 col4\" >0.686553</td>\n",
       "      <td id=\"T_8e141_row6_col5\" class=\"data row6 col5\" >0.699532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row7\" class=\"row_heading level1 row7\" >RandomForest</th>\n",
       "      <td id=\"T_8e141_row7_col0\" class=\"data row7 col0\" >0.641797</td>\n",
       "      <td id=\"T_8e141_row7_col1\" class=\"data row7 col1\" >0.547562</td>\n",
       "      <td id=\"T_8e141_row7_col2\" class=\"data row7 col2\" >0.654026</td>\n",
       "      <td id=\"T_8e141_row7_col3\" class=\"data row7 col3\" >0.666519</td>\n",
       "      <td id=\"T_8e141_row7_col4\" class=\"data row7 col4\" >0.654263</td>\n",
       "      <td id=\"T_8e141_row7_col5\" class=\"data row7 col5\" >0.679784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"4\">F1 Score Mean</th>\n",
       "      <th id=\"T_8e141_level1_row8\" class=\"row_heading level1 row8\" >GradientBoosting</th>\n",
       "      <td id=\"T_8e141_row8_col0\" class=\"data row8 col0\" >0.741941</td>\n",
       "      <td id=\"T_8e141_row8_col1\" class=\"data row8 col1\" >0.655257</td>\n",
       "      <td id=\"T_8e141_row8_col2\" class=\"data row8 col2\" >0.747344</td>\n",
       "      <td id=\"T_8e141_row8_col3\" class=\"data row8 col3\" >0.774397</td>\n",
       "      <td id=\"T_8e141_row8_col4\" class=\"data row8 col4\" >0.747970</td>\n",
       "      <td id=\"T_8e141_row8_col5\" class=\"data row8 col5\" >0.782967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row9\" class=\"row_heading level1 row9\" >LogisticRegression</th>\n",
       "      <td id=\"T_8e141_row9_col0\" class=\"data row9 col0\" >0.685382</td>\n",
       "      <td id=\"T_8e141_row9_col1\" class=\"data row9 col1\" >0.630760</td>\n",
       "      <td id=\"T_8e141_row9_col2\" class=\"data row9 col2\" >0.687629</td>\n",
       "      <td id=\"T_8e141_row9_col3\" class=\"data row9 col3\" >0.760297</td>\n",
       "      <td id=\"T_8e141_row9_col4\" class=\"data row9 col4\" >0.689405</td>\n",
       "      <td id=\"T_8e141_row9_col5\" class=\"data row9 col5\" >0.773422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row10\" class=\"row_heading level1 row10\" >MLP</th>\n",
       "      <td id=\"T_8e141_row10_col0\" class=\"data row10 col0\" >0.726076</td>\n",
       "      <td id=\"T_8e141_row10_col1\" class=\"data row10 col1\" >0.633846</td>\n",
       "      <td id=\"T_8e141_row10_col2\" class=\"data row10 col2\" >0.734686</td>\n",
       "      <td id=\"T_8e141_row10_col3\" class=\"data row10 col3\" >0.765662</td>\n",
       "      <td id=\"T_8e141_row10_col4\" class=\"data row10 col4\" >0.742662</td>\n",
       "      <td id=\"T_8e141_row10_col5\" class=\"data row10 col5\" >0.778904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row11\" class=\"row_heading level1 row11\" >RandomForest</th>\n",
       "      <td id=\"T_8e141_row11_col0\" class=\"data row11 col0\" >0.687859</td>\n",
       "      <td id=\"T_8e141_row11_col1\" class=\"data row11 col1\" >0.566279</td>\n",
       "      <td id=\"T_8e141_row11_col2\" class=\"data row11 col2\" >0.702330</td>\n",
       "      <td id=\"T_8e141_row11_col3\" class=\"data row11 col3\" >0.739211</td>\n",
       "      <td id=\"T_8e141_row11_col4\" class=\"data row11 col4\" >0.702672</td>\n",
       "      <td id=\"T_8e141_row11_col5\" class=\"data row11 col5\" >0.752233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"4\">Sensitivity Mean</th>\n",
       "      <th id=\"T_8e141_level1_row12\" class=\"row_heading level1 row12\" >GradientBoosting</th>\n",
       "      <td id=\"T_8e141_row12_col0\" class=\"data row12 col0\" >0.738383</td>\n",
       "      <td id=\"T_8e141_row12_col1\" class=\"data row12 col1\" >0.626437</td>\n",
       "      <td id=\"T_8e141_row12_col2\" class=\"data row12 col2\" >0.751859</td>\n",
       "      <td id=\"T_8e141_row12_col3\" class=\"data row12 col3\" >0.848187</td>\n",
       "      <td id=\"T_8e141_row12_col4\" class=\"data row12 col4\" >0.753550</td>\n",
       "      <td id=\"T_8e141_row12_col5\" class=\"data row12 col5\" >0.884304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row13\" class=\"row_heading level1 row13\" >LogisticRegression</th>\n",
       "      <td id=\"T_8e141_row13_col0\" class=\"data row13 col0\" >0.633822</td>\n",
       "      <td id=\"T_8e141_row13_col1\" class=\"data row13 col1\" >0.576839</td>\n",
       "      <td id=\"T_8e141_row13_col2\" class=\"data row13 col2\" >0.636748</td>\n",
       "      <td id=\"T_8e141_row13_col3\" class=\"data row13 col3\" >0.801263</td>\n",
       "      <td id=\"T_8e141_row13_col4\" class=\"data row13 col4\" >0.639967</td>\n",
       "      <td id=\"T_8e141_row13_col5\" class=\"data row13 col5\" >0.856748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row14\" class=\"row_heading level1 row14\" >MLP</th>\n",
       "      <td id=\"T_8e141_row14_col0\" class=\"data row14 col0\" >0.698814</td>\n",
       "      <td id=\"T_8e141_row14_col1\" class=\"data row14 col1\" >0.583748</td>\n",
       "      <td id=\"T_8e141_row14_col2\" class=\"data row14 col2\" >0.717631</td>\n",
       "      <td id=\"T_8e141_row14_col3\" class=\"data row14 col3\" >0.809610</td>\n",
       "      <td id=\"T_8e141_row14_col4\" class=\"data row14 col4\" >0.737535</td>\n",
       "      <td id=\"T_8e141_row14_col5\" class=\"data row14 col5\" >0.863240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row15\" class=\"row_heading level1 row15\" >RandomForest</th>\n",
       "      <td id=\"T_8e141_row15_col0\" class=\"data row15 col0\" >0.643533</td>\n",
       "      <td id=\"T_8e141_row15_col1\" class=\"data row15 col1\" >0.481607</td>\n",
       "      <td id=\"T_8e141_row15_col2\" class=\"data row15 col2\" >0.665480</td>\n",
       "      <td id=\"T_8e141_row15_col3\" class=\"data row15 col3\" >0.770691</td>\n",
       "      <td id=\"T_8e141_row15_col4\" class=\"data row15 col4\" >0.666114</td>\n",
       "      <td id=\"T_8e141_row15_col5\" class=\"data row15 col5\" >0.792558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"4\">Specificity Mean</th>\n",
       "      <th id=\"T_8e141_level1_row16\" class=\"row_heading level1 row16\" >GradientBoosting</th>\n",
       "      <td id=\"T_8e141_row16_col0\" class=\"data row16 col0\" >0.600301</td>\n",
       "      <td id=\"T_8e141_row16_col1\" class=\"data row16 col1\" >0.547074</td>\n",
       "      <td id=\"T_8e141_row16_col2\" class=\"data row16 col2\" >0.587313</td>\n",
       "      <td id=\"T_8e141_row16_col3\" class=\"data row16 col3\" >0.457009</td>\n",
       "      <td id=\"T_8e141_row16_col4\" class=\"data row16 col4\" >0.585472</td>\n",
       "      <td id=\"T_8e141_row16_col5\" class=\"data row16 col5\" >0.405922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row17\" class=\"row_heading level1 row17\" >LogisticRegression</th>\n",
       "      <td id=\"T_8e141_row17_col0\" class=\"data row17 col0\" >0.658011</td>\n",
       "      <td id=\"T_8e141_row17_col1\" class=\"data row17 col1\" >0.600025</td>\n",
       "      <td id=\"T_8e141_row17_col2\" class=\"data row17 col2\" >0.658609</td>\n",
       "      <td id=\"T_8e141_row17_col3\" class=\"data row17 col3\" >0.513901</td>\n",
       "      <td id=\"T_8e141_row17_col4\" class=\"data row17 col4\" >0.656469</td>\n",
       "      <td id=\"T_8e141_row17_col5\" class=\"data row17 col5\" >0.431025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row18\" class=\"row_heading level1 row18\" >MLP</th>\n",
       "      <td id=\"T_8e141_row18_col0\" class=\"data row18 col0\" >0.642804</td>\n",
       "      <td id=\"T_8e141_row18_col1\" class=\"data row18 col1\" >0.594165</td>\n",
       "      <td id=\"T_8e141_row18_col2\" class=\"data row18 col2\" >0.626717</td>\n",
       "      <td id=\"T_8e141_row18_col3\" class=\"data row18 col3\" >0.516017</td>\n",
       "      <td id=\"T_8e141_row18_col4\" class=\"data row18 col4\" >0.605689</td>\n",
       "      <td id=\"T_8e141_row18_col5\" class=\"data row18 col5\" >0.439875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e141_level1_row19\" class=\"row_heading level1 row19\" >RandomForest</th>\n",
       "      <td id=\"T_8e141_row19_col0\" class=\"data row19 col0\" >0.639044</td>\n",
       "      <td id=\"T_8e141_row19_col1\" class=\"data row19 col1\" >0.652174</td>\n",
       "      <td id=\"T_8e141_row19_col2\" class=\"data row19 col2\" >0.635858</td>\n",
       "      <td id=\"T_8e141_row19_col3\" class=\"data row19 col3\" >0.501290</td>\n",
       "      <td id=\"T_8e141_row19_col4\" class=\"data row19 col4\" >0.635465</td>\n",
       "      <td id=\"T_8e141_row19_col5\" class=\"data row19 col5\" >0.500913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ce3ccf23a10>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_table = train_pivot_table.transpose()\n",
    "\n",
    "# Highlight the highest value in each row of the transposed table\n",
    "styled_table = transposed_table.style.highlight_max(color='lightblue', axis=1)\n",
    "\n",
    "# Display the styled pivot table\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "57d6d522-2023-48b4-89a2-60c33fd32ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks, NearMiss\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize sampling techniques\n",
    "sampling_techniques = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "    'NearMiss': NearMiss(version=1),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to create the MLP model\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Initialize the classifiers\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'MLP': create_mlp()  # Include MLP\n",
    "}\n",
    "\n",
    "# Define 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store results for each technique\n",
    "results = {}\n",
    "\n",
    "# Loop over each sampling technique\n",
    "for technique_name, sampler in sampling_techniques.items():\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        # Store metrics for each fold\n",
    "        accuracy_list = []\n",
    "        auc_list = []\n",
    "        specificity_list = []\n",
    "        sensitivity_list = []\n",
    "        f1_list = []\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            # Split the data into training and validation sets\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            # Apply the sampling technique to the training set\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Train the model\n",
    "            if classifier_name == 'MLP':\n",
    "                classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "            else:\n",
    "                classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            # Predict on the validation set\n",
    "            y_val_pred = (classifier.predict(X_val_fold) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_val_fold)\n",
    "            y_val_pred_prob = classifier.predict_proba(X_val_fold)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_val_fold)\n",
    "\n",
    "            # Calculate metrics for the fold\n",
    "            accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "            auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Store metrics\n",
    "            accuracy_list.append(accuracy)\n",
    "            auc_list.append(auc_score)\n",
    "            specificity_list.append(specificity)\n",
    "            sensitivity_list.append(sensitivity)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        results[f\"{technique_name}_{classifier_name}\"] = {\n",
    "            'Accuracy': np.mean(accuracy_list),\n",
    "            'AUC': np.mean(auc_list),\n",
    "            'Specificity': np.mean(specificity_list),\n",
    "            'Sensitivity': np.mean(sensitivity_list),\n",
    "            'F1 Score': np.mean(f1_list)\n",
    "        }\n",
    "\n",
    "# Evaluate on the test set using each sampling technique and classifier\n",
    "for technique_name, sampler in sampling_techniques.items():\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        # Apply the sampling technique to the entire training set\n",
    "        X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the resampled training set\n",
    "        if classifier_name == 'MLP':\n",
    "            classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "        else:\n",
    "            classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        y_test_pred = (classifier.predict(X_test) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_test)\n",
    "        y_test_pred_prob = classifier.predict_proba(X_test)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics on the test set\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_auc_score = roc_auc_score(y_test, y_test_pred_prob)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "        test_specificity = tn / (tn + fp)\n",
    "        test_sensitivity = tp / (tp + fn)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        # Store test set metrics with errors (set standard deviation to zero as there is no cross-validation for the test set)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Accuracy'] = (test_accuracy)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test AUC'] = (test_auc_score)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Specificity'] = (test_specificity)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test Sensitivity'] = (test_sensitivity)\n",
    "        results[f\"{technique_name}_{classifier_name}\"]['Test F1 Score'] = (test_f1)\n",
    "\n",
    "# Create a DataFrame to present the results for comparison\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Display the results DataFrame for easy comparison of metrics across techniques and classifiers\n",
    "#print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf24b27-9b44-4d16-b3d1-205fb985dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a58c855-af8b-4c8f-81ba-27655b0bc4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Test scores of sampling methods. Each value is highlighted to indicate its rank among the classifiers for each metric. The colors represent rankings as follows: red (1st), blue (2nd), green (3rd), cyan (4th), black (5th).}\n",
      "\\label{tab:sampling_methods}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      " & \\textbf{ADASYN} & \\textbf{SMOTE} & \\textbf{SMOTEENN} & \\textbf{SMOTETomek} & \\textbf{TomekLinks} \\\\\n",
      "\\midrule\n",
      "\\textbf{Test AUC} \\\\\n",
      "GradientBoosting & \\textcolor{green}{0.7295} & \\textcolor{blue}{0.7304} & \\textcolor{black}{0.7238} & \\textcolor{cyan}{0.7293} & \\textcolor{red}{0.7314} \\\\\n",
      "LogisticRegression & \\textcolor{red}{0.6998} & \\textcolor{cyan}{0.6983} & \\textcolor{black}{0.6968} & \\textcolor{blue}{0.699} & \\textcolor{blue}{0.699} \\\\\n",
      "MLP & \\textcolor{cyan}{0.7318} & \\textcolor{green}{0.7331} & \\textcolor{black}{0.7284} & \\textcolor{blue}{0.7332} & \\textcolor{red}{0.7337} \\\\\n",
      "RandomForest & \\textcolor{cyan}{0.6953} & \\textcolor{green}{0.7035} & \\textcolor{black}{0.6754} & \\textcolor{blue}{0.7041} & \\textcolor{red}{0.705} \\\\\n",
      "\\midrule\n",
      "\\textbf{Test Accuracy} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.6849} & \\textcolor{green}{0.6877} & \\textcolor{blue}{0.6976} & \\textcolor{cyan}{0.6863} & \\textcolor{red}{0.6995} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6391} & \\textcolor{cyan}{0.6447} & \\textcolor{blue}{0.692} & \\textcolor{green}{0.6463} & \\textcolor{red}{0.694} \\\\\n",
      "MLP & \\textcolor{black}{0.6767} & \\textcolor{green}{0.6793} & \\textcolor{blue}{0.6973} & \\textcolor{green}{0.6793} & \\textcolor{red}{0.6987} \\\\\n",
      "RandomForest & \\textcolor{black}{0.647} & \\textcolor{cyan}{0.6579} & \\textcolor{blue}{0.6689} & \\textcolor{green}{0.6588} & \\textcolor{red}{0.6822} \\\\\n",
      "\\midrule\n",
      "\\textbf{Test F1 Score} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.7409} & \\textcolor{green}{0.7462} & \\textcolor{blue}{0.7763} & \\textcolor{cyan}{0.7445} & \\textcolor{red}{0.7837} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6788} & \\textcolor{cyan}{0.6871} & \\textcolor{blue}{0.7621} & \\textcolor{green}{0.6899} & \\textcolor{red}{0.7737} \\\\\n",
      "MLP & \\textcolor{black}{0.7231} & \\textcolor{cyan}{0.7276} & \\textcolor{blue}{0.7707} & \\textcolor{green}{0.7286} & \\textcolor{red}{0.7726} \\\\\n",
      "RandomForest & \\textcolor{black}{0.6926} & \\textcolor{cyan}{0.7061} & \\textcolor{blue}{0.7413} & \\textcolor{green}{0.707} & \\textcolor{red}{0.7548} \\\\\n",
      "\\midrule\n",
      "\\textbf{Test Sensitivity} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.7347} & \\textcolor{green}{0.7486} & \\textcolor{blue}{0.8554} & \\textcolor{cyan}{0.7454} & \\textcolor{red}{0.8878} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6217} & \\textcolor{cyan}{0.636} & \\textcolor{blue}{0.8042} & \\textcolor{green}{0.6415} & \\textcolor{red}{0.8528} \\\\\n",
      "MLP & \\textcolor{black}{0.6885} & \\textcolor{cyan}{0.6985} & \\textcolor{blue}{0.8295} & \\textcolor{green}{0.7019} & \\textcolor{red}{0.8347} \\\\\n",
      "RandomForest & \\textcolor{black}{0.6486} & \\textcolor{cyan}{0.6701} & \\textcolor{blue}{0.7734} & \\textcolor{green}{0.6713} & \\textcolor{red}{0.7977} \\\\\n",
      "\\midrule\n",
      "\\textbf{Test Specificity} \\\\\n",
      "GradientBoosting & \\textcolor{red}{0.6061} & \\textcolor{green}{0.591} & \\textcolor{cyan}{0.4472} & \\textcolor{blue}{0.5925} & \\textcolor{black}{0.4008} \\\\\n",
      "LogisticRegression & \\textcolor{red}{0.6668} & \\textcolor{blue}{0.6584} & \\textcolor{cyan}{0.5142} & \\textcolor{green}{0.6539} & \\textcolor{black}{0.4421} \\\\\n",
      "MLP & \\textcolor{red}{0.6579} & \\textcolor{blue}{0.6487} & \\textcolor{cyan}{0.4877} & \\textcolor{green}{0.6435} & \\textcolor{black}{0.483} \\\\\n",
      "RandomForest & \\textcolor{red}{0.6444} & \\textcolor{green}{0.6386} & \\textcolor{cyan}{0.5031} & \\textcolor{blue}{0.6389} & \\textcolor{black}{0.4991} \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "#latex for test scores\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Assume results is already populated as a dictionary from previous runs\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "results_df.rename(columns={'index': 'Sampling_Technique_Classifier'}, inplace=True)\n",
    "\n",
    "# Split Sampling_Technique_Classifier into Sampling Technique and Classifier columns\n",
    "split_df = results_df['Sampling_Technique_Classifier'].str.split('_', n=1, expand=True)\n",
    "results_df['Sampling Technique'] = split_df[0]\n",
    "results_df['Classifier'] = split_df[1]\n",
    "\n",
    "# Round values to 4 decimal places\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "# Select only the mean values for the test pivot table\n",
    "test_mean_columns = [col for col in results_df.columns if 'Test' in col or col in ['Sampling Technique', 'Classifier']]\n",
    "results_df_test_mean = results_df[test_mean_columns]\n",
    "\n",
    "# Remove the NearMiss column\n",
    "results_df_test_mean = results_df_test_mean[results_df_test_mean['Sampling Technique'] != 'NearMiss']\n",
    "\n",
    "# Create the pivot table for test metrics\n",
    "test_pivot_table = results_df_test_mean.pivot_table(index='Sampling Technique', columns='Classifier', values=[\n",
    "    'Test Accuracy', 'Test AUC', 'Test Specificity', 'Test Sensitivity', 'Test F1 Score'\n",
    "])\n",
    "\n",
    "# Function to format the DataFrame for LaTeX-style highlighting\n",
    "def format_with_underline(df):\n",
    "    color_map = ['red', 'blue', 'green', 'cyan', 'black']\n",
    "    styled_values = df.copy().astype(str)  # Make a copy and convert to string for formatting\n",
    "\n",
    "    for col in df.columns:  # Iterating over all columns in the pivot table\n",
    "        col_values = df[col]\n",
    "        ranks = col_values.rank(ascending=False)\n",
    "        for idx in ranks.index:\n",
    "            rank_value = ranks[idx]\n",
    "            if not pd.isna(rank_value):  # Make sure it's not NaN\n",
    "                rank_value = int(rank_value)\n",
    "                if rank_value <= len(color_map):\n",
    "                    color = color_map[rank_value - 1]\n",
    "                    original_value = df.loc[idx, col]\n",
    "                    styled_values.loc[idx, col] = f\"\\\\textcolor{{{color}}}{{{original_value}}}\"\n",
    "\n",
    "    return styled_values\n",
    "\n",
    "# Applying the formatting function to the test metrics\n",
    "styled_test_pivot_table = format_with_underline(test_pivot_table)\n",
    "\n",
    "# Transpose the styled DataFrame for better readability\n",
    "transposed_styled_test_pivot_table = styled_test_pivot_table.transpose()\n",
    "\n",
    "# Function to export the formatted DataFrame to LaTeX with merged columns for metrics and lines below each metric section\n",
    "def export_to_latex(df, metric_names):\n",
    "    # Update the caption to describe color ranking\n",
    "    latex_str = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Test scores of sampling methods. Each value is highlighted to indicate its rank among the classifiers for each metric. The colors represent rankings as follows: red (1st), blue (2nd), green (3rd), cyan (4th), black (5th).}\\n\\\\label{tab:sampling_methods}\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l\" + \"c\" * (df.shape[1]) + \"}\\n\\\\toprule\\n\"\n",
    "\n",
    "    # Add header row for classifiers\n",
    "    latex_str += \" & \" + \" & \".join([f\"\\\\textbf{{{col}}}\" for col in df.columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "\n",
    "    # Add metric rows with merged metric headers and lines between metrics\n",
    "    for i, metric in enumerate(metric_names):\n",
    "        latex_str += f\"\\\\textbf{{{metric}}} \\\\\\\\\\n\"\n",
    "        metric_data = df.loc[metric]\n",
    "        for idx in metric_data.index:\n",
    "            row_values = \" & \".join(metric_data.loc[idx])\n",
    "            latex_str += f\"{idx} & {row_values} \\\\\\\\\\n\"\n",
    "        latex_str += \"\\\\midrule\\n\"  # Add separation line below each metric section\n",
    "\n",
    "    # Close table syntax\n",
    "    latex_str += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\\\\end{table}\"\n",
    "    return latex_str\n",
    "\n",
    "# Define metric names for grouping\n",
    "metric_names = ['Test AUC', 'Test Accuracy', 'Test F1 Score', 'Test Sensitivity', 'Test Specificity']\n",
    "\n",
    "# Generate the LaTeX string\n",
    "latex_code = export_to_latex(transposed_styled_test_pivot_table, metric_names)\n",
    "\n",
    "# Display the LaTeX code\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f11b477-1422-4937-b96a-db0ceec387e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Training scores of sampling methods. Each value is highlighted to indicate its rank among the classifiers for each metric. The colors represent rankings as follows: red (1st), blue (2nd), green (3rd), cyan (4th), black (5th).}\n",
      "\\label{tab:sampling_methods_train}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      " & \\textbf{ADASYN} & \\textbf{SMOTE} & \\textbf{SMOTEENN} & \\textbf{SMOTETomek} & \\textbf{TomekLinks} \\\\\n",
      "\\midrule\n",
      "\\textbf{Train AUC} \\\\\n",
      "GradientBoosting & \\textcolor{cyan}{0.7282} & \\textcolor{green}{0.729} & \\textcolor{black}{0.7216} & \\textcolor{blue}{0.7293} & \\textcolor{red}{0.73} \\\\\n",
      "LogisticRegression & \\textcolor{cyan}{0.6986} & \\textcolor{blue}{0.6988} & \\textcolor{black}{0.6966} & \\textcolor{red}{0.6991} & \\textcolor{blue}{0.6988} \\\\\n",
      "MLP & \\textcolor{green}{0.7312} & \\textcolor{cyan}{0.7308} & \\textcolor{black}{0.7223} & \\textcolor{blue}{0.7322} & \\textcolor{red}{0.733} \\\\\n",
      "RandomForest & \\textcolor{cyan}{0.69} & \\textcolor{green}{0.7} & \\textcolor{black}{0.6743} & \\textcolor{blue}{0.7003} & \\textcolor{red}{0.7009} \\\\\n",
      "\\midrule\n",
      "\\textbf{Train Accuracy} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.685} & \\textcolor{cyan}{0.6882} & \\textcolor{blue}{0.6969} & \\textcolor{green}{0.6886} & \\textcolor{red}{0.6993} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6432} & \\textcolor{cyan}{0.6452} & \\textcolor{blue}{0.6901} & \\textcolor{green}{0.6463} & \\textcolor{red}{0.6921} \\\\\n",
      "MLP & \\textcolor{cyan}{0.6819} & \\textcolor{black}{0.677} & \\textcolor{blue}{0.6966} & \\textcolor{green}{0.6823} & \\textcolor{red}{0.6992} \\\\\n",
      "RandomForest & \\textcolor{black}{0.6418} & \\textcolor{cyan}{0.654} & \\textcolor{blue}{0.6665} & \\textcolor{green}{0.6543} & \\textcolor{red}{0.6798} \\\\\n",
      "\\midrule\n",
      "\\textbf{Train F1 Score} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.7419} & \\textcolor{cyan}{0.7473} & \\textcolor{blue}{0.7744} & \\textcolor{green}{0.748} & \\textcolor{red}{0.783} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6854} & \\textcolor{cyan}{0.6876} & \\textcolor{blue}{0.7603} & \\textcolor{green}{0.6894} & \\textcolor{red}{0.7734} \\\\\n",
      "MLP & \\textcolor{cyan}{0.733} & \\textcolor{black}{0.7248} & \\textcolor{blue}{0.7663} & \\textcolor{green}{0.7336} & \\textcolor{red}{0.7792} \\\\\n",
      "RandomForest & \\textcolor{black}{0.6879} & \\textcolor{cyan}{0.7023} & \\textcolor{blue}{0.7392} & \\textcolor{green}{0.7027} & \\textcolor{red}{0.7522} \\\\\n",
      "\\midrule\n",
      "\\textbf{Train Sensitivity} \\\\\n",
      "GradientBoosting & \\textcolor{black}{0.7384} & \\textcolor{cyan}{0.7519} & \\textcolor{blue}{0.8482} & \\textcolor{green}{0.7535} & \\textcolor{red}{0.8843} \\\\\n",
      "LogisticRegression & \\textcolor{black}{0.6338} & \\textcolor{cyan}{0.6367} & \\textcolor{blue}{0.8013} & \\textcolor{green}{0.64} & \\textcolor{red}{0.8567} \\\\\n",
      "MLP & \\textcolor{cyan}{0.7125} & \\textcolor{black}{0.694} & \\textcolor{blue}{0.8116} & \\textcolor{green}{0.7134} & \\textcolor{red}{0.8654} \\\\\n",
      "RandomForest & \\textcolor{black}{0.6435} & \\textcolor{cyan}{0.6655} & \\textcolor{blue}{0.7707} & \\textcolor{green}{0.6661} & \\textcolor{red}{0.7926} \\\\\n",
      "\\midrule\n",
      "\\textbf{Train Specificity} \\\\\n",
      "GradientBoosting & \\textcolor{red}{0.6003} & \\textcolor{blue}{0.5873} & \\textcolor{cyan}{0.457} & \\textcolor{green}{0.5855} & \\textcolor{black}{0.4059} \\\\\n",
      "LogisticRegression & \\textcolor{blue}{0.658} & \\textcolor{red}{0.6586} & \\textcolor{cyan}{0.5139} & \\textcolor{green}{0.6565} & \\textcolor{black}{0.431} \\\\\n",
      "MLP & \\textcolor{blue}{0.6333} & \\textcolor{red}{0.6499} & \\textcolor{cyan}{0.5143} & \\textcolor{green}{0.633} & \\textcolor{black}{0.4355} \\\\\n",
      "RandomForest & \\textcolor{red}{0.639} & \\textcolor{blue}{0.6359} & \\textcolor{cyan}{0.5013} & \\textcolor{green}{0.6355} & \\textcolor{black}{0.5009} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "#generate latex for train similary can be done for test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Assume results is already populated as a dictionary from previous runs\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "results_df.rename(columns={'index': 'Sampling_Technique_Classifier'}, inplace=True)\n",
    "\n",
    "# Split Sampling_Technique_Classifier into Sampling Technique and Classifier columns\n",
    "split_df = results_df['Sampling_Technique_Classifier'].str.split('_', n=1, expand=True)\n",
    "results_df['Sampling Technique'] = split_df[0]\n",
    "results_df['Classifier'] = split_df[1]\n",
    "\n",
    "# Rename metrics to include 'Train' in the metric names\n",
    "metrics_to_rename = ['Accuracy', 'AUC', 'Specificity', 'Sensitivity', 'F1 Score']\n",
    "for metric in metrics_to_rename:\n",
    "    if metric in results_df.columns:\n",
    "        results_df.rename(columns={metric: f\"Train {metric}\"}, inplace=True)\n",
    "\n",
    "# Round values to 4 decimal places\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "# Select only the mean values for the train pivot table\n",
    "train_mean_columns = [col for col in results_df.columns if 'Train' in col or col in ['Sampling Technique', 'Classifier']]\n",
    "results_df_train_mean = results_df[train_mean_columns]\n",
    "\n",
    "# Remove the NearMiss column\n",
    "results_df_train_mean = results_df_train_mean[results_df_train_mean['Sampling Technique'] != 'NearMiss']\n",
    "\n",
    "# Create the pivot table for train metrics\n",
    "train_pivot_table = results_df_train_mean.pivot_table(index='Sampling Technique', columns='Classifier', values=[\n",
    "    'Train Accuracy', 'Train AUC', 'Train Specificity', 'Train Sensitivity', 'Train F1 Score'\n",
    "])\n",
    "\n",
    "# Function to format the DataFrame for LaTeX-style highlighting\n",
    "def format_with_underline(df):\n",
    "    color_map = ['red', 'blue', 'green', 'cyan', 'black']\n",
    "    styled_values = df.copy().astype(str)  # Make a copy and convert to string for formatting\n",
    "\n",
    "    for col in df.columns:  # Iterating over all columns in the pivot table\n",
    "        col_values = df[col]\n",
    "        ranks = col_values.rank(ascending=False)\n",
    "        for idx in ranks.index:\n",
    "            rank_value = ranks[idx]\n",
    "            if not pd.isna(rank_value):  # Make sure it's not NaN\n",
    "                rank_value = int(rank_value)\n",
    "                if rank_value <= len(color_map):\n",
    "                    color = color_map[rank_value - 1]\n",
    "                    original_value = df.loc[idx, col]\n",
    "                    styled_values.loc[idx, col] = f\"\\\\textcolor{{{color}}}{{{original_value}}}\"\n",
    "\n",
    "    return styled_values\n",
    "\n",
    "# Applying the formatting function to the train metrics\n",
    "styled_train_pivot_table = format_with_underline(train_pivot_table)\n",
    "\n",
    "# Transpose the styled DataFrame for better readability\n",
    "transposed_styled_train_pivot_table = styled_train_pivot_table.transpose()\n",
    "\n",
    "# Function to export the formatted DataFrame to LaTeX with merged columns for metrics and lines below each metric section\n",
    "def export_to_latex(df):\n",
    "    # Update the caption to describe color ranking\n",
    "    latex_str = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Training scores of sampling methods. Each value is highlighted to indicate its rank among the classifiers for each metric. The colors represent rankings as follows: red (1st), blue (2nd), green (3rd), cyan (4th), black (5th).}\\n\\\\label{tab:sampling_methods_train}\\n\\\\resizebox{\\\\textwidth}{!}{%\\n\\\\begin{tabular}{l\" + \"c\" * (df.shape[1]) + \"}\\n\\\\toprule\\n\"\n",
    "\n",
    "    # Add header row for classifiers\n",
    "    latex_str += \" & \" + \" & \".join([f\"\\\\textbf{{{col}}}\" for col in df.columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "\n",
    "    # Add metric rows with merged metric headers and lines between metrics\n",
    "    current_metric_name = None\n",
    "    for idx in df.index:\n",
    "        metric_name, classifier = idx\n",
    "        if metric_name != current_metric_name:\n",
    "            if current_metric_name is not None:\n",
    "                latex_str += \"\\\\midrule\\n\"  # Add separation line below each metric section\n",
    "            latex_str += f\"\\\\textbf{{{metric_name}}} \\\\\\\\\\n\"\n",
    "            current_metric_name = metric_name\n",
    "\n",
    "        row_values = \" & \".join(df.loc[idx])\n",
    "        latex_str += f\"{classifier} & {row_values} \\\\\\\\\\n\"\n",
    "\n",
    "    # Close table syntax\n",
    "    latex_str += \"\\\\bottomrule\\n\\\\end{tabular}%\\n}\\n\\\\end{table}\"\n",
    "    return latex_str\n",
    "\n",
    "# Generate the LaTeX string for training metrics\n",
    "latex_code_train = export_to_latex(transposed_styled_train_pivot_table)\n",
    "\n",
    "# Display the LaTeX code for training metrics\n",
    "print(latex_code_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56239e-4ebd-4db7-8cbc-d28ec554e87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c875be7-2fa1-4dc7-9f7e-481686231303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a742c299-a01c-41ec-ad57-88aff4c24e0a",
   "metadata": {},
   "source": [
    "### Extracting Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5d52b-9b90-4b47-a0c4-91f8888c6255",
   "metadata": {
    "tags": []
   },
   "source": [
    " now we extract rules for the GB model for both cases short and long "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7891c9-dccb-4dd8-9d63-af86ade64a08",
   "metadata": {},
   "source": [
    "#### Long Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "15632df8-e2d3-4561-a08a-d5f5a23c0729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using te2rules version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# TE2Rules supports tree ensemble models from scikit-learn and xgboost   \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import te2rules\n",
    "from te2rules.explainer import ModelExplainer\n",
    "\n",
    "print(\"Using te2rules version: \" + str(te2rules.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "12a10b87-090f-478c-a6df-1b93cb623e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS_category\n",
      "long     252029\n",
      "short    158898\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#ENSURE LONG STAY\n",
    "# Define the threshold for LOS classification\n",
    "threshold = 4.5  # Define your threshold value here (in hours)\n",
    "\n",
    "# Create a new binary variable indicating short or long stays\n",
    "df_master['LOS_category'] = df_master['ed_los_hours_iter'].apply(lambda x: 'short' if x <= threshold else 'long')\n",
    "\n",
    "# Optionally, encode the binary variable as 0s and 1s\n",
    "df_master['LOS_category_encoded'] = df_master['LOS_category'].map({'short': 0, 'long': 1})\n",
    "\n",
    "# Display the counts of each category\n",
    "print(df_master['LOS_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee320317-c15d-411b-8768-6395b88deb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_master_new = df_master[['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', \n",
    "                      'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE',\n",
    "                      'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME',\n",
    "                      \"LOS_category_encoded\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "47eadf1b-4990-4778-9216-ebdf64cd3cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the specific feature to use an underscore instead of spaces\n",
    "df_master_new.rename(columns={'disposition_LEFT WITHOUT BEING SEEN': 'disposition_LEFT_WITHOUT_BEING_SEEN'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7eff6c6d-0fc7-4e55-8abb-f1415cb45bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_master_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5af8fc3a-1558-4267-9986-fd1c78619bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = df_master_new.sample(frac=0.8,random_state=10) #set seed\n",
    "data_test = df_master_new.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf6e6914-1bbb-4f38-91c9-9bb043dccf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = list(data_train.columns)\n",
    "feature_names = cols[:-1]\n",
    "label_name = cols[-1]\n",
    "\n",
    "data_train = data_train.to_numpy()\n",
    "data_test = data_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "490552ef-5e8c-47a2-b0ef-697db3fc6376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b92084fc-dd58-49ae-aa0d-4754404e271b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4124d48a-420c-486c-ac55-891288b3022f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "879347f4-d183-4363-a24c-dd7bf159ca80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9a71e-6d3a-407d-ac4e-79ecc732c8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "19976548-ad5f-4397-850a-547a7696dda9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train GB Model\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30c835c1-cfb6-4f53-b23e-47b52c8dc1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_train_pred_score = model.predict_proba(x_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred_score = model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7702e213-72fc-42e3-a72c-a96f60981e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.696611303765894\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.score(x_test, y_test)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94550ccb-bcfa-4df0-ad48-cb1a12bb703b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "82eebd7e-9f8d-41d6-9a6b-b5aec18bbb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC\n",
      "0.7280699805317472\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"AUC\")\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08d82429-eaf2-40ad-bceb-3fe200858707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [00:03<00:00, 261.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#explain model at 0.9 precision\n",
    "model_explainer = ModelExplainer(\n",
    "    model=model, \n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "rules = model_explainer.explain(\n",
    "    X=x_train, y=y_train_pred,\n",
    "    #num_stages = 10,               # stages can be between 1 and max_depth \n",
    "    min_precision = 0.90,          # higher min_precision can result in rules with more terms overfit on training data \n",
    "    #jaccard_threshold = 0.4        # lower jaccard_threshold speeds up the rule exploration, but can miss some good rules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ae612fa0-2086-4250-af45-0f3163c337c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rules found:\n",
      "\n",
      "Rule 0: age > 29.5 & arrival_transport_UNKNOWN <= 0.5 & triage_acuity_iter <= 3.5\n",
      "Rule 1: arrival_transport_AMBULANCE > 0.5\n",
      "Rule 2: age <= 70.5 & triage_acuity_iter <= 2.5\n",
      "Rule 3: chiefcom_abdominal_pain > 0.5\n",
      "Rule 4: chiefcom_abdominal_pain <= 0.5 & disposition_HOME <= 0.5 & disposition_LEFT_WITHOUT_BEING_SEEN <= 0.5\n",
      "Rule 5: eci_score > 0.5\n"
     ]
    }
   ],
   "source": [
    "#inspect rules\n",
    "print(str(len(rules)) + \" rules found:\")\n",
    "print()\n",
    "for i in range(len(rules)):\n",
    "    print(\"Rule \" + str(i) + \": \" + str(rules[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e8f10b7a-d654-40ac-84da-e972e17d171b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rules explain 88.16% of the overall predictions of the model\n",
      "The rules explain 100.0% of the positive predictions of the model\n",
      "The rules explain 48.3% of the negative predictions of the model\n"
     ]
    }
   ],
   "source": [
    "fidelity, positive_fidelity, negative_fidelity = model_explainer.get_fidelity()\n",
    "\n",
    "print(\"The rules explain \" + str(round(fidelity*100, 2)) + \"% of the overall predictions of the model\" )\n",
    "print(\"The rules explain \" + str(round(positive_fidelity*100, 2)) + \"% of the positive predictions of the model\" )\n",
    "print(\"The rules explain \" + str(round(negative_fidelity*100, 2)) + \"% of the negative predictions of the model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d82f0-59bc-4cee-a19a-c12dbf20522c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac80804-3445-4ff8-afe6-6c3c8dba6ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ea4ab-bfe7-4de0-afa1-b5a51a318eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "763f5312-58a0-4d42-85ee-cf6474342483",
   "metadata": {},
   "source": [
    "#### Short Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "313bc73d-23a9-4371-b7e0-84e939d267b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS_category\n",
      "long     252029\n",
      "short    158898\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#ENSURE SHORT STAY = 1\n",
    "# Define the threshold for LOS classification\n",
    "threshold = 4.5  # Define your threshold value here (in hours)\n",
    "\n",
    "# Create a new binary variable indicating short or long stays\n",
    "df_master['LOS_category'] = df_master['ed_los_hours_iter'].apply(lambda x: 'short' if x <= threshold else 'long')\n",
    "\n",
    "# Optionally, encode the binary variable as 0s and 1s\n",
    "df_master['LOS_category_encoded'] = df_master['LOS_category'].map({'short': 1, 'long': 0})\n",
    "\n",
    "# Display the counts of each category\n",
    "print(df_master['LOS_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cfabd8d8-0705-4b8e-9a6a-287ee38bad43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_master_new = df_master[['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', \n",
    "                      'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE',\n",
    "                      'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME',\n",
    "                      \"LOS_category_encoded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a01217b4-cb71-4fa8-b941-f20ffc625abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the specific feature to use an underscore instead of spaces\n",
    "df_master_new.rename(columns={'disposition_LEFT WITHOUT BEING SEEN': 'disposition_LEFT_WITHOUT_BEING_SEEN'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c2b08d9a-b953-4d93-982c-45e33906f637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = df_master_new.sample(frac=0.8,random_state=10) #set seed\n",
    "data_test = df_master_new.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fee4974-da36-4044-9fee-b3c30099de57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = list(data_train.columns)\n",
    "feature_names = cols[:-1]\n",
    "label_name = cols[-1]\n",
    "\n",
    "data_train = data_train.to_numpy()\n",
    "data_test = data_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa4eea11-2697-429e-968e-99d37312b98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "\n",
    "x_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7dd14a6-712a-41ae-b427-0aad4fa396fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfa18b-8734-4312-92d2-45ca9aa8d059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "46c26ea6-3370-4701-acc6-fae46bcedaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train GB Model\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c763af4d-c07c-4682-b5a7-c3ee4f49822a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_train_pred_score = model.predict_proba(x_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred_score = model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "201b4afc-03fb-4481-a30a-87d57f0842ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.696611303765894\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.score(x_test, y_test)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1d5d944-a7f3-4134-bb1c-0b8c3e662cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC\n",
      "0.7280699805317472\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"AUC\")\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6fe5091-088b-4536-a7e3-6689b571400d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [00:03<00:00, 261.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36556/36556 [03:42<00:00, 164.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744322/744322 [15:24<00:00, 805.18it/s]  \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5176412/5176412 [18:54<00:00, 4564.29it/s] \n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#explain model at 0.9 precision\n",
    "model_explainer = ModelExplainer(\n",
    "    model=model, \n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "rules = model_explainer.explain(\n",
    "    X=x_train, y=y_train_pred,\n",
    "    #num_stages = 10,               # stages can be between 1 and max_depth \n",
    "    min_precision = 0.90,          # higher min_precision can result in rules with more terms overfit on training data \n",
    "    #jaccard_threshold = 0.4        # lower jaccard_threshold speeds up the rule exploration, but can miss some good rules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2efb7f6f-fb72-4b1c-81ce-15264436e318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 rules found:\n",
      "\n",
      "Rule 0: arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter > 2.5\n",
      "Rule 1: age <= 30.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & triage_acuity_iter > 2.5\n",
      "Rule 2: triage_acuity_iter > 3.5\n",
      "Rule 3: arrival_transport_UNKNOWN > 0.5\n",
      "Rule 4: age <= 45.5 & age > 38.5 & arrival_transport_AMBULANCE <= 0.5 & arrival_transport_UNKNOWN <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & eci_score <= 0.5 & triage_acuity_iter <= 3.5 & triage_acuity_iter > 2.5\n",
      "Rule 5: age <= 37.5 & age > 32.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & eci_score <= 0.5 & triage_acuity_iter > 2.5\n",
      "Rule 6: disposition_LEFT_WITHOUT_BEING_SEEN > 0.5\n",
      "Rule 7: age <= 89.5 & age > 74.5 & arrival_transport_AMBULANCE > 0.5 & disposition_HOME <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 8: age > 74.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 10.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 9: age <= 38.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 6.5 & triage_acuity_iter > 2.5\n",
      "Rule 10: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 11: age > 70.5 & arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & med_event <= 0.5\n",
      "Rule 12: age > 89.5 & disposition_LEFT_WITHOUT_BEING_SEEN <= 0.5 & eci_score <= 17.5 & eci_score > 15.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 13: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 14: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
      "Rule 15: age <= 27.5 & arrival_transport_AMBULANCE > 0.5 & disposition_HOME <= 0.5 & eci_score <= 10.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n"
     ]
    }
   ],
   "source": [
    "#inspect rules\n",
    "print(str(len(rules)) + \" rules found:\")\n",
    "print()\n",
    "for i in range(len(rules)):\n",
    "    print(\"Rule \" + str(i) + \": \" + str(rules[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "518e2267-b5b5-4ca8-95e9-719c06d37a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rules explain 96.61% of the overall predictions of the model\n",
      "The rules explain 93.99% of the positive predictions of the model\n",
      "The rules explain 97.39% of the negative predictions of the model\n"
     ]
    }
   ],
   "source": [
    "fidelity, positive_fidelity, negative_fidelity = model_explainer.get_fidelity()\n",
    "\n",
    "print(\"The rules explain \" + str(round(fidelity*100, 2)) + \"% of the overall predictions of the model\" )\n",
    "print(\"The rules explain \" + str(round(positive_fidelity*100, 2)) + \"% of the positive predictions of the model\" )\n",
    "print(\"The rules explain \" + str(round(negative_fidelity*100, 2)) + \"% of the negative predictions of the model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca8aa7-e16f-48d8-ae71-c8d104e645ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e323bc3-283f-49cb-bcc7-76ceb8f3800e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d8603-30fe-4a15-aa9c-976c064c6e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53bc2a-6965-4b62-8530-9ae21ffcfcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af825f18-9167-4b14-be03-532231a19e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607211ba-cc43-4c41-95df-290dcc0845bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467cd5a0-62c4-4e57-add1-f2c4e413a7df",
   "metadata": {},
   "source": [
    "### Analysis of Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85a548-8770-4263-a3b8-2ebcf007284a",
   "metadata": {},
   "source": [
    "Now we analyze the rules to explore and understand rules better, we also extract metrics such as coverage, relative coverage and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4914bf92-1786-4f10-86b0-9f6fdb46be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8f54b848-45d7-4d6d-a2a5-81bc0a33e729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'disposition_LEFT WITHOUT BEING SEEN': 'disposition_LEFT_WITHOUT_BEING_SEEN'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "34697821-77b8-47c9-a723-ce9a11580859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#long stay\n",
    "\n",
    "long_rules = [\n",
    "    (df['age'] > 29.5) & (df['arrival_transport_UNKNOWN'] <= 0.5) & (df['triage_acuity_iter'] <= 3.5),\n",
    "    (df['arrival_transport_AMBULANCE'] > 0.5),\n",
    "    (df['age'] <= 37.5) & (df['triage_acuity_iter'] <= 2.5),\n",
    "    (df['chiefcom_abdominal_pain'] > 0.5),\n",
    "    (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] > 0.5),\n",
    "    (df['eci_score'] > 0.5)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Rule 0: age > 29.5 & arrival_transport_UNKNOWN <= 0.5 & triage_acuity_iter <= 3.5\n",
    "#Rule 1: arrival_transport_AMBULANCE > 0.5\n",
    "#Rule 2: age <= 70.5 & triage_acuity_iter <= 2.5\n",
    "#Rule 3: chiefcom_abdominal_pain > 0.5\n",
    "#Rule 4: arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED > 0.5\n",
    "#Rule 5: eci_score > 0.5\n",
    "#short stay\n",
    "\n",
    "short_rules = [\n",
    "    (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 30.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['triage_acuity_iter'] > 3.5),\n",
    "    (df['arrival_transport_UNKNOWN'] > 0.5),\n",
    "    (df['age'] <= 45.5) & (df['age'] > 38.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['arrival_transport_UNKNOWN'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['triage_acuity_iter'] <= 3.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 37.5) & (df['age'] > 32.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['disposition_LEFT_WITHOUT_BEING_SEEN'] > 0.5),\n",
    "    (df['age'] <= 89.5) & (df['age'] > 74.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] > 74.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_ADMITTED'] > 0.5) & (df['eci_score'] <= 10.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 38.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 6.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_ADMITTED'] > 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] > 70.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['med_event'] <= 0.5),\n",
    "    (df['age'] > 89.5) & (df['disposition_LEFT_WITHOUT_BEING_SEEN'] <= 0.5) & (df['eci_score'] <= 17.5) & (df['eci_score'] > 15.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 27.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 10.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5)\n",
    "]\n",
    "\n",
    "#Rule 0: arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter > 2.5\n",
    "#Rule 1: age <= 30.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & triage_acuity_iter > 2.5\n",
    "#Rule 2: triage_acuity_iter > 3.5\n",
    "#Rule 3: arrival_transport_UNKNOWN > 0.5\n",
    "#Rule 5: age <= 37.5 & age > 32.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & eci_score <= 0.5 & triage_acuity_iter > 2.5\n",
    "#Rule 6: disposition_LEFT_WITHOUT_BEING_SEEN > 0.5\n",
    "#Rule 7: age <= 89.5 & age > 74.5 & arrival_transport_AMBULANCE > 0.5 & disposition_HOME <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 8: age > 74.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 10.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 9: age <= 38.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 6.5 & triage_acuity_iter > 2.5\n",
    "#Rule 10: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 11: age > 70.5 & arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & med_event <= 0.5\n",
    "#Rule 12: age > 89.5 & disposition_LEFT_WITHOUT_BEING_SEEN <= 0.5 & eci_score <= 17.5 & eci_score > 15.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 13: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 14: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 15: age <= 27.5 & arrival_transport_AMBULANCE > 0.5 & disposition_HOME <= 0.5 & eci_score <= 10.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "\n",
    "#Rule 0: arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 4.5 & triage_acuity_iter > 2.5\n",
    "#Rule 1: age <= 32.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_HOME > 0.5 & med_event > 0.5 & triage_acuity_iter > 2.5\n",
    "#Rule 2: triage_acuity_iter > 3.5\n",
    "#Rule 3: arrival_transport_UNKNOWN > 0.5\n",
    "#Rule 4: age <= 45.5 & age > 38.5 & arrival_transport_AMBULANCE <= 0.5 & arrival_transport_UNKNOWN <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & eci_score <= 0.5 & triage_acuity_iter <= 3.5 & triage_acuity_iter > 2.5\n",
    "#Rule 5: age <= 38.5 & age > 32.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & eci_score <= 0.5 & med_event > 0.5 & triage_acuity_iter > 2.5\n",
    "#Rule 6: disposition_LEFT_WITHOUT_BEING_SEEN > 0.5\n",
    "#Rule 7: age <= 89.5 & age > 74.5 & disposition_ADMITTED > 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 8: age <= 37.5 & arrival_transport_AMBULANCE <= 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 6.5 & triage_acuity_iter > 2.5\n",
    "#Rule 9: age > 67.5 & arrival_transport_AMBULANCE > 0.5 & chiefcom_abdominal_pain <= 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 17.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 10: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 11: age <= 88.5 & age > 85.5 & arrival_transport_AMBULANCE > 0.5 & disposition_LEFT_WITHOUT_BEING_SEEN <= 0.5 & eci_score > 6.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 12: age <= 27.5 & arrival_transport_AMBULANCE > 0.5 & disposition_ADMITTED > 0.5 & disposition_LEFT_WITHOUT_BEING_SEEN <= 0.5 & eci_score > 6.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 13: age > 70.5 & arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & med_event <= 0.5\n",
    "#Rule 14: age > 85.5 & disposition_ADMITTED > 0.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 15: age <= 30.5 & age > 28.5 & arrival_transport_AMBULANCE > 0.5 & disposition_HOME <= 0.5 & eci_score > 7.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5\n",
    "#Rule 16: age <= 29.5 & age > 28.5 & arrival_transport_UNKNOWN <= 0.5 & disposition_ADMITTED <= 0.5 & disposition_HOME <= 0.5 & eci_score <= 0.5 & med_event <= 0.5 & triage_acuity_iter <= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e2585d22-c6a8-431b-bd3a-39b386996361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a column to store activated rule indices\n",
    "df['activated_rule'] = ''\n",
    "\n",
    "# Iterate over each observation\n",
    "for i, row in df.iterrows():\n",
    "    activated_rules = []\n",
    "\n",
    "    # Check for long stay rule activations\n",
    "    for j, rule in enumerate(long_rules):\n",
    "        if rule[i]:\n",
    "         activated_rules.append('Long rule ' + str(j))\n",
    "\n",
    "    # Check for short stay rule activations\n",
    "    for j, rule in enumerate(short_rules):\n",
    "        if rule[i]:\n",
    "            activated_rules.append('Short rule ' + str(j))\n",
    "\n",
    "    # Store activated rule index in the 'activated_rule' column\n",
    "    df.at[i, 'activated_rule'] = activated_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f6e95b3d-b173-427f-99fa-6898f4d78265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [Long rule 0, Long rule 1, Long rule 3]\n",
       "1              [Long rule 0, Long rule 1, Long rule 5]\n",
       "2              [Long rule 0, Long rule 1, Long rule 5]\n",
       "3    [Long rule 0, Long rule 1, Long rule 3, Long r...\n",
       "4    [Long rule 0, Long rule 1, Long rule 3, Long r...\n",
       "Name: activated_rule, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activated_rule'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "43a387a0-3c3f-479b-87ed-76cce05f0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty 'activated_rule' for both: 0\n"
     ]
    }
   ],
   "source": [
    "# Count rows with empty 'activated_rule'\n",
    "num_empty_activated_rules = df['activated_rule'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "# Print the number\n",
    "print(\"Number of rows with empty 'activated_rule' for both:\", num_empty_activated_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "36b46c72-5114-49f5-90f6-e8aa7a71e1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty 'activated_rule' for short stay: 314341\n"
     ]
    }
   ],
   "source": [
    "#need to edit activation rule above to work if run again\n",
    "\n",
    "# Count rows with empty 'activated_rule'\n",
    "num_empty_activated_rules = df['activated_rule'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "# Print the number\n",
    "print(\"Number of rows with empty 'activated_rule' for short stay:\", num_empty_activated_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81929867-c6d0-47de-8ecf-9306f2ac333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cffa19e9-625f-4a67-b498-801e18dd61bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty 'activated_rule' for long stay: 47222\n"
     ]
    }
   ],
   "source": [
    "#need to edit activation rule above to work if run again\n",
    "# Count rows with empty 'activated_rule'\n",
    "num_empty_activated_rules = df['activated_rule'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "# Print the number\n",
    "print(\"Number of rows with empty 'activated_rule' for long stay:\", num_empty_activated_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fa326-bdbc-4d4e-b3cc-abfd264f1add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a7b86ac4-0931-4954-a229-4ba864564a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dilemma points (both short and long run activations together)\n",
    "\n",
    "# Create a new column to indicate if both short and long rules are activated\n",
    "df['short_and_long_rules'] = ''\n",
    "\n",
    "# Iterate over each observation\n",
    "for i, row in df.iterrows():\n",
    "    activated_rules = df.at[i, 'activated_rule']\n",
    "\n",
    "    # Check if both short and long rules are activated\n",
    "    short_activated = any('Short' in rule for rule in activated_rules)\n",
    "    long_activated = any('Long' in rule for rule in activated_rules)\n",
    "\n",
    "    if short_activated and long_activated:\n",
    "        df.at[i, 'short_and_long_rules'] = ', '.join(activated_rules)\n",
    "\n",
    "# Replace empty values with NaN\n",
    "df['short_and_long_rules'].replace('', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2dd963-70b1-4d55-b97e-7f2b038dc44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da5ef0d7-b102-4ad6-8991-02fddd94e099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations with both short and long rules activated: 49364\n"
     ]
    }
   ],
   "source": [
    "# Count the number of non-null values in the 'short_and_long_rules' column\n",
    "count_short_long_rules = df['short_and_long_rules'].notnull().sum()\n",
    "print(\"Number of observations with both short and long rules activated:\", count_short_long_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6479-d669-460b-b1fc-a9424c924148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1085d3f7-5953-4175-afea-6a093df937f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of df_train: 65090916\n",
      "Size of df_test: 16272630\n"
     ]
    }
   ],
   "source": [
    "# Size of df_train\n",
    "train_size = df_train.size\n",
    "\n",
    "# Size of df_test\n",
    "test_size = df_test.size\n",
    "\n",
    "# Print the sizes\n",
    "print(\"Size of df_train:\", train_size)\n",
    "print(\"Size of df_test:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb122cd-9502-4d39-95c7-68dd7a9bdf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4774b942-4910-45d4-af5f-259516119fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define functions to calculate overall coverage, positive coverage, and accuracy\n",
    "def calculate_overall_coverage(rule, df):\n",
    "    return (df[df['activated_rule'].apply(lambda x: rule in x)].shape[0] / df.shape[0]) * 100\n",
    "\n",
    "def calculate_positive_coverage(rule, category, df):\n",
    "    return (df[df['activated_rule'].apply(lambda x: rule in x) & (df['LOS_category'] == category)].shape[0] / df.shape[0]) * 100\n",
    "\n",
    "def calculate_accuracy(rule, category, df):\n",
    "    activated_samples = df[df['activated_rule'].apply(lambda x: rule in x)]\n",
    "    correct_samples = activated_samples[activated_samples['LOS_category'] == category]\n",
    "    return (correct_samples.shape[0] / activated_samples.shape[0]) * 100 if activated_samples.shape[0] > 0 else 0\n",
    "\n",
    "# Step 2: Extract unique rules\n",
    "rules = df['activated_rule'].explode().unique()\n",
    "\n",
    "# Step 3: Calculate metrics for each rule and store in a list\n",
    "rule_metrics = []\n",
    "for rule in rules:\n",
    "    for category in ['short', 'long']:\n",
    "        if any([rule in x for x in df[df['LOS_category'] == category]['activated_rule']]):\n",
    "            overall_coverage = calculate_overall_coverage(rule, df)\n",
    "            positive_coverage = calculate_positive_coverage(rule, category, df)\n",
    "            accuracy = calculate_accuracy(rule, category, df)\n",
    "            rule_metrics.append({'Rule': rule, 'Category': category, 'Overall Coverage (%)': overall_coverage, 'Positive Coverage (%)': positive_coverage, 'Accuracy (%)': accuracy})\n",
    "\n",
    "# Step 4: Convert the list to a DataFrame\n",
    "rule_metrics_df = pd.DataFrame(rule_metrics)\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(rule_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a05293e7-91c8-4921-8506-6cbce128e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define functions to calculate overall coverage, positive coverage, and accuracy\n",
    "def calculate_overall_coverage(rule, df):\n",
    "    return (df[df['activated_rule'].apply(lambda x: rule in x)].shape[0] / df.shape[0]) * 100\n",
    "\n",
    "def calculate_positive_coverage(rule, category, df):\n",
    "    return (df[df['activated_rule'].apply(lambda x: rule in x) & (df['LOS_category'] == category)].shape[0] / df.shape[0]) * 100\n",
    "\n",
    "def calculate_accuracy(rule, category, df):\n",
    "    activated_samples = df[df['activated_rule'].apply(lambda x: rule in x)]\n",
    "    correct_samples = activated_samples[activated_samples['LOS_category'] == category]\n",
    "    return (correct_samples.shape[0] / activated_samples.shape[0]) * 100 if activated_samples.shape[0] > 0 else 0\n",
    "\n",
    "# Step 2: Extract unique rules\n",
    "rules = df['activated_rule'].explode().unique()\n",
    "\n",
    "# Step 3: Calculate metrics for each rule and store in a list\n",
    "rule_metrics = []\n",
    "for rule in rules:\n",
    "    for category in ['short', 'long']:\n",
    "        if any([rule in x for x in df[df['LOS_category'] == category]['activated_rule']]):\n",
    "            overall_coverage = calculate_overall_coverage(rule, df)\n",
    "            positive_coverage = calculate_positive_coverage(rule, category, df)\n",
    "            accuracy = calculate_accuracy(rule, category, df)\n",
    "            rule_metrics.append({'Rule': rule, 'Category': category, 'Overall Coverage (%)': overall_coverage, 'Positive Coverage (%)': positive_coverage, 'Accuracy (%)': accuracy})\n",
    "\n",
    "# Step 4: Convert the list to a DataFrame\n",
    "rule_metrics_df = pd.DataFrame(rule_metrics)\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(rule_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa62459d-916a-45f2-8f89-f314b82c2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rule</th>\n",
       "      <th>Category</th>\n",
       "      <th>Overall Coverage (%)</th>\n",
       "      <th>Positive Coverage (%)</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long rule 0</td>\n",
       "      <td>short</td>\n",
       "      <td>74.776055</td>\n",
       "      <td>23.493711</td>\n",
       "      <td>31.418762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long rule 0</td>\n",
       "      <td>long</td>\n",
       "      <td>74.776055</td>\n",
       "      <td>51.282345</td>\n",
       "      <td>68.581238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long rule 1</td>\n",
       "      <td>short</td>\n",
       "      <td>36.423988</td>\n",
       "      <td>10.539342</td>\n",
       "      <td>28.935167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Long rule 1</td>\n",
       "      <td>long</td>\n",
       "      <td>36.423988</td>\n",
       "      <td>25.884646</td>\n",
       "      <td>71.064833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Long rule 3</td>\n",
       "      <td>short</td>\n",
       "      <td>11.504476</td>\n",
       "      <td>2.485113</td>\n",
       "      <td>21.601269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long rule 3</td>\n",
       "      <td>long</td>\n",
       "      <td>11.504476</td>\n",
       "      <td>9.019364</td>\n",
       "      <td>78.398731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Long rule 5</td>\n",
       "      <td>short</td>\n",
       "      <td>43.237850</td>\n",
       "      <td>12.428728</td>\n",
       "      <td>28.745019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Long rule 5</td>\n",
       "      <td>long</td>\n",
       "      <td>43.237850</td>\n",
       "      <td>30.809122</td>\n",
       "      <td>71.254981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Long rule 4</td>\n",
       "      <td>short</td>\n",
       "      <td>18.113680</td>\n",
       "      <td>4.611768</td>\n",
       "      <td>25.460139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Long rule 4</td>\n",
       "      <td>long</td>\n",
       "      <td>18.113680</td>\n",
       "      <td>13.501912</td>\n",
       "      <td>74.539861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Short rule 0</td>\n",
       "      <td>short</td>\n",
       "      <td>11.241899</td>\n",
       "      <td>7.861250</td>\n",
       "      <td>69.928132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Short rule 0</td>\n",
       "      <td>long</td>\n",
       "      <td>11.241899</td>\n",
       "      <td>3.380649</td>\n",
       "      <td>30.071868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Short rule 1</td>\n",
       "      <td>short</td>\n",
       "      <td>4.651191</td>\n",
       "      <td>2.928501</td>\n",
       "      <td>62.962382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Short rule 1</td>\n",
       "      <td>long</td>\n",
       "      <td>4.651191</td>\n",
       "      <td>1.722690</td>\n",
       "      <td>37.037618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Short rule 2</td>\n",
       "      <td>short</td>\n",
       "      <td>7.065002</td>\n",
       "      <td>5.743843</td>\n",
       "      <td>81.299945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Short rule 2</td>\n",
       "      <td>long</td>\n",
       "      <td>7.065002</td>\n",
       "      <td>1.321159</td>\n",
       "      <td>18.700055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Short rule 3</td>\n",
       "      <td>short</td>\n",
       "      <td>3.321758</td>\n",
       "      <td>2.510422</td>\n",
       "      <td>75.575092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Short rule 3</td>\n",
       "      <td>long</td>\n",
       "      <td>3.321758</td>\n",
       "      <td>0.811336</td>\n",
       "      <td>24.424908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Short rule 6</td>\n",
       "      <td>short</td>\n",
       "      <td>1.343061</td>\n",
       "      <td>1.239150</td>\n",
       "      <td>92.263091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Short rule 6</td>\n",
       "      <td>long</td>\n",
       "      <td>1.343061</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>7.736909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Short rule 8</td>\n",
       "      <td>short</td>\n",
       "      <td>0.793085</td>\n",
       "      <td>0.625902</td>\n",
       "      <td>78.919914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Short rule 8</td>\n",
       "      <td>long</td>\n",
       "      <td>0.793085</td>\n",
       "      <td>0.167183</td>\n",
       "      <td>21.080086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Short rule 4</td>\n",
       "      <td>short</td>\n",
       "      <td>1.753839</td>\n",
       "      <td>0.970245</td>\n",
       "      <td>55.321215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Short rule 4</td>\n",
       "      <td>long</td>\n",
       "      <td>1.753839</td>\n",
       "      <td>0.783594</td>\n",
       "      <td>44.678785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Long rule 2</td>\n",
       "      <td>short</td>\n",
       "      <td>7.445848</td>\n",
       "      <td>2.769105</td>\n",
       "      <td>37.189921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Long rule 2</td>\n",
       "      <td>long</td>\n",
       "      <td>7.445848</td>\n",
       "      <td>4.676743</td>\n",
       "      <td>62.810079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Short rule 5</td>\n",
       "      <td>short</td>\n",
       "      <td>1.375913</td>\n",
       "      <td>0.775077</td>\n",
       "      <td>56.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Short rule 5</td>\n",
       "      <td>long</td>\n",
       "      <td>1.375913</td>\n",
       "      <td>0.600837</td>\n",
       "      <td>43.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Short rule 13</td>\n",
       "      <td>short</td>\n",
       "      <td>0.176674</td>\n",
       "      <td>0.143091</td>\n",
       "      <td>80.991736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Short rule 13</td>\n",
       "      <td>long</td>\n",
       "      <td>0.176674</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>19.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Short rule 9</td>\n",
       "      <td>short</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>52.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Short rule 9</td>\n",
       "      <td>long</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>47.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Short rule 7</td>\n",
       "      <td>short</td>\n",
       "      <td>0.154529</td>\n",
       "      <td>0.096854</td>\n",
       "      <td>62.677165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Short rule 7</td>\n",
       "      <td>long</td>\n",
       "      <td>0.154529</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>37.322835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Short rule 14</td>\n",
       "      <td>short</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>56.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Short rule 14</td>\n",
       "      <td>long</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>43.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Short rule 11</td>\n",
       "      <td>short</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>47.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Short rule 11</td>\n",
       "      <td>long</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>52.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Short rule 10</td>\n",
       "      <td>short</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Short rule 10</td>\n",
       "      <td>long</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Short rule 12</td>\n",
       "      <td>short</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Short rule 12</td>\n",
       "      <td>long</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Short rule 15</td>\n",
       "      <td>short</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Short rule 16</td>\n",
       "      <td>short</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rule Category  Overall Coverage (%)  Positive Coverage (%)  \\\n",
       "0     Long rule 0    short             74.776055              23.493711   \n",
       "1     Long rule 0     long             74.776055              51.282345   \n",
       "2     Long rule 1    short             36.423988              10.539342   \n",
       "3     Long rule 1     long             36.423988              25.884646   \n",
       "4     Long rule 3    short             11.504476               2.485113   \n",
       "5     Long rule 3     long             11.504476               9.019364   \n",
       "6     Long rule 5    short             43.237850              12.428728   \n",
       "7     Long rule 5     long             43.237850              30.809122   \n",
       "8     Long rule 4    short             18.113680               4.611768   \n",
       "9     Long rule 4     long             18.113680              13.501912   \n",
       "10   Short rule 0    short             11.241899               7.861250   \n",
       "11   Short rule 0     long             11.241899               3.380649   \n",
       "12   Short rule 1    short              4.651191               2.928501   \n",
       "13   Short rule 1     long              4.651191               1.722690   \n",
       "14   Short rule 2    short              7.065002               5.743843   \n",
       "15   Short rule 2     long              7.065002               1.321159   \n",
       "16   Short rule 3    short              3.321758               2.510422   \n",
       "17   Short rule 3     long              3.321758               0.811336   \n",
       "18   Short rule 6    short              1.343061               1.239150   \n",
       "19   Short rule 6     long              1.343061               0.103911   \n",
       "20   Short rule 8    short              0.793085               0.625902   \n",
       "21   Short rule 8     long              0.793085               0.167183   \n",
       "22   Short rule 4    short              1.753839               0.970245   \n",
       "23   Short rule 4     long              1.753839               0.783594   \n",
       "24    Long rule 2    short              7.445848               2.769105   \n",
       "25    Long rule 2     long              7.445848               4.676743   \n",
       "26   Short rule 5    short              1.375913               0.775077   \n",
       "27   Short rule 5     long              1.375913               0.600837   \n",
       "28  Short rule 13    short              0.176674               0.143091   \n",
       "29  Short rule 13     long              0.176674               0.033583   \n",
       "30   Short rule 9    short              0.059621               0.031149   \n",
       "31   Short rule 9     long              0.059621               0.028472   \n",
       "32   Short rule 7    short              0.154529               0.096854   \n",
       "33   Short rule 7     long              0.154529               0.057674   \n",
       "34  Short rule 14    short              0.025309               0.014358   \n",
       "35  Short rule 14     long              0.025309               0.010951   \n",
       "36  Short rule 11    short              0.008761               0.004137   \n",
       "37  Short rule 11     long              0.008761               0.004624   \n",
       "38  Short rule 10    short              0.009734               0.003894   \n",
       "39  Short rule 10     long              0.009734               0.005840   \n",
       "40  Short rule 12    short              0.001217               0.000730   \n",
       "41  Short rule 12     long              0.001217               0.000487   \n",
       "42  Short rule 15    short              0.000243               0.000243   \n",
       "43  Short rule 16    short              0.000243               0.000243   \n",
       "\n",
       "    Accuracy (%)  \n",
       "0      31.418762  \n",
       "1      68.581238  \n",
       "2      28.935167  \n",
       "3      71.064833  \n",
       "4      21.601269  \n",
       "5      78.398731  \n",
       "6      28.745019  \n",
       "7      71.254981  \n",
       "8      25.460139  \n",
       "9      74.539861  \n",
       "10     69.928132  \n",
       "11     30.071868  \n",
       "12     62.962382  \n",
       "13     37.037618  \n",
       "14     81.299945  \n",
       "15     18.700055  \n",
       "16     75.575092  \n",
       "17     24.424908  \n",
       "18     92.263091  \n",
       "19      7.736909  \n",
       "20     78.919914  \n",
       "21     21.080086  \n",
       "22     55.321215  \n",
       "23     44.678785  \n",
       "24     37.189921  \n",
       "25     62.810079  \n",
       "26     56.331800  \n",
       "27     43.668200  \n",
       "28     80.991736  \n",
       "29     19.008264  \n",
       "30     52.244898  \n",
       "31     47.755102  \n",
       "32     62.677165  \n",
       "33     37.322835  \n",
       "34     56.730769  \n",
       "35     43.269231  \n",
       "36     47.222222  \n",
       "37     52.777778  \n",
       "38     40.000000  \n",
       "39     60.000000  \n",
       "40     60.000000  \n",
       "41     40.000000  \n",
       "42    100.000000  \n",
       "43    100.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00cd574e-5d4d-4fe4-8522-55e3f835cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1765d307-4275-4c64-a7f8-44308aa6d6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_metrics_df = rule_metrics_df.round(2)\n",
    "#rule_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53af567-f36b-4fd0-88e0-20a5efc9de20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rule_metrics_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rule_metrics_df \u001b[38;5;241m=\u001b[39m rule_metrics_df[rule_metrics_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Coverage (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rule_metrics_df' is not defined"
     ]
    }
   ],
   "source": [
    "# \n",
    "rule_metrics_df = rule_metrics_df[rule_metrics_df['Overall Coverage (%)'] > 0.9].reset_index(drop=True)\n",
    "#rule_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "49ad9d32-27aa-4427-b307-26256e6dba4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rule</th>\n",
       "      <th>Category</th>\n",
       "      <th>Overall Coverage (%)</th>\n",
       "      <th>Positive Coverage (%)</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Short rule 0</td>\n",
       "      <td>short</td>\n",
       "      <td>10.54</td>\n",
       "      <td>7.30</td>\n",
       "      <td>69.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short rule 0</td>\n",
       "      <td>long</td>\n",
       "      <td>10.54</td>\n",
       "      <td>3.24</td>\n",
       "      <td>30.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Short rule 1</td>\n",
       "      <td>short</td>\n",
       "      <td>10.10</td>\n",
       "      <td>6.77</td>\n",
       "      <td>66.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Short rule 1</td>\n",
       "      <td>long</td>\n",
       "      <td>10.10</td>\n",
       "      <td>3.34</td>\n",
       "      <td>33.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Short rule 2</td>\n",
       "      <td>short</td>\n",
       "      <td>7.06</td>\n",
       "      <td>5.74</td>\n",
       "      <td>81.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Short rule 2</td>\n",
       "      <td>long</td>\n",
       "      <td>7.06</td>\n",
       "      <td>1.32</td>\n",
       "      <td>18.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Short rule 3</td>\n",
       "      <td>short</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.51</td>\n",
       "      <td>75.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Short rule 3</td>\n",
       "      <td>long</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.81</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Short rule 5</td>\n",
       "      <td>short</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.42</td>\n",
       "      <td>62.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Short rule 5</td>\n",
       "      <td>long</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Short rule 4</td>\n",
       "      <td>short</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>55.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Short rule 4</td>\n",
       "      <td>long</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>44.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Short rule 6</td>\n",
       "      <td>short</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.24</td>\n",
       "      <td>92.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Short rule 6</td>\n",
       "      <td>long</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Long rule 0</td>\n",
       "      <td>short</td>\n",
       "      <td>74.78</td>\n",
       "      <td>23.49</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Long rule 0</td>\n",
       "      <td>long</td>\n",
       "      <td>74.78</td>\n",
       "      <td>51.28</td>\n",
       "      <td>68.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Long rule 5</td>\n",
       "      <td>short</td>\n",
       "      <td>43.24</td>\n",
       "      <td>12.43</td>\n",
       "      <td>28.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Long rule 5</td>\n",
       "      <td>long</td>\n",
       "      <td>43.24</td>\n",
       "      <td>30.81</td>\n",
       "      <td>71.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Long rule 1</td>\n",
       "      <td>short</td>\n",
       "      <td>36.42</td>\n",
       "      <td>10.54</td>\n",
       "      <td>28.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Long rule 1</td>\n",
       "      <td>long</td>\n",
       "      <td>36.42</td>\n",
       "      <td>25.88</td>\n",
       "      <td>71.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Long rule 4</td>\n",
       "      <td>short</td>\n",
       "      <td>18.11</td>\n",
       "      <td>4.61</td>\n",
       "      <td>25.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Long rule 4</td>\n",
       "      <td>long</td>\n",
       "      <td>18.11</td>\n",
       "      <td>13.50</td>\n",
       "      <td>74.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Long rule 3</td>\n",
       "      <td>short</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.49</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Long rule 3</td>\n",
       "      <td>long</td>\n",
       "      <td>11.50</td>\n",
       "      <td>9.02</td>\n",
       "      <td>78.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Long rule 2</td>\n",
       "      <td>short</td>\n",
       "      <td>7.45</td>\n",
       "      <td>2.77</td>\n",
       "      <td>37.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Long rule 2</td>\n",
       "      <td>long</td>\n",
       "      <td>7.45</td>\n",
       "      <td>4.68</td>\n",
       "      <td>62.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rule Category  Overall Coverage (%)  Positive Coverage (%)  \\\n",
       "0   Short rule 0    short                 10.54                   7.30   \n",
       "1   Short rule 0     long                 10.54                   3.24   \n",
       "2   Short rule 1    short                 10.10                   6.77   \n",
       "3   Short rule 1     long                 10.10                   3.34   \n",
       "4   Short rule 2    short                  7.06                   5.74   \n",
       "5   Short rule 2     long                  7.06                   1.32   \n",
       "6   Short rule 3    short                  3.32                   2.51   \n",
       "7   Short rule 3     long                  3.32                   0.81   \n",
       "8   Short rule 5    short                  2.28                   1.42   \n",
       "9   Short rule 5     long                  2.28                   0.86   \n",
       "10  Short rule 4    short                  1.75                   0.97   \n",
       "11  Short rule 4     long                  1.75                   0.78   \n",
       "12  Short rule 6    short                  1.34                   1.24   \n",
       "13  Short rule 6     long                  1.34                   0.10   \n",
       "14   Long rule 0    short                 74.78                  23.49   \n",
       "15   Long rule 0     long                 74.78                  51.28   \n",
       "16   Long rule 5    short                 43.24                  12.43   \n",
       "17   Long rule 5     long                 43.24                  30.81   \n",
       "18   Long rule 1    short                 36.42                  10.54   \n",
       "19   Long rule 1     long                 36.42                  25.88   \n",
       "20   Long rule 4    short                 18.11                   4.61   \n",
       "21   Long rule 4     long                 18.11                  13.50   \n",
       "22   Long rule 3    short                 11.50                   2.49   \n",
       "23   Long rule 3     long                 11.50                   9.02   \n",
       "24   Long rule 2    short                  7.45                   2.77   \n",
       "25   Long rule 2     long                  7.45                   4.68   \n",
       "\n",
       "    Accuracy (%)  \n",
       "0          69.27  \n",
       "1          30.73  \n",
       "2          66.97  \n",
       "3          33.03  \n",
       "4          81.30  \n",
       "5          18.70  \n",
       "6          75.58  \n",
       "7          24.42  \n",
       "8          62.23  \n",
       "9          37.77  \n",
       "10         55.33  \n",
       "11         44.67  \n",
       "12         92.26  \n",
       "13          7.74  \n",
       "14         31.42  \n",
       "15         68.58  \n",
       "16         28.75  \n",
       "17         71.25  \n",
       "18         28.94  \n",
       "19         71.06  \n",
       "20         25.46  \n",
       "21         74.54  \n",
       "22         21.60  \n",
       "23         78.40  \n",
       "24         37.21  \n",
       "25         62.79  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter short and long rules separately\n",
    "short_rules_df = rule_metrics_df[rule_metrics_df['Rule'].str.contains('Short')].sort_values(by='Overall Coverage (%)', ascending=False)\n",
    "long_rules_df = rule_metrics_df[rule_metrics_df['Rule'].str.contains('Long')].sort_values(by='Overall Coverage (%)', ascending=False)\n",
    "\n",
    "# Concatenate the short and long rules\n",
    "sorted_rule_metrics_df = pd.concat([short_rules_df, long_rules_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_rule_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b96e8405-c852-4c1b-bdc6-268601382a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Rules Empirical Metrics}\n",
      "\\label{tab:rules_empirical_metrics}\n",
      "\\renewcommand{\\arraystretch}{1.5}\n",
      "\\setlength{\\tabcolsep}{10pt}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{|l|c|l|c|c|}\n",
      "\\hline\n",
      "\\textbf{Rule} & \\textbf{Overall Coverage (\\%)} & \\textbf{Category} & \\textbf{Relative Coverage (\\%)} & \\textbf{Accuracy (\\%)} \\\\\n",
      "\\hline\n",
      "Short rule 0 & 10.54 & Short & 7.30 & 69.27 \\\\\n",
      "& & Long & 3.24 & 30.73 \\\\\n",
      "\\hline\n",
      "Short rule 1 & 10.10 & Short & 6.77 & 66.97 \\\\\n",
      "& & Long & 3.34 & 33.03 \\\\\n",
      "\\hline\n",
      "Short rule 2 & 7.06 & Short & 5.74 & 81.30 \\\\\n",
      "& & Long & 1.32 & 18.70 \\\\\n",
      "\\hline\n",
      "Short rule 3 & 3.32 & Short & 2.51 & 75.58 \\\\\n",
      "& & Long & 0.81 & 24.42 \\\\\n",
      "\\hline\n",
      "Short rule 5 & 2.28 & Short & 1.42 & 62.23 \\\\\n",
      "& & Long & 0.86 & 37.77 \\\\\n",
      "\\hline\n",
      "Short rule 4 & 1.75 & Short & 0.97 & 55.33 \\\\\n",
      "& & Long & 0.78 & 44.67 \\\\\n",
      "\\hline\n",
      "Short rule 6 & 1.34 & Short & 1.24 & 92.26 \\\\\n",
      "& & Long & 0.10 & 7.74 \\\\\n",
      "\\hline\n",
      "Long rule 0 & 74.78 & Short & 23.49 & 31.42 \\\\\n",
      "& & Long & 51.28 & 68.58 \\\\\n",
      "\\hline\n",
      "Long rule 5 & 43.24 & Short & 12.43 & 28.75 \\\\\n",
      "& & Long & 30.81 & 71.25 \\\\\n",
      "\\hline\n",
      "Long rule 1 & 36.42 & Short & 10.54 & 28.94 \\\\\n",
      "& & Long & 25.88 & 71.06 \\\\\n",
      "\\hline\n",
      "Long rule 4 & 18.11 & Short & 4.61 & 25.46 \\\\\n",
      "& & Long & 13.50 & 74.54 \\\\\n",
      "\\hline\n",
      "Long rule 3 & 11.50 & Short & 2.49 & 21.60 \\\\\n",
      "& & Long & 9.02 & 78.40 \\\\\n",
      "\\hline\n",
      "Long rule 2 & 7.45 & Short & 2.77 & 37.21 \\\\\n",
      "& & Long & 4.68 & 62.79 \\\\\n",
      "\\hline\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `rule_metrics_df` is your initial DataFrame\n",
    "\n",
    "# Step 1: Filter short and long rules separately\n",
    "short_rules_df = rule_metrics_df[rule_metrics_df['Rule'].str.contains('Short')].sort_values(by='Overall Coverage (%)', ascending=False)\n",
    "long_rules_df = rule_metrics_df[rule_metrics_df['Rule'].str.contains('Long')].sort_values(by='Overall Coverage (%)', ascending=False)\n",
    "\n",
    "# Step 2: Concatenate the short and long rules to create sorted DataFrame\n",
    "sorted_rule_metrics_df = pd.concat([short_rules_df, long_rules_df]).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Function to generate LaTeX code for the table\n",
    "def generate_latex_table(df):\n",
    "    latex_code = \"\\\\begin{table}[ht]\\n\"\n",
    "    latex_code += \"\\\\centering\\n\"\n",
    "    latex_code += \"\\\\caption{Rules Empirical Metrics}\\n\"\n",
    "    latex_code += \"\\\\label{tab:rules_empirical_metrics}\\n\"\n",
    "    latex_code += \"\\\\renewcommand{\\\\arraystretch}{1.5}\\n\"\n",
    "    latex_code += \"\\\\setlength{\\\\tabcolsep}{10pt}\\n\"\n",
    "    latex_code += \"\\\\resizebox{\\\\textwidth}{!}{%\\n\"\n",
    "    latex_code += \"\\\\begin{tabular}{|l|c|l|c|c|}\\n\"\n",
    "    latex_code += \"\\\\hline\\n\"\n",
    "    latex_code += \"\\\\textbf{Rule} & \\\\textbf{Overall Coverage (\\\\%)} & \\\\textbf{Category} & \\\\textbf{Relative Coverage (\\\\%)} & \\\\textbf{Accuracy (\\\\%)} \\\\\\\\\\n\"\n",
    "    latex_code += \"\\\\hline\\n\"\n",
    "    \n",
    "    for i in range(0, len(df), 2):\n",
    "        rule = df.loc[i, 'Rule']\n",
    "        overall_coverage = df.loc[i, 'Overall Coverage (%)']\n",
    "        \n",
    "        # Short category\n",
    "        short_category = df.loc[i, 'Category'].capitalize()\n",
    "        short_relative_coverage = df.loc[i, 'Positive Coverage (%)']\n",
    "        short_accuracy = df.loc[i, 'Accuracy (%)']\n",
    "        \n",
    "        # Long category\n",
    "        if i + 1 < len(df) and df.loc[i + 1, 'Rule'] == rule:\n",
    "            long_category = df.loc[i + 1, 'Category'].capitalize()\n",
    "            long_relative_coverage = df.loc[i + 1, 'Positive Coverage (%)']\n",
    "            long_accuracy = df.loc[i + 1, 'Accuracy (%)']\n",
    "        else:\n",
    "            long_category, long_relative_coverage, long_accuracy = \"-\", \"-\", \"-\"\n",
    "        \n",
    "        latex_code += f\"{rule} & {overall_coverage:.2f} & {short_category} & {short_relative_coverage:.2f} & {short_accuracy:.2f} \\\\\\\\\\n\"\n",
    "        latex_code += f\"& & {long_category} & {long_relative_coverage:.2f} & {long_accuracy:.2f} \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\hline\\n\"\n",
    "\n",
    "    latex_code += \"\\\\end{tabular}%\\n\"\n",
    "    latex_code += \"}\\n\"\n",
    "    latex_code += \"\\\\end{table}\\n\"\n",
    "    \n",
    "    return latex_code\n",
    "\n",
    "# Step 4: Generate and print the LaTeX code\n",
    "latex_table_code = generate_latex_table(sorted_rule_metrics_df)\n",
    "print(latex_table_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f1710-cbe3-49a6-86bb-df3187c5dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#long stay\n",
    "\n",
    "long_rules = [\n",
    "    (df['age'] > 29.5) & (df['arrival_transport_UNKNOWN'] <= 0.5) & (df['triage_acuity_iter'] <= 3.5),\n",
    "    (df['arrival_transport_AMBULANCE'] > 0.5),\n",
    "    (df['age'] <= 37.5) & (df['triage_acuity_iter'] <= 2.5),\n",
    "    (df['chiefcom_abdominal_pain'] > 0.5),\n",
    "    (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] > 0.5),\n",
    "    (df['eci_score'] > 0.5)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Rule 0: age > 29.5 & arrival_transport_UNKNOWN <= 0.5 & triage_acuity_iter <= 3.5\n",
    "#Rule 1: arrival_transport_AMBULANCE > 0.5\n",
    "#Rule 2: age <= 70.5 & triage_acuity_iter <= 2.5\n",
    "#Rule 3: chiefcom_abdominal_pain > 0.5\n",
    "#Rule 4: arrival_transport_AMBULANCE <= 0.5 & disposition_ADMITTED > 0.5\n",
    "#Rule 5: eci_score > 0.5\n",
    "#short stay\n",
    "\n",
    "short_rules = [\n",
    "    (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 30.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['triage_acuity_iter'] > 3.5),\n",
    "    (df['arrival_transport_UNKNOWN'] > 0.5),\n",
    "    (df['age'] <= 45.5) & (df['age'] > 38.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['arrival_transport_UNKNOWN'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['triage_acuity_iter'] <= 3.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 37.5) & (df['age'] > 32.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['disposition_LEFT_WITHOUT_BEING_SEEN'] > 0.5),\n",
    "    (df['age'] <= 89.5) & (df['age'] > 74.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] > 74.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_ADMITTED'] > 0.5) & (df['eci_score'] <= 10.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 38.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['chiefcom_abdominal_pain'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 6.5) & (df['triage_acuity_iter'] > 2.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_ADMITTED'] > 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] > 70.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['med_event'] <= 0.5),\n",
    "    (df['age'] > 89.5) & (df['disposition_LEFT_WITHOUT_BEING_SEEN'] <= 0.5) & (df['eci_score'] <= 17.5) & (df['eci_score'] > 15.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] <= 0.5) & (df['disposition_ADMITTED'] <= 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 0.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 30.5) & (df['age'] > 28.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5),\n",
    "    (df['age'] <= 27.5) & (df['arrival_transport_AMBULANCE'] > 0.5) & (df['disposition_HOME'] <= 0.5) & (df['eci_score'] <= 10.5) & (df['eci_score'] > 7.5) & (df['med_event'] <= 0.5) & (df['triage_acuity_iter'] <= 1.5)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff30881-6a13-4f62-b8e3-8bc83e53a8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd229a0b-64ed-441a-ac65-53da4277fca5",
   "metadata": {},
   "source": [
    "### Minority class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f488d4d-4f02-45c2-a23d-f51ef2b08bc2",
   "metadata": {},
   "source": [
    "Now we try to see how is the model perofrmance on the minorty class for the classiifers, each is done with 5 folds CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7fb41e8-2c5c-4aa0-bf84-5150f48f9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS_category_encoded\n",
      "0    252033\n",
      "1    158894\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#ENSURE Short STAY\n",
    "# Define the threshold for LOS classification\n",
    "threshold = 4.5  # Define your threshold value here (in hours)\n",
    "\n",
    "# Create a new binary variable indicating short or long stays\n",
    "df_master['LOS_category'] = df_master['ed_los_hours_iter'].apply(lambda x: 'short' if x <= threshold else 'long')\n",
    "\n",
    "# Optionally, encode the binary variable as 0s and 1s\n",
    "df_master['LOS_category_encoded'] = df_master['LOS_category'].map({'short': 1, 'long': 0})\n",
    "\n",
    "# Display the counts of each category\n",
    "print(df_master['LOS_category_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2570f50a-298f-4e8d-a07f-9d89bae5fc72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train= df_master.sample(frac=0.8,random_state=10) #set seed\n",
    "df_test= df_master.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09a7ed33-c0f3-4576-abd7-3408268c1c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = ['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', \n",
    "            'eci_score', 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE',\n",
    "            'age', 'med_event', 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME']\n",
    "\n",
    "\n",
    "outcome = \"LOS_category_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8200ee38-6eb7-4206-9df1-481acc43c057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "X_train = df_train[variable]\n",
    "y_train = df_train[outcome]\n",
    "\n",
    "X_test = df_test[variable]\n",
    "y_test = df_test[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8cdd7-5c67-42de-87bb-cbbd28eacaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "634b2ce3-6d29-479c-a034-47c9750a4c6b",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bdb0ef7-fcce-4907-addb-eb7483302994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define feature columns and target outcome\n",
    "X = df_master[variable]  \n",
    "y = df_master[outcome]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7ca0298-a23f-42fd-8dfb-8948e93388cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.7332 (+/- 0.0002)\n",
      "Mean Validation Accuracy: 0.6794 (+/- 0.0008)\n",
      "Mean Train AUC: 0.8055 (+/- 0.0002)\n",
      "Mean Validation AUC: 0.7022 (+/- 0.0010)\n",
      "Mean Train Sensitivity: 0.5611 (+/- 0.0037)\n",
      "Mean Validation Sensitivity: 0.4922 (+/- 0.0029)\n",
      "Mean Train Specificity: 0.8417 (+/- 0.0026)\n",
      "Mean Validation Specificity: 0.7975 (+/- 0.0013)\n",
      "Mean Train F1 Score: 0.6193 (+/- 0.0014)\n",
      "Mean Validation F1 Score: 0.5428 (+/- 0.0019)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6828\n",
      "AUC Score: 0.7024\n",
      "Specificity: 0.8064\n",
      "Sensitivity: 0.4866\n",
      "F1 Score: 0.5426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = rf_classifier.predict(X_train_fold)\n",
    "    y_val_pred = rf_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, rf_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, rf_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "y_test_pred_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d3ef5-86d0-42d9-bdc2-144340d42114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699cd74-1f53-4d67-86b4-81d75277c3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb5acf-305a-485b-9bab-7e52aade49a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db822c5-af40-47f4-9579-f2e76d7a3745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4cec53c-a2aa-411a-808e-70a627027912",
   "metadata": {},
   "source": [
    "#### Gradeint Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e71d4f7-ee67-45c9-bfe3-f718496076f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.7001 (+/- 0.0004)\n",
      "Mean Validation Accuracy: 0.7000 (+/- 0.0018)\n",
      "Mean Train AUC: 0.7314 (+/- 0.0003)\n",
      "Mean Validation AUC: 0.7308 (+/- 0.0018)\n",
      "Mean Train Sensitivity: 0.4077 (+/- 0.0094)\n",
      "Mean Validation Sensitivity: 0.4076 (+/- 0.0104)\n",
      "Mean Train Specificity: 0.8844 (+/- 0.0056)\n",
      "Mean Validation Specificity: 0.8843 (+/- 0.0051)\n",
      "Mean Train F1 Score: 0.5125 (+/- 0.0058)\n",
      "Mean Validation F1 Score: 0.5123 (+/- 0.0074)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6986\n",
      "AUC Score: 0.7284\n",
      "Specificity: 0.8866\n",
      "Sensitivity: 0.4005\n",
      "F1 Score: 0.5068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    gb_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = gb_classifier.predict(X_train_fold)\n",
    "    y_val_pred = gb_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, gb_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, gb_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = gb_classifier.predict(X_test)\n",
    "y_test_pred_prob = gb_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827696c-83e0-475b-8a86-a1f7f57f6ae8",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "703cad88-feb6-4afb-9234-a5ce1f219ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 0.6936 (+/- 0.0003)\n",
      "Mean Validation Accuracy: 0.6936 (+/- 0.0014)\n",
      "Mean Train AUC: 0.7000 (+/- 0.0005)\n",
      "Mean Validation AUC: 0.7000 (+/- 0.0018)\n",
      "Mean Train Sensitivity: 0.4337 (+/- 0.0015)\n",
      "Mean Validation Sensitivity: 0.4338 (+/- 0.0016)\n",
      "Mean Train Specificity: 0.8575 (+/- 0.0005)\n",
      "Mean Validation Specificity: 0.8574 (+/- 0.0021)\n",
      "Mean Train F1 Score: 0.5226 (+/- 0.0011)\n",
      "Mean Validation F1 Score: 0.5227 (+/- 0.0016)\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.6914\n",
      "AUC Score: 0.6961\n",
      "Specificity: 0.8590\n",
      "Sensitivity: 0.4256\n",
      "F1 Score: 0.5161\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = lr_classifier.predict(X_train_fold)\n",
    "    y_val_pred = lr_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, lr_classifier.predict_proba(X_train_fold)[:, 1]))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, lr_classifier.predict_proba(X_val_fold)[:, 1]))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = lr_classifier.predict(X_test)\n",
    "y_test_pred_prob = lr_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1f115-01f8-41c7-bdd6-1b3ee1802827",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80a85311-3480-401d-a583-c0755793bf74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step\n",
      "\u001b[1m8219/8219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "Mean Train AUC: 0.7311 (+/- 0.0003)\n",
      "Mean Validation AUC: 0.7308 (+/- 0.0017)\n",
      "Mean Train Accuracy: 0.6996 (+/- 0.0008)\n",
      "Mean Validation Accuracy: 0.6996 (+/- 0.0019)\n",
      "Mean Train Sensitivity: 0.4456 (+/- 0.0174)\n",
      "Mean Validation Sensitivity: 0.4454 (+/- 0.0153)\n",
      "Mean Train Specificity: 0.8597 (+/- 0.0110)\n",
      "Mean Validation Specificity: 0.8598 (+/- 0.0114)\n",
      "Mean Train F1 Score: 0.5341 (+/- 0.0097)\n",
      "Mean Validation F1 Score: 0.5340 (+/- 0.0079)\n",
      "\n",
      "Test Set Evaluation:\n",
      "AUC Score: 0.7290\n",
      "Accuracy: 0.7001\n",
      "Specificity: 0.8565\n",
      "Sensitivity: 0.4520\n",
      "F1 Score: 0.5382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, f1_score, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the scores for each fold\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "train_sensitivities = []\n",
    "val_sensitivities = []\n",
    "train_specificities = []\n",
    "val_specificities = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Define MLP model architecture\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Initialize the MLP model\n",
    "    mlp_model = create_mlp()\n",
    "\n",
    "    # Train the model\n",
    "    mlp_model.fit(X_train_fold, y_train_fold, batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred_prob = mlp_model.predict(X_train_fold)\n",
    "    y_train_pred = (y_train_pred_prob > 0.5).astype(int)\n",
    "    y_val_pred_prob = mlp_model.predict(X_val_fold)\n",
    "    y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for training set\n",
    "    train_accuracies.append(accuracy_score(y_train_fold, y_train_pred))\n",
    "    train_aucs.append(roc_auc_score(y_train_fold, y_train_pred_prob))\n",
    "    train_sensitivities.append(recall_score(y_train_fold, y_train_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_pred).ravel()\n",
    "    train_specificities.append(tn / (tn + fp))\n",
    "    train_f1_scores.append(f1_score(y_train_fold, y_train_pred))\n",
    "\n",
    "    # Calculate metrics for validation set\n",
    "    val_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val_fold, y_val_pred_prob))\n",
    "    val_sensitivities.append(recall_score(y_val_fold, y_val_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    val_specificities.append(tn / (tn + fp))\n",
    "    val_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Train the model on the full training set\n",
    "mlp_model = create_mlp()\n",
    "mlp_model.fit(X_train, y_train, batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred_prob = mlp_model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "final_test_specificity = tn / (tn + fp)\n",
    "final_test_sensitivity = tp / (tp + fn)\n",
    "final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print mean scores with standard deviation (error) from cross-validation\n",
    "print(\"Mean Train AUC: {:.4f} (+/- {:.4f})\".format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "print(\"Mean Validation AUC: {:.4f} (+/- {:.4f})\".format(np.mean(val_aucs), np.std(val_aucs)))\n",
    "print(\"Mean Train Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(train_accuracies), np.std(train_accuracies)))\n",
    "print(\"Mean Validation Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(val_accuracies), np.std(val_accuracies)))\n",
    "print(\"Mean Train Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(train_sensitivities), np.std(train_sensitivities)))\n",
    "print(\"Mean Validation Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(val_sensitivities), np.std(val_sensitivities)))\n",
    "print(\"Mean Train Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(train_specificities), np.std(train_specificities)))\n",
    "print(\"Mean Validation Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(val_specificities), np.std(val_specificities)))\n",
    "print(\"Mean Train F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(train_f1_scores), np.std(train_f1_scores)))\n",
    "print(\"Mean Validation F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(val_f1_scores), np.std(val_f1_scores)))\n",
    "\n",
    "# Print final test set results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"AUC Score: {final_test_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"Specificity: {final_test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {final_test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {final_test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47540da1-0691-4071-b546-2a65dc419622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
