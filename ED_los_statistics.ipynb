{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5697bce-1b77-4636-b68e-c2d12b29465b",
   "metadata": {},
   "source": [
    "# ED LOS Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36893b3-a7e6-47d8-b57c-cbc6446da8cc",
   "metadata": {},
   "source": [
    "## Load Dataset + Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9cd43185-4482-48b2-af82-79ac1dfb0be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c452cb6-a73a-48de-b1d7-ff4f2a17b3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('df_master_imputed_iter_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0820baf-ad23-4271-acf1-9840900428f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  2.  4.  1.  5. -0.]\n"
     ]
    }
   ],
   "source": [
    "# Round off all the decimal values in the 'triage_acuity' column\n",
    "df_master['triage_acuity_iter'] = df_master['triage_acuity_iter'].round()\n",
    "\n",
    "# Check the unique values in the 'triage_acuity' column after rounding off\n",
    "unique_values_rounded = df_master['triage_acuity_iter'].unique()\n",
    "print(unique_values_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da2d5d35-9ae2-441f-9e53-cab2562a9b60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS_category\n",
      "long     252029\n",
      "short    158898\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold for LOS classification\n",
    "threshold = 4.5  # Define your threshold value here (in hours)\n",
    "\n",
    "# Create a new binary variable indicating short or long stays\n",
    "df_master['LOS_category'] = df_master['ed_los_hours_iter'].apply(lambda x: 'short' if x <= threshold else 'long')\n",
    "\n",
    "# Optionally, encode the binary variable as 0s and 1s\n",
    "df_master['LOS_category_encoded'] = df_master['LOS_category'].map({'short': 0, 'long': 1})\n",
    "\n",
    "# Display the counts of each category\n",
    "print(df_master['LOS_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fdc8c58-c5cb-4398-810c-92919afd8094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train= df_master.sample(frac=0.8,random_state=10) #set seed\n",
    "df_test= df_master.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12c0fb-6a12-421d-ad8c-cb25039e70ea",
   "metadata": {},
   "source": [
    "## Baseline Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271871fe-d8fd-4697-83e3-11fb7f451708",
   "metadata": {},
   "source": [
    "Firstly, we calculate the baseline characteristics of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7c263ff-026f-415b-a6e4-42ab28fb807e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_dbp_iter</th>\n",
       "      <th>triage_dbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>410927.000000</td>\n",
       "      <td>392590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.395660</td>\n",
       "      <td>77.458206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.694691</td>\n",
       "      <td>14.946127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.194811</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triage_dbp_iter     triage_dbp\n",
       "count    410927.000000  392590.000000\n",
       "mean         77.395660      77.458206\n",
       "std          14.694691      14.946127\n",
       "min           0.000000       0.000000\n",
       "25%          68.000000      68.000000\n",
       "50%          77.000000      77.000000\n",
       "75%          86.194811      87.000000\n",
       "max         375.000000     375.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master[['triage_dbp_iter', 'triage_dbp']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a082d6c7-d037-4f39-8730-c33cdac3af5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(df_master['triage_dbp_iter'])\n",
    "plt.title('Boxplot of Triage DBP')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "acd0aa7d-2b26-47d4-944e-0130c8a871ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43a11f3a-6333-4d7a-b72c-1146ee255b65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: age\n",
      "  Mean: 52.768586634609065\n",
      "  Std Dev: 20.608776351990933\n",
      "\n",
      "Variable: gender_encoded\n",
      "  Mean: 0.4589841991399932\n",
      "  Std Dev: 0.4983154707277417\n",
      "\n",
      "Variable: cci_score\n",
      "  Mean: 1.3748378665797087\n",
      "  Std Dev: 2.6319786020434277\n",
      "\n",
      "Variable: eci_score\n",
      "  Mean: 3.098399472412375\n",
      "  Std Dev: 4.789939791567895\n",
      "\n",
      "Variable: n_ed_30d\n",
      "  Mean: 0.23762128066542232\n",
      "  Std Dev: 0.7835596352360459\n",
      "\n",
      "Variable: n_ed_90d\n",
      "  Mean: 0.5277044341209023\n",
      "  Std Dev: 1.6050551133218163\n",
      "\n",
      "Variable: n_ed_365d\n",
      "  Mean: 1.3979465939205746\n",
      "  Std Dev: 4.21356914653612\n",
      "\n",
      "Variable: n_hosp_30d\n",
      "  Mean: 0.1572201388567799\n",
      "  Std Dev: 0.5150207610244796\n",
      "\n",
      "Variable: n_hosp_90d\n",
      "  Mean: 0.36158490437474294\n",
      "  Std Dev: 1.0336267938528831\n",
      "\n",
      "Variable: n_hosp_365d\n",
      "  Mean: 0.9679286101911045\n",
      "  Std Dev: 2.704140938806648\n",
      "\n",
      "Variable: n_icu_30d\n",
      "  Mean: 0.020371014803115883\n",
      "  Std Dev: 0.15617289605617052\n",
      "\n",
      "Variable: n_icu_90d\n",
      "  Mean: 0.04813993726379625\n",
      "  Std Dev: 0.2671967614082772\n",
      "\n",
      "Variable: n_icu_365d\n",
      "  Mean: 0.11297627072448391\n",
      "  Std Dev: 0.4960189031858446\n",
      "\n",
      "Variable: triage_temperature_iter\n",
      "  Mean: 36.716160442933095\n",
      "  Std Dev: 0.5385597499794499\n",
      "\n",
      "Variable: triage_heartrate_iter\n",
      "  Mean: 85.22100815935134\n",
      "  Std Dev: 17.49759766036082\n",
      "\n",
      "Variable: triage_resprate_iter\n",
      "  Mean: 17.582509255014067\n",
      "  Std Dev: 2.499912795440543\n",
      "\n",
      "Variable: triage_o2sat_iter\n",
      "  Mean: 98.35678395554878\n",
      "  Std Dev: 2.407802748367417\n",
      "\n",
      "Variable: triage_sbp_iter\n",
      "  Mean: 134.7771748561468\n",
      "  Std Dev: 22.13173556054898\n",
      "\n",
      "Variable: triage_dbp_iter\n",
      "  Mean: 77.39565953042194\n",
      "  Std Dev: 14.69469116355736\n",
      "\n",
      "Variable: triage_pain_iter\n",
      "  Mean: 4.111741505069216\n",
      "  Std Dev: 3.6234936482707223\n",
      "\n",
      "Variable: triage_acuity_iter\n",
      "  Mean: 2.6324821683656707\n",
      "  Std Dev: 0.7059328555172564\n",
      "\n",
      "Variable: ed_temperature_last_iter\n",
      "  Mean: 36.76098660160363\n",
      "  Std Dev: 0.3744506135025887\n",
      "\n",
      "Variable: ed_heartrate_last_iter\n",
      "  Mean: 78.18652877941878\n",
      "  Std Dev: 14.458030588560462\n",
      "\n",
      "Variable: ed_resprate_last_iter\n",
      "  Mean: 17.26205142553671\n",
      "  Std Dev: 2.4843726958048635\n",
      "\n",
      "Variable: ed_o2sat_last_iter\n",
      "  Mean: 98.15631650180461\n",
      "  Std Dev: 2.9335876484315246\n",
      "\n",
      "Variable: ed_sbp_last_iter\n",
      "  Mean: 127.37896384705616\n",
      "  Std Dev: 19.56282790717624\n",
      "\n",
      "Variable: ed_dbp_last_iter\n",
      "  Mean: 73.54490146903696\n",
      "  Std Dev: 13.598980412959802\n",
      "\n",
      "Variable: ed_pain_last_iter\n",
      "  Mean: 2.1830910021419165\n",
      "  Std Dev: 2.828685133650633\n",
      "\n",
      "Variable: med_event\n",
      "  Counts:\n",
      "    1.0: 297075\n",
      "    0.0: 113852\n",
      "  Percentages:\n",
      "    1.0: 72.29%\n",
      "    0.0: 27.71%\n",
      "\n",
      "Variable: outcome_hospitalization\n",
      "  Counts:\n",
      "    False: 219638\n",
      "    True: 191289\n",
      "  Percentages:\n",
      "    False: 53.45%\n",
      "    True: 46.55%\n",
      "\n",
      "Variable: outcome_critical\n",
      "  Counts:\n",
      "    False: 382938\n",
      "    True: 27989\n",
      "  Percentages:\n",
      "    False: 93.19%\n",
      "    True: 6.81%\n",
      "\n",
      "Variable: gender\n",
      "  Counts:\n",
      "    F: 222318\n",
      "    M: 188609\n",
      "  Percentages:\n",
      "    F: 54.10%\n",
      "    M: 45.90%\n",
      "\n",
      "Variable: outcome_ed_revisit_3d\n",
      "  Counts:\n",
      "    False: 396370\n",
      "    True: 14557\n",
      "  Percentages:\n",
      "    False: 96.46%\n",
      "    True: 3.54%\n",
      "\n",
      "Variable: outcome_icu_transfer_12h\n",
      "  Counts:\n",
      "    False: 384485\n",
      "    True: 26442\n",
      "  Percentages:\n",
      "    False: 93.57%\n",
      "    True: 6.43%\n",
      "\n",
      "Variable: outcome_inhospital_mortality\n",
      "  Counts:\n",
      "    False: 406234\n",
      "    True: 4693\n",
      "  Percentages:\n",
      "    False: 98.86%\n",
      "    True: 1.14%\n",
      "\n",
      "Variable: LOS_category\n",
      "  Counts:\n",
      "    long: 252029\n",
      "    short: 158898\n",
      "  Percentages:\n",
      "    long: 61.33%\n",
      "    short: 38.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the variables list\n",
    "variables = [\"age\", \"gender_encoded\", \"cci_score\", \"eci_score\",\n",
    "             \"n_ed_30d\", \"n_ed_90d\", \"n_ed_365d\", \"n_hosp_30d\", \"n_hosp_90d\",\n",
    "             \"n_hosp_365d\", \"n_icu_30d\", \"n_icu_90d\", \"n_icu_365d\",\n",
    "             \"triage_temperature_iter\", \"triage_heartrate_iter\", \"triage_resprate_iter\",\n",
    "             \"triage_o2sat_iter\", \"triage_sbp_iter\", \"triage_dbp_iter\", \"triage_pain_iter\", \"triage_acuity_iter\",\n",
    "             \"ed_temperature_last_iter\", \"ed_heartrate_last_iter\", \"ed_resprate_last_iter\", \"ed_o2sat_last_iter\",\n",
    "             \"ed_sbp_last_iter\", \"ed_dbp_last_iter\", \"ed_pain_last_iter\",\n",
    "             \"med_event\", \"outcome_hospitalization\", \"outcome_critical\",\"gender\",\"outcome_ed_revisit_3d\",\n",
    "            \"outcome_icu_transfer_12h\",\"outcome_inhospital_mortality\",\"LOS_category\"]\n",
    "\n",
    "categorical_variables = [\"gender\", \"outcome_ed_revisit_3d\", \"med_event\", \"outcome_hospitalization\", \"outcome_critical\",\n",
    "                         \"outcome_icu_transfer_12h\",\"outcome_inhospital_mortality\",\"LOS_category\"]\n",
    "\n",
    "# Function to compute statistics for numerical variables\n",
    "def compute_numerical_stats(df, var):\n",
    "    return df[var].mean(), df[var].std()\n",
    "\n",
    "# Function to compute statistics for categorical variables\n",
    "def compute_categorical_stats(df, var):\n",
    "    counts = df[var].value_counts()\n",
    "    percentages = df[var].value_counts(normalize=True) * 100\n",
    "    return counts, percentages\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Compute statistics\n",
    "for var in variables:\n",
    "    if var in categorical_variables:\n",
    "        counts, percentages = compute_categorical_stats(df_master, var)\n",
    "        results[var] = {'Counts': counts.to_dict(), 'Percentages': percentages.to_dict()}\n",
    "    else:\n",
    "        mean, std = compute_numerical_stats(df_master, var)\n",
    "        results[var] = {'Mean': mean, 'Std Dev': std}\n",
    "\n",
    "# Print the results\n",
    "for var, stats in results.items():\n",
    "    print(f\"Variable: {var}\")\n",
    "    if 'Mean' in stats:\n",
    "        print(f\"  Mean: {stats['Mean']}\")\n",
    "        print(f\"  Std Dev: {stats['Std Dev']}\")\n",
    "    else:\n",
    "        print(\"  Counts:\")\n",
    "        for k, v in stats['Counts'].items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "        print(\"  Percentages:\")\n",
    "        for k, v in stats['Percentages'].items():\n",
    "            print(f\"    {k}: {v:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd21b05-e2e9-46b0-b71b-8d45257a2b92",
   "metadata": {},
   "source": [
    "## Statistics by Outcome (Short/Long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b0716-8314-4e23-beb1-99eeb7ec7e3f",
   "metadata": {},
   "source": [
    "now we calculate the statistics by outcome ED_LOS for the important variables found by GB importance eariler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e427505e-f14d-4257-ab93-205c98c3e8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#chosen variables\n",
    "variable = ['triage_acuity_iter', 'disposition_ADMITTED', 'arrival_transport_UNKNOWN', 'eci_score', \n",
    " 'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE', 'age', 'med_event', \n",
    " 'disposition_LEFT WITHOUT BEING SEEN', 'disposition_HOME']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1f46a-a7d0-4667-ae7b-0aeda3d69f8a",
   "metadata": {},
   "source": [
    "### continous variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a9930fb-20ea-4f66-b1a2-4aac45ee9308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-------+--------------------+\n",
      "|      Variable      |   Outcome    | Mean  | Standard Deviation |\n",
      "+--------------------+--------------+-------+--------------------+\n",
      "| triage_acuity_iter | ED LOS LONG  | 2.54  |        0.63        |\n",
      "| triage_acuity_iter | ED LOS SHORT | 2.78  |        0.79        |\n",
      "|        age         | ED LOS LONG  | 55.65 |       20.17        |\n",
      "|        age         | ED LOS SHORT | 48.19 |       20.47        |\n",
      "|     eci_score      | ED LOS LONG  | 3.73  |        5.10        |\n",
      "|     eci_score      | ED LOS SHORT | 2.10  |        4.06        |\n",
      "+--------------------+--------------+-------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "continuous_vars = variable = ['triage_acuity_iter','age','eci_score']\n",
    "# Create a table to store the results\n",
    "table = []\n",
    "\n",
    "# Calculate mean and standard deviation for each continuous variable\n",
    "for variable in continuous_vars:\n",
    "    # Calculate mean and standard deviation for ED LOS LONG cases\n",
    "    outcome_ed_los_mean = df_master[df_master['LOS_category_encoded'] == 1][variable].mean()\n",
    "    outcome_ed_los_std = df_master[df_master['LOS_category_encoded'] == 1][variable].std()\n",
    "    \n",
    "    # Calculate mean and standard deviation for ED LOS SHORT cases\n",
    "    outcome_ed_los_short_mean = df_master[df_master['LOS_category_encoded'] == 0][variable].mean()\n",
    "    outcome_ed_los_short_std = df_master[df_master['LOS_category_encoded'] == 0][variable].std()\n",
    "        # Append results to the table\n",
    "    table.append([variable, \"ED LOS LONG\", f\"{outcome_ed_los_mean:.2f}\", f\"{outcome_ed_los_std:.2f}\"])\n",
    "    table.append([variable, \"ED LOS SHORT\", f\"{outcome_ed_los_short_mean:.2f}\", f\"{outcome_ed_los_short_std:.2f}\"])\n",
    "# Display the table\n",
    "headers = [\"Variable\", \"Outcome\", \"Mean\", \"Standard Deviation\"]\n",
    "print(tabulate(table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a4f54-3893-4c03-9418-52c7a1e5e0ee",
   "metadata": {},
   "source": [
    "### categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9df0dd4-eb45-467f-8212-6726fa520db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and Percentages for arrival_transport_UNKNOWN in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "arrival_transport_UNKNOWN\n",
      "False    248695\n",
      "True       3334\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "arrival_transport_UNKNOWN\n",
      "False    98.68%\n",
      "True      1.32%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "arrival_transport_UNKNOWN\n",
      "False    148582\n",
      "True      10316\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "arrival_transport_UNKNOWN\n",
      "False    93.51%\n",
      "True      6.49%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for disposition_ADMITTED in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "disposition_ADMITTED\n",
      "False    139072\n",
      "True     112957\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "disposition_ADMITTED\n",
      "False    55.18%\n",
      "True     44.82%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "disposition_ADMITTED\n",
      "False    116061\n",
      "True      42837\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "disposition_ADMITTED\n",
      "False    73.04%\n",
      "True     26.96%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for chiefcom_abdominal_pain in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "chiefcom_abdominal_pain\n",
      "0    214966\n",
      "1     37063\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "chiefcom_abdominal_pain\n",
      "0    85.29%\n",
      "1    14.71%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "chiefcom_abdominal_pain\n",
      "0    148686\n",
      "1     10212\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "chiefcom_abdominal_pain\n",
      "0    93.57%\n",
      "1     6.43%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for arrival_transport_AMBULANCE in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "arrival_transport_AMBULANCE\n",
      "False    145666\n",
      "True     106363\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "arrival_transport_AMBULANCE\n",
      "False    57.80%\n",
      "True     42.20%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "arrival_transport_AMBULANCE\n",
      "False    115585\n",
      "True      43313\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "arrival_transport_AMBULANCE\n",
      "False    72.74%\n",
      "True     27.26%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for med_event in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "med_event\n",
      "1.0    196693\n",
      "0.0     55336\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "med_event\n",
      "1.0    78.04%\n",
      "0.0    21.96%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "med_event\n",
      "1.0    100382\n",
      "0.0     58516\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "med_event\n",
      "1.0    63.17%\n",
      "0.0    36.83%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for disposition_HOME in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "disposition_HOME\n",
      "True     128794\n",
      "False    123235\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "disposition_HOME\n",
      "True     51.10%\n",
      "False    48.90%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "disposition_HOME\n",
      "True     104881\n",
      "False     54017\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "disposition_HOME\n",
      "True     66.01%\n",
      "False    33.99%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n",
      "Counts and Percentages for disposition_LEFT WITHOUT BEING SEEN in LOS Cases:\n",
      "Total Counts: 410927\n",
      "LOS Long stay:\n",
      "disposition_LEFT WITHOUT BEING SEEN\n",
      "False    251602\n",
      "True        427\n",
      "Name: count, dtype: int64\n",
      "LOS Long Stay Percentags:\n",
      "disposition_LEFT WITHOUT BEING SEEN\n",
      "False    99.83%\n",
      "True      0.17%\n",
      "Name: count, dtype: object\n",
      "LOS Short stay Counts:\n",
      "disposition_LEFT WITHOUT BEING SEEN\n",
      "False    153806\n",
      "True       5092\n",
      "Name: count, dtype: int64\n",
      "LOS Short Stay Percentages:\n",
      "disposition_LEFT WITHOUT BEING SEEN\n",
      "False    96.80%\n",
      "True      3.20%\n",
      "Name: count, dtype: object\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#refer to output\n",
    "\n",
    "\n",
    "# List of categorical variables\n",
    "categorical_vars = [ 'arrival_transport_UNKNOWN', 'disposition_ADMITTED', 'chiefcom_abdominal_pain', \n",
    "            'arrival_transport_AMBULANCE', 'med_event', 'disposition_HOME', 'disposition_LEFT WITHOUT BEING SEEN']\n",
    "\n",
    "# Calculate counts and percentages for each categorical variable\n",
    "for variable in categorical_vars:\n",
    "    # Calculate total counts\n",
    "    total_counts = df_master[variable].count()\n",
    "\n",
    "    # Calculate counts for Long Stay\n",
    "    hospitalization_counts = df_master[df_master['LOS_category_encoded'] == 1][variable].value_counts()\n",
    "    hospitalization_percentage = hospitalization_counts / hospitalization_counts.sum() * 100\n",
    "\n",
    "\n",
    "    # Calculate counts for Short Stay\n",
    "    no_hospitalization_counts = df_master[df_master['LOS_category_encoded'] == 0][variable].value_counts()\n",
    "    no_hospitalization_counts_percentage = no_hospitalization_counts / no_hospitalization_counts.sum() * 100\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Counts and Percentages for {variable} in LOS Cases:\")\n",
    "    print(f\"Total Counts: {total_counts}\")\n",
    "   \n",
    "    # Format Hospitalization Counts and Percentages\n",
    "    print(\"LOS Long stay:\")\n",
    "    print(hospitalization_counts)\n",
    "    print(\"LOS Long Stay Percentags:\")\n",
    "    print(hospitalization_percentage.apply(lambda x: f\"{x:.2f}%\"))\n",
    "   \n",
    "    # Format No ED Revisit Counts and Percentages\n",
    "    print(\"LOS Short stay Counts:\")\n",
    "    print(no_hospitalization_counts)\n",
    "    print(\"LOS Short Stay Percentages:\")\n",
    "    print(no_hospitalization_counts_percentage.apply(lambda x: f\"{x:.2f}%\"))\n",
    "   \n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1e346-10c0-4880-b43e-708238c0b45e",
   "metadata": {},
   "source": [
    "## Statistics by train/test split and overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501801a-1a4c-4c88-bf36-280d854030cd",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad55d3f-dbe3-4be5-a7c9-e8286430c5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED LOS LONG</th>\n",
       "      <th>ED LOS SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data</th>\n",
       "      <td>201574 (61.32%)</td>\n",
       "      <td>127168 (38.68%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome)</th>\n",
       "      <td>252033 (61.33%)</td>\n",
       "      <td>158894 (38.67%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ED LOS LONG     ED LOS SHORT\n",
       "Training Data       201574 (61.32%)  127168 (38.68%)\n",
       "Test Data            50459 (61.40%)   31726 (38.60%)\n",
       "Total (by outcome)  252033 (61.33%)  158894 (38.67%)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store the statistics\n",
    "statistics = {}\n",
    "outcome_variable = 'LOS_category_encoded'\n",
    "# Calculate statistics for the Training Data\n",
    "statistics['Training Data'] = {\n",
    "    'ED LOS LONG': f\"{df_train[outcome_variable].sum()} ({df_train[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_train.shape[0] - df_train[outcome_variable].sum())} ({(1 - df_train[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Test Data\n",
    "statistics['Test Data'] = {\n",
    "    'ED LOS LONG': f\"{df_test[outcome_variable].sum()} ({df_test[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_test.shape[0] - df_test[outcome_variable].sum())} ({(1 - df_test[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Total (by outcome)\n",
    "statistics['Total (by outcome)'] = {\n",
    "    'ED LOS LONG': f\"{df_master[outcome_variable].sum()} ({df_master[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_master.shape[0] - df_master[outcome_variable].sum())} ({(1 - df_master[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the statistics dictionary\n",
    "df_statistics = pd.DataFrame(statistics).transpose()\n",
    "\n",
    "df_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475f869-78cf-4997-8687-0a154c3a66b2",
   "metadata": {},
   "source": [
    "### Tomeklink Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff6c45dc-842e-4a28-9cf3-4458d9f2024d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome = 'LOS_category_encoded'\n",
    "\n",
    "\n",
    "X_train = df_train[variable]\n",
    "y_train = df_train[outcome]\n",
    "\n",
    "X_test = df_test[variable]\n",
    "y_test = df_test[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03f7eac4-77aa-4be1-85fe-9b30295cad57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcbc2980-884c-4c56-ba5c-81394a32e270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define feature columns and target outcome\n",
    "X = df_master[variable]  \n",
    "y = df_master[outcome]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9daab66f-d186-4504-80fc-1a47330eea12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9272dc8-33b0-4070-898a-619182d6df72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "LOS_category_encoded\n",
      "1    201626\n",
      "0    127115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after Tomek Links:\n",
      "LOS_category_encoded\n",
      "1    201381\n",
      "0    127115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "import pandas as pd\n",
    "\n",
    "# Apply Tomek Links to remove overlapping examples between classes\n",
    "tomek = TomekLinks()\n",
    "X_train_res, y_train_res = tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Compare class distributions before and after Tomek Links\n",
    "original_class_distribution = y_train.value_counts()\n",
    "resampled_class_distribution = pd.Series(y_train_res).value_counts()\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(original_class_distribution)\n",
    "print(\"\\nClass distribution after Tomek Links:\")\n",
    "print(resampled_class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44c0020b-1c4c-45de-96a2-9874cb34a8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED LOS LONG</th>\n",
       "      <th>ED LOS SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data (Tomek Links)</th>\n",
       "      <td>201381 (61.30%)</td>\n",
       "      <td>127115 (38.70%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data (Tomek Links)</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome) (Tomek Links)</th>\n",
       "      <td>251840 (61.32%)</td>\n",
       "      <td>158841 (38.68%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ED LOS LONG     ED LOS SHORT\n",
       "Training Data (Tomek Links)       201381 (61.30%)  127115 (38.70%)\n",
       "Test Data (Tomek Links)            50459 (61.40%)   31726 (38.60%)\n",
       "Total (by outcome) (Tomek Links)  251840 (61.32%)  158841 (38.68%)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the resampled y_train to calculate new statistics\n",
    "df_train_res = pd.DataFrame({outcome_variable: y_train_res})\n",
    "\n",
    "# Calculate statistics for the Training Data (Tomek Links)\n",
    "statistics['Training Data (Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{df_train_res[outcome_variable].sum()} ({df_train_res[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_train_res.shape[0] - df_train_res[outcome_variable].sum())} ({(1 - df_train_res[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Test Data (same as original since Tomek Links is not applied to test data)\n",
    "statistics['Test Data (Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{df_test[outcome_variable].sum()} ({df_test[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_test.shape[0] - df_test[outcome_variable].sum())} ({(1 - df_test[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Total (by outcome) (Tomek Links)\n",
    "total_long_tomek = df_train_res[outcome_variable].sum() + df_test[outcome_variable].sum()\n",
    "total_samples_tomek = df_train_res.shape[0] + df_test.shape[0]\n",
    "statistics['Total (by outcome) (Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{total_long_tomek} ({total_long_tomek / total_samples_tomek * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{total_samples_tomek - total_long_tomek} ({(total_samples_tomek - total_long_tomek) / total_samples_tomek * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the updated statistics dictionary\n",
    "df_statistics_tomek = pd.DataFrame(statistics).transpose()\n",
    "\n",
    "df_statistics_tomek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab358c-d872-43aa-bcba-93ca7b0b4c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9640cf40-85b7-4037-8969-c1a3d77f4e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED LOS LONG (Original)</th>\n",
       "      <th>ED LOS SHORT (Original)</th>\n",
       "      <th>ED LOS LONG (Tomeklinks)</th>\n",
       "      <th>ED LOS SHORT (Tomeklinks)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data</th>\n",
       "      <td>201574 (61.32%)</td>\n",
       "      <td>127168 (38.68%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome)</th>\n",
       "      <td>252033 (61.33%)</td>\n",
       "      <td>158894 (38.67%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Data (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201339 (61.29%)</td>\n",
       "      <td>127168 (38.71%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome) (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251798 (61.31%)</td>\n",
       "      <td>158894 (38.69%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ED LOS LONG (Original)  \\\n",
       "Training Data                           201574 (61.32%)   \n",
       "Test Data                                50459 (61.40%)   \n",
       "Total (by outcome)                      252033 (61.33%)   \n",
       "Training Data (Tomek Links)                         NaN   \n",
       "Test Data (Tomek Links)                             NaN   \n",
       "Total (by outcome) (Tomek Links)                    NaN   \n",
       "\n",
       "                                 ED LOS SHORT (Original)  \\\n",
       "Training Data                            127168 (38.68%)   \n",
       "Test Data                                 31726 (38.60%)   \n",
       "Total (by outcome)                       158894 (38.67%)   \n",
       "Training Data (Tomek Links)                          NaN   \n",
       "Test Data (Tomek Links)                              NaN   \n",
       "Total (by outcome) (Tomek Links)                     NaN   \n",
       "\n",
       "                                 ED LOS LONG (Tomeklinks)  \\\n",
       "Training Data                                         NaN   \n",
       "Test Data                                             NaN   \n",
       "Total (by outcome)                                    NaN   \n",
       "Training Data (Tomek Links)               201339 (61.29%)   \n",
       "Test Data (Tomek Links)                    50459 (61.40%)   \n",
       "Total (by outcome) (Tomek Links)          251798 (61.31%)   \n",
       "\n",
       "                                 ED LOS SHORT (Tomeklinks)  \n",
       "Training Data                                          NaN  \n",
       "Test Data                                              NaN  \n",
       "Total (by outcome)                                     NaN  \n",
       "Training Data (Tomek Links)                127168 (38.71%)  \n",
       "Test Data (Tomek Links)                     31726 (38.60%)  \n",
       "Total (by outcome) (Tomek Links)           158894 (38.69%)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two DataFrames side by side\n",
    "df_combined_statistics = pd.concat([df_statistics, df_statistics_tomek], axis=1)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_combined_statistics.columns = ['ED LOS LONG (Original)', 'ED LOS SHORT (Original)', \n",
    "                                  'ED LOS LONG (Tomeklinks)', 'ED LOS SHORT (Tomeklinks)']\n",
    "\n",
    "df_combined_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "093ee8a9-e23f-42fe-8444-dd87d282541a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Gradient Boosting):\n",
      "Accuracy: 0.6994 (+/- 0.0016)\n",
      "AUC: 0.7304 (+/- 0.0013)\n",
      "Specificity: 0.4071 (+/- 0.0051)\n",
      "Sensitivity: 0.8840 (+/- 0.0014)\n",
      "F1 Score: 0.7829 (+/- 0.0009)\n",
      "\n",
      "Test Set Evaluation (Gradient Boosting):\n",
      "Accuracy: 0.7012\n",
      "AUC: 0.7311\n",
      "Specificity: 0.4095\n",
      "Sensitivity: 0.8852\n",
      "F1 Score: 0.7842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define the classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics for each fold\n",
    "cv_accuracy_list = []\n",
    "cv_auc_list = []\n",
    "cv_specificity_list = []\n",
    "cv_sensitivity_list = []\n",
    "cv_f1_list = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train_res, y_train_res):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train_res.iloc[train_index], X_train_res.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_res.iloc[train_index], y_train_res.iloc[val_index]\n",
    "\n",
    "    # Train the Gradient Boosting model\n",
    "    gb_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = gb_classifier.predict(X_val_fold)\n",
    "    y_val_pred_prob = gb_classifier.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "    # Calculate metrics for the validation set\n",
    "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    cv_accuracy_list.append(accuracy)\n",
    "    cv_auc_list.append(auc_score)\n",
    "    cv_specificity_list.append(specificity)\n",
    "    cv_sensitivity_list.append(sensitivity)\n",
    "    cv_f1_list.append(f1)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "print(\"Cross-Validation Results (Gradient Boosting):\")\n",
    "print(\"Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(cv_accuracy_list), np.std(cv_accuracy_list)))\n",
    "print(\"AUC: {:.4f} (+/- {:.4f})\".format(np.mean(cv_auc_list), np.std(cv_auc_list)))\n",
    "print(\"Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(cv_specificity_list), np.std(cv_specificity_list)))\n",
    "print(\"Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(cv_sensitivity_list), np.std(cv_sensitivity_list)))\n",
    "print(\"F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(cv_f1_list), np.std(cv_f1_list)))\n",
    "\n",
    "# Evaluate on the original unused test set\n",
    "gb_classifier.fit(X_train_res, y_train_res)\n",
    "y_test_pred = gb_classifier.predict(X_test)\n",
    "y_test_pred_prob = gb_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_auc_score = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_specificity = tn / (tn + fp)\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Display the test set metrics\n",
    "print(\"\\nTest Set Evaluation (Gradient Boosting):\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC: {test_auc_score:.4f}\")\n",
    "print(f\"Specificity: {test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28894f09-8d5d-43a7-9a6c-f7f79e3834f8",
   "metadata": {},
   "source": [
    "### Smote+Tomeklink Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d41ce6c2-997d-4f5d-a130-a9d2ca0071f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "LOS_category_encoded\n",
      "1    201626\n",
      "0    127115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after SMOTETomek:\n",
      "LOS_category_encoded\n",
      "1    201489\n",
      "0    201489\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply SMOTETomek to balance the classes and remove overlapping examples between classes\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Compare class distributions before and after SMOTETomek\n",
    "original_class_distribution = y_train.value_counts()\n",
    "resampled_class_distribution = pd.Series(y_train_res).value_counts()\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(original_class_distribution)\n",
    "print(\"\\nClass distribution after SMOTETomek:\")\n",
    "print(resampled_class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf985966-bc87-4c08-b3e5-c78017c5bf67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED LOS LONG</th>\n",
       "      <th>ED LOS SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data (Tomek Links)</th>\n",
       "      <td>201489 (50.00%)</td>\n",
       "      <td>201489 (50.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data (Tomek Links)</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome) (Tomek Links)</th>\n",
       "      <td>251948 (51.93%)</td>\n",
       "      <td>233215 (48.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Data (Smote+Tomek Links)</th>\n",
       "      <td>201489 (50.00%)</td>\n",
       "      <td>201489 (50.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data (Smote+Tomek Links)</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome) (Smote+Tomek Links)</th>\n",
       "      <td>251948 (51.93%)</td>\n",
       "      <td>233215 (48.07%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ED LOS LONG     ED LOS SHORT\n",
       "Training Data (Tomek Links)             201489 (50.00%)  201489 (50.00%)\n",
       "Test Data (Tomek Links)                  50459 (61.40%)   31726 (38.60%)\n",
       "Total (by outcome) (Tomek Links)        251948 (51.93%)  233215 (48.07%)\n",
       "Training Data (Smote+Tomek Links)       201489 (50.00%)  201489 (50.00%)\n",
       "Test Data (Smote+Tomek Links)            50459 (61.40%)   31726 (38.60%)\n",
       "Total (by outcome) (Smote+Tomek Links)  251948 (51.93%)  233215 (48.07%)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the resampled y_train to calculate new statistics\n",
    "df_train_res = pd.DataFrame({outcome_variable: y_train_res})\n",
    "\n",
    "# Calculate statistics for the Training Data \n",
    "statistics['Training Data (Smote+Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{df_train_res[outcome_variable].sum()} ({df_train_res[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_train_res.shape[0] - df_train_res[outcome_variable].sum())} ({(1 - df_train_res[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Test Data (same as original since Tomek Links is not applied to test data)\n",
    "statistics['Test Data (Smote+Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{df_test[outcome_variable].sum()} ({df_test[outcome_variable].mean() * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{(df_test.shape[0] - df_test[outcome_variable].sum())} ({(1 - df_test[outcome_variable].mean()) * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Calculate statistics for the Total (by outcome) (Tomek Links)\n",
    "total_long_tomek = df_train_res[outcome_variable].sum() + df_test[outcome_variable].sum()\n",
    "total_samples_tomek = df_train_res.shape[0] + df_test.shape[0]\n",
    "statistics['Total (by outcome) (Smote+Tomek Links)'] = {\n",
    "    'ED LOS LONG': f\"{total_long_tomek} ({total_long_tomek / total_samples_tomek * 100:.2f}%)\",\n",
    "    'ED LOS SHORT': f\"{total_samples_tomek - total_long_tomek} ({(total_samples_tomek - total_long_tomek) / total_samples_tomek * 100:.2f}%)\"\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the updated statistics dictionary\n",
    "df_statistics_tomek = pd.DataFrame(statistics).transpose()\n",
    "\n",
    "df_statistics_tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "324ba6a0-5cbf-4aac-864f-c287e900b21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED LOS LONG (Original)</th>\n",
       "      <th>ED LOS SHORT (Original)</th>\n",
       "      <th>ED LOS LONG (Smote+Tomelinks)</th>\n",
       "      <th>ED LOS SHORT (Smote+Tomeklinks)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data</th>\n",
       "      <td>201574 (61.32%)</td>\n",
       "      <td>127168 (38.68%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data</th>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome)</th>\n",
       "      <td>252033 (61.33%)</td>\n",
       "      <td>158894 (38.67%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Data (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201489 (50.00%)</td>\n",
       "      <td>201489 (50.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Data (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50459 (61.40%)</td>\n",
       "      <td>31726 (38.60%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total (by outcome) (Tomek Links)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251948 (51.93%)</td>\n",
       "      <td>233215 (48.07%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ED LOS LONG (Original)  \\\n",
       "Training Data                           201574 (61.32%)   \n",
       "Test Data                                50459 (61.40%)   \n",
       "Total (by outcome)                      252033 (61.33%)   \n",
       "Training Data (Tomek Links)                         NaN   \n",
       "Test Data (Tomek Links)                             NaN   \n",
       "Total (by outcome) (Tomek Links)                    NaN   \n",
       "\n",
       "                                 ED LOS SHORT (Original)  \\\n",
       "Training Data                            127168 (38.68%)   \n",
       "Test Data                                 31726 (38.60%)   \n",
       "Total (by outcome)                       158894 (38.67%)   \n",
       "Training Data (Tomek Links)                          NaN   \n",
       "Test Data (Tomek Links)                              NaN   \n",
       "Total (by outcome) (Tomek Links)                     NaN   \n",
       "\n",
       "                                 ED LOS LONG (Smote+Tomelinks)  \\\n",
       "Training Data                                              NaN   \n",
       "Test Data                                                  NaN   \n",
       "Total (by outcome)                                         NaN   \n",
       "Training Data (Tomek Links)                    201489 (50.00%)   \n",
       "Test Data (Tomek Links)                         50459 (61.40%)   \n",
       "Total (by outcome) (Tomek Links)               251948 (51.93%)   \n",
       "\n",
       "                                 ED LOS SHORT (Smote+Tomeklinks)  \n",
       "Training Data                                                NaN  \n",
       "Test Data                                                    NaN  \n",
       "Total (by outcome)                                           NaN  \n",
       "Training Data (Tomek Links)                      201489 (50.00%)  \n",
       "Test Data (Tomek Links)                           31726 (38.60%)  \n",
       "Total (by outcome) (Tomek Links)                 233215 (48.07%)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two DataFrames side by side\n",
    "df_combined_statistics = pd.concat([df_statistics, df_statistics_tomek], axis=1)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_combined_statistics.columns = ['ED LOS LONG (Original)', 'ED LOS SHORT (Original)', \n",
    "                                  'ED LOS LONG (Smote+Tomelinks)', 'ED LOS SHORT (Smote+Tomeklinks)']\n",
    "\n",
    "df_combined_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c68d8fd-231f-4c72-b4a3-ee06321cd607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Gradient Boosting):\n",
      "Accuracy: 0.6784 (+/- 0.0017)\n",
      "AUC: 0.7417 (+/- 0.0020)\n",
      "Specificity: 0.6043 (+/- 0.0065)\n",
      "Sensitivity: 0.7524 (+/- 0.0036)\n",
      "F1 Score: 0.7005 (+/- 0.0008)\n",
      "\n",
      "Test Set Evaluation (Gradient Boosting):\n",
      "Accuracy: 0.6894\n",
      "AUC: 0.7296\n",
      "Specificity: 0.5785\n",
      "Sensitivity: 0.7593\n",
      "F1 Score: 0.7499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define the classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics for each fold\n",
    "cv_accuracy_list = []\n",
    "cv_auc_list = []\n",
    "cv_specificity_list = []\n",
    "cv_sensitivity_list = []\n",
    "cv_f1_list = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train_res, y_train_res):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train_res.iloc[train_index], X_train_res.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_res.iloc[train_index], y_train_res.iloc[val_index]\n",
    "\n",
    "    # Train the Gradient Boosting model\n",
    "    gb_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = gb_classifier.predict(X_val_fold)\n",
    "    y_val_pred_prob = gb_classifier.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "    # Calculate metrics for the validation set\n",
    "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    cv_accuracy_list.append(accuracy)\n",
    "    cv_auc_list.append(auc_score)\n",
    "    cv_specificity_list.append(specificity)\n",
    "    cv_sensitivity_list.append(sensitivity)\n",
    "    cv_f1_list.append(f1)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "print(\"Cross-Validation Results (Gradient Boosting):\")\n",
    "print(\"Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(cv_accuracy_list), np.std(cv_accuracy_list)))\n",
    "print(\"AUC: {:.4f} (+/- {:.4f})\".format(np.mean(cv_auc_list), np.std(cv_auc_list)))\n",
    "print(\"Specificity: {:.4f} (+/- {:.4f})\".format(np.mean(cv_specificity_list), np.std(cv_specificity_list)))\n",
    "print(\"Sensitivity: {:.4f} (+/- {:.4f})\".format(np.mean(cv_sensitivity_list), np.std(cv_sensitivity_list)))\n",
    "print(\"F1 Score: {:.4f} (+/- {:.4f})\".format(np.mean(cv_f1_list), np.std(cv_f1_list)))\n",
    "\n",
    "# Evaluate on the original unused test set\n",
    "gb_classifier.fit(X_train_res, y_train_res)\n",
    "y_test_pred = gb_classifier.predict(X_test)\n",
    "y_test_pred_prob = gb_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_auc_score = roc_auc_score(y_test, y_test_pred_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_specificity = tn / (tn + fp)\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Display the test set metrics\n",
    "print(\"\\nTest Set Evaluation (Gradient Boosting):\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC: {test_auc_score:.4f}\")\n",
    "print(f\"Specificity: {test_specificity:.4f}\")\n",
    "print(f\"Sensitivity: {test_sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952dfea9-0b52-44c6-8067-f42f00fd7c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2221d84b-f6d3-48f8-a9be-96d7a438cd9d",
   "metadata": {},
   "source": [
    "## Testing Signficance (T-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "243b1f57-04d2-4d82-8d4e-f991e1ecc06e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>T-Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triage_acuity_iter</td>\n",
       "      <td>109.311054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrival_transport_UNKNOWN</td>\n",
       "      <td>90.952954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eci_score</td>\n",
       "      <td>-107.313745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disposition_ADMITTED</td>\n",
       "      <td>-116.812115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chiefcom_abdominal_pain</td>\n",
       "      <td>-81.655293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arrival_transport_AMBULANCE</td>\n",
       "      <td>-98.075625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>-114.810667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>med_event</td>\n",
       "      <td>-105.107156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disposition_HOME</td>\n",
       "      <td>94.958383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disposition_LEFT WITHOUT BEING SEEN</td>\n",
       "      <td>83.000230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Variable  T-Statistic  P-Value\n",
       "0                   triage_acuity_iter   109.311054      0.0\n",
       "1            arrival_transport_UNKNOWN    90.952954      0.0\n",
       "2                            eci_score  -107.313745      0.0\n",
       "3                 disposition_ADMITTED  -116.812115      0.0\n",
       "4              chiefcom_abdominal_pain   -81.655293      0.0\n",
       "5          arrival_transport_AMBULANCE   -98.075625      0.0\n",
       "6                                  age  -114.810667      0.0\n",
       "7                            med_event  -105.107156      0.0\n",
       "8                     disposition_HOME    94.958383      0.0\n",
       "9  disposition_LEFT WITHOUT BEING SEEN    83.000230      0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your variables and outcome\n",
    "variables = ['triage_acuity_iter', 'arrival_transport_UNKNOWN', 'eci_score', 'disposition_ADMITTED', \n",
    "             'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE', 'age', 'med_event', \n",
    "             'disposition_HOME', 'disposition_LEFT WITHOUT BEING SEEN']\n",
    "outcome = \"LOS_category_encoded\"\n",
    "\n",
    "# Separate the data into two groups: short stay and long stay\n",
    "group_short = df_master[df_master[outcome] == 0]  #  short stay is encoded as 0\n",
    "group_long = df_master[df_master[outcome] == 1]   #  long stay is encoded as 1\n",
    "\n",
    "# Initialize lists to store the results\n",
    "t_stats = []\n",
    "p_values = []\n",
    "\n",
    "# Perform t-test for each variable\n",
    "for var in variables:\n",
    "    t_stat, p_value = ttest_ind(group_short[var], group_long[var], nan_policy='omit')\n",
    "    t_stats.append(t_stat)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Variable': variables,\n",
    "    'T-Statistic': t_stats,\n",
    "    'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c79b3-60cd-42c8-8cae-fd289d1d7a5b",
   "metadata": {},
   "source": [
    "## Mcnemar's Test (Balanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd3f71-4316-45e9-8c35-6d3b426861d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your variables and outcome\n",
    "variables = ['triage_acuity_iter', 'arrival_transport_UNKNOWN', 'eci_score', 'disposition_ADMITTED', \n",
    "             'chiefcom_abdominal_pain', 'arrival_transport_AMBULANCE', 'age', 'med_event', \n",
    "             'disposition_HOME', 'disposition_LEFT WITHOUT BEING SEEN']\n",
    "outcome = \"LOS_category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f12a0174-c755-40f5-8fc7-7e33287f6c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 07:05:14.681447: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-04 07:05:14.694619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-04 07:05:14.702241: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-04 07:05:14.704478: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 07:05:14.710513: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 07:05:16.549051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730696717.857865  375450 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-04 07:05:17.889380: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step\n",
      "\u001b[1m2055/2055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstylianides/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2569/2569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step\n",
      "\u001b[1m2569/2569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step\n",
      "                                        Accuracy  \\\n",
      "RF   (0.6560818456896931, 0.0013417129453022923)   \n",
      "GB    (0.6875473494402596, 0.002246902519083595)   \n",
      "LR   (0.6449636680463433, 0.0018965791251948916)   \n",
      "MLP  (0.6798604446067985, 0.0027242784110975055)   \n",
      "\n",
      "                                             AUC  \\\n",
      "RF   (0.7012546044173497, 0.0016680075780969562)   \n",
      "GB    (0.7291197192808342, 0.001407295164619997)   \n",
      "LR   (0.6987549076354223, 0.0021718239314696343)   \n",
      "MLP  (0.7307185620860073, 0.0017482787169857408)   \n",
      "\n",
      "                                    Specificity  \\\n",
      "RF   (0.6375880108563112, 0.002816589111737541)   \n",
      "GB    (0.587711914408213, 0.006104150733385404)   \n",
      "LR    (0.6572316406403651, 0.00407337923330883)   \n",
      "MLP  (0.6364945128427014, 0.019208763193883083)   \n",
      "\n",
      "                                     Sensitivity  \\\n",
      "RF     (0.667741281894162, 0.002265524814688474)   \n",
      "GB     (0.750488559898329, 0.004962448346726062)   \n",
      "LR   (0.6372293452503448, 0.0036403912580537236)   \n",
      "MLP   (0.7072004770543504, 0.015628957384530684)   \n",
      "\n",
      "                                        F1 Score  \\\n",
      "RF    (0.7042838159323155, 0.001394606556954334)   \n",
      "GB   (0.7465939651980953, 0.0023660349438935696)   \n",
      "LR    (0.6876550548730357, 0.002204963777530293)   \n",
      "MLP   (0.7303586850741668, 0.005776165855610482)   \n",
      "\n",
      "                                           Predictions  \\\n",
      "RF   [([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0...   \n",
      "GB   [([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0...   \n",
      "LR   [([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0...   \n",
      "MLP  [([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0...   \n",
      "\n",
      "                 Test Accuracy                   Test AUC  \\\n",
      "RF   (0.6573625678339376, 0.0)  (0.7040759091694385, 0.0)   \n",
      "GB   (0.6893753193974643, 0.0)  (0.7295811452840526, 0.0)   \n",
      "LR   (0.6456817462828219, 0.0)  (0.7008065289729182, 0.0)   \n",
      "MLP  (0.6851410215851849, 0.0)  (0.7323744410857183, 0.0)   \n",
      "\n",
      "              Test Specificity           Test Sensitivity  \\\n",
      "RF   (0.6363007017212625, 0.0)  (0.6706409824032377, 0.0)   \n",
      "GB   (0.5785267000220271, 0.0)  (0.7592596266391572, 0.0)   \n",
      "LR   (0.6621353724157463, 0.0)  (0.6353085880929236, 0.0)   \n",
      "MLP  (0.6235879039617357, 0.0)  (0.7239470708433352, 0.0)   \n",
      "\n",
      "                 Test F1 Score  \n",
      "RF   (0.7059622011068184, 0.0)  \n",
      "GB   (0.7498946832169134, 0.0)  \n",
      "LR   (0.6874463335050661, 0.0)  \n",
      "MLP  (0.7382486521479653, 0.0)  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from imblearn.combine import SMOTETomek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize SMOTETomek sampling technique\n",
    "sampler = SMOTETomek(random_state=42)\n",
    "\n",
    "# Function to create the MLP model\n",
    "def create_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "# Initialize the classifiers\n",
    "classifiers = {\n",
    "    'RF': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GB': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LR': LogisticRegression(random_state=42),\n",
    "    'MLP': create_mlp()  # Include MLP\n",
    "}\n",
    "\n",
    "# Define 5-fold Stratified Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store results for each classifier\n",
    "results = {}\n",
    "model_predictions = {}\n",
    "\n",
    "# Loop over each classifier\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    # Store metrics and predictions for each fold\n",
    "    accuracy_list = []\n",
    "    auc_list = []\n",
    "    specificity_list = []\n",
    "    sensitivity_list = []\n",
    "    f1_list = []\n",
    "    predictions = []\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Apply SMOTETomek to the training set\n",
    "        X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Train the model\n",
    "        if classifier_name == 'MLP':\n",
    "            classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "        else:\n",
    "            classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Predict on the validation set\n",
    "        y_val_pred = (classifier.predict(X_val_fold) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_val_fold)\n",
    "        y_val_pred_prob = classifier.predict_proba(X_val_fold)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_val_fold)\n",
    "\n",
    "        # Store predictions\n",
    "        predictions.append((y_val_fold, y_val_pred))\n",
    "\n",
    "        # Calculate metrics for the fold\n",
    "        accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "        auc_score = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        f1 = f1_score(y_val_fold, y_val_pred)\n",
    "\n",
    "        # Store metrics\n",
    "        accuracy_list.append(accuracy)\n",
    "        auc_list.append(auc_score)\n",
    "        specificity_list.append(specificity)\n",
    "        sensitivity_list.append(sensitivity)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    # Calculate average metrics across all folds\n",
    "    results[classifier_name] = {\n",
    "        'Accuracy': (np.mean(accuracy_list), np.std(accuracy_list)),\n",
    "        'AUC': (np.mean(auc_list), np.std(auc_list)),\n",
    "        'Specificity': (np.mean(specificity_list), np.std(specificity_list)),\n",
    "        'Sensitivity': (np.mean(sensitivity_list), np.std(sensitivity_list)),\n",
    "        'F1 Score': (np.mean(f1_list), np.std(f1_list)),\n",
    "        'Predictions': predictions\n",
    "    }\n",
    "\n",
    "# Evaluate on the test set using each classifier\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    # Apply SMOTETomek to the entire training set\n",
    "    X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Train the model on the resampled training set\n",
    "    if classifier_name == 'MLP':\n",
    "        classifier.fit(X_train_resampled, y_train_resampled, batch_size=200, epochs=20, verbose=0)\n",
    "    else:\n",
    "        classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_test_pred = (classifier.predict(X_test) > 0.5).astype(int) if classifier_name == 'MLP' else classifier.predict(X_test)\n",
    "    y_test_pred_prob = classifier.predict_proba(X_test)[:, 1] if classifier_name != 'MLP' else classifier.predict(X_test)\n",
    "\n",
    "    # Calculate metrics on the test set\n",
    "    final_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    final_test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    final_test_specificity = tn / (tn + fp)\n",
    "    final_test_sensitivity = tp / (tp + fn)\n",
    "    final_test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    # Store test set metrics with errors (set standard deviation to zero as there is no cross-validation for the test set)\n",
    "    results[classifier_name]['Test Accuracy'] = (final_test_accuracy, 0.0)\n",
    "    results[classifier_name]['Test AUC'] = (final_test_auc, 0.0)\n",
    "    results[classifier_name]['Test Specificity'] = (final_test_specificity, 0.0)\n",
    "    results[classifier_name]['Test Sensitivity'] = (final_test_sensitivity, 0.0)\n",
    "    results[classifier_name]['Test F1 Score'] = (final_test_f1, 0.0)\n",
    "\n",
    "    # Save model predictions\n",
    "    model_predictions[classifier_name] = y_test_pred\n",
    "\n",
    "# Save predictions to a folder\n",
    "output_folder = \"model_predictions\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for model_name, predictions in model_predictions.items():\n",
    "    output_path = os.path.join(output_folder, f\"{model_name}_predictions.npy\")\n",
    "    np.save(output_path, predictions)\n",
    "\n",
    "# Create a DataFrame to present the results for comparison\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Display the results DataFrame for easy comparison of metrics across classifiers\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3c7dc7b-6855-4b84-a5d2-74f481aff786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': array([1, 1, 1, ..., 0, 0, 0]),\n",
       " 'GB': array([1, 1, 1, ..., 0, 0, 0]),\n",
       " 'LR': array([1, 1, 1, ..., 0, 0, 0]),\n",
       " 'MLP': array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a09d213-0e68-41b2-a802-a362bd12fcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba123e2d-5613-420f-a5e6-f9adc16a0c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flatten the MLP predictions and update the dictionary\n",
    "model_predictions['MLP'] = model_predictions['MLP'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ecd0dfb-0183-4dc4-9f04-619e50b7eef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between RF and GB:\n",
      "Chi-squared statistic: 4425.0\n",
      "p-value: 3.302111961850581e-134\n",
      "The difference between RF and GB is statistically significant.\n",
      "\n",
      "Comparison between RF and LR:\n",
      "Chi-squared statistic: 7893.0\n",
      "p-value: 1.2370118372181496e-13\n",
      "The difference between RF and LR is statistically significant.\n",
      "\n",
      "Comparison between RF and MLP:\n",
      "Chi-squared statistic: 4005.0\n",
      "p-value: 5.88658303380493e-113\n",
      "The difference between RF and MLP is statistically significant.\n",
      "\n",
      "Comparison between GB and LR:\n",
      "Chi-squared statistic: 4322.0\n",
      "p-value: 1.7823272879987216e-234\n",
      "The difference between GB and LR is statistically significant.\n",
      "\n",
      "Comparison between GB and MLP:\n",
      "Chi-squared statistic: 2292.0\n",
      "p-value: 7.693210869284592e-07\n",
      "The difference between GB and MLP is statistically significant.\n",
      "\n",
      "Comparison between LR and MLP:\n",
      "Chi-squared statistic: 3975.0\n",
      "p-value: 3.597626322049011e-209\n",
      "The difference between LR and MLP is statistically significant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform pairwise McNemar's test for all model combinations\n",
    "model_pairs = list(itertools.combinations(model_predictions.keys(), 2))\n",
    "\n",
    "for model_a_name, model_b_name in model_pairs:\n",
    "    # Predictions for the selected models\n",
    "    model_a_predictions = model_predictions[model_a_name]\n",
    "    model_b_predictions = model_predictions[model_b_name]\n",
    "\n",
    "    # Construct contingency table\n",
    "    both_correct = np.sum((model_a_predictions == y_test) & (model_b_predictions == y_test))\n",
    "    model_a_correct_b_wrong = np.sum((model_a_predictions == y_test) & (model_b_predictions != y_test))\n",
    "    model_b_correct_a_wrong = np.sum((model_b_predictions == y_test) & (model_a_predictions != y_test))\n",
    "    both_wrong = np.sum((model_a_predictions != y_test) & (model_b_predictions != y_test))\n",
    "\n",
    "    # Construct contingency table for McNemar's test\n",
    "    contingency_table = [[both_correct, model_a_correct_b_wrong],\n",
    "                         [model_b_correct_a_wrong, both_wrong]]\n",
    "\n",
    "    # Apply McNemar's test\n",
    "    result = mcnemar(contingency_table, exact=True)\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Comparison between {model_a_name} and {model_b_name}:\")\n",
    "    print(f\"Chi-squared statistic: {result.statistic}\")\n",
    "    print(f\"p-value: {result.pvalue}\")\n",
    "\n",
    "    if result.pvalue < 0.05:\n",
    "        print(f\"The difference between {model_a_name} and {model_b_name} is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(f\"The difference between {model_a_name} and {model_b_name} is not statistically significant.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a4f562c-950f-4375-9d7f-bd4a727cf650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d93cb9-719b-4e3f-a81a-aa161241070e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
